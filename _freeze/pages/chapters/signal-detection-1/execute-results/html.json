{
  "hash": "a46628aff8c91c3dfad2fedf9e2c117c",
  "result": {
    "markdown": "---\ntitle: \"Einführung\"\ndescription: |\n  Signal Detection Theory: Entscheidungen unter Unsicherheit.\ndate: \"2022-04-24\"\nauthor:\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universität Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography.bib\nformat:\n    html:\n        toc: true\n        code-link: true\nexecute: \n  cache: false\ncode-annotations: select\n---\n\n\n:::{.callout-tip collapse=\"false\"}\n## Lernziele\n\nIn der heutigen Sitzung lernen wir:\n\n- Simple binäre Entscheidungen mit Signal Detection Theory modellieren\n- Konzepte der Signal Detection Theorie (SDT) \n- SDT mit R simulieren\n:::\n\n# Entscheidungen unter Unsicherheit\nEntscheidungsfindung unter Unsicherheit tritt auf, wenn Sie Entscheidungen treffen müssen, ohne vollständige Informationen über mögliche Ergebnisse zu haben. Der Prozess beinhaltet:\n\n- Identifizierung des Problems oder der Entscheidung. Dies bedeutet, dass wir unsere Hypothesen formulieren müssen.\n- Sammeln von Informationen (Evidenz) als Entscheidungsgrundlage.\n- Schätzung der Wahrscheinlichkeiten von Ergebnissen für jede Alternative unter Verwendung verrauschter Daten.\n- Bewertung potenzieller Kosten und Risiken unter Berücksichtigung objektiver und subjektiver Faktoren.\n- Abwägung von Faktoren und Auswahl der Option, die Ihren Zielen und Präferenzen am besten entspricht.\n\nMehrere Modelle und Werkzeuge können bei der Bewältigung von Unsicherheit helfen:\n\n    - Erwartungs-Nutzen-Theorie: Schlägt vor, die Option mit dem höchsten erwarteten Nutzen zu wählen, berechnet durch Multiplikation der Wahrscheinlichkeit jedes Ergebnisses mit seinem Nutzen (Zufriedenheit oder Präferenz).\n    - Prospect-Theorie: Berücksichtigt die Verzerrungen und Heuristiken von Menschen bei der Entscheidungsfindung unter Unsicherheit, wie Verlustaversion und Wahrscheinlichkeitsgewichtung.\n    - Entscheidungsbäume: Grafische Darstellungen, die bei der Visualisierung und dem Vergleich von Optionen, Ergebnissen und Wahrscheinlichkeiten helfen.\n    - Bayesianische Entscheidungstheorie: Kombiniert vorhandenes Wissen mit neuen Informationen, um Wahrscheinlichkeiten zu aktualisieren und Entscheidungen auf der Grundlage der aktualisierten Wahrscheinlichkeiten zu treffen. \n  \nDas Verständnis von Entscheidungsfindung unter Unsicherheit ist relevant für Bereiche wie Wirtschaft, Finanzen, Psychologie, Management und öffentliche Politik, in denen Entscheidungen oft unsichere Ergebnisse beinhalten.\n\n:::{.callout-important}\n## Übung\nÜberlegen Sie sich einige Beispiele für Entscheidungen, die Sie in Ihrem Leben treffen müssen, bei denen Sie nicht alle Informationen haben, die Sie benötigen, um eine fundierte Entscheidung zu treffen. \n\nWelche Modelle und Werkzeuge könnten Ihnen helfen, diese Entscheidungen zu treffen? Wie unterscheiden sich die Prozesse der Entscheidungsfindung in diesen Beipielen? welche Gemeinsamkeiten gibt es?\n\n\n:::{.callout-tip collapse=\"true\"}\n## Beipiele\n- Perzeptuelle Entscheidungen\n- Kaufentscheidungen\n- \n:::\n\n:::\n\n\n\n# Signal Detection Theory\n\nWir schauen uns eine Framework an, das uns hilft, Entscheidungen unter Unsicherheit zu verstehen und zu modellieren. \n\nSignal-Detektionstheorie (SDT) ist eine statistische Entscheidungstheorie, die verwendet werden kann, um die Leistung eines Probanden in jeder Aufgabe zu modellieren, die eine binäre Entscheidung erfordert. Die SDT wurde auf viele Bereiche der Psychologie und Neurowissenschaften angewendet. Für einen etwas älteren, aber immer noch sehr guten Überblick siehe @goldNeuralBasisDecision2007a. Dieses Papier beschreibt mehrere Anwendungen der SDT, insbesondere für die Untersuchung von Reizmustern mit zufälliger Punktverschiebung.\n\nDie SDT kann angewendet werden, wann immer zwei mögliche Stimulus-Typen unterschieden werden müssen. Die Theorie wurde zuerst in Studien zur Wahrnehmung angewandt, bei denen Probanden zwischen Signalen (Reizen) und Rauschen (keine Reize) unterschieden. Die Bezeichnungen Signal und Rauschen sind geblieben, aber die SDT wurde seitdem in vielen anderen Bereichen angewendet. Beispiele (und ihre entsprechenden Signal- und Rauschreize) sind \"Recognition memory\" (alte und neue Elemente), Lügendetektion (Lügen und Wahrheiten), Personalauswahl (wünschenswerte und unerwünschte Bewerber), medizinische Diagnose (kranke und gesunde Patienten), industrielle Inspektion (inakzeptable und akzeptable Produkte) und \"Information retrieval\" (relevante und irrelevante Informationen). In neurowissenschaftlichen Studien werden mit SDT perzeptuelle System, aber auch Entscheidungen in anderen Bereichen untersucht. Ein mögliches Anwendungsgebiet ist \"value-based decision making\"; hier geht Entscheidungen auf der Basis von geschätzten Kosten und Nutzen einher. Ein Beispiel dafür wäre eine Kaufentscheidung, bei der der Käufer zwischen zwei Produkten wählt, die unterschiedliche Kosten und Nutzen haben.\n\nDie SDT geht davon aus, dass der Entscheidungsträger eine binäre Wahl zwischen zwei Alternativen (z. B. Signal oder Rauschen) auf der Grundlage begrenzter oder unsicherer Informationen treffen muss. Die Entscheidung wird getroffen, indem die empfangenen Informationen mit einem Kriterium oder Schwellenwert verglichen werden. Wenn die Informationen diesen Schwellenwert überschreiten, wählt der Entscheidungsträger das Signal; andernfalls wählt er das Rauschen. \n\n:::{.callout-important}\n## Übung\nInwiefern entspricht dieses Vorgehen dem, was Sie über Hypothesentests in der Statistik gelernt haben?\n:::\n\nEiner der wichtigsten Beiträge der SDT ist die Unterscheidung zwischen Sensitivität und Voreingenommenheit (Bias) im Entscheidungsprozess. Sensitivität bezieht sich auf die Fähigkeit des Entscheidungsträgers, zwischen zwei verschiedenen Arten von Signalen zu unterscheiden, während der Bias die Tendenz des Entscheidungsträgers bezeichnet, eine Alternative gegenüber der anderen a priori zu bevorzugen. Durch die Trennung dieser beiden Komponenten können Forscher analysieren, wie verschiedene Faktoren die Entscheidungsleistung beeinflussen.\n\n\n:::{.callout-tip}\n## Literatur\nFür eine ausführlichere Einführung in die SDT, siehe @stanislawCalculationSignalDetection1999b und @macmillanDetectionTheoryUser2004a. @knoblauchSignalDetectionTheory2012 bietet eine gute Einführung in die Verwendung von R zur Durchführung von SDT-Analysen. @decarloSignalDetectionTheory diskutiert die Beziehung zwischen SDT und verallgemeinerten linearen Modellen.\n:::\n\n\n\n\n## Theorie\n\nDie zentrale Fragestellung der SDT lautet: was ist der (unbekannte) Zustand der Welt, angesichts der verrauschten Daten, die von den Sinnessystemen bereitgestellt werden? \n\nIn einem Modell macht es Sinn, sicherzustellen, dass das Problem einfach ist -- wir beschränken die Welt auf zwei mögliche Zustände beschränken. Diese können als Hypothesen betrachtet werden.\n\n:::{.callout-important}\n## Beispiele\n- Signal / Rauschen\n- Links / Rechts\n- Gedächtnis: alt (schon gesehen) / neu (noch nie gesehen)\n:::\n\n\nWir werden nun die Signal Detection Theorie anhand eine Beispiels durchgehen. Dieses werden wir aus zwei Perspektiven betrachten: 1) aus der Perspektive einer Person, welche die Aufgabe hat, Stimuli in zwei Klassen zu klassifizieren und 2) aus der Perspektive eines Modells, das die Leistung der Person in der Aufgabe vorhersagt.\n\n\n### Die Perspektive der Versuchsperson\nWir betrachten ein Experiment, bei dem eine Person einen Stimulus in eine von zwei möglichen Kategorien einordnen muss; dies könnte ein Random Dot Experiment sein, bei dem die Stimuli entweder nach links oder rechts bewegt sind, oder ein Gedächtnisexperiment, bei dem die Stimuli entweder alt (schon gesehen wurden) oder neu sind.\n\nDie Aufgabe der Person ist es, eine binäre Klassifikation mit den Antwortoptionen `alt` und `neu` durchzuführen. Die Antwortoptionen entsprechen den beiden möglichen Zuständen der Welt, oder genauer gesagt, Hypothesen der Person über die möglichen Zustände der Welt.\n\n\nGegeben den Reiz hat die Person zwei Antwortmöglichkeiten. Daher betrachten wir nur die `Ja`-Antworten, wenn der Reiz alt (Treffer) oder `neu` (Falschalarme) ist.\n\n\n\n#### Annahmen\n\n1) Die Person verarbeitet den Stimulus (in diesem Fall ein Wort oder ein Bild) und gelangt zu einer internen Repräsentation des Stimulus. Diese interne Repräsentation ist nicht deterministisch, sondern variiert zufällig. Die interne Repräsentation demzufolge eine Zufallsvariable $X$. Wir nehmen an, dass die interne Repräsentation normalverteilt ist, mit einer bekannten Standardabweichung $\\sigma$ (der Einfachheit halber nehmen wir an, dass $\\sigma=1$). \n2) Die Zufallsvariable $X$ repräsentiert die Information, die die Person über den Stimulus hat, also die Evidenz.\n\n3) Die Person weiss, dass die $X$ aus einer von zwei Verteilungen gezogen wurde, die sich nur in ihrer Lage (in ihrem Mittelwert) unterscheiden. Welche Verteilung es war, weiss die Person jedoch nicht -- dies muss sie anhand eines Kriteriums entscheiden.\n\n4) Die Person hat ein Kriterium $k$, das sie verwendet, um zu entscheiden, ob der Stimulus alt oder neu ist. Eine einfache Entscheidungsregel lautet: Wenn $X > k$, dann ist der Stimulus alt, andernfalls ist er neu.\n\n<aside>\nBeispiel Recognition Memory: Wenn der Versuchsperson ein Bild gezeigt wird, ruft dies ein Gefühl von 'Vertrautheit' (familiarity) hervor. Dies ist eine latente Variable.\n</aside>\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nNoch nie gesehene Stimuli (neu) produzieren eine niedrige Vertrautheit (familiarity), während alte Stimuli eine hohe Vertrautheit produzieren.\nUm einen Stimulus zu klassifizieren, braucht die Person eine Entscheidungsregel.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nEine einfache  Entscheidungsregel lautet: Wenn die Vertrautheit grösser als das Kriterium ist, wenn also $x > k$, dann ist der Stimulus alt, andernfalls ist er neu.\n\n### Die Perspektive des/der externen Beobachter*in\n\nDie Leistung der Versuchsperson kann durch die Wahrscheinlichkeit beschrieben werden, dass sie einen Treffer (`Hit`) oder einen `False Alarm` produziert. Diese Wahrscheinlichkeiten werden als _Hit Rate_ und _False Alarm Rate_ bezeichnet. Die _Hit Rate_ ist die Wahrscheinlichkeit, dass die Person einen Treffer produziert, wenn der Stimulus alt ist. Die _False Alarm Rate_ ist die Wahrscheinlichkeit, dass die Person einen Falschalarm produziert, wenn der Stimulus neu ist.\n\nDie Antworten der Versuchspersonen können in einer Tabelle zusammengefasst werden, mit vier möglichen Ergebnissen. Wir nennen hier die Antwortoptionen der Einfachheit halber `ja` und `nein`; die Frage an die Versuchsperson lautet: \"Hast du den Stimulus schon einmal gesehen?\".\n\n|              | **Signal**     |                        |\n|------------- |--------------- |------------------------|\n| **Antwort**  | Ja             | Nein                   |\n| Ja           | Hit            | False alarm (FA)       |\n| Nein         | Miss           | Correct rejection (CR) |\n\n- **Hit**:  Stimulus ist `alt`, Antwort ist `Ja`\n- Miss: Stimulus ist `alt`, Antwort ist `Nein`\n- **False alarm**: Stimulus ist `neu`, Antwort ist `Ja`\n- Correct rejection: Stimulus is `neu`,  Antwort ist `Nein`\n\n\nAls Forscher*in interessiert uns nicht nur, wie oft die Versuchsperson Hits und False ALarms produziert, sondern vor allem folgende Fragen:\n\n- Wie gut kann die Person Stimuli klassifizieren?\n- Hat die Person eine Vorliebe für eine der beiden Antwortoptionen?\n\n\nDiese beiden Fragen können wir mit den Signal Detection Theory (SDT) Parametern beschreiben.\n\nDie beiden wichtigsten SDT Parameter sind $d'$ und $c$. $d'$ ist ein Mass dafür, wie weit auseinander die Verteilungen der beiden Stimuluskategorien liegen. $c$ ist ein Mass dafür, ob eine Voreingenommenheit (bias) für eine der beiden Antwortoptionen besteht. Genauer gesagt ist $c$ der Abstand vom tatsächlichen Kriterium zum Punkt welcher genau zwischen den Verteilungen liegt.\n\nUm diese beiden Parameter aus den beobachteten Antworthäufigkeiten zu schätzen, müssen wir zuerst die relativen Häufigkeiten der Hits und der False Alarms schätzen.\n\n\nDie Hits sind die korrekten Antworten auf alte Stimuli. Dies bedeutet, dass wir zählen, wie oft bei einem `alten` Stimulus die Antwort `ja` war. Die False Alarms sind die inkorrekten Antworten auf neue Stimuli. Dies bedeutet, dass wir zählen, wie oft bei einem `neuen` Stimulus die Antwort `ja` war.\n$$ p_{H} = \\frac{Hits}{Hits + Misses} $$\n$$ p_{FA} = \\frac{False Alarms}{False Alarms + Correct Rejections} $$\n\n\n\nSchauen wir uns die Grafik an: Wenn der Stimulus `neu` ist, dann werden wir mit einer Wahrscheinlichkeit von $p_{FA}$ einen False Alarm produzieren. \n\n$$ p_{FA} = P(y = 1 | X = 0) = 1 - \\Phi(k) $$\n\n$k$ ist die die von der Person willkürlich gesetzte Klassifikationsgrenze. $\\Phi$ ist die Verteilungsfunktion der Normalverteilung.\n\n:::{.callout-important}\n$\\Phi(k)$ gibt hier die Wahrscheinlichkeit, dass eine Zufallsvariable $x$ kleiner als $k$ ist. Wir wollen eigentlich wissen, was die Wahrscheinlichkeit ist, dass $x$ grösser als $k$ ist -- diese ist $1 - \\Phi(k)$. \n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nWenn der Stimulus `alt` ist, dann werden wir mit einer Wahrscheinlichkeit von $p_{H}$ einen Hit produzieren.\n\n$$ p_{H} = P(y = 1 | X=1) = 1 - \\Phi(k-d') $$\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nWir können das auch in einer Gleichung schreiben:\n\n$$ P(y = 1 | X = x) = 1 - \\Phi(k-d'X) = \\Phi(-k + d'X) $$\nwo $X$ eine Indikatorvariable ist, d.h. sie nimmt den Wert `1` für `alt` und `0` für `neu`.\n\nDie Gleichung gibt die bedingte Wahrheitswahrscheinlichkeit für eine `ja` Antwort, gegeben den Stimulus. Ist der Stimulus `alt`, dann ist $X = 1$ und $d'X = d'$, ist der Stimulus `neu`, dann ist $X = 0$ und $d'X = 0$.\n\n\n\nHier sind beide Verteilungen nochmals in einer Grafik zusammengefasst:\n\n\n::: {.cell}\n\n:::\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nUnser Ziel ist es, die Parameter $d'$ und $c$ zu schätzen, d.h. wir wollen wissen: Wie weit liegen die Mittelwerte der Verteilung auseinander, und wo hat die Person ihr Kriterium gesetzt? Wir können dies mit folgenden Gleichung machen:\n\n**Kriterium k**:\n Hier wollen wir wissen: Wo liegt der Wert, für den die Wahrscheinlichkeit, über $k$ zu liegen, $p_{FA}$ entspricht? Wir brauchen dafür die Umkehrfunktion der Verteilungsfunktion $\\Phi$: $\\phi^{-1}$.\n\n\n\n:::{.callout-info}\n## Verteilungen in R\nDie Verteilungsfunktion der Normalverteilung heisst in R `pnorm()`. Die Umkehrfunktion dazu heisst Quantilfunktion und heisst in R `qnorm()`.\n\nDie verwandten Funktionen sind die Dichtefunktion `dnorm()` und `rnorm()`, mit der wir Zufallszahlen aus der Normalverteilung ziehen können.\n\nDie kumulative Verteilungsfunktion:\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nDie Quantilfunktion sieht so aus:\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-1_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n\n\n\n\nWir können nun umformen:\n$$ p_{FA} = P(y = 1 | X = 0) = 1 - \\Phi(k) $$\n$$ \\Phi(k) = 1 - p_{FA} $$\n\n$$ k = \\phi^{-1}(1-p_{FA}) = -\\phi^{-1}(p_{FA}) $$\n\n\nWir interessieren uns nun aber für den Abstand zum optimalen Kriterium: dieser Parameter wird $c$ genannt. Im optimalen Fall ist $c = 0$, und $k=\\frac{d'}{2}$. Dann wären die Miss- und Fehlalarmrate gleich gross (anhand der Grafik selber überprüfen). $c$ ist also der Durchschnitt der Hit- und False Alarm Rate, mit $-1$ multipliziert. Negative Werte von $c$ bedeuten, dass die Person tendenziell mehr Fehlalarme produziert als Misses, positive Werte bedeuten, dass die Person tendenziell mehr Misses produziert als Fehlalarme.\n\n$$ c = -\\frac{1}{2} \\left[\\phi^{-1}(p_{H}) + \\phi^{-1}(p_{FA})\\right] $$\n\n\n\n\n\n\n\n\n\nFür $d'$ gilt:\n\n$$ d' = k - \\phi^{-1}(1-p_{H}) = \\phi^{-1}(p_{H}) - \\phi^{-1}(p_{FA}) $$\n\noder anders ausgedrückt:\n$$ d' = \\phi^{-1}(P(y = 1 | old)) - \\phi^{-1}(P(y = 1 | new)) $$\n\nund in Worten:\n\n$d'$ = Z-Score der Hit Rate - Z-Score der False Alarm Rate.\n\n:::{.callout-info}\nDer Begriff Z-Score wird oftmals verwendet, und die Quantile einer Standardnormalverteilung zi beziechnen.\n:::\n\n\n\n# Parameter recovery\n\nTo get a feel for how the parameters `c` and `d'` relate to observed hit and false alarm rates, we will do the following: we first simulate an observer performing a classification experiment with known parameters, i.e. `c` and `d'` are known to us and used to generate the data. We then attempt to recover `c` and `d'` from the observed hit and false alarm rates.\n\nTo do this, we can define a function that takes `c` and `d'` as input, and then simulates $N$ signal and $N$ noise trials, giving a total of $2\\cdot N$ trials. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_sdt <- function(dp = 1, c = 0, N = 100) {\n  nS <- nN <- N\n\n  pFA <- 1 - pnorm(c + dp/2)\n  pH <- 1 - pnorm(c - dp/2)\n  \n  FA <- rbinom(1, nN, pFA)\n  Hit <- rbinom(1, nS, pH)\n  \n  CR <- nN-FA\n  Miss <- nS-Hit\n\n  tibble(Hit, Miss, FA, CR)\n}\n```\n:::\n\n\nWe first calculate the probability of a hit, `pH`, and a false alarm, `pFA`, as they correspond to the area under the curve to the right of the criterion, under both signal and noise distributions, respectively. \n\n```r\npFA <- 1 - pnorm(c + dp/2)\npH <- 1 - pnorm(c - dp/2)\n```\n\n> We are using the bias `c` to parameterize the distributions here. Alternatively, we could also use the criterion `k`, which would result in \n\n```r\npFA <- 1 - pnorm(k)\npH <- 1 - pnorm(k - dp)\n```\n\nThis has the more intuitive interpretation that `pFA` is simply the area under the noise distribution that lies to the right of the criterion `k`, or: \"given that my criterion is $k$, what is the probability that my response was a false alarm?\". However, `c` is a more interesting quantity for us, because it quantifies the devation from an ideal observer.\n\nWe then generate false alarms and hits as binomially distributed random variables, i.e. number of `yes` responses in `N` trials, given the hit and false alarm rates, respectively.\n\n```r\nFA <- rbinom(1, nN, pFA)\nHit <- rbinom(1, nS, pH)\n```\n\nOnce we have the number of hits and false alarms, we can compute the number of misses and correct rejections, given that we know how many trials were performed in each condition.\n\n```r\nCR <- nN-FA\nMiss <- nS-Hit\n```\n\nNow, we can simulate the behaviour of an observer. An ideal observer would be unbiased, i.e. use a value of $c=0$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(89)\nideal_observer <- sim_sdt(d = 1, c = 0)\nideal_observer\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n    Hit  Miss    FA    CR\n  <int> <dbl> <int> <dbl>\n1    61    39    26    74\n```\n:::\n:::\n\n\nOne thing to note is that, even an unbiased,  ideal observer cannot achieve perfect performance given that $d=1$. \n\nWe can compute the observer's accuracy as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nideal_observer |> \n  summarise(accuracy = (Hit + CR)/(Hit + CR + Miss + FA))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  accuracy\n     <dbl>\n1    0.675\n```\n:::\n:::\n\n<aside>\nThere are of course more elegant ways to compute the accuracy.\n</aside>\n\n:::{.callout-note}\nHow can you make the ideal observer achieve an (almost) perfect performance?\n:::\n\nWe can also simulate the behaviour of an observer that is biased to toward giving `yes` responses, i.e. an observer with a value of $c<0$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(89)\nyes_observer <- sim_sdt(d = 1, c = -1)\nyes_observer\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n    Hit  Miss    FA    CR\n  <int> <dbl> <int> <dbl>\n1    92     8    74    26\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyes_observer |> \n  summarise(accuracy = (Hit + CR)/(Hit + CR + Miss + FA))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  accuracy\n     <dbl>\n1     0.59\n```\n:::\n:::\n\n\n:::{.callout-tip}\nHere, it should become clear why accuracy by itself is not that informative. The observer that is biased toward saying `yes` will achieve a very high hit rate, but has to trade this off against a very high false alarm rate. If we just look at accuracy, we might think that the biased observer isn't good at the task, but using SDT we may discover that it is the choice of criterion that is to blame, not the observer's ability!\n:::\n\n## Parameter recovery\nWe can now attempt to recover the _known_ parameters `c` and `d'` from the observed hit and false alarm rates.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes_observer <- yes_observer |>\n    mutate(hit_rate = Hit/(Hit + Miss),\n           fa_rate = FA/(FA + CR))\n\nyes_observer <- yes_observer |>\n    mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\n\nyes_observer <- yes_observer |>\n    mutate(dprime = zhr - zfa,\n           k = - zfa,\n           c = -0.5 * (zhr + zfa)) |>\n    mutate(across(c(dprime, c), round, 2))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(c(dprime, c), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyes_observer \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 11\n    Hit  Miss    FA    CR hit_rate fa_rate   zhr   zfa dprime      k     c\n  <int> <dbl> <int> <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n1    92     8    74    26     0.92    0.74  1.41 0.643   0.76 -0.643 -1.02\n```\n:::\n:::\n\n\nFor the biased observer, the valuues we used were $d' = 1$ and $c = -1$. Are we able to recover these? \n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes_observer |> pull(c, dprime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 0.76 \n-1.02 \n```\n:::\n:::\n\n\n:::{.callout-note}\nWhy is it seemingly difficult to recover theses parameters?\n:::\n\n# Memory experiment\n\nLet's look at an example (borrowing heavily from this [blog post](https://vuorre.netlify.com/post/2017/10/09/bayesian-estimation-of-signal-detection-theory-models-part-1/)).\n\nThe data are from a recognition memory experiment:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# You might first need to install the `remotes` package\n# install.packages(\"remotes\")\n# install sdtalt\n# remotes::install_github(\"cran/sdtalt\")\n\nlibrary(sdtalt)\nlibrary(tidyverse)\n\ndata(confcontr)\n\nconfcontr <- as_tibble(confcontr) |> \n  mutate(subno = as_factor(subno),\n         item = isold - 0.5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconfcontr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3,100 × 4\n   subno sayold isold  item\n   <fct>  <dbl> <dbl> <dbl>\n 1 53         1     0  -0.5\n 2 53         1     1   0.5\n 3 53         1     1   0.5\n 4 53         1     1   0.5\n 5 53         1     0  -0.5\n 6 53         1     1   0.5\n 7 53         1     0  -0.5\n 8 53         0     0  -0.5\n 9 53         0     1   0.5\n10 53         0     1   0.5\n# ℹ 3,090 more rows\n```\n:::\n:::\n\n\nFirst we classify each response as hit, miss, correct rejection (cr) or false alarm (fa):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt <- confcontr |> \n  mutate(type = case_when(\n        isold==1 & sayold==1 ~ \"Hit\",\n        isold==1 & sayold==0 ~ \"Miss\",\n        isold==0 & sayold==0 ~ \"CR\",\n        isold==0 & sayold==1 ~ \"FA\"))\n```\n:::\n\n\nAnd then count the number of hits, etc.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary <- sdt |>\n    group_by(subno) |>\n    count(type) |> \n  pivot_wider(names_from = type, values_from = n) \n```\n:::\n\n\nWe will need the following two functions later on. The first replaces all instances of `NA` with `0`; i.e. if there is a count of zero, then we have the value `NA` in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreplace_NA <- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n```\n:::\n\n\nThe second function provides a minor correction in case we have hit or false alarm rates of either `0` or `1`. Since a _rate_ $r$ is a relative frequency, which we interpret as a probability, it must lie within the range `0:1`: $0 < r < 1$. The function adds or subtracts a small number, depending on whether the rate is $0$ or $1$. In this case, neither function is necessary; we apply them anyway, for demonstration.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrect_zero_one <- function(rate, e = 0.001) {\n    if (identical(rate, 0)) {\n        rate = rate + e\n    } else if (identical(rate, 1)) {\n        rate = rate - e\n    }\n    rate\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 5\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss\n   <fct> <int> <int> <int> <int>\n 1 53       33    20    25    22\n 2 54       39    14    28    19\n 3 55       36    17    31    16\n 4 56       43    10    38     9\n 5 57       35    18    29    18\n 6 58       41    12    30    17\n 7 59       46     7    21    26\n 8 60       38    15    33    14\n 9 61       42    11    25    22\n10 62       45     8    22    25\n# ℹ 21 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary <- sdt_summary |>\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))\n\nsdt_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 5\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss\n   <fct> <int> <int> <int> <int>\n 1 53       33    20    25    22\n 2 54       39    14    28    19\n 3 55       36    17    31    16\n 4 56       43    10    38     9\n 5 57       35    18    29    18\n 6 58       41    12    30    17\n 7 59       46     7    21    26\n 8 60       38    15    33    14\n 9 61       42    11    25    22\n10 62       45     8    22    25\n# ℹ 21 more rows\n```\n:::\n:::\n\n\nNext, we **estimate** the hit and false alarm rates, based on the observed number of hits and false alarms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary <- sdt_summary |>\n    mutate(hit_rate = Hit/(Hit + Miss),\n           fa_rate = FA/(FA + CR))\nsdt_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 7\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>\n 1 53       33    20    25    22    0.532   0.377\n 2 54       39    14    28    19    0.596   0.264\n 3 55       36    17    31    16    0.660   0.321\n 4 56       43    10    38     9    0.809   0.189\n 5 57       35    18    29    18    0.617   0.340\n 6 58       41    12    30    17    0.638   0.226\n 7 59       46     7    21    26    0.447   0.132\n 8 60       38    15    33    14    0.702   0.283\n 9 61       42    11    25    22    0.532   0.208\n10 62       45     8    22    25    0.468   0.151\n# ℹ 21 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary <- sdt_summary |>\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))\nsdt_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 7\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>\n 1 53       33    20    25    22    0.532   0.377\n 2 54       39    14    28    19    0.596   0.264\n 3 55       36    17    31    16    0.660   0.321\n 4 56       43    10    38     9    0.809   0.189\n 5 57       35    18    29    18    0.617   0.340\n 6 58       41    12    30    17    0.638   0.226\n 7 59       46     7    21    26    0.447   0.132\n 8 60       38    15    33    14    0.702   0.283\n 9 61       42    11    25    22    0.532   0.208\n10 62       45     8    22    25    0.468   0.151\n# ℹ 21 more rows\n```\n:::\n:::\n\n\nGiven the hit and false alarm rates, we can calculate the value on the _latent strength_ variable that must result in the hit and false alarm rate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary <- sdt_summary |> \n  mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\nsdt_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 9\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate     zhr    zfa\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>   <dbl>  <dbl>\n 1 53       33    20    25    22    0.532   0.377  0.0801 -0.312\n 2 54       39    14    28    19    0.596   0.264  0.242  -0.631\n 3 55       36    17    31    16    0.660   0.321  0.411  -0.466\n 4 56       43    10    38     9    0.809   0.189  0.872  -0.883\n 5 57       35    18    29    18    0.617   0.340  0.298  -0.413\n 6 58       41    12    30    17    0.638   0.226  0.354  -0.751\n 7 59       46     7    21    26    0.447   0.132 -0.134  -1.12 \n 8 60       38    15    33    14    0.702   0.283  0.531  -0.574\n 9 61       42    11    25    22    0.532   0.208  0.0801 -0.815\n10 62       45     8    22    25    0.468   0.151 -0.0801 -1.03 \n# ℹ 21 more rows\n```\n:::\n:::\n\n\nFinally, we compute $d'$, $k$ and $c$ using the formulae given above. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary <- sdt_summary |> \n  mutate(dprime = zhr - zfa,\n         k = -zfa,\n         c = -0.5 * (zhr + zfa)) |>\n    mutate(across(c(dprime, k, c), round, 2))\n\nsdt_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 12\n# Groups:   subno [31]\n   subno    CR    FA   Hit  Miss hit_rate fa_rate     zhr    zfa dprime     k\n   <fct> <int> <int> <int> <int>    <dbl>   <dbl>   <dbl>  <dbl>  <dbl> <dbl>\n 1 53       33    20    25    22    0.532   0.377  0.0801 -0.312   0.39  0.31\n 2 54       39    14    28    19    0.596   0.264  0.242  -0.631   0.87  0.63\n 3 55       36    17    31    16    0.660   0.321  0.411  -0.466   0.88  0.47\n 4 56       43    10    38     9    0.809   0.189  0.872  -0.883   1.76  0.88\n 5 57       35    18    29    18    0.617   0.340  0.298  -0.413   0.71  0.41\n 6 58       41    12    30    17    0.638   0.226  0.354  -0.751   1.1   0.75\n 7 59       46     7    21    26    0.447   0.132 -0.134  -1.12    0.98  1.12\n 8 60       38    15    33    14    0.702   0.283  0.531  -0.574   1.1   0.57\n 9 61       42    11    25    22    0.532   0.208  0.0801 -0.815   0.9   0.81\n10 62       45     8    22    25    0.468   0.151 -0.0801 -1.03    0.95  1.03\n# ℹ 21 more rows\n# ℹ 1 more variable: c <dbl>\n```\n:::\n:::\n\n\n# Memory experiment: single subject\n\nFor simplicity, we first look at the data from subject `53` only:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdt_summary |> \n  filter(subno == 53) |> \n  select(subno, hit_rate, fa_rate, zhr, zfa, dprime, k, c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n# Groups:   subno [1]\n  subno hit_rate fa_rate    zhr    zfa dprime     k     c\n  <fct>    <dbl>   <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>\n1 53       0.532   0.377 0.0801 -0.312   0.39  0.31  0.12\n```\n:::\n:::\n",
    "supporting": [
      "signal-detection-1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}