{
  "hash": "4a018651a7c1b5805f1d15980461ffb1",
  "result": {
    "markdown": "---\ntitle: \"Einf√ºhrung in die Bayesianische Statistik\"\ndescription: |\n  Eine Alternative zu Null Hypothesis Significance Testing (NHST).\ndate: \"2022-05-08\"\nauthor:\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography.bib\nformat:\n    html:\n        toc: true\n        code-link: true\nexecute: \n  cache: false\ncode-annotations: select\n---\n\n\n\n\n:::{.callout-tip}\n## Wichtig\n\nüëâ [Daten (`FancyHat.csv`) herunterladen](../../downloadable_files/FancyHat.csv)\n\nüëâ [Jasp installieren]([../../downloadable_files/rdkdata_clean.csv](https://jasp-stats.org/))\n:::\n\n\n\n:::{.callout-tip collapse=\"false\"}\n## Lernziele\n\nIn der heutigen Sitzung:\n\n- Brainstorming: NHST, Power\n- Welche Fagen kann NHST beantworten?\n- Einf√ºhrung in die Bayes'sche Inferenz\n:::\n\n\n## Parameter sch√§tzen vs Hypothesen testen\n\nEin t-Test ist ein Beispiel f√ºr den statistischen vorherrschenden Ansatz in den Neuro- und Sozialwissenschaften. Diese Vorgehensweise wird frequentistische Statistik genannt. In der traditionellen Weise, wie diese unterrichtet wird, werden oft zwei Dinge vermischt: 1) Parametersch√§tzung und 2) Hypothesentests.\n\nWir werden nun einen anderen Ansatz kennenlernen: die Bayes'sche Statistik. Dieser Ansatz ist nicht neu, hat aber erst in den letzten Jahren Verbreitung gefunden. Dies hat unter anderem damit zu tun, dass die Berechnungen, die f√ºr die Bayes'sche Statistik n√∂tig sind, erst mit der Verf√ºgbarkeit von schnellen Computern m√∂glich wurden.\n\nWir werden nun anhand eines simplen Beispiels zuerst die Bayes'sche Parametersch√§tzung kennenlernen. \n\n<!-- Electronic voice phenomena (EVP) -->\n\nTwo players are playing a game of cards. You observe that they play 9 games, and that player A wins 6 of those. Now you would like to estimate the probability that player A will win the next game. Another way of putting it that you would to estimate the ability of player A to beat player B at this particular game.\n\nYou know that the probability of success must lie in the range $[0, 1]$. What you might not be aware of is that you are assuming a certain probability model, and the probability of success is a parameter of that model. Let's take a closer look:\n\nWe know that the number of $k$ successes in $n$ games follows a binomial distribution with parameters $n$ and $\\theta$. To make things simpler, we also know that each individual game is independent of the others, and the probability of success $\\theta$ is the same for each game. Each success therefore follows a Bernoulli distribution with parameter $\\theta$.\n\n\n$$ \ny_i \\sim \\mathcal{Bernoulli}(\\theta)\n$$\n\n:::{callout-tip}\nI will generally use the notation $y$ for a variable that is observed, i.e. the data.\n:::\n\n$y_i$ is the $i$ th observation in the data, meaning that it tells us whether player A won the game or not on trial $i$. $\\theta$ is the probability of success for each individual game; this is a parameter of our model ($\\mathcal{M}$).\n\nPreviously, we used maximum likelihood to estimate $\\theta$ - we will repeat this briefly here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwins <- 6\ngames <- 9\n```\n:::\n\n\nThe goal is to figure out the \"best\" value of $\\theta$, i.e. the value that maximizes the likelihood of observing the data. To do this, we need to consider a range of possible values of $\\theta$ (we already know that this range is $[0, 1]$, so that part is easy). We will consider 101 values of $\\theta$ between 0 and 1, and compute the likelihood of observing the data for each value of $\\theta$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_points <- 101\ntheta_grid <- seq( from=0 , to=1 , length.out = n_points )\n```\n:::\n\n\nAssuming that both players have an equal chance of winning, the parameter should be $\\theta = 0.5$. The probability of the data given $\\theta = 0.5$ is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(x = wins, size = games, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1640625\n```\n:::\n:::\n\n\nThe probability of winning 6 out of 9 games, given that both players are equally likely to win, is 0.1640625.\n\n\nWe can also compute the probability of A winning 6, 7, 8 or 9 games, using the cumulative distribution function of the binomial distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pbinom(q = 5, size = games, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2539063\n```\n:::\n:::\n\n\nor\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(q = 5, size = games, prob = 0.5, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2539063\n```\n:::\n:::\n\n\n\n:::aside\n`pbinom()` gives us the lower tail probability, which is the probability that the number of successes is less than or equal to the given value, by default.\n:::\n\n\n:::{.callout-tip}\n## p-value\nDoes this seem familiar?\n\nIf we want to quantify our _null_ hypothsis that both players are equally likely to win, we would assume that $\\theta=0.5$. Computing the probability of the data under the null is exactly what we have just done. We then plug in the actual data, i.e. 6 out of 9, and the upper tail probability is the p-value. In this case, the p-value is approximately $0.25$. Using cut-off of 0.05, we would not reject the null hypothesis, and conclude that there is not enough evidence that player A is better than player B (this is a one-sided test).\n:::\n\nNow we compute the probability of the data under all parameter values under consideration. In R, this is very simple, since all functions are vectorized.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(likelihood)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nWe can see in the above figure that the probability of observing the data is small for a lot of values of $\\theta$. The probability of observing the data, or the likelihood, is maximal for the value 0.6666667:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta_grid[which.max(likelihood)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.67\n```\n:::\n:::\n\n\nWhat we have done so far highlights the distinction between parameter estimation and hypothesis testing. Computing the tail probability under the null ($\\theta=0.5$) is a hypothesis test, and estimating $\\theta$ is parameter estimation.\n\n\n\n\n## Bayes'sche Inferenz\n\nSo far, we haven't considered any prior knowledge we might have had about which parameters are the most likely a priori. In fact, as we will see a bit further down, we have implicitly assumed that all parameters are equally likely. We will now introduce a new concept: a prior distribution for the parameter(s) we are trying to estimate^[In frequentist statistics, the concept is meaningless - parameters cannot have distribution. In Bayesian statistics, a prior distribution should reflect everything we know about the parameter, before we consider the data. The prior reflects our belief, which can be subjective, or objective.].\n\nWe will then use that __prior__ belief in order to obtain a __posterior__ belief\nover the possible parameter values. To do this, we need to multiply the prior probability of each parameter value by the likelihood of the data, i.e. by the probability of observing the data given that parameter value. This is an application of Bayes theorem:\n\n$$ \np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n$$\n\nThis states that the posterior probability of $\\theta$ given the observed data $y$ is equal to the probability of the data, multiplied by how probable each value of $\\theta$ is a priori. You can think of it like this: each parameter value is weighted according to how well it predicts the data. The product $p(y|\\theta) * p(\\theta)$ is then divided by the probability of the data, which in this case is summed over all possible parameter values. This step serves to normalize the posterior, so that it sums to $1$. This essentially turns the unnormalized posterior into a proper probability distribution.\n\n$$\np(y) = \\sum_{\\theta}p(y|\\theta) * p(\\theta) \n$$\n\nWhen we are interested in estimating the parameters of a given model, we can often neglect the (constant for a model) normalizing term $p(y)$. This term, often called the evidence, reflects the probability of the data, averaged over all parameter values. Written without the normalizing constant, Bayes rule is often written as:\n\n$$ \np(\\theta|y) \\propto  p(y|\\theta) * p(\\theta) \n$$\n\n\n:::{.callout-important}\n## Bayesian inference in a nutshell\n\n1) Represent your prior belief by a probability distribution over the possible parameter values. This is a principled way of dealing with uncertainty.\n\n2) Use the likelihood to weight the prior belief.\n\n3) Obtain a posterior belief over the possible parameter values.\n:::\n\n:::aside\nThe term _belief_ is used synonymously with _probability distribution_.\n:::\n \n### Bayesian inference in the card game: a numerical example\n\nRecall that we defined a sequence of 101 points between 0 and 1, which represented the possible $\\theta$ values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_points <- 101\ntheta_grid <- seq( from=0 , to=1 , length.out = n_points )\n```\n:::\n\n\nFor each of these, we computed the likelihood, that is the probability of observing the (fixed) data, given the parameter. Now, we can make our knowledge about the probability of each parameter value explicit. At first, we will assume that all parameters are equally likely. We will assign the probability of 1 to each parameter value. This is our prior distribution. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_1 <- rep(1, length(theta_grid))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior_1, \"type\" = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nWe could also express the belief that player is at least as good as player B, i.e. they are equally good or A is better than B. One way of doing this is to assign a probability of $1$ to parameter values greater than or equal to $0.5$, and the value $0$ to parameter values less than $0.5$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_2 <- ifelse(theta_grid < 0.5, 0, 2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior_2, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nA more systematic way of doing this is to use a parameterized probability distribution that expresses our beliefs about the parameter. \n\n:::{.callout-note}\nA family of probability distributions that are suitable for parameters that lie in the interval $[0,1]$ is the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution). This distribution has $2$ parameters $\\alpha$ und $\\beta$, \nwhich can be interpreted as the prior number of successes and the number of failures, respectively. The number of trials is therefore $\\alpha + \\beta$. @fig-betadist shows a number of possible Beta distributions for various settings of $\\alpha$ and $\\beta$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.2     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlength <- 1e4\nd <- crossing(shape1 = c(.1, 1:4),\n           shape2 = c(.1, 1:4)) |>\n  tidyr::expand(nesting(shape1, shape2),\n         x = seq(from = 0, to = 1, length.out = length)) |> \n  mutate(a = str_c(\"a = \", shape1),\n         b = str_c(\"b = \", shape2),\n         group = rep(1:length, each = 25))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd |> \n  ggplot(aes(x = x, group = group)) +\n  \n  geom_line(aes(y = dbeta(x, shape1 = shape1, shape2 = shape2)),\n            color = \"steelblue4\", size = 1.1) +\n  scale_x_continuous(expression(theta), breaks = c(0, .5, 1)) +\n  coord_cartesian(ylim = c(0, 3)) +\n  labs(title = \"Beta distributions\",\n       y = expression(p(theta*\"|\"*a*\", \"*b))) +\n  theme(panel.grid = element_blank()) +\n  facet_grid(b~a)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n:::\n\nIf we want to use a Beta distribution to express the belief that all values of $\\theta$ are equally likely (uniform prior), we can a Beta distribution with $\\alpha = 1$ and $\\beta = 1$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_3 <- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior_3, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\nFinally, we could express the following prior information as a Beta distribution: imagine you had previously observed $100$ games between A and B, and each won half of the games. You can set $\\alpha$ and $\\beta$ to the number of games won by A, and the number of games won by B, respectively.  A won $50$, and B won $50$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 50, shape2 = 50)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\nNow, we can combine the prior and the likelihood by multiplying them element-wise, i.e. we need to multiply each parameter value with the probability of the data given that parameter. \n\n:::{.callout-note}\nRecall Bayes theorem:\n\n$$\np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n$$\n:::\n\n\nIn R, this is simply:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwins <- 6\ngames <- 9\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 4, shape2 = 4)\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunstandardized_posterior <- likelihood * prior\n```\n:::\n\n\nThis gives us the unnormalized posterior:\n\n\n$$ \np(\\theta|y) \\propto  p(y|\\theta) * p(\\theta)\n$$\n\n\nWe can then normalize the posterior distribution by dividing it by $p(y) = \\sum_{\\theta}p(y|\\theta) * p(\\theta)$. \n\nIn R we can use the `sum()` function: `sum(unstandardized_posterior)`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior <- unstandardized_posterior / sum(unstandardized_posterior)\n```\n:::\n\n\nWe can now plot the resulting normalized posterior distribution. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, posterior, type = \"l\", yaxt = 'n', ylab = 'Probability', \n        main = \"Posterior\", cex.lab = 1.5, cex.main = 3)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n\nTo make this repeatable, we will write two functions. The first, `compute_posterior()`, will compute the posterior, given the prior and likelihood, and return a dataframe containing prior, likelihood and posterior. The second, `plot_posterior()`, will plot all three side-by-side. You can also pass in the maximum likelihood estimate, e.g. `6/9`, and this will be plotted as well.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_posterior = function(likelihood, prior){\n  # compute product of likelihood and prior\n  unstandardized_posterior <- likelihood * prior\n  \n  # standardize the posterior, so it sums to 1\n  posterior <- unstandardized_posterior / sum(unstandardized_posterior)\n  \n  out <- tibble(prior, likelihood, posterior)\n  out\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior <- function(df, mle = 6/9){\nwith(df, {\n    par(mfrow=c(1, 3))\n    plot(theta_grid , prior, type=\"l\", main=\"Prior\", col = \"dodgerblue3\", \n            lwd = 4, yaxt = 'n', ylab = 'Probability', cex.lab = 1.5, cex.main = 3)\n    plot(theta_grid , likelihood, type = \"l\", main = \"Likelihood\", col = \"firebrick3\", \n            lwd = 4, yaxt = 'n', ylab = '', cex.lab = 1.5, cex.main = 3)\n    plot(theta_grid , posterior , type = \"l\", main = \"Posterior\", col = \"darkorchid3\", \n            lwd = 4, yaxt = 'n', ylab = '', cex.lab = 1.5, cex.main = 3)\n    abline(v = mle, col = 4, lty = 2, lwd = 2)\n  } )\n}\n```\n:::\n\n\n\nYou can now try out various prior distributions, and observe the effect on the posterior.\n\n\nLet's try out a uniform prior first:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- compute_posterior(likelihood, prior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior(df)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-note}\nIn this case, the maximum likelihood estimate coincides with the value that maximizes the posterior probability. This is the case because maximum likelihood estimate uses only the likelihood and does not consider prior knowledge. If we are are using a uniform prior, that amounts to saying that all values of $\\theta$ are equally likely. In other words, we have no information as which values are more probable.\n:::\n\nNow let's try out our prior expressing the belief that player A cannot be worse than player B:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- ifelse(theta_grid < 0.5, 0, 1)\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- compute_posterior(likelihood, prior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior(df)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nThe resulting posterior distribution is zero for all values of $\\theta$ that are less than 0.5. This is because our prior allocates zero probability those values.\n\n:::{.callout-tip}\nTry out various priors. How do they affect the posterior?\n\n- A prior expressing the belief that B is better than A.\n- A prior expressing that belief that either A is a lot better, or B is a lot better.\n- A prior expressing the belief that the players are probably as good as each other, and that it is unlikely that either is much better than the other.\n:::\n\n\nThe posterior represents our belief about the the possible parameter values, after having observed the data. You can therefore think of Bayesian inference as a method for updating your beliefs, conditional on observed data. You are re-allocating probabilities over parameter values, depending on how well those parameter values predicted the data.\n\n:::{.callout-tip collapse=\"true\"}\n## Analytic solution\n\nFor a few problem, it is possible to derive an analytic solution. The Bernoulli/Binomial likelihood and Beta prior is one of those.\n\nIn the above example, we used a technique called grid approximation to obtain the posterior distribution for a parameter. This means that we tried out various parameter values by constructing a grid, and then computed the posterior by applying Bayes' rule. This technique was used merely for educational purposes, as it does not scale well to real-world problems. In the simple example of a sequence of binary observations, the parameter of interest (the probability of success $\\theta$ in a Bernoulli trial) is bounded between $0$ and $1$ ($\\theta \\in [0, 1]$). Furthermore, there is only $1$ parameter to estimate. In more complex models, with many parameters, using grid approximation can be very inefficient, or even impossible. In such cases, we usually use numerical methods to approximate the posterior distribution. These methods are know collectively as *Monte Carlo sampling*, or *Markov Chain Monte Carlo* (MCMC). Using MCMC, we will not obtain an analytical description of posterior distributions, but instead a collection of random numbers (samples), that are drawn from the posterior distribution. We will use these samples to represent the posterior distribution.\n\nIn this particular case, however, we also obtain the posterior distribution $p(\\theta|y)$ analytically. By this, I mean that if we use a Beta distribution to describe our prior belief over the $\\theta$ parameter, and the likelihood is Bernoulli or Binomial, the posterior distribution is also a Beta distribution.\n\n\nThis is shown here for the Binomial likelihood, with the data consisting of $k$ successes in $N$ trials.\n\n\n$$\np(\\theta|k, N) = \\frac{p(y|\\theta) \\cdot p(\\theta) = \\theta^k (1-\\theta)^{N-k} \\cdot beta(\\theta|a, b)}{p(k, N)}\n$$\n\nwhere $a, b$ are the parameters of the Beta distribution.\n\n$$\np(\\theta|a, b) = beta(\\theta|a, b) = \\frac{\\theta^{a-1} (1-\\theta)^{b-1}} {B(a, b)}\n$$\n\n\nThe function $B(a, b)$ is a normalizing constant and ensures that the area under the curve integrates to $1$.\n\n$$\np(\\theta|k, N) = \\frac{\\theta^{(a+k)-1} (1-\\theta)^{(b+N-k)-1}} { B(a+k, b+N-k) }\n$$\n\nPut more simply: \n\n:::{.callout-tip}\nIf the prior distribution is $beta(\\theta|a, b)$, and the data have $k$ heads in $N$ flips, then the posterior distribution is $beta(\\theta|a + k, b + N ‚àí k)$.\n:::\n\nYou can therefore think of the parameters $a$ and $b$ as the prior successes and failures in $N$ trials, and these parameters are updated by observing $k$ heads in $N$ flips.\n\n### Example\n\nThis time, we are using `theta_grid` merely so we can plot the prior and posterior. Suppose that we have observed 8 games, and that player A has won 4 of those. Our prior should therefore be $p(\\theta|4,4)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 4, shape2 = 4)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior, \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\nIf we now observe that player A wins 3 out of the next 4 games, our posterior should be $p(\\theta|4+3,4+1)$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior <- dbeta(x = theta_grid, shape1 = 7, shape2 = 5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(prior = prior, \n       posterior = posterior, \n       theta = theta_grid) |> \n  pivot_longer(c(prior, posterior), names_to = \"distribution\") |> \n  ggplot(aes(theta, value, color = distribution)) +\n  geom_line(size = 2) +\n  scale_color_viridis_d(end = 0.8) +\n  ylab(\"\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\nWe can write a function that updates a Beta prior, given $k$ successes in $N$ trials:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nupdate_beta <- function(a, b, k, N) {\n  theta_grid <- seq(0, 1, length = 101)\n  dbeta(x = theta_grid, shape1 = a + k, shape2 = b + N-k)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior <- update_beta(a = 4, b = 4, k = 3, N = 4)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(prior = prior, \n       posterior = posterior, \n       theta = theta_grid) |> \n  pivot_longer(c(prior, posterior), names_to = \"distribution\") |> \n  ggplot(aes(theta, value, color = distribution)) +\n  geom_line(size = 2) +\n  scale_color_viridis_d(end = 0.8) +\n  ylab(\"\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n:::\n\n### Summarizing the posterior\n\nWe now need one last step: we need to summarize the posterior distribution. We can do this, for example by computing the mean and standard deviation of the posterior distribution. \n\nTo show how this works, we can draw a thousand samples from the posterior distribution. First, we'll create a posterior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\nlikelihood <- dbinom(wins, size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- compute_posterior(likelihood, prior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior(df)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n\nNow we'll draw 1000 random numbers from the posterior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_samples <- 1e3\n\nsamples <- theta_grid |> sample(size = n_samples, replace = TRUE, prob = df$posterior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(samples, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.59 0.67 0.44 0.59 0.66 0.53 0.41 0.55 0.56 0.35\n```\n:::\n:::\n\n\nNow we can summarize the samples, e.g. by computing the mean or quantiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.63871\n```\n:::\n:::\n\n\nThe following will give us the median, and a 50% **credible interval**, i.e. an interval that contains 50% of the mass of the distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(samples, c(0.25, 0.5, 0.75))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 25%  50%  75% \n0.55 0.65 0.74 \n```\n:::\n:::\n\n\nWe can also use this approach to compute a 95% credible interval.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha <- 0.05\n\nquantile(samples, c(alpha/2, 1-alpha/2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 2.5% 97.5% \n 0.36  0.88 \n```\n:::\n:::\n\n\n\n:::{.callout-warning}\nThis should not be confused with the 95% confidence interval. Can you remember how a confidence interval is defined? What is the difference between a confidence interval and a credible interval?\n:::\n\nWhat we have done so far is to look at Bayesian inference for parameter estimation (in a very simple model). Let's call this model $\\mathcal{M}$. We have only considered one model at a time, but in the next session we will consider two or models $\\mathcal{M_j}, which differ in the prior distributions they use. We will then look at methods for comparing models, in order to perform hypothesis testing in a Bayesian framework.\n\nIn particular, we will look at how Bayesian model comparison can help, in the case that we have no significant results (see @sec-fancyhat).\n\n\n",
    "supporting": [
      "bayesian-statistics-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}