{
  "hash": "d34d95a6aca82f14f31479f76c9d9451",
  "result": {
    "markdown": "---\ntitle: \"Bayesianische Parametersch√§tzung\"\ndescription: |\n  Eine Alternative zu Null Hypothesis Significance Testing (NHST).\ndate: \"2022-05-08\"\nauthor:\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography.bib\nformat:\n    html:\n        toc: true\n        code-link: true\nexecute: \n  cache: false\ncode-annotations: select\n---\n\n\n\n\n\n:::{.callout-tip collapse=\"false\"}\n## Lernziele\n\nIn der heutigen Sitzung:\n\n- Einf√ºhrung in die Bayesianische Inferenz\n- Parametersch√§tzung vs Modelle vergleichen\n:::\n\n\n## Bayesian Inference (In A Nutshell)\n\n\n> \"Probability theory is nothing more than common sense reduced to calculation.\"\n>\n> ‚Äï Pierre Simon Laplace, 1819\n\nIn Bayesianischen Statistik geht es unter anderem, aber nicht nur, um die Anwendung von Bayes' Theorem. \n\n:::{.callout-tip collapse=\"true\" appearance=\"minimal\"}\n## Bayes' Theorem\n\nBayes Theorem gibt die Formel f√ºr eine bedingte Wahrscheinlichkeit an $P(A|B)$. \n$$ P(A|B) = \\frac{P(B|A)‚ãÖP(A)}{P(B)} $$\n\nIn menschlicher Sprache: die Wahrscheinlichkeit eines Ereignisses A unter der Bedingung, dass ein Ereignis B wahr ist, ist gleich der a priori Wahrscheinlichkeit, dass A wahr ist, multipliziert mit der Wahrscheinlichkeit, dass B eintritt, wenn A wahr ist. Dividiert wird das ganze durch die Wahrscheinlichkeit, dass B eintritt, egal ob A wahr oder falsch ist.\n\n\nMan kann das auch spezifisch f√ºr Hypothesentests formulieren:\n\n$$ P(Hypothesis|Data) =  \\frac{P(Data|Hypothesis) ‚ãÖ P(Data)}{P(Hypothesis)} $$\n:::\n\nDer wesentlichste Unterschied zwischen der Bayesianischen und der frequentistischen Statistik ist, dass in der Bayesianischen Statistik die Wahrscheinkeitstheorie konsequent angewandt wird, um Parameter zu sch√§tzen. \n\n- In der frequentistischen Statistik wird die Wahrscheinkeitslehre vor allem angewandt, um die Wahrscheinlichkeit der Daten zu berechnen, unter der Annahme, dass die Nullhypothese wahr ist. \n- In der Bayesianischen Statistik wird die Wahrscheinkeitslehre angewandt, um die Wahrscheinlichkeit der Parameter zu berechnen.\n\nDieser Unterschied hat weitreichende Konsequenzen. So kann man in der frequentistischen Statistik Parameter sch√§tzen, aber es wird wird angenommen, dass ein Parameter einen wahren (aber unbekannten) Wert hat. Der Parameter ist aber keine Zufallszahl, und hat daher keine Wahrscheinlichkeitsverteilung. Daher darf man nicht √ºber die Wahrscheinlichkeit eines Parameters sprechen. In der Bayesianischen Statistik ist ein Parameter eine Zufallszahl, und hat daher eine Wahrscheinlichkeitsverteilung. Wir ben√ºtzen Bayes Theorem um die Wahrscheinlichkeit von Parametern zu berechnen.\n\nIm foglenden Kapitel werden uns (in einer sehr verk√ºrzten Form) damit besch√§ftigen, was die Konsequenzen dieser unterschiedlichen Sichtweisen sind, und wie Bayesianische Statistik funktioniert. Am Anfang m√ºssen wir jedoch eine zentral Frage beantworten: Was ist eigentlich der Unterschied zwischen Parametersch√§tzung und Modellvergleichen / Hypothesentests? \n\n<aside>\nModellvergleiche und Hypothesentests werden hier synomym verwendet.\n</aside>\n\nIn der frequentistischen Statistik werden diese beiden Dinge oft gemeinsam behandelt, und es ist nicht auf Anhieb klar, dass es sich um zwei unterschiedliche Dinge handelt. Dies hat vor allem damit zu tun, dass Parametersch√§tzung einfach ist, weil nur eine sogennante Punksch√§tzung erfolgt, und weil es oft um die Anwendung eines Hypothesentests geht.\n\nIn der Bayesianischen Statistik ist Parametersch√§tzung nicht einfach, da eine ganze Wahrscheinlichkeitsverteilung gesch√§tzt wird. Es lohnt sich, dass wir uns klarmachen, was genau Parametersch√§tzung ist. Wir werden zuerst anhand eines t-Tests anschauen, wie Parametersch√§tzung und Hypothesentests im frequentistischen Gebrauch kombiniert werden und danach anhand eines einfachen Wahrscheinlichkeitsbeispiel die Parametersch√§tzung illustrieren.\n\n\n## Parameter sch√§tzen vs Hypothesen testen anhand eines t-Tests\n\nMit einem t-Test wollen wir einen Mittelwertsunterschied testen. Dies bedeutet, wir wollen wissen, ob sich zwei Mittelwerte voneinander unterscheiden (wir beschr√§nken uns hier auf zwei unabh√§ngige Gruppen). Diese Frage bezieht sich auf einen __Modellvergleich__: Wir vergleichen ein Modell, in dem die Mittelwerte gleich sind, mit einem Modell, in dem die Mittelwerte unterschiedlich sind.\n\nBevor wir diesen Vergleich machen k√∂nnen, m√ºssen wir jedoch die Mittelwerte sch√§tzen. Dies ist eine __Parametersch√§tzung__. Im frequentistischen Ansatz benutzen wir den Stichprobenmittelwert als Sch√§tzer f√ºr den Mittelwert, der in der Population, aus der diese Stichprobe gezogen wurde, gilt. \n\n\n:::{.callout-important collapse=\"true\"}\n## Wie funktioniert ein frequentistischer t-Test?\n\nWir schauen uns hier noch einmal explizit das Vorgehen und die Annahmen eines t-Tests an.Mehr dazu finden Sie bei [Aufgabe 3](http://localhost:7820/pages/chapters/bayesian-statistics-1.html#sec-ttest).\n\nWir haben zwei Gruppen, und wollen wissen, ob sich die Mittelwerte der beiden Gruppen unterscheiden. \n\n1) Unser statistisches Modell lautet: Alle Beobachtungen innerhalb einer Gruppe $j$ sind normalverteilt. Die beiden Gruppen unterschieden wich in ihrem Mittelwert, aber die Standardabweichung $\\sigma$ ist in beiden Gruppen dieselbe.\n\n$$ \ny_{ij} \\sim \\mathcal{N}(\\mu_j, \\sigma^2)\n$$\n\n$y_{ij}$ ist die Beobachtung $i$ in Gruppe $j \\in \\{1, 2\\}$. Wir interessieren uns f√ºr den Unterschied zwischen den Mittelwerten $\\mu_1$ und $\\mu_2$.\n\n2) Wir sch√§tzen die Gruppenmittelwerte mittels Maximum Likelihood Sch√§tzung. In diesem Falle geht das ganz einfach; die Stichprobenmittelwerte sind Maximum Likelihood Sch√§tzer, und k√∂nnen einfach berechnet werden. Der weitere Parameter wir ebenfalls gesch√§tzt, und zwar als die gepoolte Standardabweichung $s_p$. Dies ist der __Parametersch√§tzung__-Schritt.\n\n3) Wir berechnen eine Test Statistik. Diese basiert auf dem Mittelwertsunterschied $\\mu_1 - \\mu_2$.\n\n$$\nt = \\frac{\\bar{x_1} - \\bar{x_2}}{s_p \\sqrt{2/n}}\n$$\n\n\n$s_p \\sqrt{2/n}$ ist der Standardfehler der Differenz $\\bar{x_1} - \\bar{x_2}$. _Unter der Annahme, dass die Nullhypothese gilt_, folgt $t$ einer Student-t Verteilung. Wir k√∂nnen nun berechnen, was die Wahrscheinlichkeit w√§re, einen mindestens so extremen t-Wert zu erhalten. Diese Wahrscheinlichkeit nennt man den *p-Wert*. Wichtig: dies ist bereits ein __Modellvergleich__. Wir benutzen hier ein Modell, in dem die Mittelwerte gleich sind.\n\n4) Wir k√∂nnen uns nun entscheiden, ob wir die Nullhypothese verwerfen oder nicht. Wir vergleichen den p-Wert mit einem vorgegebenen Signifikanzniveau $\\alpha$. Wenn der p-Wert kleiner ist als $\\alpha$, dann verwerfen wir die Nullhypothese. Dies bedeutet, dass wir die Tatsache, dass der p-Wert \"gen√ºgend\" klein ist, als Evidenz gegen die Nullhypothese deuten. \n\n:::\n\n\n## Bayesianische Parametersch√§tzung\n\nWir werden nun einen anderen Ansatz kennenlernen: die Bayesianische Statistik. Dieser Ansatz ist nicht neu, hat aber erst in den letzten Jahren Verbreitung gefunden. Dies hat unter anderem damit zu tun, dass die Berechnungen, die f√ºr die Bayesianische Statistik n√∂tig sind, erst mit der Verf√ºgbarkeit von schnellen Computern m√∂glich wurden.\n\n\n:::{.callout-tip collapse=\"true\"}\n## Rechenleistung\nBayesianische Statistik braucht sehr viel Rechenleistung, da wir durch Anwendung von Bayes Theorem die Wahrscheinlichkeitsverteilungen von Parametern sch√§tzen m√ºssen. F√ºr das nachfolgende Beispiel, in dem wir einen Parameter haben, ist dies einfach. F√ºr komplexere Modelle, mit sehr vielen Parametern, brauchen wir Methoden wie Monte Carlo Sampling, welche sehr schnelle CPU und vor allem Parallelisierung ben√∂tigen.\n\nMittlerweile k√∂nnen diese Rechenoperationen auf Laptops durchgef√ºhrt werden. Dies war fr√ºher jedoch nicht der Fall; zu Zeiten, in denen die Bayesianische Statistik entwickelt wurde, war dies nur auf Grossrechnern m√∂glich. Dies ist einer der Gr√ºnde, weshalb die Bayesianische Statistik erst in den letzten Jahren an Popularit√§t gewonnen hat.\n:::\n\n\nWir werden nun anhand eines simplen Beispiels zuerst die Bayesianische Parametersch√§tzung kennenlernen. Ich verwende als Cover Story ein Kartenspiel, da dies ein einfaches Lehrbuchbeispiel ist. Die Cover Story selber ist jedoch nicht wichtig - es geht hier darum, dass unsere beobachteten Daten bin√§r sind.\n\n\n:::{.callout-tip collapse=\"true\"}\n## Weitere Beispiele f√ºr bin√§re Daten\n\n- Eine M√ºnze wird geworfen. Wir wollen die Wahrscheinlichkeit sch√§tzen, dass Kopf oben liegt.\n- Eine Sch√ºler\\*in beantwortet Fragen in einer Pr√ºfung. Wir wollen die Wahrscheinlichkeit sch√§tzen, dass die Sch√ºler\\*in eine Frage richtig beantwortet, um daraus etwas √ºber die F√§higkeit der Sch√ºler\\*in zu lernen.\n- Wir untersuchen die Wahrnehmungsleistung einer Person, welche Signale in Rauschen entdecken soll. Wir wollen die Wahrscheinlichkeit sch√§tzen, mit der die Person ein Signal korrekt entdeckt.\n- Wir untersuchen Kaufentscheidungen. Wir wollen die Wahrscheinlichkeit unter verschiedenen Bedingungen sch√§tzen, mit der eine Person ein Produkt anderen Produkten vorzieht.\n\nDiese Beispiele haben also alle etwas gemeinsam: Wir haben eine bin√§re beobachtete Variable; dies bedeutet, die Variable nimmt einen von zwei m√∂glichen Zust√§nden an. Wir definieren nun einen dieser Zust√§nde als \"Erfolg\", und wollen etwas √ºber die Wahrscheinlichkeit eines Erfolgs lernen.\n:::\n\n\nZwei Spieler spielen ein Kartenspiel. Sie beobachten, dass sie 9 Spiele spielen und dass Spieler A 6 davon gewinnt. Jetzt m√∂chten Sie die Wahrscheinlichkeit sch√§tzen, dass Spieler A das n√§chste Spiel gewinnen wird. Anders ausgedr√ºckt, m√∂chten Sie die F√§higkeit von Spieler A einsch√§tzen, Spieler B in diesem speziellen Spiel zu besiegen.\n\nSie wissen, dass die Erfolgswahrscheinlichkeit im Bereich $[0, 1]$ liegen muss. Was Ihnen vielleicht nicht bewusst ist, ist, dass Sie ein bestimmtes Wahrscheinlichkeitsmodell annehmen und die Erfolgswahrscheinlichkeit ein Parameter dieses Modells ist. Lassen Sie uns das genauer betrachten:\n\nWir wissen, dass die Anzahl der $k$ Erfolge in $n$ Spielen einer Binomialverteilung mit den Parametern $n$ und $\\theta$ folgt. Wir nehmen an, dass jedes einzelne Spiel unabh√§ngig von den anderen ist und die Erfolgswahrscheinlichkeit $\\theta$ f√ºr jedes Spiel gleich ist. Daher k√∂nnen wir auch jedes Kartenspiel als Bernoulli-Experiment mit dem Wahrscheinlichkeitsparameter $\\theta$ betrachten.\n\n$$ \ny_i \\sim \\mathcal{Bernoulli}(\\theta)\n$$\n\n:::{callout-tip}\nIch werde im Allgemeinen die Notation $y$ f√ºr eine Variable verwenden, die beobachtet wird, d.h. die Daten.\n:::\n\n$y_i$ ist die $i$-te Beobachtung in den Daten, was bedeutet, dass es uns sagt, ob Spieler A das Spiel im $i$-ten Versuch gewonnen hat oder nicht. $\\theta$ ist die Erfolgswahrscheinlichkeit f√ºr jedes einzelne Spiel; dies ist ein Parameter unseres Modells ($\\mathcal{M}$).\n\nWenn wir frequentistisch vorgehen, m√ºssen wir nun den Wert von $\\theta$ so sch√§tzen, dass die Wahrscheinlichkeit, die Daten zu beobachten, maximiert wird. \n\n\n:::{callout-tip collapse=\"true\"}\n## Maximum Likelihood Sch√§tzer\n\nWenn wir beobachten, dass Spieler A 6 Mal in 9 Spielen gewonnen hat, dann ist die Erfolgswahrscheinlichkeit $\\theta = 6/9 = 0.67$. Dies ist der Maximum Likelihood Sch√§tzer f√ºr $\\theta$.\n:::\n\nWir k√∂nnen dies auch mit in R numerisch, d.h. mit der \"brute force\" Methode, berechnen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwins <- 6\ngames <- 9\n```\n:::\n\n\nDas Ziel ist es, den \"besten\" Wert von $\\theta$ zu ermitteln, d.h. den Wert, der die Wahrscheinlichkeit maximiert, die Daten zu beobachten. Um dies zu tun, m√ºssen wir eine Reihe von m√∂glichen Werten von $\\theta$ in Betracht ziehen (wir wissen bereits, dass dieser Bereich $[0, 1]$ ist). Wir werden 101 Werte von $\\theta$ zwischen 0 und 1 betrachten und die Wahrscheinlichkeit berechnen, die Daten f√ºr jeden Wert von $\\theta$ zu beobachten.\n\n<aside>\nWarum 101? Ist willk√ºrlich, wir k√∂nnten auch 1000 oder 10000 benutzen. Je mehr Punkte wir nehmen, je feiner unser Raster, desto besser k√∂nnen wir die L√∂sung approximieren. Mehr Punkte heisst aber auch mehr Rechenoperationen, was mehr Rechenleistung ben√∂tigt.\n</aside>\n\n::: {.cell}\n\n```{.r .cell-code}\nn_points <- 101\ntheta_grid <- seq( from=0 , to=1 , length.out = n_points )\n```\n:::\n\n\nUnter der Annahme, dass beide Spieler eine gleiche Gewinnchance haben, sollte der Parameter $\\theta = 0.5$ sein. Die Wahrscheinlichkeit der Daten gegeben $\\theta = 0.5$ ist:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(x = wins, size = games, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1640625\n```\n:::\n:::\n\n\nDie Wahrscheinlichkeit, 6 von 9 Spielen zu gewinnen, unter der Annahme, dass beide Spieler gleich wahrscheinlich gewinnen, ist 0.1640625.\n\nWir k√∂nnen auch die Wahrscheinlichkeit berechnen, dass A 6, 7, 8 oder 9 Spiele gewinnt, indem wir die kumulative Verteilungsfunktion der Binomialverteilung verwenden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pbinom(q = 5, size = games, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2539063\n```\n:::\n:::\n\n\noder\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(q = 5, size = games, prob = 0.5, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2539063\n```\n:::\n:::\n\n\n<aside>\n`pbinom()` gibt standardm√§ssig die Wahrscheinlichkeit, dass die Anzahl der Erfolge kleiner oder gleich dem gegebenen Wert ist. Da wir die Wahrscheinlichkeit berechnen wollen, dass die Anzahl der Erfolge gr√∂sser oder gleich dem gegebenen Wert ist, m√ºssen wir `lower.tail = FALSE` setzen.\n</aside>\n\n:::{.callout-tip collapse=\"true\"}\n## p-Wert\nKommt Ihnen das bekannt vor?\n\nWenn wir unsere Null-Hypothese quantifizieren wollen, dass beide Spieler gleich wahrscheinlich gewinnen, w√ºrden wir annehmen, dass $\\theta=0.5$. Die Berechnung der Wahrscheinlichkeit der Daten unter der Null ist genau das, was wir gerade getan haben. Dann setzen wir die tats√§chlichen Daten ein, d.h. 6 von 9, und die obere Schwanzwahrscheinlichkeit ist der p-Wert. In diesem Fall ist der p-Wert ungef√§hr $0.25$. Mit einem Schwellenwert von 0.05 w√ºrden wir die Nullhypothese nicht ablehnen und schliessen, dass es nicht gen√ºgend Beweise daf√ºr gibt, dass Spieler A besser ist als Spieler B (dies ist ein einseitiger Test).\n:::\n\nNun berechnen wir die Wahrscheinlichkeit der Daten unter Ber√ºcksichtigung aller m√∂glichen Parameterwerte. Dies ist der entscheidende Schritt in Richtung Bayesianische Inferenz üöÄ. \n\nIn R ist dies sehr einfach, da alle Funktionen vektorisiert sind.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n\nWir haben gerade die Wahrscheinlichkeit der Daten (genauer gesagt: A gewinnt 6 Mal in 9 Spielen) f√ºr jeden Wert von $\\theta$ berechnet (genauer: f√ºr 101 Werte von $\\theta$ zwischen 0 und 1). Wir k√∂nnen dies grafisch darstellen.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, likelihood, xlab = expression(theta), ylab = \"likelihood\")\nlines(theta_grid, likelihood, type = \"l\", lty = 1)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\nWir k√∂nnen in der obigen Abbildung sehen, dass die Wahrscheinlichkeit, die Daten zu beobachten, f√ºr viele Werte von $\\theta$ klein ist. Die Wahrscheinlichkeit, die Daten zu beobachten, oder die Likelihood, ist maximal f√ºr den Wert 0.6666667:\n\n\nDiesen finden wir auch numerisch:\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta_grid[which.max(likelihood)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.67\n```\n:::\n:::\n\n\nWas wir bisher gemacht haben, unterstreicht den Unterschied zwischen Parametersch√§tzung und Hypothesentest. Die Berechnung der Unter- und √úberschreitungswahrscheinlichkeit unter der Nullhypothese ($\\theta=0.5$) ist ein __Hypothesentest__, und die Sch√§tzung von $\\theta$ ist die __Parametersch√§tzung__.\n\n\n\n\n### Vorwissen\n\ndie wahrscheinlichsten Parameter a priori gehabt h√§tten. Tats√§chlich haben wir, wie wir etwas weiter unten sehen werden, implizit angenommen, dass alle Parameter gleich wahrscheinlich sind. Jetzt f√ºhren wir ein neues Konzept ein: eine a-priori-Verteilung f√ºr die Parameter, die wir versuchen zu sch√§tzen^[In der frequentistischen Statistik ist das Konzept bedeutungslos - Parameter k√∂nnen keine Verteilung haben. In der Bayesschen Statistik sollte eine a-priori-Verteilung alles widerspiegeln, was wir √ºber den Parameter wissen, bevor wir die Daten ber√ºcksichtigen. Die a-priori-Verteilung spiegelt unseren Glauben wider, der subjektiv oder objektiv sein kann.].\n\nWir werden dann diesen _a-priori_-Glauben verwenden, um einen _a-posteriori_-Glauben √ºber die m√∂glichen Parameterwerte zu erlangen. Um dies zu tun, m√ºssen wir die a-priori-Wahrscheinlichkeit jedes Parameterwerts mit der Likelihood der Daten, d.h. mit der bedingten Wahrscheinlichkeit, die Daten zu beobachten, gegeben diesen Parameterwert, multiplizieren. Dies ist eine Anwendung des Bayes'schen Theorems:\n\n$$ \np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n$$\n\nDies besagt, dass die a-posteriori-Wahrscheinlichkeit von $\\theta$ gegeben den beobachteten Daten $y$ gleich ist der Wahrscheinlichkeit der Daten, multipliziert mit der a-priori-Wahrscheinlichkeit jedes Werts von $\\theta$. Sie k√∂nnen es sich so vorstellen: Jeder Parameterwert wird gewichtet, je nachdem, wie gut er die Daten vorhersagt. Das Produkt $p(y|\\theta) * p(\\theta)$ wird dann durch die Wahrscheinlichkeit der Daten geteilt, die in diesem Fall √ºber alle m√∂glichen Parameterwerte summiert wird. Dieser Schritt dient dazu, die a-posteriori-Wahrscheinlichkeit zu normalisieren, so dass sie sich zu $1$ aufaddiert. Dies verwandelt die unnormalisierte a-posteriori-Wahrscheinlichkeit im Grunde in eine richtige Wahrscheinlichkeitsverteilung.\n\n$$\np(y) = \\sum_{\\theta}p(y|\\theta) * p(\\theta) \n$$\n\nWenn wir daran interessiert sind, die Parameter eines gegebenen Modells zu sch√§tzen, k√∂nnen wir oft den (f√ºr ein Modell konstanten) normalisierenden Term $p(y)$ vernachl√§ssigen. Dieser Term, oft als Evidenz bezeichnet, spiegelt die Wahrscheinlichkeit der Daten wider, gemittelt √ºber alle Parameterwerte. Ohne den normalisierenden Konstanten geschrieben, wird die Bayes-Regel oft so geschrieben:\n\n$$ \np(\\theta|y) \\propto  p(y|\\theta) * p(\\theta) \n$$\n\n\n:::{.callout-important}\n## Zusammenfassung\n\n1) Repr√§sentieren Sie Ihre a-priori √úberzeugung durch eine Wahrscheinlichkeitsverteilung √ºber die m√∂glichen Parameterwerte. Dies ist eine prinzipielle Methode, um mit Unsicherheit umzugehen.\n\n2) Verwenden Sie die Likelihood, um die a-priori √úberzeugung zu gewichten.\n\n3) Erhalten Sie eine a-posteriori √úberzeugung √ºber die m√∂glichen Parameterwerte.\n\n:::\n\n<aside>\nDer Begriff _belief_ wird im Englischen oft als Synomym f√ºr Wahrscheinlichkeitsverteilung verwendet. Ich √ºbersetze _belief_ hier mit _√úberzeugung_.\n</aside>\n \n### Bayesianische Inferenz mit bin√§ren Daten: Ein numerisches Beispiel\n\nErinnern Sie sich daran, dass wir eine Sequenz von 101 Punkten zwischen 0 und 1 definiert haben, die die m√∂glichen $\\theta$-Werte darstellten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_points <- 101\ntheta_grid <- seq( from=0 , to=1 , length.out = n_points )\n```\n:::\n\n\nF√ºr jeden von diesen haben wir die Likelihood berechnet, das heisst die Wahrscheinlichkeit, die (festgelegten) Daten zu beobachten, gegeben den Parameter. Jetzt k√∂nnen wir unser Wissen √ºber die Wahrscheinlichkeit jedes Parameterwerts explizit machen. Zun√§chst nehmen wir an, dass alle Parameter gleich wahrscheinlich sind. Wir weisen jedem Parameterwert die Wahrscheinlichkeit 1 zu. Dies ist unsere a-priori-Verteilung.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_1 <- rep(1, length(theta_grid))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior_1, \"type\" = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nWir k√∂nnten auch die √úberzeugung ausdr√ºcken, dass Spieler A mindestens so gut ist wie Spieler B, d.h. sie sind gleich gut oder A ist besser als B. Eine M√∂glichkeit, dies zu tun, besteht darin, Parameterwerten, die gr√∂sser oder gleich $0.5$ sind, eine Wahrscheinlichkeit von $2$^[2 damit die Fl√§che zwischen 0 und 1 sich zu 1 addiert.] zuzuweisen und den Wert $0$ f√ºr Parameterwerte kleiner als $0.5$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_2 <- ifelse(theta_grid < 0.5, 0, 2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior_2, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\nEine systematischere Methode besteht darin, eine parametrisierte Wahrscheinlichkeitsverteilung zu verwenden, die unsere √úberzeugungen √ºber den Parameter ausdr√ºckt.\n\n:::{.callout-tip collapse=\"true\"}\n## Beta-Verteilung\nEine Familie von Wahrscheinlichkeitsverteilungen, die f√ºr Parameter geeignet sind, die im Intervall $[0,1]$ liegen, ist die [Beta-Verteilung](https://de.wikipedia.org/wiki/Beta-Verteilung). Diese Verteilung hat $2$ Parameter $\\alpha$ und $\\beta$, die jeweils als die vorherige Anzahl von Erfolgen und die Anzahl der Misserfolge interpretiert werden k√∂nnen. Die Anzahl der Versuche betr√§gt daher $\\alpha + \\beta$. Die Grafik zeigt eine Reihe von m√∂glichen Beta-Verteilungen f√ºr verschiedene Einstellungen von $\\alpha$ und $\\beta$. Beachten Sie, dass in R die Parameter $\\alpha$ und $\\beta$ als `shape1` und `shape2` bezeichnet werden. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.2     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlength <- 1e4\nd <- crossing(shape1 = c(.1, 1:4),\n           shape2 = c(.1, 1:4)) |>\n  tidyr::expand(nesting(shape1, shape2),\n         x = seq(from = 0, to = 1, length.out = length)) |> \n  mutate(a = str_c(\"a = \", shape1),\n         b = str_c(\"b = \", shape2),\n         group = rep(1:length, each = 25))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd |> \n  ggplot(aes(x = x, group = group)) +\n  \n  geom_line(aes(y = dbeta(x, shape1 = shape1, shape2 = shape2)),\n            color = \"steelblue4\", linewidth = 1.1) +\n  scale_x_continuous(expression(theta), breaks = c(0, .5, 1)) +\n  coord_cartesian(ylim = c(0, 3)) +\n  labs(title = \"Beta distributions\",\n       y = expression(p(theta*\"|\"*a*\", \"*b))) +\n  theme(panel.grid = element_blank()) +\n  facet_grid(b~a)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n:::\n\nWenn wir eine Beta-Verteilung verwenden wollen, um die √úberzeugung auszudr√ºcken, dass alle Werte von $\\theta$ gleich wahrscheinlich sind (uniforme a-priori-Verteilung), k√∂nnen wir eine Beta-Verteilung mit $\\alpha = 1$ und $\\beta = 1$ verwenden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_3 <- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior_3, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\nSchliesslich k√∂nnten wir folgendes Vorwissen als Beta-Verteilung ausdr√ºcken: Stellen Sie sich vor, Sie h√§tten zuvor 100 Spiele zwischen A und B beobachtet, und jeder hat die H√§lfte der Spiele gewonnen. Sie k√∂nnen nun $\\alpha$ der Anzahl der von A gewonnenen Spiele und $\\beta$ der Anzahl der von B gewonnenen Spiele gleichsetzen. A hat 50 Spiele gewonnen und B hat 50 Spiele gewonnen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 50, shape2 = 50)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\nNun k√∂nnen wir unser Vorwissen und die Wahrscheinlichkeit durch elementweises Multiplizieren kombinieren. Dies bedeutet wir m√ºssen jeden Parameterwert mit der Wahrscheinlichkeit der Daten (gegeben diesen Parameter) multiplizieren.\n\n:::{.callout-note}\nZur Erinnerung: Bayes Theorem lautet:\n\n$$\np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n$$\n:::\n\n\nIn R ist dies einfach:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwins <- 6\ngames <- 9\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 4, shape2 = 4)\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunstandardized_posterior <- likelihood * prior\n```\n:::\n\n\nDies gibt uns die unnormalisierte Posterior-Verteilung.\n\n$$ \np(\\theta|y) \\propto  p(y|\\theta) * p(\\theta)\n$$\n\n\nWir k√∂nnen diese normalisieren, indem wir sie durch die Summe der Werte teilen. Dies ist der Nenner von Bayes Theorem: $p(y) = \\sum_{\\theta}p(y|\\theta) * p(\\theta)$. \n\nIn R k√∂nnen wir die `sum()` Funktion verwenden: `sum(unstandardized_posterior)`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior <- unstandardized_posterior / sum(unstandardized_posterior)\n```\n:::\n\n\nDie normalisierte Posterior-Verteilung sieht folgendermassen aus.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, posterior, type = \"l\", yaxt = 'n', ylab = 'Probability', \n        main = \"Posterior\", cex.lab = 1.5, cex.main = 3)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\nUm dies wiederholbar zu machen, werden wir zwei Funktionen schreiben. Die erste, `compute_posterior()`, berechnet die Posterior-Verteilung, und gibt ein Dataframe zur√ºck, welches Prior, Likelihood und Posterior enth√§lt. Die zweite, `plot_posterior()`, plottet alle drei nebeneinander. Sie k√∂nnen auch die Maximum-Likelihood-Sch√§tzung √ºbergeben, z.B. 6/9, und diese wird ebenfalls geplottet.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_posterior = function(likelihood, prior){\n  # compute product of likelihood and prior\n  unstandardized_posterior <- likelihood * prior\n  \n  # standardize the posterior, so it sums to 1\n  posterior <- unstandardized_posterior / sum(unstandardized_posterior)\n  \n  out <- tibble(prior, likelihood, posterior)\n  out\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior <- function(df, mle = 6/9){\nwith(df, {\n    par(mfrow=c(1, 3))\n    plot(theta_grid , prior, type=\"l\", main=\"Prior\", col = \"dodgerblue3\", \n            lwd = 4, yaxt = 'n', ylab = 'Probability', cex.lab = 1.5, cex.main = 3)\n    plot(theta_grid , likelihood, type = \"l\", main = \"Likelihood\", col = \"firebrick3\", \n            lwd = 4, yaxt = 'n', ylab = '', cex.lab = 1.5, cex.main = 3)\n    plot(theta_grid , posterior , type = \"l\", main = \"Posterior\", col = \"darkorchid3\", \n            lwd = 4, yaxt = 'n', ylab = '', cex.lab = 1.5, cex.main = 3)\n    abline(v = mle, col = 4, lty = 2, lwd = 2)\n  } )\n}\n```\n:::\n\n\n\nJetzt k√∂nnen Sie verschiedene a-priori-Verteilungen ausprobieren und die Auswirkungen auf die a-posteriori-Verteilung beobachten.\n\nWir probieren zuerst eine uniforme a-priori-Verteilung aus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- compute_posterior(likelihood, prior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior(df)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-note}\nIn diesem Fall stimmt die Maximum-Likelihood-Sch√§tzung mit dem Wert √ºberein, der die a-posteriori-Wahrscheinlichkeit maximiert. Dies ist der Fall, weil die Maximum-Likelihood-Sch√§tzung nur die Likelihood verwendet und keine a priori-Kenntnisse ber√ºcksichtigt. Wenn wir eine uniforme a-priori-Verteilung verwenden, bedeutet das, dass alle Werte von $\\theta$ gleich wahrscheinlich sind. Mit anderen Worten haben wir keine Informationen dar√ºber, welche Werte wahrscheinlicher sind.\n:::\n\nJetzt probieren wir die a-priori-Verteilung aus, die die √úberzeugung ausdr√ºckt, dass Spieler A nicht schlechter sein kann als Spieler B:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- ifelse(theta_grid < 0.5, 0, 1)\nlikelihood <- dbinom(wins , size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- compute_posterior(likelihood, prior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior(df)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nDie resultierende a-posteriori-Verteilung ist f√ºr alle Werte von $\\theta$, die kleiner als 0.5 sind, gleich Null. Dies liegt daran, dass unsere a-priori-Verteilung diesen Werten eine Wahrscheinlichkeit von Null zuweist.\n\n:::{.callout-caution}\n## Hands-on\nProbieren Sie verschiedene a-priori-Verteilungen aus. Wie beeinflussen sie die a-posteriori-Verteilung?\n\n- Eine a-priori-Verteilung, die den Glauben ausdr√ºckt, dass B besser ist als A.\n- Eine a-priori-Verteilung, die den Glauben ausdr√ºckt, dass entweder A deutlich besser oder B deutlich besser ist.\n- Eine a-priori-Verteilung, die den Glauben ausdr√ºckt, dass die Spieler wahrscheinlich gleich gut sind und es unwahrscheinlich ist, dass einer viel besser ist als der andere.\n:::\n\n\nDie a-posteriori-Verteilung repr√§sentiert unseren Glauben an die m√∂glichen Parameterwerte, nachdem wir die Daten beobachtet haben. __Man kann daher den bayesianische Inferenzprozess als eine Methode betrachten, um die √úberzeugungen unter Ber√ºcksichtigung der beobachteten Daten zu aktualisieren__. Dabei werden die Wahrscheinlichkeiten √ºber die Parameterwerte neu verteilt, abh√§ngig davon, wie gut diese Parameterwerte die Daten vorhersagten.\n\n:::{.callout-tip collapse=\"true\"}\n## Analytische L√∂sung\n\nF√ºr einige Probleme ist es m√∂glich, eine analytische L√∂sung zu finden. Die Likelihood Bernoulli/Binomial und der Beta-Prior geh√∂ren dazu.\n\nIn dem obigen Beispiel haben wir eine Technik namens Rasterapproximation verwendet, um die a-posteriori-Verteilung f√ºr einen Parameter zu erhalten. Das bedeutet, dass wir verschiedene Parameterwerte ausprobiert haben, indem wir ein Raster erstellt und dann die a-posteriori-Verteilung mit Hilfe der Bayes'schen Regel berechnet haben. Diese Technik wurde lediglich zu Bildungszwecken verwendet, da sie f√ºr reale Probleme nicht gut skalierbar ist. In dem einfachen Beispiel einer Abfolge bin√§rer Beobachtungen ist der interessierende Parameter (die Erfolgswahrscheinlichkeit $\\theta$ bei einem Bernoulli-Versuch) zwischen $0$ und $1$ begrenzt ($\\theta \\in [0, 1]$). Dar√ºber hinaus gibt es nur einen Parameter, der gesch√§tzt werden soll. In komplexeren Modellen mit vielen Parametern kann die Verwendung der Rasterapproximation sehr ineffizient oder sogar unm√∂glich sein. In solchen F√§llen verwenden wir in der Regel numerische Methoden, um die a-posteriori-Verteilung anzun√§hern. Diese Methoden werden allgemein als Monte-Carlo-Stichproben oder Markov-Chain-Monte-Carlo (MCMC) bezeichnet. Mit Hilfe von MCMC erhalten wir keine analytische Beschreibung der a-posteriori-Verteilungen, sondern eine Sammlung von Zufallszahlen (Stichproben), die aus der a-posteriori-Verteilung gezogen wurden. Wir verwenden diese Stichproben, um die a-posteriori-Verteilung darzustellen.\n\nIn diesem speziellen Fall erhalten wir jedoch die a-posteriori-Verteilung $p(\\theta|y)$ analytisch. Damit meine ich, dass, wenn wir eine Beta-Verteilung verwenden, um unseren a-priori-Glauben √ºber den Parameter $\\theta$ zu beschreiben, und die Likelihood Bernoulli oder Binomial ist, die a-posteriori-Verteilung ebenfalls eine Beta-Verteilung ist.\n\nDies wird hier f√ºr die Binomial-Likelihood mit den Daten $k$ Erfolgen in $N$ Versuchen gezeigt.\n\n\n$$\np(\\theta|k, N) = \\frac{p(y|\\theta) \\cdot p(\\theta) = \\theta^k (1-\\theta)^{N-k} \\cdot beta(\\theta|a, b)}{p(k, N)}\n$$\n\nwo $a, b$ die Parameters der Beta-Verteilung sind.\n\n$$\np(\\theta|a, b) = beta(\\theta|a, b) = \\frac{\\theta^{a-1} (1-\\theta)^{b-1}} {B(a, b)}\n$$\n\n\nDie Funktion $B(a, b)$ ist eine Normalisierungskonstante und stellt sicher, dass die Fl√§che unter der Kurve zu $1$ integriert.\n\n$$\np(\\theta|k, N) = \\frac{\\theta^{(a+k)-1} (1-\\theta)^{(b+N-k)-1}} { B(a+k, b+N-k) }\n$$\n\nEinfach ausgedr√ºckt:\n\n:::{.callout-tip}\nWenn die a-priori-Verteilung $beta(\\theta|a, b)$ ist und die Daten $k$ Erfolge in $N$ Versuchen haben, dann ist die a-posteriori-Verteilung $beta(\\theta|a + k, b + N - k)$.\n:::\n\nSie k√∂nnen daher die Parameter $a$ und $b$ als die vorherigen Erfolge und Misserfolge in $N$ Versuchen betrachten, und diese Parameter werden durch die Beobachtung von $k$ Erfolgen in $N$ Versuchen aktualisiert.\n\n#### Beispiel\n\nDiesmal verwenden wir theta_grid nur, um die a-priori-Verteilung und die a-posteriori-Verteilung darzustellen. Angenommen, wir haben 8 Spiele beobachtet und Spieler A hat 4 davon gewonnen. Unsere a-priori-Verteilung sollte daher $p(\\theta|4,4)$ sein.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 4, shape2 = 4)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(theta_grid, prior, \"l\")\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n\nWenn wir nun beobachten, dass Spieler A 3 von den n√§chsten 4 Spielen gewinnt, sollte unsere a-posteriori-Verteilung $p(\\theta|4+3,4+1)$ sein.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior <- dbeta(x = theta_grid, shape1 = 7, shape2 = 5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(prior = prior, \n       posterior = posterior, \n       theta = theta_grid) |> \n  pivot_longer(c(prior, posterior), names_to = \"distribution\") |> \n  ggplot(aes(theta, value, color = distribution)) +\n  geom_line(size = 2) +\n  scale_color_viridis_d(end = 0.8) +\n  ylab(\"\") +\n      theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\nWir k√∂nnen eine Funktion schreiben, die einen Beta-Prior aktualisiert, gegeben $k$ Erfolgen in $N$ Versuchen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nupdate_beta <- function(a, b, k, N) {\n  theta_grid <- seq(0, 1, length = 101)\n  dbeta(x = theta_grid, shape1 = a + k, shape2 = b + N-k)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior <- update_beta(a = 4, b = 4, k = 3, N = 4)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(prior = prior, \n       posterior = posterior, \n       theta = theta_grid) |> \n  pivot_longer(c(prior, posterior), names_to = \"distribution\") |> \n  ggplot(aes(theta, value, color = distribution)) +\n  geom_line(size = 2) +\n  scale_color_viridis_d(end = 0.8) +\n  ylab(\"\") +\n      theme_minimal()\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n:::\n\n### Posterior-Verteilung Zusammenfassen\n\nWir m√ºssen jetzt noch einen letzten Schritt machen: Wir m√ºssen die a-posteriori-Verteilung zusammenfassen. Dies k√∂nnen wir zum Beispiel tun, indem wir den Mittelwert und die Standardabweichung der a-posteriori-Verteilung berechnen.\n\nUm zu zeigen, wie das funktioniert, k√∂nnen wir tausend Stichproben aus der a-posteriori-Verteilung ziehen. Zuerst werden wir eine a-posteriori-Verteilung erstellen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\nlikelihood <- dbinom(wins, size = games , prob = theta_grid)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- compute_posterior(likelihood, prior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior(df)\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-2_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\nNun ziehen wir 1000 Zufallszahlen aus der a-posteriori-Verteilung. \n\n<aside>\nDies ist vielleicht nicht ganz verst√§ndlich; Methoden wie z.B. Monte Carlo Sampling, welche f√ºr komplexe Probleme verwendet werden, generieren Zufallszahlen aus einer Verteilung, die der a-posteriori-Verteilung entspricht. Wir werden hier nicht auf die Details eingehen, aber Sie k√∂nnen sich das als eine Art \"Zufallszahlengenerator\" vorstellen, der Zufallszahlen aus der a-posteriori-Verteilung generiert.\n</aside>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_samples <- 1e3\n\nsamples <- theta_grid |> sample(size = n_samples, replace = TRUE, prob = df$posterior)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(samples, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.64 0.59 0.42 0.60 0.73 0.67 0.71 0.84 0.61 0.52\n```\n:::\n:::\n\n\nJetzt k√∂nnen wir die Zufallszahlen zusammenfassen, zum Beispiel durch Berechnung des Mittelwerts oder der Quantile.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.63345\n```\n:::\n:::\n\n\nMit dem folgenden Code erhalten wir den Median und ein 50% **credible interval**, das heisst ein Intervall, das 50% der Verteilungsmasse enth√§lt.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(samples, c(0.25, 0.5, 0.75))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 25%  50%  75% \n0.54 0.64 0.74 \n```\n:::\n:::\n\n\nWir k√∂nnen diesen Ansatz auch verwenden, um ein 95% **credible interval** zu berechnen.\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(samples, c(0.025, 1 - 0.025))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 2.5% 97.5% \n 0.37  0.88 \n```\n:::\n:::\n\n\n\n:::{.callout-warning}\n## **Credible interval** vs Konfidenzintervall\n**Credible interval** ist ein bayesianisches Konzept, das sich von dem Konfidenzintervall unterscheidet, das wir in der frequentistischen Statistik verwenden. Ein **credible interval** ist ein Intervall, das eine bestimmte Wahrscheinlichkeit enth√§lt, dass der wahre Parameter innerhalb dieses Intervalls liegt.\nDies sollte nicht mit dem Konfidenzintervall verwechselt werden. K√∂nnen Sie sich daran erinnern, wie ein Konfidenzintervall definiert ist? Was ist der Unterschied zwischen einem Konfidenzintervall und einem **credible interval**?\n:::\n\nWas wir bisher gemacht haben, ist, die bayessche Inferenz f√ºr die Parametersch√§tzung in einem sehr einfachen Modell zu betrachten. Nennen wir dieses Modell $\\mathcal{M}$. Wir haben immer nur ein Modell betrachtet, aber im n√§chsten teil werden wir zwei oder mehrere Modelle $\\mathcal{M_j}$ betrachten, die sich in den a-priori-Verteilungen unterscheiden. Dann werden wir Methoden zur Modellvergleich untersuchen, um Hypothesentests in einem bayesianischen Framework durchzuf√ºhren.\n\nInsbesondere werden wir uns ansehen, wie der bayesianischen Modellvergleich helfen kann, wenn wir keine signifikanten Ergebnisse haben.\n\n\n",
    "supporting": [
      "bayesian-statistics-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}