{
  "hash": "c23d4d2127dc93a565c826d4a9098330",
  "result": {
    "markdown": "---\ntitle: \"Aggregierte Statistiken\"\ndescription: |\n  Daten aus Verhaltensexperimenten zusammenfassen.\ndate: \"2022-03-27\"\nauthor:\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography.bib\nformat:\n    html:\n        toc: true\n        code-link: true\nexecute: \n  cache: false\ncode-annotations: select\n---\n\n\n\n\n<!-- :::{.callout-note}\nüëâ [R Code f√ºr dieses Kapitel downloaden](../../downloadable_files/summarizing-data.R)\n::: -->\n\n\n\n:::{.callout-tip collapse=\"false\"}\n## Lernziele\n\nIn der heutigen Sitzung lernen wir:\n\n- Zusammenfassende Statistiken berechnen.\n- In _within-subject_ Designs aggregierte Statistiken berechnen.\n- Standardfehler berechnen, welche Messwiederholungen ber√ºcksichtigen.\n:::\n\n\n\nWir haben in den vorherigen Kapiteln gesehen, wie wir Daten aus Verhaltensexperimenten in R einlesen und bearbeiten k√∂nnen. In diesem Kapitel werden wir uns mit der Frage besch√§ftigen, wie wir zusammenfassende Statistiken erstellen k√∂nnen, um diese grafisch darzustellen und zu interpretieren. Da wir uns in den Neurowissenschaften meist mit _within-subject_ Designs besch√§ftigen, werden wir uns in diesem Kapitel auf Messwiederholungsdaten konzentrieren.\n\n\n\n# Daten aus dem RDK Experiment einlesen\nZum Schluss der letzten Sitzung haben wir f√ºr jede Versuchsperson pro Bedingung die `accuracy` berechnet, und grafisch dargestellt. Wir wiederholen diesen Schritt hier nochmals, um die Daten f√ºr die folgenden Analysen vorzubereiten.\n\n\nZuerst laden wir das `tidyverse` Package und lesen das gespeicherte `csv` File ein.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndata <- read_csv(\"data_clean/rdkdata.csv\")\n```\n:::\n\n\n\nIm ersten Schritt konvertieren wir wieder alle Gruppierungsvariablen zu Faktoren. Ob eine Variable als `factor` definiert ist, wird als Attribut gespeichert. Attribute werden aber in einem `.csv.` File nicht mitgespeichert; deshalb m√ºssen wir diesen Schritt nach dem Einlesen jedesmal neu ausf√ºhren. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |>\n  mutate(across(where(is.character), as_factor))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, ‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, left, none‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, left, right, ‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, left, left, ‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, neutral, val‚Ä¶\n```\n:::\n:::\n\n\nDie ersten 20 Zeilen der Tabelle sehen wie folgt aus:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |>\n  slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n```\n:::\n:::\n\n\n\n# Individuelle und Aggregierte Kennzahlen\n\nIn neurowissenschaftlichen Fragestellungen interessieren wir uns sowohl f√ºr aggregierte Statistiken, als auch f√ºr individuelle Kennzahlen, d.h. f√ºr die Kennzahlen, die wir erhalten, wenn wir die Daten f√ºr jede Versuchsperson einzeln betrachten. Wir schauen uns dies am Beispiel der korrekten Antworten in der RDK Entscheidungsaufgabe an.\n\n:::{.callout-important}\n- √úberlegen Sie sich, in welchen F√§llen Sie aggregierte Statistiken ben√∂tigen, und in welchen F√§llen individuelle Kennzahlen.\n:::\n\n\n\n# Korrekte Entscheidungen\n\n\n\nWir schauen uns zuerst (wie im letzten Kapitel) die Anzahl korrekter Entscheidungen an. Wir k√∂nnen diese entweder f√ºr jede Person in jeder Bedingung berechnen, oder f√ºr jede Bedingung, aggregiert √ºber alle Personen.\n\n## Individuell f√ºr jede Person in jeder Bedingung\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_individual <- data |>\n    group_by(ID, condition) |>\n    summarise(\n        N = n(),\n        ncorrect = sum(correct),\n        accuracy = mean(correct)\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n```\n:::\n\n```{.r .cell-code}\naccuracy_individual\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    valid        64       60    0.938\n 2 JH    neutral      80       66    0.825\n 3 JH    invalid      16       13    0.812\n 4 NS    valid        64       58    0.906\n 5 NS    neutral      80       56    0.7  \n 6 NS    invalid      16       11    0.688\n 7 rh    valid        64       61    0.953\n 8 rh    neutral      80       64    0.8  \n 9 rh    invalid      16        2    0.125\n10 sb    valid        64       62    0.969\n# ‚Ä¶ with 17 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_individual |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per person/condition\") +\n  facet_wrap(~ID) +\n  theme_linedraw(base_size = 14) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n##  Pro Bedingung, √ºber alle Personen aggregiert\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_aggregated <- data |>\n    group_by(condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\naccuracy_aggregated\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 √ó 4\n  condition     N ncorrect accuracy\n  <fct>     <int>    <dbl>    <dbl>\n1 valid       576      475    0.825\n2 neutral     720      453    0.629\n3 invalid     144       56    0.389\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_aggregated |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = 1), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per condition\") +\n  theme_linedraw(base_size = 14) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-important}\n## Hands-on\nWir beurteilen Sie die beiden obenstehenden Plots. Was f√§llt Ihnen auf? Sind die Mittelwerte aussagekr√§ftig?\n:::\n\n:::{.callout-tip collapse=\"true\"}\n## L√∂sung\nEs fehlt eine Darstellung der Unsicherheit, die wir in der Sch√§tzung des Mittelwerts haben. \n:::\n\n\n\n## Standardfehler\n\nWir wollen wir nicht mehr nur den Mittelwert betrachten, sondern auch die Standardabweichung und den Standardfehler. Letzteres ist eine Mass f√ºr die Unsicherheit, die wir in der Sch√§tzung des Mittelwerts haben. Leider gibt es keine Funktion in R, die uns den Standardfehler berechnet. Der Standardfehler ist definiert als die Standardabweichung geteilt durch die Wurzel aus der Anzahl der Datenpunkte:  $$SE = sd/ \\sqrt{n}$$.\n\n\nWir k√∂nnen eine solche Funktion einfach selber definieren. `sd()` berechnet die Standardabweichung eines Vektors, und die Anzahl Datenpunkte ist die L√§nge des Vektors (`length()`), den wir als Argument √ºbergeben.\n\n\n::: {.cell}\n\n:::\n::: {.cell}\n\n```{.r .cell-code}\nse <- function(x) {\n  sd(x) / sqrt(length(x))\n}\n```\n:::\n\n\n\n\n## Aggregierte Accuracy mit Standardfehler\n\nEine M√∂glichkeit w√§re, die Anzahl korrekter Entscheidungen in jeder Bedingung insgesamt, d.h. √ºber alle Personen aggregiert, zu berechnen. Wir berechnen dabei den Standardfehler des Mittelwertes um ein Mass f√ºr die Unsicherheit zu enthalten, mit der wir die Mittelwerte sch√§tzen k√∂nnen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |>\n    group_by(condition) |>\n            summarise(\n                  n = n(),\n                  ncorrect = sum(correct),\n                  accuracy = mean(correct),\n                  se = se(correct)\n            )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 √ó 5\n  condition     n ncorrect accuracy     se\n  <fct>     <int>    <dbl>    <dbl>  <dbl>\n1 valid       576      475    0.825 0.0159\n2 neutral     720      453    0.629 0.0180\n3 invalid     144       56    0.389 0.0408\n```\n:::\n:::\n\n\n\n:::{.callout-caution}\n## Hands-on\n- Was sagen uns diese Kennzahlen? \n- Welche Informationen gehen dabei verloren?\n- √úberlegen Sie sich, was wir genau berechnet haben.\n:::\n\n\n\n:::{.callout-tip collapse=\"true\"}\n\n## Ein Exkurs √ºber within-person Standardfehler \n\nFolgender Code erstellt einen Dataframe mit 10 Personen, die jeweils zu zwei  Messzeitpunkten getestet werden. Es handelt sich also um ein within-subject Design.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as_factor(subject))\n```\n:::\n\n\nDer Dataframe ist im `wide` Format -- um die Daten zu analysieren, ist das `long` Format besser geeignet. Wir konvertieren vom `wide` ins `long` Format mit der Funktion `pivot_longer()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 √ó 3\n   subject pretest posttest\n   <fct>     <dbl>    <dbl>\n 1 1          59.4     64.5\n 2 2          46.4     52.4\n 3 3          46       49.7\n 4 4          49       48.7\n 5 5          32.5     37.4\n 6 6          45.2     49.5\n 7 7          60.3     59.9\n 8 8          54.3     54.1\n 9 9          45.4     49.6\n10 10         38.9     48.5\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndfl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 √ó 3\n   subject condition value\n   <fct>   <fct>     <dbl>\n 1 1       pretest    59.4\n 2 1       posttest   64.5\n 3 2       pretest    46.4\n 4 2       posttest   52.4\n 5 3       pretest    46  \n 6 3       posttest   49.7\n 7 4       pretest    49  \n 8 4       posttest   48.7\n 9 5       pretest    32.5\n10 5       posttest   37.4\n11 6       pretest    45.2\n12 6       posttest   49.5\n13 7       pretest    60.3\n14 7       posttest   59.9\n15 8       pretest    54.3\n16 8       posttest   54.1\n17 9       pretest    45.4\n18 9       posttest   49.6\n19 10      pretest    38.9\n20 10      posttest   48.5\n```\n:::\n:::\n\n\n\nWas uns hier interessiert ist vor allem die \"Verbesserung\" jeder Person vom ersten zum zweiten Messzeitpunkt. Diese k√∂nnen wir grafisch darstellen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nWir stellen fest, dass fast jede Person zum zweiten Messzeitpunkt einen h√∂heren Wert als beim ersten aufweist. Gleichzeitig gibt es aber auch erhebliche Unterschiede zwischen den Personen in Bezug auf ihren Anfangswert. Diese interindividuellen Unterschiede sind aber hier nicht von Interesse. Wir k√∂nnen davon ausgehen, dass diese Unterschiede auf \"stabile\" Eigenschaften der Personen zur√ºckzuf√ºhren sind. Die Personen sind also eine Quelle der Variabilit√§t, die unsere Fragestellung \"st√∂rt\" - diese lautet: wie ist die √Ñnderung zwischen den beiden Zeitpunkten?\n\n\nWir k√∂nnen so tun, als ob der Messzeitpunkt eine __between__-subject Variable w√§re. In diesem Fall w√ºrden wir die Standardfehler wie folgt berechnen.\n\n::: {.cell}\n\n```{.r .cell-code}\ndflsum_between_1 <- dfl |>\n    group_by(condition) |>\n    summarize(\n        mean = mean(value),\n        se = se(value)\n    )\n\ndflsum_between_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 √ó 3\n  condition  mean    se\n  <fct>     <dbl> <dbl>\n1 pretest    47.7  2.72\n2 posttest   51.4  2.29\n```\n:::\n:::\n\n\n\nEine Alternative dazu bietet die Funktion `summarySE()` aus dem `Rmisc` Package.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n```\n:::\n:::\n\n\n\n\n\nDIe Fehlerbalken im folgenden Plot ber√ºcksichtigen folgendermassen nicht die Tatsachen, dass ein grosser Anteil der Variabilit√§t auf \"stabile\" Personenunterschiede zur√ºckzuf√ºhren ist. In diesem Fall sind die \"errorbars\" sehr gross, und es sieht so aus, als ob es keinen feststellbaren Unterschied zwischen den Zeitpunkten gibt. Wir vermuten aber aufgrund der individuellen Grafiken, dass es sehr wohl einen Unterschied gibt.\n  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\nWenn wir nur die Unterschiede zwischen den Personen ber√ºcksichtigen k√∂nnten, h√§tten wir in diesem Fall kleinere Standardfehler, da wir sozusagen die Personenvariabilit√§t subtrahieren k√∂nnen.\n\n\nIm `Rmisc` Package gibt es eine solche Funktion: mit `summarySEwithin()` k√∂nnen wir korrekt Standardfehler in __within__-subject Designs berechnen.\n\n::: {.cell}\n\n```{.r .cell-code}\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n```\n:::\n\n\n\nDie resultierenden Fehlerbalken sind nun kleiner.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60) +\n    ggtitle(\"Correct within standard errors\")\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n\nWenn wir beide Varianten zusammen darstellen, wird der Unterschiedlich offentsichtlich. In dieser Grafik sind die `between` Standardfehler in rot eingezeichnet; die `within` Standardfehler sind in schwarz.\n\n::: {.cell}\n\n```{.r .cell-code}\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"black\", data = dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nWas wir hier machen ist eigentlich einfach. Um die `within` Standardfehler zu berechnen, m√ºssen wir zuerst die personen-spezifische Mittelwerte von den Daten subtrahieren. Dies k√∂nnen wir mit der Funktion `normDataWithin()` machen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, \n                                     idvar=\"subject\",    \n                                     measurevar=\"value\")\ndfNorm_long\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   subject condition value valueNormed\n1        1   pretest  59.4      47.035\n2        1  posttest  64.5      52.135\n3       10   pretest  38.9      44.785\n4       10  posttest  48.5      54.385\n5        2   pretest  46.4      46.585\n6        2  posttest  52.4      52.585\n7        3   pretest  46.0      47.735\n8        3  posttest  49.7      51.435\n9        4   pretest  49.0      49.735\n10       4  posttest  48.7      49.435\n11       5   pretest  32.5      47.135\n12       5  posttest  37.4      52.035\n13       6   pretest  45.2      47.435\n14       6  posttest  49.5      51.735\n15       7   pretest  60.3      49.785\n16       7  posttest  59.9      49.385\n17       8   pretest  54.3      49.685\n18       8  posttest  54.1      49.485\n19       9   pretest  45.4      47.485\n20       9  posttest  49.6      51.685\n```\n:::\n:::\n\n\nWenn wir nun die \"normierten\" Daten plotten, sind die Unterschiede zwischen den Personen \"verschwunden\", weil wir eben die Daten normiert haben.\n\n::: {.cell}\n\n```{.r .cell-code}\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\n\nDie Argumente der Funktion `summarySEwithin()` sind folgende:\n\n- `measurevar`: die outcome` Variable\n- `withinvars`: eine o(oder mehrere) within-subject Variablen\n- `idvar`: die Gruppierungsvariable der within-subject Variablen (Versuchsperson)\n- `na.rm`: sollen fehlende Werte ignoriert werden?  \n- `conf.interval`: der gew√ºnschte Konfidenzintervall (default: 0.95)\n\nIm Output erhalten wir die Mittelwerte der `outcome` Variablen f√ºr jede Stufe der within-Variable, sowie Standardabweichungen, Standardfehler und Konfidenzintervalle.\n\n\n::: {.cell}\n\n:::\n::: {.cell}\n\n```{.r .cell-code}\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n```\n:::\n\n\n\nZum Vergleich: die Berechnung der Standardfehler in `dflsum` ber√ºcksichtigt die Tatsache, dass Personen sich von Anfang an unterscheiden, und subtrahiert von jedem Datenpunkt den Mittelwert der Person. \n\n\n::: {.cell}\n\n:::\n::: {.cell}\n\n```{.r .cell-code}\ndflsum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition  N value       sd        se       ci\n1   pretest 10 47.74 2.262361 0.7154214 1.618396\n2  posttest 10 51.43 2.262361 0.7154214 1.618396\n```\n:::\n:::\n\n\nBei der Berechnung der Standardfehler in `dflsum_between` haben wir im Prinzip so getan, als seien die Messzeitpunkte unabh√§ngig voneinander. Wir haben also die Standardfehler in `dflsum_between` so berechnet, als ob wir die Daten in zwei unabh√§ngige Gruppen aufgeteilt h√§tten. \n \n\n::: {.cell}\n\n```{.r .cell-code}\ndflsum_between\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n```\n:::\n:::\n\n\n<!-- end excursion -->\n:::\n\n\n\n\n\n\n## Accuracy mit within-person Standardfehler\n\nWir k√∂nnen nun dieses Prinzip auf unsere RDK daten anwenden. Die messwiederholte Variable ist nun nicht mehr der Messzeitunkt, sondern die `cue`-Bedingung, und die `outcome` Variable ist `accuracy`, also die Proportion korrekter Antworten.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_individual |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\nAuch hier stellen wir fest, dass es scheinbar einen Trend gibt, dass die Proportion korrekter Antworten in der `valid` Bedingung hoch, und in der `invalid` Bedingung niedrig ist. In der `neutral` Bedingung liegt die `accuracy` dazwischen.\n\n\nOhne Ber√ºcksichtigung der Messwiederholungen erhalten wir folgende Standarfehler:\n\nVon Hand berechnet:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             accuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 √ó 5\n  condition     N accuracy    sd     se\n  <fct>     <int>    <dbl> <dbl>  <dbl>\n1 valid       576    0.825 0.381 0.0159\n2 neutral     720    0.629 0.483 0.0180\n3 invalid     144    0.389 0.489 0.0408\n```\n:::\n:::\n\n\nMit der Funktion `summarySE()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition   N   correct        sd         se         ci\n1     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n```\n:::\n:::\n\n\nWenn wir nun die `within` Standardfehler berechnen, erhalten wir folgende Ergebnisse:\n\n::: {.cell}\n\n```{.r .cell-code}\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition   N   correct        sd         se         ci\n1     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n\n\n\n# Reaktionszeiten\n\nDasselbe k√∂nnen wir nun auch mit den mittleren Reaktionszeiten machen.\n\n\n## Pro Versuchsperson\n\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und Standarabweichung zusammen. Wenn wir Daten anhand mehrerer statistischer Kennzahlen zusammenfassen m√∂chten, k√∂nnen wir dies entweder manuell machen, oder die Funktion `across()` verwenden.\n\nEinfachere Version:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n```\n:::\n\n\nKomplizierte Version:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfuns <- list(mean = mean, median = median, sd = sd, se = se)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nby_subj \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 27 √ó 6\n# Groups:   ID [9]\n   ID    condition  mean median     sd      se\n   <fct> <fct>     <dbl>  <dbl>  <dbl>   <dbl>\n 1 JH    valid     0.696  0.658 0.190  0.0240 \n 2 JH    neutral   0.799  0.733 0.202  0.0226 \n 3 JH    invalid   0.775  0.739 0.163  0.0421 \n 4 NS    valid     0.738  0.715 0.191  0.0240 \n 5 NS    neutral   0.885  0.844 0.201  0.0226 \n 6 NS    invalid   0.894  0.913 0.207  0.0518 \n 7 rh    valid     0.443  0.390 0.185  0.0233 \n 8 rh    neutral   0.525  0.503 0.0841 0.00941\n 9 rh    invalid   0.423  0.389 0.151  0.0378 \n10 sb    valid     0.386  0.349 0.175  0.0218 \n# ‚Ä¶ with 17 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-40-1.png){width=1440}\n:::\n:::\n\n\n\nWir k√∂nnen selbstverst√§ndlich auch die indivuellen mittleren Reaktionszeiten mit Standardfehler plotten:\n\n::: {.cell}\n\n```{.r .cell-code}\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-41-1.png){width=768}\n:::\n:::\n\n\n## √úber Versuchsperson aggregiert\n\n::: {.cell}\n\n```{.r .cell-code}\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition   N        rt        sd         se         ci\n1     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np_rt\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-44-1.png){width=768}\n:::\n:::\n\n\n\nWir haben oben die beiden Grafiken als Variablen `p_accuracy` und  `p_rt` gespeichert. Nun k√∂nnen wir diese Grafiken mit dem `patchwork` Package kombinieren.\n\n<aside>\n`patchwork` muss zuerst installiert werden: `install.packages(\"patchwork\")`\n</aside>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np_accuracy / p_rt\n```\n\n::: {.cell-output-display}\n![](summarizing-data_files/figure-html/unnamed-chunk-46-1.png){width=768}\n:::\n:::\n",
    "supporting": [
      "summarizing-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}