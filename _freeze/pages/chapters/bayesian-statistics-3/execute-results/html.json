{
  "hash": "6e5b11a393a3c14dd532f1aff7b9c3b0",
  "result": {
    "markdown": "---\ntitle: \"Bayes Factors: Bayesianische Hypothesentests\"\ndescription: |\n  Eine Alternative zu Null Hypothesis Significance Testing (NHST).\ndate: \"2022-05-15\"\nauthor:\n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern \n    affiliation-url: https://www.kog.psy.unibe.ch\n    orcid: 0000-0002-2788-936X\nlicense: CC BY\ncitation: true\nbibliography: ../../bibliography.bib\nformat:\n    html:\n        toc: true\n        code-link: true\nexecute: \n  cache: false\ncode-annotations: select\n---\n\n\n\n\n:::{.callout-tip}\n## Daten herunterladen\n\nüëâ [`ExamQuestions.csv`](../../downloadable_files/ExamQuestions.csv)\n\nüëâ [`SmartDrug.csv`](../../downloadable_files/SmartDrug.csv)\n:::\n\n\n\n:::{.callout-tip collapse=\"false\"}\n## Lernziele\n\nIn der heutigen Sitzung:\n\n- Modellvergleiche mit Bayes Factors\n- Bayes Factors mit Jasp berechnen\n:::\n\n\n:::{.callout-tip}\n## Weiterf√ºhrende Literatur\n- [Bayesian Inference in JASP: A Guide for Students](http://static.jasp-stats.org/Manuals/Bayesian_Guide_v0_12_2_1.pdf): Einf√ºhrung in die Bayesianische Statistik mit JASP (mit [Datens√§tzen](https://osf.io/8qtu2/)).\n\n- Ein sehr gutes Lehrbuch Statistik mit JASP: [Learn Statistics with JASP](https://learnstatswithjasp.com/). Enth√§lt ein Kapitel zur Bayesianischen Statistik.\n\n- Keysers, C., Gazzola, V., & Wagenmakers, E.-J. (2020). Using Bayes factor hypothesis testing in neuroscience to establish evidence of absence. Nature Neuroscience, 23(7), [https://doi.org/10.1038/s41593-020-0660-4](https://www.nature.com/articles/s41593-020-0660-4)\n:::\n\n\n\n## Absence of Evidence vs. Evidence of Absence\n\nIn den Neurowissenschaftler*innen ist es wichtig zu wissen, welche experimentellen Manipulationen einen Effekt haben. Genauso wichtig ist es jedoch zu wissen, welche Manipulationen _keinen Effekt_ haben. Diese Frage zu beantworten ist jedoch mit traditionellen statistischen Ans√§tzen schwierig.  Nicht signifikante Ergebnisse sind schwer zu interpretieren: Unterst√ºtzen sie die Nullhypothese oder sind sie einfach nicht informativ? \n\n:::{.callout-important}\n## p-Werte\np-Werte sind [schwierig](https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/) zu erkl√§ren. √úberlegen Sie sich nochmals, was man mit einem p-Wert genau aussagen kann. \n:::\n\nAls Beispiel dient folgendes Experiment aus dem Paper von @keysersUsingBayesFactor2020. Nehmen wir an, dass der vordere cingul√§re Kortex (ACC) bei Ratten f√ºr die \"emotionale Ansteckung\" entscheidend ist und dass eine Deaktivierung des ACC durch lokale Injektion von Muscimol die emotionale Ansteckung im Vergleich zur Injektion von Kochsalzl√∂sung verringern sollte.\n\nEin injiziertes Tier beobachtete, wie ein Artgenosse Elektroschocks erhielt, und die Erstarrung wurde als Mass f√ºr die emotionale Ansteckung gemessen. Es gab auch eine nicht-soziale Kontrollbedingung, bei der das injizierte Tier einem schock-konditionierten Ton ausgesetzt wurde. In einem solchen Experiment ist es wichtig zu zeigen, dass die Manipulation (Injektion von Muscimol) die emotionale Ansteckung reduziert, aber nicht die Erstarrung im Allgemeinen. Dies bedeutet, dass in der Kontrollbedingung keinen Unterschied zwischen den Injektionen von Muscimol und Kochsalzl√∂sung geben sollte. \n\n\nIn diesem Kapitel lernen wir nun eine alternative Methode kennen, um Evidenz zu quantifizieren: **Bayes Factors**. Alternativ zu p-Werten bieten Bayes Factors Evidenz f√ºr oder gegen Hypothesen. Bayes Factors sind ein kontinuierliches Mass, welches im Prinzip angibt, um wieviel wir unsere √úberzeugung f√ºr eine Hypothese √§ndern sollten, nachdem wir die Daten gesehen haben. \n\n\n\n\n## Bayesianische Statistik?\nWir wir in der letzten Sitzungen geh√∂rt haben, ist es wichtig, zwischen Parametersch√§tzung und Hypothesentest zu unterscheiden. Parametersch√§tzung bezeichnet den Prozess, einen oder mehrere Parameter in einem Modell zu sch√§tzen. Um diese Sch√§tzung durchzuf√ºhren, m√ºssen wir eine a-priori-Verteilung der Parameterwerte angeben. Hypothesentesten ist einen Vergleich zwischen mehreren Modellen, welche sich in ihren a-priori-Verteilungen unterscheiden.\n\nZum Beispiel hatten wir im Kartenspiel verschiedene Vorannahmen √ºber die F√§higkeiten der Spieler A und B. Eine Vorannahme dr√ºckte z.B. unsere √úberzeugung aus, dass beide Spieler gleich gut waren, w√§hrend eine andere Vorannahme die √úberzeugung ausdr√ºckte, dass entweder Spieler A oder Spieler B besser war. Diese Vorannahmen, zusammen mit unseren Annahmen √ºber die Verteilung der Daten, bilden ein Modell $\\mathcal{M}$.\n\n### Bayesianische Parametersch√§tzung\n\nIn der Bayesianischen Parametersch√§tzung konzentrieren wir uns auf ein Modell $\\mathcal{M}$. Das Ziel unserer Inferenz ist die a-posteriori-Verteilung der Parameter $\\theta$, und wir k√∂nnen diese durch Anwendung von Bayes' Theorem erhalten (unter Verwendung von Markov Chain Monte Carlo Sampling oder anderen Methoden).\n\n$$ \np(\\theta | y) =  p(\\theta) \\cdot \\frac{p(y | \\theta)}{p(y)}\n$$\n\n\nWir k√∂nnen die Bayes'sche Regel umformulieren, so dass die Abh√§ngigkeit der Parameter $\\mathbf{\\theta}$ vom Modell $\\mathcal{M}$ eindeutig wird:\n$$ \np(\\theta | y, \\mathcal{M}) = \\frac{p(y|\\theta, \\mathcal{M}) \\cdot p(\\theta | \\mathcal{M})} {p(y | \\mathcal{M})}\n$$\n\nwo $\\mathcal{M}$ auf ein spezifisches Modell verweist. Dieses Modell wird durch die a-priori-Verteilung der Parameter $p(\\theta | \\mathcal{M})$ und die Wahrscheinlichkeit der Daten $p(y|\\theta, \\mathcal{M})$ bestimmt.\n\n:::{.callout-important}\n## Wahrscheinlichkeit der Daten\nDie bedingte Wahrscheinlichkeit $p(y | \\mathcal{M})$ gibt nun die Wahrscheinlichkeit der Daten an, gemittelt √ºber alle m√∂glichen Parameterwerte unter der Vorverteilung im Modell $\\mathcal{M}$. Sie auch **Modell-Evidenz** genannt.\n:::\n\nBei der Parametersch√§tzung spielt  $p(y | \\mathcal{M})$ nur die Rolle eines Normalisierungsfaktors. Beim Modellvergleich ist $p(y | \\mathcal{M})$ jedoch von zentraler Bedeutung.\n\n\nDie Randwahrscheinlichkeit $p(y | \\mathcal{M})$ ist der Nenner aus der Bayes'schen Formel:\n\n$$ \np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n$$\n\n\n\nund ist gegeben durch:\n$$ \np(y | \\mathcal{M}) = \\int{p(y | \\theta, \\mathcal{M}) p(\\theta|\\mathcal{M})d\\theta}\n$$\n\n\nDies bedeutet, dass wir die Wahrscheinlichkeit der Daten $p(y | \\mathcal{M})$ erhalten, indem wir die Wahrscheinlichkeit der Daten f√ºr jeden m√∂glichen Parameterwert $\\theta$ berechnen und dann √ºber alle m√∂glichen Parameterwerte mitteln.\n\n\nDie a-priori-Verteilungen f√ºr $\\theta$ sind wichtig, da sie die Wahrscheinlichkeit m√∂glicher Werte von $\\theta$ bestimmen.\n\n\n\n\n\n### Bayesianische Modellvergleiche\n\nNun wollen wir zwei verschiedene Modelle miteinander vergleichen -- wir wollen wissen, welches Modell die Daten besser erkl√§rt. Wir k√∂nnen die Bayes'sche Regel verwenden, um die Wahrscheinlichkeit der Modelle  $\\mathcal{M1}$ und $\\mathcal{M2}$ zu berechnen (gemittelt √ºber alle m√∂glichen Parameterwerte innerhalb des Modells):\n\n$$ \np(\\mathcal{M}_1 | y) = \\frac{P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)}{p(y)} \n$$\n\nund\n\n$$ \np(\\mathcal{M}_2 | y) = \\frac{P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}{p(y)} \n$$\n\n\nEine M√∂glichkeit w√§re, das Verh√§ltnis der beiden Wahrscheinlichkeiten zu berechnen: $p(\\mathcal{M}_1 | y) / p(\\mathcal{M}_2 | y)$. Dieses Verh√§ltnis wird als **posterior odds** bezeichnet:\n\n$$ \n\\frac{p(\\mathcal{M}_1 | y) = \\frac{P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)}{p(y)}} {p(\\mathcal{M}_2 | y) = \\frac{P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}{p(y)}}\n$$\n\n\n$p(y)$ k√∂nnen wir k√ºrzen, da es in oberhalb und unterhalb des Bruchstriches im Nenner vorkommt. Wir erhalten:\n\n$$ \n\\frac{p(\\mathcal{M}_1 | y) = P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)} {p(\\mathcal{M}_2 | y) = P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}\n$$\n\n\nAuf der linken Seite haben wir das Verh√§ltnis der a-posteriori Wahrscheinlichkeiten der beiden Modelle. Auf der rechten Seite haben wir das Verh√§ltnis der **Marginal Likelihoods** der beiden Modelle, multipliziert mit den a-priori Wahrscheinlichkeiten jedes Modells. Die Marginal Likelihoods (auch bekannt als Modell-Evidenz) zeigen, wie gut jedes Modell die Daten erkl√§rt. \n\n:::{.callout-tip}\n## Marginal Likelihoods\nDiese sagt uns im Prinzip, wie wahrscheinlich die Daten sind, wenn wir alle m√∂glichen Parameterwerte ber√ºcksichtigen. Die Marginal Likelihoods sind also die Wahrscheinlichkeit der Daten, gemittelt √ºber alle m√∂glichen Parameterwerte.\n:::\n\n\n$$\n\\underbrace{\\frac{p(\\mathcal{M}_1 | y)} {p(\\mathcal{M}_2 | y)}}_\\text{Posterior odds} = \\underbrace{\\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}}_\\text{Ratio of marginal likelihoods} \\cdot \\underbrace{ \\frac{p(\\mathcal{M}_1)}{p(\\mathcal{M}_2)}}_\\text{Prior odds}\n$$\n\n\n\n$\\frac{p(\\mathcal{M}_1)}{p(\\mathcal{M}_2)}$ sind nun die **Prior Odds**, und $\\frac{p(\\mathcal{M}_1 | y)}{p(\\mathcal{M}_2 | y)}$ sind die  **Posterior Odds**. Diese sagen uns, welches Modell wir a-priori und a-posteriori f√ºr wahrscheinlicher halten. Da unsere a-priori √úberzeugungen aber subjektiv sein k√∂nnen, sind wir eigentlich nur an dem Verh√§ltnis der marginalen Likelihoods interessiert. Wir k√∂nnen annehmen, dass a-priori die beiden Modelle gleichwahrscheinlich sind; das heisst, wir setzen die Prior Odds auf 1 setzen. So erhalten wir\n\n\n$$\n\\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}\n$$\n\nDies ist der **Bayes Factor**. Falls $P(y | \\mathcal{M}_1)$ gr√∂sser ist als $P(y | \\mathcal{M}_2)$, dann ist der Bayes Factor gr√∂sser als 1. Falls $P(y | \\mathcal{M}_1)$ kleiner ist als $P(y | \\mathcal{M}_2)$, dann ist der Bayes Factor kleiner als 1. Der **Bayes Factor** gibt also direkt an, welches Modell die Daten besser erkl√§rt.\n\nWenn wir zwei Modelle $\\mathcal{M}_1$ und $\\mathcal{M}_2$ vergleichen, wird der **Bayes Factor** oftmals so geschrieben:\n\n$$ BF_{12} = \\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}$$\n\n\n$BF_{12}$ ist also der Bayes Factor f√ºr $\\mathcal{M}_1$ und gibt an um wieviel $\\mathcal{M}_1$ die Daten besser \"erkl√§rt\".\n\n\nAls Beispiel, wenn wir ein $BF_{12} = 5$ erhalten, bedeutet dies, dass die Daten 5 Mal wahrscheinlicher unter Modell 1 als unter Modell 2 aufgetreten sind. Umgekehrt, wenn $BF_{12} = 0.2$, dann sind die Daten 5 Mal wahrscheinlicher unter Modell 2 aufgetreten.\n\nWenn wir $BF_{12} = 0.2$ erhalten, ist es einfacher, Z√§hler und Nenner zu vertauschen:\n\n$$ BF_{21} = \\frac{P(y | \\mathcal{M}_2)}{P(y | \\mathcal{M}_1)}$$\n\n\nDie folgenden [Interpretationen](https://www.statology.org/bayes-factor/) von Bayes Factors werden manchmal verwendet, obwohl es nicht wirklich notwendig ist, diese zu klassifizieren. Bayes Factors sind ein kontinuierliches Mass f√ºr Evidenz.\n\n\n\n## Hypothesentesten\n\nWir f√ºhren oft Modellvergleiche zwischen einer Nullhypothese $\\mathcal{H}_0$ und einer alternativen Hypothese $\\mathcal{H}_1$ durch (Die Begriffe \"Modell\" und \"Hypothese\" werden synonym verwendet). Eine Nullhypothese bedeutet, dass wir den Wert des Parameters auf einen bestimmten Wert festlegen, z.B. $\\theta = 0.5$. Die alternative Hypothese bedeutet, dass wir den Wert des Parameters nicht festlegen, sondern eine a-priori Verteilung annehmen.\n\n:::{.callout-important}\n## Alternativhypothese\nIm Gegensatz zu NHST muss die Alternativhypothese spezifiziert werden. Mit anderen Worten, die Parameter m√ºssen eine a-priori Verteilung erhalten.\n:::\n\n\nIn JASP werden Bayes Factors (BF) so berichtet:\n\n$$ BF_{10} = \\frac{P(y | \\mathcal{H}_1)}{P(y | \\mathcal{H}_0)}$$\n\nDies ist ein BF f√ºr eine ungerichtete Alternative $\\mathcal{H}_1$ gegen die Nullhypothese $\\mathcal{H}_0$. Wenn wir einen gerichteten Test durchf√ºhren, dann wird der BF entweder so ($>0$):\n\n$$ BF_{+0} = \\frac{P(y | \\mathcal{H}_+)}{P(y | \\mathcal{H}_0)}$$\n\noder so ($<0$) berichtet.\n$$ BF_{-0} = \\frac{P(y | \\mathcal{H}_-)}{P(y | \\mathcal{H}_0)}$$\n\n\nWenn wir nun einen BF f√ºr die Nullhypothese wollen, k√∂nnen wir einfach den Kehrwert von $BF_{10}$ nehmen:\n\n$$ BF_{01} = \\frac{1}{BF_{10}}$$\n\n\n:::{.callout-tip collapse=\"true\"}\n## Savage-Dickey Density Ratio\n\nWenn wir zwei genestete Modelle vergleichen, d.h. ein Modell mit 1 freiem Parameter und ein Nullmodell (in dem dieser Parameter auf einen bestimmten Wert festgelegt ist), k√∂nnen wir das Savage-Dickey Density Ratio verwenden, um den Bayes-Faktor zu berechnen.\n\n- Nullmodell ($\\mathcal{H}_0$ or $\\mathcal{M}_0$): $\\theta = \\theta_0$\n\n- Alternativmodell ($\\mathcal{H}_1$ or $\\mathcal{M}_1$): $\\theta \\neq \\theta_0$\n\n$\\theta$ braucht unter $\\mathcal{H}_1$ eine a-priori Verteilung. Im Kartenspiel-Beispiel vom letzten Kapitel war dies eine Beta-Verteilung mit $\\alpha = 1$ und $\\beta = 1$: $\\theta \\sim \\text{Beta}(1, 1)$. Diese Hypothese besagt, dass alle Parameterwerte gleich wahrscheinlich sind.\n\nDas Savage-Dickey Density Ratio ist eine verinfachte Methode, um einen Bayes Factor zu erhalten - wir m√ºssen einfach $\\mathcal{M}_1$ betrachten, und die a-posterior Verteilung durch die a-prior Verteilung an der Stelle $\\theta_0$ teilen.\n\nAls Beispiel: stellen Sie sich vor, dass eine Person 9 von 10 Ja/Nein Fragen korrekt beantwortet.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn_correct <- 9\nn_questions <- 10\n```\n:::\n\n\nWir wollen wissen: wie wahrscheinlich ist es, dass die Person geraten hat ($\\theta=0.5$)?\n\nWir nehmen nun eine uniforme a-priori Verteilung f√ºr  $\\theta$ an:\n$$\np(\\theta) = Beta(1, 1)\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npd <- tibble(\n    x = seq(0, 1, by = .01),\n    Prior = dbeta(x, 1, 1)\n)\nggplot(pd, aes(x, Prior)) +\n    geom_line(linewidth = 1.5) +\n    coord_cartesian(xlim = 0:1, ylim = c(0, 6), expand = 0.01) +\n    labs(y = \"Density\", x = bquote(theta))\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-3_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nIm n√§chsten Schritt wenden wir Bayes Theorem an, um die a-posteriori Verteilung zu erhalten:\n\n$$\np(\\theta|y) = Beta(1 + 9, 1 + 1)\n$$\n\nUnser \"Test-Wert\" ist $Œ∏ = 0.5$. Wir k√∂nnen nun sowohl die a-priori als auch die a-posteriori Verteilung an dieser Stelle auswerten:\n\nPrior:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(dprior <- dbeta(0.5, 1, 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\n\nPosterior:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(dposterior <- dbeta(0.5, 10, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1074219\n```\n:::\n:::\n\n\nDer Bayes Factor f√ºr die Nullhypothese $BF_{01}$ ist die Wahrscheinlichkeit der a-posteriori Verteilung geteilt durch die Wahrscheinlichkeit der a-priori Verteilung an der Stelle $\\theta_0$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBF01 <- dposterior / dprior\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nBF01\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1074219\n```\n:::\n:::\n\n\nDa eine Zahl $<0$ nicht so leicht interpretierbar ist, berechnen wir $BF_{10}$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(BF10 <- 1/BF01)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.309091\n```\n:::\n:::\n\n\nDie Daten (9 von 10 Fragen richtig beantwortet) sind also $9.3$ mal wahrscheinlicher unter der Alternativhypothese als unter der Nullhypothese.\n\nIn JASP wird der BF folgendermassen grafisch dargestellt. Wir plotten sowohl die a-priori als auch die a-posteriori Verteilung, und die Wahrscheinlichkeitsdichten an der Stelle $\\theta_0 = 0.5$.\n\nDie Wahrscheinlichkeitsdichte von $\\theta_0$ wird kleiner, nachdem wir die Daten ber√ºcksichtigt haben. Anders formuliert: Die Wahrscheinlichkeit von $\\theta_0$ hat abgenommen, nachdem wir die Daten beobachtet haben. Dies erm√∂glicht uns zu schlussfolgern, dass die Daten (9 von 10) etwa 9 Mal wahrscheinlicher unter $\\mathcal{M_1}$ sind.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npd <- pd |> \n    mutate(Posterior = dbeta(x, 1 + n_correct, 1 + (n_questions-n_correct)))\n\npdw <- pd |> \n  pivot_longer(names_to = \"Type\", \n               values_to = \"density\", \n               Prior:Posterior)\npdw |> \n  ggplot(aes(x, density, col = Type)) +\n  geom_vline(xintercept = 0.5, linetype = \"dotted\") +\n  geom_line(linewidth = 1.5) +\n  scale_x_continuous(expand = expansion(0.01)) +\n  scale_color_viridis_d(end = 0.8) +\n  labs(y = \"Density\", x = bquote(theta)) +\n  annotate(\"point\", x = c(.5, .5), \n           y = c(pdw$density[pdw$x == .5]),\n           size = 4) +\n  annotate(\"label\",\n    x = c(.5, .5),\n    y = pdw$density[pdw$x == .5],\n    label = round(pdw$density[pdw$x == .5], 3),\n    vjust = -.5\n  )\n```\n\n::: {.cell-output-display}\n![](bayesian-statistics-3_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(pd, x == .5) |>\n  mutate(\n    BF01 = Posterior / Prior,\n    BF10 = 1 / BF01) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 √ó 5\n      x Prior Posterior  BF01  BF10\n  <dbl> <dbl>     <dbl> <dbl> <dbl>\n1   0.5     1     0.107 0.107  9.31\n```\n:::\n:::\n\n\n:::\n\n\n:::{.callout-caution}\n## Hands-on\n\nEine Student*in beantwortet 9 von 10 Fragen korrekt.\n\n- Was ist die Evidenz daf√ºr, dass die Student*in geraten hat (Gl√ºck hatte)?\n- Was ist die Evidenz daf√ºr, dass die Wahrscheinlichkeit einer korrekten Antwort der Student*in gr√∂sser als $0.5$ ist?\n\nImportieren Sie den Datensatz `ExamQuestions.csv` ins JASP und f√ºhren Sie einen __Bayesian binomial rate test__ durch.\n:::\n\n\n## Bayesian t-Test\n\nUm einen Bayesianischen t-Test durchzuf√ºhren, m√ºssen wir ebenfalls Parameter sch√§tzen, und zwei Modelle miteinander vergleichen. Dies werden wir anhand zweier Beispiele in JASP demonstrieren.\n\n\n:::{.callout-caution}\n## Smart Drug\n\nIn diesem Beispiel m√∂chten wir die IQ-Werte von zwei Gruppen vergleichen. Einer der Gruppen wurde ein Medikament zur Steigerung der Intelligenz verabreicht, die andere ist die Kontrollgruppe.\n\nImportieren Sie den Datensatz `SmartDrug.csv` ins JASP und f√ºhren Sie einen __Bayesian t-test__ durch.\n:::\n\n\n:::{.callout-caution}\n## Horizontal Eye Movements\n√ñffnen Sie den Datensatz `Eye Movements` in JASP: `Open > Data Library > T-Tests > Eye Movements`. In diesem Datensatz wird die Anzahl erinnerter W√∂rter zwischen zwei Gruppen verglichen. In der einen Gruppe wurden die Probanden instruiert, w√§hrend der Erinnerungsphase auf einen zentralen Punkt zu fixieren; in der anderen Gruppe wurden die Probanden instruiert, horizontale Sakkaden auszuf√ºhren.\n:::\n",
    "supporting": [
      "bayesian-statistics-3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}