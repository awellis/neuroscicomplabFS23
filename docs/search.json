[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "Fr√ºhjahrssemester 2023"
  },
  {
    "objectID": "pages/admin/01_overview.html",
    "href": "pages/admin/01_overview.html",
    "title": "√úbersicht",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses Forschungsgebiets. Das bedeutet, wir analysieren Daten aus Verhaltensexperimenten ‚Äî sowohl mit herk√∂mmlichen statistischen Verfahren, als auch mit mathematischen Modellen. Die Resultate dieser Analysen k√∂nnen wiederum in der Analyse bildgebender Verfahren oder EEG benutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Themen daraus aufgreifen. Das Buch ist auf SpringerLink verf√ºgbar: An Introduction to Model-Based Cognitive Neuroscience.\n\nWir werden folgende Themen im Laufe des Semester behandeln:\n\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. bin√§re Daten, Reaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinf√ºhrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von Entscheidungsverhalten)"
  },
  {
    "objectID": "pages/admin/01_overview.html#experimente",
    "href": "pages/admin/01_overview.html#experimente",
    "title": "√úbersicht",
    "section": "Experimente",
    "text": "Experimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen Benutzeroberfl√§che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/admin/01_overview.html#datenanalyse",
    "href": "pages/admin/01_overview.html#datenanalyse",
    "title": "√úbersicht",
    "section": "Datenanalyse",
    "text": "Datenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu analysieren werden wir R verwenden. Sie sollten daher die aktuelle Version von R installieren (Version r paste(R.Version()[c(\"major\", \"minor\")], collapse = \".\")), sowie RStudio.\nR üëâ https://cloud.r-project.org/\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download\nF√ºr Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, √§hnlich wie Jamovi, mit dem sich simple Bayesianische Tests durchf√ºhren lassen.\nJASP üëâ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R aus benutzen. Die daf√ºr ben√∂tigte Software werden wir im Verlauf des Semesters installieren."
  },
  {
    "objectID": "pages/admin/03_zulip_forum.html",
    "href": "pages/admin/03_zulip_forum.html",
    "title": "Zulip Forum",
    "section": "",
    "text": "Wir benutzen in dieser Veranstaltung Zulip als Diskussionforum. Zulip hat einige Vorteile gegen√ºber ILIAS und Email:\n\nZulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum f√ºr die Vormittags- und Nachmittagsveranstaltungen.\nDie Diskussion ist f√ºr alle Teilnehmer*innen sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron) stattfinden.\n\nBitte erstellen Sie unter diesem Link einen Account. Sie m√ºssen daf√ºr Ihre Uni Emailadresse verwenden. Account erstellen üëâ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, k√∂nnen Sie sich unter folgendem Link einloggen. Zulip Forum üëâ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App f√ºr alle g√§ngigen Betriebssysteme erh√§ltlich. Apps üëâ zulip.com/apps\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Ellis, Andrew},\n  title = {Zulip {Forum}},\n  url = {https://kogpsy.github.io/neuroscicomplabFS23//pages/admin/03_zulip_forum.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nEllis, Andrew. n.d. ‚ÄúZulip Forum.‚Äù https://kogpsy.github.io/neuroscicomplabFS23//pages/admin/03_zulip_forum.html."
  },
  {
    "objectID": "pages/admin/dozierende.html",
    "href": "pages/admin/dozierende.html",
    "title": "Dozierende",
    "section": "",
    "text": "Andrew ist Data Scientist an der Berner Fachhochschule und Wissenschaftlicher Mitarbeiter an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre der Uni Bern. An der BFH besch√§ftigt er sich haupts√§chlich mit der Verwendung k√ºnstlicher Intelligenz in der Lehre, und versucht ein intelligentes Tutoring-System zu entwickeln.\nüì¨ Email: andrew.ellis@unibe.ch\nüîó Website: www.kog.psy.unibe.ch/ueber_uns/personen/dr_ellis_andrew"
  },
  {
    "objectID": "pages/admin/dozierende.html#andrew-ellis",
    "href": "pages/admin/dozierende.html#andrew-ellis",
    "title": "Dozierende",
    "section": "",
    "text": "Andrew ist Data Scientist an der Berner Fachhochschule und Wissenschaftlicher Mitarbeiter an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre der Uni Bern. An der BFH besch√§ftigt er sich haupts√§chlich mit der Verwendung k√ºnstlicher Intelligenz in der Lehre, und versucht ein intelligentes Tutoring-System zu entwickeln.\nüì¨ Email: andrew.ellis@unibe.ch\nüîó Website: www.kog.psy.unibe.ch/ueber_uns/personen/dr_ellis_andrew"
  },
  {
    "objectID": "pages/admin/dozierende.html#gerda-wyssen",
    "href": "pages/admin/dozierende.html#gerda-wyssen",
    "title": "Dozierende",
    "section": "Gerda Wyssen",
    "text": "Gerda Wyssen\nGerda arbeitet an ihrer Dissertation an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre. Sie untersucht den Einfluss von Gleichgewichts- und Bewegungsinformationen auf r√§umliches Denken. Hierzu nutzt sie die Moog Bewegungsplattform oder das starke Magnetfeld eines 7T MRI Scanners. Besonders faszinierend findet sie Bewegungsillusionen.\nüì¨ Email: gerda.wyssen@unibe.ch\nüîó Website: www.kog.psy.unibe.ch/ueber_uns/personen/m_sc_wyssen_gerda"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html",
    "href": "pages/admin/leistungsnachweise.html",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Unsere Veranstaltungen werden so aufgebaut sein, dass wir etwa die H√§lfte der Zeit Inhalt pr√§sentieren; die andere H√§lfte ist praktischen Hands-on Sessions gewidmet. Dies wird jedoch stark vom jeweiligen Inhalt anh√§ngig sein. Wir denken, dass der Umgang mit Programmiersprachen und Datenanalyse am besten gelernt wird, indem man selber ausprobiert. Deshalb werden wir versuchen, die Theorie auf das N√∂tigste zu beschr√§nken, und uns mehr auf praktische Anwendungen zu fokussieren."
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#hands-on-sessions",
    "href": "pages/admin/leistungsnachweise.html#hands-on-sessions",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Unsere Veranstaltungen werden so aufgebaut sein, dass wir etwa die H√§lfte der Zeit Inhalt pr√§sentieren; die andere H√§lfte ist praktischen Hands-on Sessions gewidmet. Dies wird jedoch stark vom jeweiligen Inhalt anh√§ngig sein. Wir denken, dass der Umgang mit Programmiersprachen und Datenanalyse am besten gelernt wird, indem man selber ausprobiert. Deshalb werden wir versuchen, die Theorie auf das N√∂tigste zu beschr√§nken, und uns mehr auf praktische Anwendungen zu fokussieren."
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "href": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "title": "Leistungskontrollen",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nLeistungsnachweise werden in Form von √úbungen erbracht. Es wird insgesamt 5 √úbungen geben ‚Äì davon m√ºssen alle abgegeben werden. Die √úbungen werden in den Veranstaltungen angek√ºndigt und in den entsprechenden Ordner auf ILIAS hochgeladen. Je nach Umfang der √úbung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens eine Woche betragen.\nDie Evaluation der √úbungen erfolgt in Form von Peer-Feedback; dies bedeutet, dass Sie nach dem Abgabetermin aufgefordert werden, zu den √úbungen von zuf√§llig ausgew√§hlten Mitstudierenden Feedback zu geben. Danach erhalten Sie selber von anderen Mitstudierenden Feedback zu Ihrer √úbung. Das Peer-Feedback ist somit Teil des Leistungsnachweises. Auf Ilias finden Sie Informationen zur Art und Form des Feedbacks passend zur √úbung. Grunds√§tzliche Guidelines zum Peer-Feedback finden Sie untenstehend.\nILIAS (Montag) üëâ 468703-FS2023-1\nILIAS (Donnerstag) üëâ 468703-FS2023-0"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "href": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "title": "Leistungskontrollen",
    "section": "Peer Feedback Guidelines",
    "text": "Peer Feedback Guidelines\nWissenschaftliche Artikel werden von Forschenden aus denselben/√§hnlichen Forschungsgebieten begutachtet. In diesem Kurs w√§hlen wir f√ºr das Feedback zu den √úbungen ebenfalls dieses Prinzip des peer review. F√ºr jede √úbung erhalten Sie einen klaren Begutachtungsauftrag mit Fragen wie z.B. Was w√ºrde die Grafik informativer machen?. Wir bitten Sie, beim Verfassen des Peer-Feedbacks folgende Richtlinien zu beachten:\n\nbe kind: Seien Sie freundlich. W√§hlen Sie Ihre R√ºckmeldungspunkte sorgf√§ltig. Nehmen Sie sich Zeit und geben Sie nicht sehr knappes, versp√§tetes oder gar kein Feedback. Schreiben Sie was Ihnen positiv aufgefallen ist und unbedingt beibehalten werden sollte.\nbe specific: Beschreiben Sie das Problem oder die Kritikpunkte pr√§zise und spezifisch (statt z.B. ‚ÄúCode l√§uft nicht‚Äù k√∂nnten Sie schreiben ‚Äúin Zeile 34 gibt es eine Fehlermeldung, es scheint die Variable wurde falsch benannt, ‚Ä¶‚Äù)\nbe helpful: Seien Sie konstruktiv. Es gibt immer etwas was verbessert werden k√∂nnte. Beschreiben Sie diese Punkte und f√ºgen Sie bestenfalls einen L√∂sungsansatz oder -vorschlag hinzu (statt z.B. ‚Äúdie Farben sind nicht geeignet f√ºr farbenblinde Personen‚Äù k√∂nnten Sie schreiben ‚Äúdie viridis Palette w√ºrde die Grafik f√ºr farbenblinde Personen zug√§nglich machen‚Äù).\n\nWertvolles Feedback zu geben ben√∂tigt Zeit. Deshalb planen Sie sich bitte ca. 1 Lektion f√ºr das jeweilige Peer Feedback ein."
  },
  {
    "objectID": "pages/admin/syllabus.html",
    "href": "pages/admin/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Sitzungen\nAn den 14 Sitzungen werden wir voraussichtlich diese Themen behandeln (kleine √Ñnderungen vorbehalten).\n\n1 Einf√ºhrung\nSitzung 1\n\nWir schauen uns ein paar in den Neurowissenschaften verwendeten Programmiersprachen (Python, R, Matlab) an, und diskutieren ChatGPT.\nEinf√ºhrung in DataCamp (f√ºr Python/R).\n\n\n\n\n\n\n\nImportant\n\n\n\nAuf DataCamp den Python Einf√ºhrungskurs ausprobieren.\n\n\n\n\n2 Experimente mit Python programmieren\nSitzungen 2 und 3\n\nWir erstellen selber ein Experiment mit Python und PsychoPy.\n\n\n\n3 Data Wrangling\nSitzungen 4, 5 und 6\n\nWir schauen uns an, wie wir mit R die Daten aus unserem selber programmierten Experiment einlesen und bearbeiten k√∂nnen, um damit statistische Analysen durchzuf√ºhren.\n\n\n\n4 Visualisieren\nSitzungen 7 und 8\n\nRmarkdown\nExplorative Datenanalyse und grafische Darstellung mit mit R package ggplot2.\n\n\n\n5 Signal Detection Theory\nSitzungen 9 und 10\n\nWir verwenden ein in den Neurowissenschaften und der Psychologie beliebtes Modell f√ºr kategoriale oder ordinale Verhaltensdaten, um Daten aus unserem Experiment zu analysieren.\n\n\n\n\n6 Bayesianische Datenanalyse\nSitzungen 11, 12 und 13\n\nIm letzten Thema geht es um einen modernen Ansatz in der Statistik, welcher auf den Axiomen der Wahrscheinlichkeitstheorie beruht, und einige Vorteile gegen√ºber der herk√∂mmlichen (frequentistischen) Statistik bietet. Wir werden hier mit dem Programm Jasp arbeiten.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-1.html",
    "href": "pages/chapters/bayesian-statistics-1.html",
    "title": "Reaktivierung: Statistikwissen",
    "section": "",
    "text": "Wichtig\n\n\n\nüëâ Daten (FancyHat.csv) herunterladen\nüëâ Jasp installieren"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-1.html#aufgabe-1",
    "href": "pages/chapters/bayesian-statistics-1.html#aufgabe-1",
    "title": "Reaktivierung: Statistikwissen",
    "section": "Aufgabe 1",
    "text": "Aufgabe 1\n√úberlegen Sie sich anhand folgenden Bildes, wie Konzepte aus der Signal Detection Theory mit statistischen Hypothesentests (NHST) zusammenh√§ngen.\n\n\n\n\n\n\n\nFragen\n\n\n\n\nWas sind Typ I und Typ II Fehler?\nWas k√∂nnte hier die Null- und Alternativhypothese sein?\nGibt es √Ñhnlichkeiten/Unterschiede zwischen der Signal Detection Theory und NHST?"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-1.html#aufgabe-2",
    "href": "pages/chapters/bayesian-statistics-1.html#aufgabe-2",
    "title": "Reaktivierung: Statistikwissen",
    "section": "Aufgabe 2",
    "text": "Aufgabe 2\nFolgende Grafik versucht, einen t-Test f√ºr unabh√§ngige Stichproben zu illustrieren. Versuchen Sie, die fehlenden Beschriftungen einzuf√ºgen.\n\n\n\n\n\n\n\n\n\n\n\nFragen\n\n\n\n\nWas ist eine Nullhypothese?\nWas ist die Bedeutung der eingef√§rbten Fl√§chen?\nWas ist die Distanz zwischen den beiden Mittelwerten?\nWas ist statistische Power?\nWelche Rolle spielt die Stichprobengr√∂√üe \\(n\\)?\nK√∂nnen Sie beschreiben, was ein p-Wert ist?\nWelche Fragen k√∂nnen Sie mit einem NUllhypothesen-Test beantworten?\n\n\n\nVielleicht hilft Ihnen folgende interaktive Grafik: Understanding Statistical Power and Significance Testing"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-1.html#sec-ttest",
    "href": "pages/chapters/bayesian-statistics-1.html#sec-ttest",
    "title": "Reaktivierung: Statistikwissen",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3\nImportieren Sie das CSV File FancyHat.csv in Jasp und f√ºhren Sie einen t-Test f√ºr unabh√§ngige Stichproben durch.\nIn dieser (fiktiven) Studie wurden Versuchspersonen in zwei Gruppen eingeteilt; eine Gruppe durfte w√§hrend einer Kreativit√§ts-Aufgabe einen fancy hat tragen, die andere Gruppe musste sich mit einer konventionellen Kopfbedeckung begn√ºgen. Die abh√§ngige Variable ist die Kreativit√§t (diese Skala ist analog zur IQ-Skala normiert, d.h. der Mittelwert ist 100 und die Standardabweichung 15).\n\n\n\n\n\n\nFragen\n\n\n\n\nWelche Fragen k√∂nnen Sie mit einem Nullhypothesen-Test beantworten?\nWas sind die Ergebnisse des t-Tests?\nWelche Fragen w√ºrden Sie gerne beantworten k√∂nnen?\nK√∂nnen Sie diese mit einem Signifikanztest beantworten?\n\n\n\n\n\n\n\n\n\nInformationen zu den Daten\n\n\n\n\n\nDie Daten wurden von generiert, basieren aber auf einer echten Studie. Beide Gruppen wurden als normalverteilte Zufallszahlen simuliert, mit einer gemeinsamen Standardabweichung von 15. Die Gruppe mit den fancy hats hat einen Mittelwert von 103, die Gruppe ohne fancy hats einen Mittelwert von 98. Die Stichprobe umfasst 50 Personen pro Gruppe. Die wurden also so simuliert, dass es einen Unterschied zwischen den Gruppen gibt, der aber klein ist.\nHier ist der R Code, um die Daten zu generieren:\n\nset.seed(12)\n\n\nfancyhats = tibble(Creativity = rnorm(50, 103, 15),\n               Group = \"Fancy Hat\")\n\nnofancyhats = tibble(Creativity = rnorm(50, 98, 15),\n                 Group = \"No Fancy Hat\")\n\nFancyHat &lt;- bind_rows(fancyhats, nofancyhats)  |&gt;\n    mutate(Group = fct_relevel(as.factor(Group), \"No Fancy Hat\"))\n\nWenn Sie in R damit einen t-Test machen wollen:\n\nlibrary(tidyverse)\n\n\nFancyHat |&gt; \n    ggplot(aes(y = Creativity, x = Group, fill = Group)) +\n    geom_boxplot(aes(y = Creativity, x = Group)) +\n    geom_jitter() +\n    scale_fill_manual(values = c(\"steelblue2\", \"#E7B800\")) +\n    labs(title= \"Box Plot of Creativity Values\") +\n    theme_bw()\n\n\n\n\nTwo-tailed t-test:\n\nfancyhat_ttest &lt;- t.test(Creativity ~ Group,\n       var.equal = TRUE,\n       data = FancyHat)\n\n\nfancyhat_ttest\n\n\n    Two Sample t-test\n\ndata:  Creativity by Group\nt = -0.63685, df = 98, p-value = 0.5257\nalternative hypothesis: true difference in means between group No Fancy Hat and group Fancy Hat is not equal to 0\n95 percent confidence interval:\n -6.779899  3.485558\nsample estimates:\nmean in group No Fancy Hat    mean in group Fancy Hat \n                  99.20888                  100.85606 \n\n\nEs mag auf den ersten Blick nicht offensichtlich sein, was wir hier gemacht haben:\n\nWir haben angenommen, dass die Daten bedingt normalverteilt sind, gegeben die Gruppenzugeh√∂rigkeit, mit gleicher Varianz. \\[\ny_{ij} \\sim \\mathcal{N}(\\mu_j, \\sigma^2)\n\\]\nWir haben drei Parameter gesch√§tzt: \\(\\mu_1\\), \\(\\mu_2\\) 1, und \\(\\sigma\\).\nWir haben die Differenz zwischen den Gruppen als \\(\\mu_1 - \\mu_2\\) berechnet. Dies gibt uns eine Sch√§tzung der Differenz zwischen den Mittelwerten 2.\nWir haben eine Teststatistik (empirischer t-Wert)3 berechnet. Dieser setzt sich aus der Mittelwertsdifferenz zusammen, geteilt durch die gemeinsame Standardabweichung der beiden Gruppen. In diese fliesst auch die Stichprobengr√∂sse ein - je gr√∂sser die Stichprobe, desto kleiner der Standardfehler und folglich desto gr√∂sser der t-Wert.\nWir haben die Wahrscheinlichkeit berechnet, einen dem Betrag nach mindestens so grossen t-Wert zu erhalten, unter der Nullhypothese, dass die Mittelwerte gleich sind (\\(\\mu_1 = \\mu_2\\))4. Dies ist ein zweiseitiger Test, d.h. wir haben keine Hypothese dar√ºber, welche Gruppe den gr√∂√üeren Mittelwert hat.\n\n\nfancyhat_ttest_tab &lt;- broom::tidy(fancyhat_ttest)\n\n\nfancyhat_ttest_tab |&gt;\n    select(estimate, estimate1, estimate2, statistic, p.value, conf.low, conf.high) |&gt;\n    round(3)\n\n# A tibble: 1 √ó 7\n  estimate estimate1 estimate2 statistic p.value conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1    -1.65      99.2      101.    -0.637   0.526    -6.78      3.49\n\n\n\n\n\n\n\n\n\n\n\nZusatzfragen\n\n\n\n\nWas sagt uns der erhaltene p-Wert?\nWas sagt uns dieser nicht?\nDer p-Wert ist 0.526. Dies ist gr√∂sser \\(\\alpha=0.05\\). Was bedeutet das? \n\nWas w√ºrden Sie einer Forscher*in raten, welche diese Studie durchgef√ºhrt hat?\n\n\n\n\n\n\n\n\n\nWeiterf√ºhrende Literatur\n\n\n\n\nFalls Sie mehr √ºber Power in neurowissenschaftlichen Studien lesen m√∂chten, empfehle ich Ihnen folgenden Artikel: Button et al. (2013).\nFalls Sie mehr √ºber t-Tests erfahren m√∂chten, empfehle ich Ihnen folgenden Artikel: Kruschke (2013)."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-1.html#aufgabe-4",
    "href": "pages/chapters/bayesian-statistics-1.html#aufgabe-4",
    "title": "Reaktivierung: Statistikwissen",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4\nAktivieren Sie das Modul ‚ÄúLearn Bayes‚Äù in Jasp.\n\nSie sehen nun in der Menuleiste das ‚ÄúLearn Bayes‚Äù Modul mit einem Dropdown Menu. W√§hlen Sie unter Counts die Option Binomial Estimation aus.\n\nBei Input Type k√∂nnen nun entweder Specify counts oder Enter sequence ausgew√§hlt werden.\n\nStellen Sie sich vor, sie untersuchen eine Person, welche behauptet, extrasensorische F√§higkeiten zu besitzen. Diese Person behauptet, dass vorhersagen kann, auf welcher Seite eine M√ºnze landet, bevor sie geworfen wurde. Sie werfen die M√ºnze 10 mal und die Person macht 7 korrekte Vorhersagen.\n\n\n\n\n\n\nFragen\n\n\n\n\nWelche Fragen k√∂nnten von Interesse sein?\nWie w√ºrden Sie die Behauptung der Person √ºberpr√ºfen?\nGlauben Sie, dass die Person √ºber extra-sensorische F√§higkeiten verf√ºgt? Sind Sie skeptisch?\n\nUnter den Dropdown Menus Model, Prior and Posterior Distributions und Plots gibt es verschiedene Checkboxes. Versuchen Sie herauszufinden, was diese bewirken.\n\nWie k√∂nnen Sie ihr Vorwissen in die Analyse einbeziehen? Wie verbinden sie ihr Vorwissen mit den beobachteten Daten?"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-1.html#footnotes",
    "href": "pages/chapters/bayesian-statistics-1.html#footnotes",
    "title": "Reaktivierung: Statistikwissen",
    "section": "Footnotes",
    "text": "Footnotes\n\nestimate1 und estimate2‚Ü©Ô∏é\nestimate‚Ü©Ô∏é\nstatistic‚Ü©Ô∏é\np.value‚Ü©Ô∏é"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-2.html",
    "href": "pages/chapters/bayesian-statistics-2.html",
    "title": "Bayesianische Parametersch√§tzung",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung:\n\nEinf√ºhrung in die Bayesianische Inferenz\nParametersch√§tzung vs Modelle vergleichen"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-2.html#bayesian-inference-in-a-nutshell",
    "href": "pages/chapters/bayesian-statistics-2.html#bayesian-inference-in-a-nutshell",
    "title": "Bayesianische Parametersch√§tzung",
    "section": "Bayesian Inference (In A Nutshell)",
    "text": "Bayesian Inference (In A Nutshell)\n\n‚ÄúProbability theory is nothing more than common sense reduced to calculation.‚Äù\n‚Äï Pierre Simon Laplace, 1819\n\nIn Bayesianischen Statistik geht es unter anderem, aber nicht nur, um die Anwendung von Bayes‚Äô Theorem.\n\n\n\n\n\n\nBayes‚Äô Theorem\n\n\n\n\n\nBayes Theorem gibt die Formel f√ºr eine bedingte Wahrscheinlichkeit an \\(P(A|B)\\). \\[ P(A|B) = \\frac{P(B|A)‚ãÖP(A)}{P(B)} \\]\nIn menschlicher Sprache: die Wahrscheinlichkeit eines Ereignisses A unter der Bedingung, dass ein Ereignis B wahr ist, ist gleich der a priori Wahrscheinlichkeit, dass A wahr ist, multipliziert mit der Wahrscheinlichkeit, dass B eintritt, wenn A wahr ist. Dividiert wird das ganze durch die Wahrscheinlichkeit, dass B eintritt, egal ob A wahr oder falsch ist.\nMan kann das auch spezifisch f√ºr Hypothesentests formulieren:\n\\[ P(Hypothesis|Data) =  \\frac{P(Data|Hypothesis) ‚ãÖ P(Data)}{P(Hypothesis)} \\]\n\n\n\nDer wesentlichste Unterschied zwischen der Bayesianischen und der frequentistischen Statistik ist, dass in der Bayesianischen Statistik die Wahrscheinlichkeitstheorie konsequent angewandt wird, um Parameter zu sch√§tzen.\n\nIn der frequentistischen Statistik wird die Wahrscheinkeitslehre vor allem angewandt, um die Wahrscheinlichkeit der Daten zu berechnen, unter der Annahme, dass die Nullhypothese wahr ist.\nIn der Bayesianischen Statistik wird die Wahrscheinkeitslehre angewandt, um die Wahrscheinlichkeit der Parameter zu berechnen.\n\nDieser Unterschied hat weitreichende Konsequenzen. So kann man in der frequentistischen Statistik Parameter sch√§tzen, aber es wird wird angenommen, dass ein Parameter einen wahren (aber unbekannten) Wert hat. Der Parameter ist aber keine Zufallszahl, und hat daher keine Wahrscheinlichkeitsverteilung. Daher darf man nicht √ºber die Wahrscheinlichkeit eines Parameters sprechen. In der Bayesianischen Statistik ist ein Parameter eine Zufallszahl, und hat daher eine Wahrscheinlichkeitsverteilung. Wir ben√ºtzen Bayes Theorem um die Wahrscheinlichkeit von Parametern zu berechnen.\nIm folgenden Kapitel werden uns (in einer sehr verk√ºrzten Form) damit besch√§ftigen, was die Konsequenzen dieser unterschiedlichen Sichtweisen sind, und wie Bayesianische Statistik funktioniert. Am Anfang m√ºssen wir jedoch eine zentral Frage beantworten: Was ist eigentlich der Unterschied zwischen Parametersch√§tzung und Modellvergleichen / Hypothesentests?\n\nModellvergleiche und Hypothesentests werden hier synomym verwendet.\nIn der frequentistischen Statistik werden diese beiden Dinge oft gemeinsam behandelt, und es ist nicht auf Anhieb klar, dass es sich um zwei unterschiedliche Dinge handelt. Dies hat vor allem damit zu tun, dass Parametersch√§tzung einfach ist, weil nur eine sogennante Punksch√§tzung erfolgt, und weil es oft um die Anwendung eines Hypothesentests geht.\nIn der Bayesianischen Statistik ist Parametersch√§tzung nicht einfach, da eine ganze Wahrscheinlichkeitsverteilung gesch√§tzt wird. Es lohnt sich, dass wir uns klarmachen, was genau Parametersch√§tzung ist. Wir werden zuerst anhand eines t-Tests anschauen, wie Parametersch√§tzung und Hypothesentests im frequentistischen Gebrauch kombiniert werden und danach anhand eines einfachen Wahrscheinlichkeitsbeispiel die Parametersch√§tzung illustrieren."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-2.html#parameter-sch√§tzen-vs-hypothesen-testen-anhand-eines-t-tests",
    "href": "pages/chapters/bayesian-statistics-2.html#parameter-sch√§tzen-vs-hypothesen-testen-anhand-eines-t-tests",
    "title": "Bayesianische Parametersch√§tzung",
    "section": "Parameter sch√§tzen vs Hypothesen testen anhand eines t-Tests",
    "text": "Parameter sch√§tzen vs Hypothesen testen anhand eines t-Tests\nMit einem t-Test wollen wir einen Mittelwertsunterschied testen. Dies bedeutet, wir wollen wissen, ob sich zwei Mittelwerte voneinander unterscheiden (wir beschr√§nken uns hier auf zwei unabh√§ngige Gruppen). Diese Frage bezieht sich auf einen Modellvergleich: Wir vergleichen ein Modell, in dem die Mittelwerte gleich sind, mit einem Modell, in dem die Mittelwerte unterschiedlich sind.\nBevor wir diesen Vergleich machen k√∂nnen, m√ºssen wir jedoch die Mittelwerte sch√§tzen. Dies ist eine Parametersch√§tzung. Im frequentistischen Ansatz benutzen wir den Stichprobenmittelwert als Sch√§tzer f√ºr den Mittelwert, der in der Population, aus der diese Stichprobe gezogen wurde, gilt.\n\n\n\n\n\n\nWie funktioniert ein frequentistischer t-Test?\n\n\n\n\n\nWir schauen uns hier noch einmal explizit das Vorgehen und die Annahmen eines t-Tests an.Mehr dazu finden Sie bei Aufgabe 3.\nWir haben zwei Gruppen, und wollen wissen, ob sich die Mittelwerte der beiden Gruppen unterscheiden.\n\nUnser statistisches Modell lautet: Alle Beobachtungen innerhalb einer Gruppe \\(j\\) sind normalverteilt. Die beiden Gruppen unterschieden wich in ihrem Mittelwert, aber die Standardabweichung \\(\\sigma\\) ist in beiden Gruppen dieselbe.\n\n\\[\ny_{ij} \\sim \\mathcal{N}(\\mu_j, \\sigma^2)\n\\]\n\\(y_{ij}\\) ist die Beobachtung \\(i\\) in Gruppe \\(j \\in \\{1, 2\\}\\). Wir interessieren uns f√ºr den Unterschied zwischen den Mittelwerten \\(\\mu_1\\) und \\(\\mu_2\\).\n\nWir sch√§tzen die Gruppenmittelwerte mittels Maximum Likelihood Sch√§tzung. In diesem Falle geht das ganz einfach; die Stichprobenmittelwerte sind Maximum Likelihood Sch√§tzer, und k√∂nnen einfach berechnet werden. Der Parameter \\(\\sigma\\) wird ebenfalls gesch√§tzt, und zwar als die gepoolte Standardabweichung \\(s_p\\). Dies ist der Parametersch√§tzungs-Schritt.\nWir berechnen eine Test Statistik. Diese basiert auf dem Mittelwertsunterschied \\(\\mu_1 - \\mu_2\\).\n\n\\[\nt = \\frac{\\bar{x_1} - \\bar{x_2}}{s_p \\sqrt{2/n}}\n\\]\n\\(s_p \\sqrt{2/n}\\) ist der Standardfehler der Differenz \\(\\bar{x_1} - \\bar{x_2}\\). Unter der Annahme, dass die Nullhypothese gilt, folgt \\(t\\) einer Student-t Verteilung. Wir k√∂nnen nun berechnen, was die Wahrscheinlichkeit w√§re, einen mindestens so extremen t-Wert zu erhalten. Diese Wahrscheinlichkeit nennt man den p-Wert. Wichtig: dies ist bereits ein Modellvergleich. Wir benutzen hier ein Modell, in dem die Mittelwerte gleich sind.\n\nWir k√∂nnen uns nun entscheiden, ob wir die Nullhypothese verwerfen oder nicht. Wir vergleichen den p-Wert mit einem vorgegebenen Signifikanzniveau \\(\\alpha\\). Wenn der p-Wert kleiner ist als \\(\\alpha\\), dann verwerfen wir die Nullhypothese. Dies bedeutet, dass wir die Tatsache, dass der p-Wert ‚Äúgen√ºgend‚Äù klein ist, als Evidenz gegen die Nullhypothese deuten.\n\n\n\n\n\n\n\nMissverst√§ndnisse √ºber p-Werte\n\n\n\np-Werte sind schwierig zu verstehen; eine sehr gute Einf√ºhrung und Erkl√§rung von Missverst√§ndnissen finden Sie im online Buch Improving Your Statistical Inferences von Daniel Lakens."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-2.html#bayesianische-parametersch√§tzung",
    "href": "pages/chapters/bayesian-statistics-2.html#bayesianische-parametersch√§tzung",
    "title": "Bayesianische Parametersch√§tzung",
    "section": "Bayesianische Parametersch√§tzung",
    "text": "Bayesianische Parametersch√§tzung\nWir werden nun einen anderen Ansatz kennenlernen: die Bayesianische Statistik. Dieser Ansatz ist nicht neu, hat aber erst in den letzten Jahren Verbreitung gefunden. Dies hat unter anderem damit zu tun, dass die Berechnungen, die f√ºr die Bayesianische Statistik n√∂tig sind, erst mit der Verf√ºgbarkeit von schnellen Computern m√∂glich wurden.\n\n\n\n\n\n\nRechenleistung\n\n\n\n\n\nBayesianische Statistik braucht sehr viel Rechenleistung, da wir durch Anwendung von Bayes Theorem die Wahrscheinlichkeitsverteilungen von Parametern sch√§tzen m√ºssen. F√ºr das nachfolgende Beispiel, in dem wir einen Parameter haben, ist dies einfach. F√ºr komplexere Modelle, mit sehr vielen Parametern, brauchen wir Methoden wie Monte Carlo Sampling, welche sehr schnelle CPU und vor allem Parallelisierung ben√∂tigen.\nMittlerweile k√∂nnen diese Rechenoperationen auf Laptops durchgef√ºhrt werden. Dies war fr√ºher jedoch nicht der Fall; zu Zeiten, in denen die Bayesianische Statistik entwickelt wurde, war dies nur auf Grossrechnern m√∂glich. Dies ist einer der Gr√ºnde, weshalb die Bayesianische Statistik erst in den letzten Jahren an Popularit√§t gewonnen hat.\n\n\n\nWir werden nun anhand eines simplen Beispiels zuerst die Bayesianische Parametersch√§tzung kennenlernen. Ich verwende als Cover Story ein Kartenspiel, da dies ein einfaches Lehrbuchbeispiel ist. Die Cover Story selber ist jedoch nicht wichtig - es geht hier darum, dass unsere beobachteten Daten bin√§r sind.\n\n\n\n\n\n\nWeitere Beispiele f√ºr bin√§re Daten\n\n\n\n\n\n\nEine M√ºnze wird geworfen. Wir wollen die Wahrscheinlichkeit sch√§tzen, dass Kopf oben liegt.\nEine Sch√ºler*in beantwortet Fragen in einer Pr√ºfung. Wir wollen die Wahrscheinlichkeit sch√§tzen, dass die Sch√ºler*in eine Frage richtig beantwortet, um daraus etwas √ºber die F√§higkeit der Sch√ºler*in zu lernen.\nWir untersuchen die Wahrnehmungsleistung einer Person, welche Signale in Rauschen entdecken soll. Wir wollen die Wahrscheinlichkeit sch√§tzen, mit der die Person ein Signal korrekt entdeckt.\nWir untersuchen Kaufentscheidungen. Wir wollen die Wahrscheinlichkeit unter verschiedenen Bedingungen sch√§tzen, mit der eine Person ein Produkt anderen Produkten vorzieht.\n\nDiese Beispiele haben also alle etwas gemeinsam: Wir haben eine bin√§re beobachtete Variable; dies bedeutet, die Variable nimmt einen von zwei m√∂glichen Zust√§nden an. Wir definieren nun einen dieser Zust√§nde als ‚ÄúErfolg‚Äù, und wollen etwas √ºber die Wahrscheinlichkeit eines Erfolgs lernen.\n\n\n\nZwei Spieler spielen ein Kartenspiel. Sie beobachten, dass sie 9 Spiele spielen und dass Spieler A 6 davon gewinnt. Jetzt m√∂chten Sie die Wahrscheinlichkeit sch√§tzen, dass Spieler A das n√§chste Spiel gewinnen wird. Anders ausgedr√ºckt, m√∂chten Sie die F√§higkeit von Spieler A einsch√§tzen, Spieler B in diesem speziellen Spiel zu besiegen.\nSie wissen, dass die Erfolgswahrscheinlichkeit im Bereich \\([0, 1]\\) liegen muss. Was Ihnen vielleicht nicht bewusst ist, ist, dass Sie ein bestimmtes Wahrscheinlichkeitsmodell annehmen und die Erfolgswahrscheinlichkeit ein Parameter dieses Modells ist. Lassen Sie uns das genauer betrachten:\nWir wissen, dass die Anzahl der \\(k\\) Erfolge in \\(n\\) Spielen einer Binomialverteilung mit den Parametern \\(n\\) und \\(\\theta\\) folgt. Wir nehmen an, dass jedes einzelne Spiel unabh√§ngig von den anderen ist und die Erfolgswahrscheinlichkeit \\(\\theta\\) f√ºr jedes Spiel gleich ist. Daher k√∂nnen wir auch jedes Kartenspiel als Bernoulli-Experiment mit dem Wahrscheinlichkeitsparameter \\(\\theta\\) betrachten.\n\\[\ny_i \\sim \\mathcal{Bernoulli}(\\theta)\n\\]\n\nIch werde im Allgemeinen die Notation \\(y\\) f√ºr eine Variable verwenden, die beobachtet wird, d.h. die Daten.\n\n\\(y_i\\) ist die \\(i\\)-te Beobachtung in den Daten, was bedeutet, dass es uns sagt, ob Spieler A das Spiel im \\(i\\)-ten Versuch gewonnen hat oder nicht. \\(\\theta\\) ist die Erfolgswahrscheinlichkeit f√ºr jedes einzelne Spiel; dies ist ein Parameter unseres Modells (\\(\\mathcal{M}\\)).\nWenn wir frequentistisch vorgehen, m√ºssen wir nun den Wert von \\(\\theta\\) so sch√§tzen, dass die Wahrscheinlichkeit, die Daten zu beobachten, maximiert wird.\n\n\n\n\n\n\nMaximum Likelihood Sch√§tzer\n\n\n\n\n\nWenn wir beobachten, dass Spieler A sechs von neun Spielen gewonnen hat, dann ist die Erfolgswahrscheinlichkeit \\(\\theta = 6/9 = 0.67\\). Dies ist der Maximum Likelihood Sch√§tzer f√ºr \\(\\theta\\).\nDieser Sch√§tzer ist die beste Punktsch√§tzung, die wir machen k√∂nnen, wenn wir nur die Daten betrachten, und kein weiteres Vorwissen ber√ºcksichtigen. Wir k√∂nnen jedoch auch andere Informationen in Betracht ziehen. Dies ist der Fall, wenn wir die Bayesianische Statistik verwenden.\nMehr Informationen zum Thema Maximum Likelihood finden Sie auf dieser interaktiven Webseite: rpsychologist.com/likelihood.\n\n\n\nWir k√∂nnen dies auch mit in R numerisch, d.h. mit der ‚Äúbrute force‚Äù Methode, berechnen:\n\nwins &lt;- 6\ngames &lt;- 9\n\nDas Ziel ist es, den ‚Äúbesten‚Äù Wert von \\(\\theta\\) zu ermitteln, d.h. den Wert, der die Wahrscheinlichkeit maximiert, die Daten zu beobachten. Um dies zu tun, m√ºssen wir eine Reihe von m√∂glichen Werten von \\(\\theta\\) in Betracht ziehen (wir wissen bereits, dass dieser Bereich \\([0, 1]\\) ist). Wir werden 101 Werte von \\(\\theta\\) zwischen 0 und 1 betrachten und die Wahrscheinlichkeit berechnen, die Daten f√ºr jeden Wert von \\(\\theta\\) zu beobachten.\n\nWarum 101? Ist willk√ºrlich, wir k√∂nnten auch 1000 oder 10000 benutzen. Je mehr Punkte wir nehmen, je feiner unser Raster, desto besser k√∂nnen wir die L√∂sung approximieren. Mehr Punkte heisst aber auch mehr Rechenoperationen, was mehr Rechenleistung ben√∂tigt.\n\nn_points &lt;- 101\ntheta_grid &lt;- seq( from=0 , to=1 , length.out = n_points )\n\nUnter der Annahme, dass beide Spieler eine gleiche Gewinnchance haben, sollte der Parameter \\(\\theta = 0.5\\) sein. Die Wahrscheinlichkeit der Daten gegeben \\(\\theta = 0.5\\) ist:\n\ndbinom(x = wins, size = games, prob = 0.5)\n\n[1] 0.1640625\n\n\nDie Wahrscheinlichkeit, 6 von 9 Spielen zu gewinnen, unter der Annahme, dass beide Spieler gleich wahrscheinlich gewinnen, ist 0.1640625.\nWir k√∂nnen auch die Wahrscheinlichkeit berechnen, dass A 6, 7, 8 oder 9 Spiele gewinnt, indem wir die kumulative Verteilungsfunktion der Binomialverteilung verwenden.\n\n1 - pbinom(q = 5, size = games, prob = 0.5)\n\n[1] 0.2539063\n\n\noder\n\npbinom(q = 5, size = games, prob = 0.5, lower.tail = FALSE)\n\n[1] 0.2539063\n\n\npbinom() gibt standardm√§ssig die Wahrscheinlichkeit, dass die Anzahl der Erfolge kleiner oder gleich dem gegebenen Wert ist. Da wir die Wahrscheinlichkeit berechnen wollen, dass die Anzahl der Erfolge gr√∂sser oder gleich dem gegebenen Wert ist, m√ºssen wir lower.tail = FALSE setzen.\n\n\n\n\n\n\np-Wert\n\n\n\n\n\nKommt Ihnen das bekannt vor?\nWenn wir unsere Null-Hypothese quantifizieren wollen, dass beide Spieler gleich wahrscheinlich gewinnen, w√ºrden wir annehmen, dass \\(\\theta=0.5\\). Die Berechnung der Wahrscheinlichkeit der Daten unter der Null ist genau das, was wir gerade getan haben. Dann setzen wir die tats√§chlichen Daten ein, d.h. 6 von 9, und die obere Schwanzwahrscheinlichkeit ist der p-Wert. In diesem Fall ist der p-Wert ungef√§hr \\(0.25\\). Mit einem Schwellenwert von 0.05 w√ºrden wir die Nullhypothese nicht ablehnen und schliessen, dass es nicht gen√ºgend Beweise daf√ºr gibt, dass Spieler A besser ist als Spieler B (dies ist ein einseitiger Test).\n\n\n\nNun berechnen wir die Wahrscheinlichkeit der Daten unter Ber√ºcksichtigung aller m√∂glichen Parameterwerte. Dies ist der entscheidende Schritt in Richtung Bayesianische Inferenz üöÄ.\nIn R ist dies sehr einfach, da alle Funktionen vektorisiert sind.\n\nlikelihood &lt;- dbinom(wins , size = games , prob = theta_grid)\n\nWir haben gerade die Wahrscheinlichkeit der Daten (genauer gesagt: A gewinnt 6 Mal in 9 Spielen) f√ºr jeden Wert von \\(\\theta\\) berechnet (genauer: f√ºr 101 Werte von \\(\\theta\\) zwischen 0 und 1). Wir k√∂nnen dies grafisch darstellen.\n\nplot(theta_grid, likelihood, xlab = expression(theta), ylab = \"likelihood\")\nlines(theta_grid, likelihood, type = \"l\", lty = 1)\n\n\n\n\nWir k√∂nnen in der obigen Abbildung sehen, dass die Wahrscheinlichkeit, die Daten zu beobachten, f√ºr viele Werte von \\(\\theta\\) klein ist. Die Wahrscheinlichkeit, die Daten zu beobachten, oder die Likelihood, ist maximal f√ºr den Wert 0.6666667:\nDiesen finden wir auch numerisch:\n\ntheta_grid[which.max(likelihood)]\n\n[1] 0.67\n\n\nWas wir bisher gemacht haben, unterstreicht den Unterschied zwischen Parametersch√§tzung und Hypothesentest. Die Berechnung der Unter- und √úberschreitungswahrscheinlichkeit unter der Nullhypothese (\\(\\theta=0.5\\)) ist ein Hypothesentest, und die Sch√§tzung von \\(\\theta\\) ist die Parametersch√§tzung.\nVorwissen\nBisher haben wir keine vorherigen Kenntnisse ber√ºcksichtigt, die wir m√∂glicherweise √ºber die wahrscheinlichsten Parameter a priori gehabt h√§tten. Tats√§chlich haben wir, wie wir etwas weiter unten sehen werden, implizit angenommen, dass alle Parameter gleich wahrscheinlich sind. Jetzt f√ºhren wir ein neues Konzept ein: eine a-priori-Verteilung f√ºr die Parameter, die wir versuchen zu sch√§tzen1.\nWir werden dann diesen a-priori-Glauben verwenden, um einen a-posteriori-Glauben √ºber die m√∂glichen Parameterwerte zu erlangen. Um dies zu tun, m√ºssen wir die a-priori-Wahrscheinlichkeit jedes Parameterwerts mit der Likelihood der Daten, d.h. mit der bedingten Wahrscheinlichkeit, die Daten zu beobachten, gegeben diesen Parameterwert, multiplizieren. Dies ist eine Anwendung des Bayes‚Äôschen Theorems:\n\\[\np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n\\]\nDies besagt, dass die a-posteriori-Wahrscheinlichkeit von \\(\\theta\\) gegeben den beobachteten Daten \\(y\\) gleich ist der Wahrscheinlichkeit der Daten, multipliziert mit der a-priori-Wahrscheinlichkeit jedes Werts von \\(\\theta\\). Sie k√∂nnen es sich so vorstellen: Jeder Parameterwert wird gewichtet, je nachdem, wie gut er die Daten vorhersagt. Das Produkt \\(p(y|\\theta) * p(\\theta)\\) wird dann durch die Wahrscheinlichkeit der Daten geteilt, die in diesem Fall √ºber alle m√∂glichen Parameterwerte summiert wird. Dieser Schritt dient dazu, die a-posteriori-Wahrscheinlichkeit zu normalisieren, so dass sie sich zu \\(1\\) aufaddiert. Dies verwandelt die unnormalisierte a-posteriori-Wahrscheinlichkeit im Grunde in eine richtige Wahrscheinlichkeitsverteilung.\n\\[\np(y) = \\sum_{\\theta}p(y|\\theta) * p(\\theta)\n\\]\nWenn wir daran interessiert sind, die Parameter eines gegebenen Modells zu sch√§tzen, k√∂nnen wir oft den (f√ºr ein Modell konstanten) normalisierenden Term \\(p(y)\\) vernachl√§ssigen. Dieser Term, oft als Evidenz bezeichnet, spiegelt die Wahrscheinlichkeit der Daten wider, gemittelt √ºber alle Parameterwerte. Ohne den normalisierenden Konstanten geschrieben, wird die Bayes-Regel oft so geschrieben:\n\\[\np(\\theta|y) \\propto  p(y|\\theta) * p(\\theta)\n\\]\n\n\n\n\n\n\nZusammenfassung\n\n\n\n\nRepr√§sentieren Sie Ihre a-priori √úberzeugung durch eine Wahrscheinlichkeitsverteilung √ºber die m√∂glichen Parameterwerte. Dies ist eine prinzipielle Methode, um mit Unsicherheit umzugehen.\nVerwenden Sie die Likelihood, um die a-priori √úberzeugung zu gewichten.\nErhalten Sie eine a-posteriori √úberzeugung √ºber die m√∂glichen Parameterwerte.\n\n\n\n\nDer Begriff belief wird im Englischen oft als Synonym f√ºr Wahrscheinlichkeitsverteilung verwendet. Ich √ºbersetze belief hier mit √úberzeugung.\nBayesianische Inferenz mit bin√§ren Daten: Ein numerisches Beispiel\nErinnern Sie sich daran, dass wir eine Sequenz von 101 Punkten zwischen 0 und 1 definiert haben, die die m√∂glichen \\(\\theta\\)-Werte darstellten.\n\nn_points &lt;- 101\ntheta_grid &lt;- seq( from=0 , to=1 , length.out = n_points )\n\nF√ºr jeden von diesen haben wir die Likelihood berechnet, das heisst die Wahrscheinlichkeit, die (festgelegten) Daten zu beobachten, gegeben den Parametern. Jetzt k√∂nnen wir unser Wissen √ºber die Wahrscheinlichkeit jedes Parameterwerts explizit machen. Zun√§chst nehmen wir an, dass alle Parameter gleich wahrscheinlich sind. Wir weisen jedem Parameterwert die Wahrscheinlichkeit 1 zu. Dies ist unsere a-priori-Verteilung.\n\nprior_1 &lt;- rep(1, length(theta_grid))\n\n\nplot(theta_grid, prior_1, \"type\" = \"l\")\n\n\n\n\nWir k√∂nnten auch die √úberzeugung ausdr√ºcken, dass Spieler A mindestens so gut ist wie Spieler B, d.h. sie sind gleich gut oder A ist besser als B. Eine M√∂glichkeit, dies zu tun, besteht darin, Parameterwerten, die gr√∂sser oder gleich \\(0.5\\) sind, eine Wahrscheinlichkeit von \\(2\\)2 zuzuweisen und den Wert \\(0\\) f√ºr Parameterwerte kleiner als \\(0.5\\).\n\nprior_2 &lt;- ifelse(theta_grid &lt; 0.5, 0, 2)\n\n\nplot(theta_grid, prior_2, type = \"l\")\n\n\n\n\nEine systematischere Methode besteht darin, eine parametrisierte Wahrscheinlichkeitsverteilung zu verwenden, die unsere √úberzeugungen √ºber den Parameter ausdr√ºckt.\n\n\n\n\n\n\nBeta-Verteilung\n\n\n\n\n\nEine Familie von Wahrscheinlichkeitsverteilungen, die f√ºr Parameter geeignet sind, die im Intervall \\([0,1]\\) liegen, ist die Beta-Verteilung. Diese Verteilung hat \\(2\\) Parameter \\(\\alpha\\) und \\(\\beta\\), die jeweils als die vorherige Anzahl von Erfolgen und die Anzahl der Misserfolge interpretiert werden k√∂nnen. Die Anzahl der Versuche betr√§gt daher \\(\\alpha + \\beta\\). Die Grafik zeigt eine Reihe von m√∂glichen Beta-Verteilungen f√ºr verschiedene Einstellungen von \\(\\alpha\\) und \\(\\beta\\). Beachten Sie, dass in R die Parameter \\(\\alpha\\) und \\(\\beta\\) als shape1 und shape2 bezeichnet werden.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.2     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlength &lt;- 1e4\nd &lt;- crossing(shape1 = c(.1, 1:4),\n           shape2 = c(.1, 1:4)) |&gt;\n  tidyr::expand(nesting(shape1, shape2),\n         x = seq(from = 0, to = 1, length.out = length)) |&gt; \n  mutate(a = str_c(\"a = \", shape1),\n         b = str_c(\"b = \", shape2),\n         group = rep(1:length, each = 25))\n\n\nd |&gt; \n  ggplot(aes(x = x, group = group)) +\n  \n  geom_line(aes(y = dbeta(x, shape1 = shape1, shape2 = shape2)),\n            color = \"steelblue4\", linewidth = 1.1) +\n  scale_x_continuous(expression(theta), breaks = c(0, .5, 1)) +\n  coord_cartesian(ylim = c(0, 3)) +\n  labs(title = \"Beta distributions\",\n       y = expression(p(theta*\"|\"*a*\", \"*b))) +\n  theme(panel.grid = element_blank()) +\n  facet_grid(b~a)\n\n\n\n\n\n\n\nWenn wir eine Beta-Verteilung verwenden wollen, um die √úberzeugung auszudr√ºcken, dass alle Werte von \\(\\theta\\) gleich wahrscheinlich sind (uniforme a-priori-Verteilung), k√∂nnen wir eine Beta-Verteilung mit \\(\\alpha = 1\\) und \\(\\beta = 1\\) verwenden.\n\nprior_3 &lt;- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\n\n\nplot(theta_grid, prior_3, type = \"l\")\n\n\n\n\nSchliesslich k√∂nnten wir folgendes Vorwissen als Beta-Verteilung ausdr√ºcken: Stellen Sie sich vor, Sie h√§tten zuvor 100 Spiele zwischen A und B beobachtet, und jeder hat die H√§lfte der Spiele gewonnen. Sie k√∂nnen nun \\(\\alpha\\) der Anzahl der von A gewonnenen Spiele und \\(\\beta\\) der Anzahl der von B gewonnenen Spiele gleichsetzen. A hat 50 Spiele gewonnen und B hat 50 Spiele gewonnen:\n\nprior &lt;- dbeta(x = theta_grid, shape1 = 50, shape2 = 50)\n\n\nplot(theta_grid, prior, type = \"l\")\n\n\n\n\nNun k√∂nnen wir unser Vorwissen und die Wahrscheinlichkeit durch elementweises Multiplizieren kombinieren. Dies bedeutet wir m√ºssen jeden Parameterwert mit der Wahrscheinlichkeit der Daten (gegeben diesen Parameter) multiplizieren.\n\n\n\n\n\n\nNote\n\n\n\nZur Erinnerung: Bayes Theorem lautet:\n\\[\np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n\\]\n\n\nIn R ist dies einfach:\n\nwins &lt;- 6\ngames &lt;- 9\n\n\nprior &lt;- dbeta(x = theta_grid, shape1 = 4, shape2 = 4)\nlikelihood &lt;- dbinom(wins , size = games , prob = theta_grid)\n\n\nunstandardized_posterior &lt;- likelihood * prior\n\nDies gibt uns die unnormalisierte Posterior-Verteilung.\n\\[\np(\\theta|y) \\propto  p(y|\\theta) * p(\\theta)\n\\]\nWir k√∂nnen diese normalisieren, indem wir sie durch die Summe der Werte teilen. Dies ist der Nenner von Bayes Theorem: \\(p(y) = \\sum_{\\theta}p(y|\\theta) * p(\\theta)\\).\nIn R k√∂nnen wir die sum() Funktion verwenden: sum(unstandardized_posterior).\n\nposterior &lt;- unstandardized_posterior / sum(unstandardized_posterior)\n\nDie normalisierte Posterior-Verteilung sieht folgendermassen aus.\n\nplot(theta_grid, posterior, type = \"l\", yaxt = 'n', ylab = 'Probability', \n        main = \"Posterior\", cex.lab = 1.5, cex.main = 3)\n\n\n\n\nUm dies wiederholbar zu machen, werden wir zwei Funktionen schreiben. Die erste, compute_posterior(), berechnet die Posterior-Verteilung, und gibt ein Dataframe zur√ºck, welches Prior, Likelihood und Posterior enth√§lt. Die zweite, plot_posterior(), plottet alle drei nebeneinander. Sie k√∂nnen auch die Maximum-Likelihood-Sch√§tzung √ºbergeben, z.B. 6/9, und diese wird ebenfalls geplottet.\n\ncompute_posterior = function(likelihood, prior){\n  # compute product of likelihood and prior\n  unstandardized_posterior &lt;- likelihood * prior\n  \n  # standardize the posterior, so it sums to 1\n  posterior &lt;- unstandardized_posterior / sum(unstandardized_posterior)\n  \n  out &lt;- tibble(prior, likelihood, posterior)\n  out\n}\n\n\nplot_posterior &lt;- function(df, mle = 6/9){\nwith(df, {\n    par(mfrow=c(1, 3))\n    plot(theta_grid , prior, type=\"l\", main=\"Prior\", col = \"dodgerblue3\", \n            lwd = 4, yaxt = 'n', ylab = 'Probability', cex.lab = 1.5, cex.main = 3)\n    plot(theta_grid , likelihood, type = \"l\", main = \"Likelihood\", col = \"firebrick3\", \n            lwd = 4, yaxt = 'n', ylab = '', cex.lab = 1.5, cex.main = 3)\n    plot(theta_grid , posterior , type = \"l\", main = \"Posterior\", col = \"darkorchid3\", \n            lwd = 4, yaxt = 'n', ylab = '', cex.lab = 1.5, cex.main = 3)\n    abline(v = mle, col = 4, lty = 2, lwd = 2)\n  } )\n}\n\nJetzt k√∂nnen Sie verschiedene a-priori-Verteilungen ausprobieren und die Auswirkungen auf die a-posteriori-Verteilung beobachten.\nWir probieren zuerst eine uniforme a-priori-Verteilung aus:\n\nprior &lt;- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\nlikelihood &lt;- dbinom(wins , size = games , prob = theta_grid)\n\n\ndf &lt;- compute_posterior(likelihood, prior)\n\n\nplot_posterior(df)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn diesem Fall stimmt die Maximum-Likelihood-Sch√§tzung mit dem Wert √ºberein, der die a-posteriori-Wahrscheinlichkeit maximiert. Dies ist der Fall, weil die Maximum-Likelihood-Sch√§tzung nur die Likelihood verwendet und keine a priori-Kenntnisse ber√ºcksichtigt. Wenn wir eine uniforme a-priori-Verteilung verwenden, bedeutet das, dass alle Werte von \\(\\theta\\) gleich wahrscheinlich sind. Mit anderen Worten haben wir keine Informationen dar√ºber, welche Werte wahrscheinlicher sind.\n\n\nJetzt probieren wir die a-priori-Verteilung aus, die die √úberzeugung ausdr√ºckt, dass Spieler A nicht schlechter sein kann als Spieler B:\n\nprior &lt;- ifelse(theta_grid &lt; 0.5, 0, 1)\nlikelihood &lt;- dbinom(wins , size = games , prob = theta_grid)\n\n\ndf &lt;- compute_posterior(likelihood, prior)\n\n\nplot_posterior(df)\n\n\n\n\nDie resultierende a-posteriori-Verteilung ist f√ºr alle Werte von \\(\\theta\\), die kleiner als 0.5 sind, gleich Null. Dies liegt daran, dass unsere a-priori-Verteilung diesen Werten eine Wahrscheinlichkeit von Null zuweist.\n\n\n\n\n\n\nHands-on\n\n\n\nProbieren Sie verschiedene a-priori-Verteilungen aus. Wie beeinflussen sie die a-posteriori-Verteilung?\n\nEine a-priori-Verteilung, die den Glauben ausdr√ºckt, dass B besser ist als A.\nEine a-priori-Verteilung, die den Glauben ausdr√ºckt, dass entweder A deutlich besser oder B deutlich besser ist.\nEine a-priori-Verteilung, die den Glauben ausdr√ºckt, dass die Spieler wahrscheinlich gleich gut sind und es unwahrscheinlich ist, dass einer viel besser ist als der andere.\n\n\n\nDie a-posteriori-Verteilung repr√§sentiert unseren Glauben an die m√∂glichen Parameterwerte, nachdem wir die Daten beobachtet haben. Man kann daher den bayesianische Inferenzprozess als eine Methode betrachten, um die √úberzeugungen unter Ber√ºcksichtigung der beobachteten Daten zu aktualisieren. Dabei werden die Wahrscheinlichkeiten √ºber die Parameterwerte neu verteilt, abh√§ngig davon, wie gut diese Parameterwerte die Daten vorhersagten.\n\n\n\n\n\n\nAnalytische L√∂sung\n\n\n\n\n\nF√ºr einige Probleme ist es m√∂glich, eine analytische L√∂sung zu finden. Die Likelihood Bernoulli/Binomial und der Beta-Prior geh√∂ren dazu.\nIn dem obigen Beispiel haben wir eine Technik namens Rasterapproximation verwendet, um die a-posteriori-Verteilung f√ºr einen Parameter zu erhalten. Das bedeutet, dass wir verschiedene Parameterwerte ausprobiert haben, indem wir ein Raster erstellt und dann die a-posteriori-Verteilung mit Hilfe der Bayes‚Äôschen Regel berechnet haben. Diese Technik wurde lediglich zu Bildungszwecken verwendet, da sie f√ºr reale Probleme nicht gut skalierbar ist. In dem einfachen Beispiel einer Abfolge bin√§rer Beobachtungen ist der interessierende Parameter (die Erfolgswahrscheinlichkeit \\(\\theta\\) bei einem Bernoulli-Versuch) zwischen \\(0\\) und \\(1\\) begrenzt (\\(\\theta \\in [0, 1]\\)). Dar√ºber hinaus gibt es nur einen Parameter, der gesch√§tzt werden soll. In komplexeren Modellen mit vielen Parametern kann die Verwendung der Rasterapproximation sehr ineffizient oder sogar unm√∂glich sein. In solchen F√§llen verwenden wir in der Regel numerische Methoden, um die a-posteriori-Verteilung anzun√§hern. Diese Methoden werden allgemein als Monte-Carlo-Stichproben oder Markov-Chain-Monte-Carlo (MCMC) bezeichnet. Mit Hilfe von MCMC erhalten wir keine analytische Beschreibung der a-posteriori-Verteilungen, sondern eine Sammlung von Zufallszahlen (Stichproben), die aus der a-posteriori-Verteilung gezogen wurden. Wir verwenden diese Stichproben, um die a-posteriori-Verteilung darzustellen.\nIn diesem speziellen Fall erhalten wir jedoch die a-posteriori-Verteilung \\(p(\\theta|y)\\) analytisch. Damit meine ich, dass, wenn wir eine Beta-Verteilung verwenden, um unseren a-priori-Glauben √ºber den Parameter \\(\\theta\\) zu beschreiben, und die Likelihood Bernoulli oder Binomial ist, die a-posteriori-Verteilung ebenfalls eine Beta-Verteilung ist.\nDies wird hier f√ºr die Binomial-Likelihood mit den Daten \\(k\\) Erfolgen in \\(N\\) Versuchen gezeigt.\n\\[\np(\\theta|k, N) = \\frac{p(y|\\theta) \\cdot p(\\theta) = \\theta^k (1-\\theta)^{N-k} \\cdot beta(\\theta|a, b)}{p(k, N)}\n\\]\nwo \\(a, b\\) die Parameters der Beta-Verteilung sind.\n\\[\np(\\theta|a, b) = beta(\\theta|a, b) = \\frac{\\theta^{a-1} (1-\\theta)^{b-1}} {B(a, b)}\n\\]\nDie Funktion \\(B(a, b)\\) ist eine Normalisierungskonstante und stellt sicher, dass die Fl√§che unter der Kurve zu \\(1\\) integriert.\n\\[\np(\\theta|k, N) = \\frac{\\theta^{(a+k)-1} (1-\\theta)^{(b+N-k)-1}} { B(a+k, b+N-k) }\n\\]\nEinfach ausgedr√ºckt:\n\n\n\n\n\n\nTip\n\n\n\nWenn die a-priori-Verteilung \\(beta(\\theta|a, b)\\) ist und die Daten \\(k\\) Erfolge in \\(N\\) Versuchen haben, dann ist die a-posteriori-Verteilung \\(beta(\\theta|a + k, b + N - k)\\).\n\n\nSie k√∂nnen daher die Parameter \\(a\\) und \\(b\\) als die vorherigen Erfolge und Misserfolge in \\(N\\) Versuchen betrachten, und diese Parameter werden durch die Beobachtung von \\(k\\) Erfolgen in \\(N\\) Versuchen aktualisiert.\nBeispiel\nDiesmal verwenden wir theta_grid nur, um die a-priori-Verteilung und die a-posteriori-Verteilung darzustellen. Angenommen, wir haben 8 Spiele beobachtet und Spieler A hat 4 davon gewonnen. Unsere a-priori-Verteilung sollte daher \\(p(\\theta|4,4)\\) sein.\n\nprior &lt;- dbeta(x = theta_grid, shape1 = 4, shape2 = 4)\n\n\nplot(theta_grid, prior, \"l\")\n\n\n\n\nWenn wir nun beobachten, dass Spieler A 3 von den n√§chsten 4 Spielen gewinnt, sollte unsere a-posteriori-Verteilung \\(p(\\theta|4+3,4+1)\\) sein.\n\nposterior &lt;- dbeta(x = theta_grid, shape1 = 7, shape2 = 5)\n\n\ntibble(prior = prior, \n       posterior = posterior, \n       theta = theta_grid) |&gt; \n  pivot_longer(c(prior, posterior), names_to = \"distribution\") |&gt; \n  ggplot(aes(theta, value, color = distribution)) +\n  geom_line(size = 2) +\n  scale_color_viridis_d(end = 0.8) +\n  ylab(\"\") +\n      theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\nWir k√∂nnen eine Funktion schreiben, die einen Beta-Prior aktualisiert, gegeben \\(k\\) Erfolgen in \\(N\\) Versuchen:\n\nupdate_beta &lt;- function(a, b, k, N) {\n  theta_grid &lt;- seq(0, 1, length = 101)\n  dbeta(x = theta_grid, shape1 = a + k, shape2 = b + N-k)\n}\n\n\nposterior &lt;- update_beta(a = 4, b = 4, k = 3, N = 4)\n\n\ntibble(prior = prior, \n       posterior = posterior, \n       theta = theta_grid) |&gt; \n  pivot_longer(c(prior, posterior), names_to = \"distribution\") |&gt; \n  ggplot(aes(theta, value, color = distribution)) +\n  geom_line(size = 2) +\n  scale_color_viridis_d(end = 0.8) +\n  ylab(\"\") +\n      theme_minimal()\n\n\n\n\n\n\n\n\nPosterior-Verteilung Zusammenfassen\nWir m√ºssen jetzt noch einen letzten Schritt machen: Wir m√ºssen die a-posteriori-Verteilung zusammenfassen. Dies k√∂nnen wir zum Beispiel tun, indem wir den Mittelwert und die Standardabweichung der a-posteriori-Verteilung berechnen.\nUm zu zeigen, wie das funktioniert, k√∂nnen wir tausend Stichproben aus der a-posteriori-Verteilung ziehen. Zuerst werden wir eine a-posteriori-Verteilung erstellen.\n\nprior &lt;- dbeta(x = theta_grid, shape1 = 1, shape2 = 1)\nlikelihood &lt;- dbinom(wins, size = games , prob = theta_grid)\n\n\ndf &lt;- compute_posterior(likelihood, prior)\n\n\nplot_posterior(df)\n\n\n\n\nNun ziehen wir 1000 Zufallszahlen aus der a-posteriori-Verteilung.\n\nDies ist vielleicht nicht ganz verst√§ndlich; Methoden wie z.B. Monte Carlo Sampling, welche f√ºr komplexe Probleme verwendet werden, generieren Zufallszahlen aus einer Verteilung, die der a-posteriori-Verteilung entspricht. Wir werden hier nicht auf die Details eingehen, aber Sie k√∂nnen sich das als eine Art ‚ÄúZufallszahlengenerator‚Äù vorstellen, der Zufallszahlen aus der a-posteriori-Verteilung generiert.\n\nn_samples &lt;- 1e3\n\nsamples &lt;- theta_grid |&gt; sample(size = n_samples, replace = TRUE, prob = df$posterior)\n\n\nhead(samples, 10)\n\n [1] 0.67 0.66 0.80 0.53 0.48 0.75 0.72 0.56 0.85 0.91\n\n\nJetzt k√∂nnen wir die Zufallszahlen zusammenfassen, zum Beispiel durch Berechnung des Mittelwerts oder der Quantile.\n\nmean(samples)\n\n[1] 0.63937\n\n\nMit dem folgenden Code erhalten wir den Median und ein 50% credible interval, das heisst ein Intervall, das 50% der Verteilungsmasse enth√§lt.\n\nquantile(samples, c(0.25, 0.5, 0.75))\n\n   25%    50%    75% \n0.5475 0.6500 0.7500 \n\n\nWir k√∂nnen diesen Ansatz auch verwenden, um ein 95% credible interval zu berechnen.\n\nquantile(samples, c(0.025, 1 - 0.025))\n\n 2.5% 97.5% \n 0.35  0.88 \n\n\n\n\n\n\n\n\nCredible interval vs Konfidenzintervall\n\n\n\nCredible interval ist ein bayesianisches Konzept, das sich von dem Konfidenzintervall unterscheidet, das wir in der frequentistischen Statistik verwenden. Ein credible interval ist ein Intervall, das eine bestimmte Wahrscheinlichkeit enth√§lt, dass der wahre Parameter innerhalb dieses Intervalls liegt. Dies sollte nicht mit dem Konfidenzintervall verwechselt werden. K√∂nnen Sie sich daran erinnern, wie ein Konfidenzintervall definiert ist? Was ist der Unterschied zwischen einem Konfidenzintervall und einem credible interval?\n\n\nWas wir bisher gemacht haben, ist, die bayessche Inferenz f√ºr die Parametersch√§tzung in einem sehr einfachen Modell zu betrachten. Nennen wir dieses Modell \\(\\mathcal{M}\\). Wir haben immer nur ein Modell betrachtet, aber im n√§chsten teil werden wir zwei oder mehrere Modelle \\(\\mathcal{M_j}\\) betrachten, die sich in den a-priori-Verteilungen unterscheiden. Dann werden wir Methoden zur Modellvergleich untersuchen, um Hypothesentests in einem bayesianischen Framework durchzuf√ºhren.\nInsbesondere werden wir uns ansehen, wie der bayesianischen Modellvergleich helfen kann, wenn wir keine signifikanten Ergebnisse haben."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-2.html#footnotes",
    "href": "pages/chapters/bayesian-statistics-2.html#footnotes",
    "title": "Bayesianische Parametersch√§tzung",
    "section": "Footnotes",
    "text": "Footnotes\n\nIn der frequentistischen Statistik ist das Konzept bedeutungslos - Parameter k√∂nnen keine Verteilung haben. In der Bayesschen Statistik sollte eine a-priori-Verteilung alles widerspiegeln, was wir √ºber den Parameter wissen, bevor wir die Daten ber√ºcksichtigen. Die a-priori-Verteilung spiegelt unseren Glauben wider, der subjektiv oder objektiv sein kann.‚Ü©Ô∏é\n2 damit die Fl√§che zwischen 0 und 1 sich zu 1 addiert.‚Ü©Ô∏é"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-3.html",
    "href": "pages/chapters/bayesian-statistics-3.html",
    "title": "Bayes Factors: Bayesianische Hypothesentests",
    "section": "",
    "text": "Daten herunterladen\n\n\n\nüëâ ExamQuestions.csv\nüëâ SmartDrug.csv"
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-3.html#absence-of-evidence-vs.-evidence-of-absence",
    "href": "pages/chapters/bayesian-statistics-3.html#absence-of-evidence-vs.-evidence-of-absence",
    "title": "Bayes Factors: Bayesianische Hypothesentests",
    "section": "Absence of Evidence vs.¬†Evidence of Absence",
    "text": "Absence of Evidence vs.¬†Evidence of Absence\nIn den Neurowissenschaftler*innen ist es wichtig zu wissen, welche experimentellen Manipulationen einen Effekt haben. Genauso wichtig ist es jedoch zu wissen, welche Manipulationen keinen Effekt haben. Diese Frage zu beantworten ist jedoch mit traditionellen statistischen Ans√§tzen schwierig. Nicht signifikante Ergebnisse sind schwer zu interpretieren: Unterst√ºtzen sie die Nullhypothese oder sind sie einfach nicht informativ?\n\n\n\n\n\n\np-Werte\n\n\n\np-Werte sind schwierig zu erkl√§ren. √úberlegen Sie sich nochmals, was man mit einem p-Wert genau aussagen kann.\n\n\nAls Beispiel dient folgendes Experiment aus dem Paper von Keysers, Gazzola, and Wagenmakers (2020). Nehmen wir an, dass der vordere cingul√§re Kortex (ACC) bei Ratten f√ºr die ‚Äúemotionale Ansteckung‚Äù entscheidend ist und dass eine Deaktivierung des ACC durch lokale Injektion von Muscimol die emotionale Ansteckung im Vergleich zur Injektion von Kochsalzl√∂sung verringern sollte.\nEin injiziertes Tier beobachtete, wie ein Artgenosse Elektroschocks erhielt, und die Erstarrung wurde als Mass f√ºr die emotionale Ansteckung gemessen. Es gab auch eine nicht-soziale Kontrollbedingung, bei der das injizierte Tier einem schock-konditionierten Ton ausgesetzt wurde. In einem solchen Experiment ist es wichtig zu zeigen, dass die Manipulation (Injektion von Muscimol) die emotionale Ansteckung reduziert, aber nicht die Erstarrung im Allgemeinen. Dies bedeutet, dass in der Kontrollbedingung keinen Unterschied zwischen den Injektionen von Muscimol und Kochsalzl√∂sung geben sollte.\nIn diesem Kapitel lernen wir nun eine alternative Methode kennen, um Evidenz zu quantifizieren: Bayes Factors. Alternativ zu p-Werten bieten Bayes Factors Evidenz f√ºr oder gegen Hypothesen. Bayes Factors sind ein kontinuierliches Mass, welches im Prinzip angibt, um wieviel wir unsere √úberzeugung f√ºr eine Hypothese √§ndern sollten, nachdem wir die Daten gesehen haben."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-3.html#bayesianische-statistik",
    "href": "pages/chapters/bayesian-statistics-3.html#bayesianische-statistik",
    "title": "Bayes Factors: Bayesianische Hypothesentests",
    "section": "Bayesianische Statistik?",
    "text": "Bayesianische Statistik?\nWir wir in der letzten Sitzungen geh√∂rt haben, ist es wichtig, zwischen Parametersch√§tzung und Hypothesentest zu unterscheiden. Parametersch√§tzung bezeichnet den Prozess, einen oder mehrere Parameter in einem Modell zu sch√§tzen. Um diese Sch√§tzung durchzuf√ºhren, m√ºssen wir eine a-priori-Verteilung der Parameterwerte angeben. Hypothesentesten ist einen Vergleich zwischen mehreren Modellen, welche sich in ihren a-priori-Verteilungen unterscheiden.\nZum Beispiel hatten wir im Kartenspiel verschiedene Vorannahmen √ºber die F√§higkeiten der Spieler A und B. Eine Vorannahme dr√ºckte z.B. unsere √úberzeugung aus, dass beide Spieler gleich gut waren, w√§hrend eine andere Vorannahme die √úberzeugung ausdr√ºckte, dass entweder Spieler A oder Spieler B besser war. Diese Vorannahmen, zusammen mit unseren Annahmen √ºber die Verteilung der Daten, bilden ein Modell \\(\\mathcal{M}\\).\nBayesianische Parametersch√§tzung\nIn der Bayesianischen Parametersch√§tzung konzentrieren wir uns auf ein Modell \\(\\mathcal{M}\\). Das Ziel unserer Inferenz ist die a-posteriori-Verteilung der Parameter \\(\\theta\\), und wir k√∂nnen diese durch Anwendung von Bayes‚Äô Theorem erhalten (unter Verwendung von Markov Chain Monte Carlo Sampling oder anderen Methoden).\n\\[\np(\\theta | y) =  p(\\theta) \\cdot \\frac{p(y | \\theta)}{p(y)}\n\\]\nWir k√∂nnen die Bayes‚Äôsche Regel umformulieren, so dass die Abh√§ngigkeit der Parameter \\(\\mathbf{\\theta}\\) vom Modell \\(\\mathcal{M}\\) eindeutig wird: \\[\np(\\theta | y, \\mathcal{M}) = \\frac{p(y|\\theta, \\mathcal{M}) \\cdot p(\\theta | \\mathcal{M})} {p(y | \\mathcal{M})}\n\\]\nwo \\(\\mathcal{M}\\) auf ein spezifisches Modell verweist. Dieses Modell wird durch die a-priori-Verteilung der Parameter \\(p(\\theta | \\mathcal{M})\\) und die Wahrscheinlichkeit der Daten \\(p(y|\\theta, \\mathcal{M})\\) bestimmt.\n\n\n\n\n\n\nWahrscheinlichkeit der Daten\n\n\n\nDie bedingte Wahrscheinlichkeit \\(p(y | \\mathcal{M})\\) gibt nun die Wahrscheinlichkeit der Daten an, gemittelt √ºber alle m√∂glichen Parameterwerte unter der Vorverteilung im Modell \\(\\mathcal{M}\\). Sie auch Modell-Evidenz genannt.\n\n\nBei der Parametersch√§tzung spielt \\(p(y | \\mathcal{M})\\) nur die Rolle eines Normalisierungsfaktors. Beim Modellvergleich ist \\(p(y | \\mathcal{M})\\) jedoch von zentraler Bedeutung.\nDie Randwahrscheinlichkeit \\(p(y | \\mathcal{M})\\) ist der Nenner aus der Bayes‚Äôschen Formel:\n\\[\np(\\theta|y) = \\frac{ p(y|\\theta) * p(\\theta) } {p(y)}\n\\]\nund ist gegeben durch: \\[\np(y | \\mathcal{M}) = \\int{p(y | \\theta, \\mathcal{M}) p(\\theta|\\mathcal{M})d\\theta}\n\\]\nDies bedeutet, dass wir die Wahrscheinlichkeit der Daten \\(p(y | \\mathcal{M})\\) erhalten, indem wir die Wahrscheinlichkeit der Daten f√ºr jeden m√∂glichen Parameterwert \\(\\theta\\) berechnen und dann √ºber alle m√∂glichen Parameterwerte mitteln.\nDie a-priori-Verteilungen f√ºr \\(\\theta\\) sind wichtig, da sie die Wahrscheinlichkeit m√∂glicher Werte von \\(\\theta\\) bestimmen.\nBayesianische Modellvergleiche\nNun wollen wir zwei verschiedene Modelle miteinander vergleichen ‚Äì wir wollen wissen, welches Modell die Daten besser erkl√§rt. Wir k√∂nnen die Bayes‚Äôsche Regel verwenden, um die Wahrscheinlichkeit der Modelle \\(\\mathcal{M1}\\) und \\(\\mathcal{M2}\\) zu berechnen (gemittelt √ºber alle m√∂glichen Parameterwerte innerhalb des Modells):\n\\[\np(\\mathcal{M}_1 | y) = \\frac{P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)}{p(y)}\n\\]\nund\n\\[\np(\\mathcal{M}_2 | y) = \\frac{P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}{p(y)}\n\\]\nEine M√∂glichkeit w√§re, das Verh√§ltnis der beiden Wahrscheinlichkeiten zu berechnen: \\(p(\\mathcal{M}_1 | y) / p(\\mathcal{M}_2 | y)\\). Dieses Verh√§ltnis wird als posterior odds bezeichnet:\n\\[\n\\frac{p(\\mathcal{M}_1 | y) = \\frac{P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)}{p(y)}} {p(\\mathcal{M}_2 | y) = \\frac{P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}{p(y)}}\n\\]\n\\(p(y)\\) k√∂nnen wir k√ºrzen, da es in oberhalb und unterhalb des Bruchstriches im Nenner vorkommt. Wir erhalten:\n\\[\n\\frac{p(\\mathcal{M}_1 | y) = P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)} {p(\\mathcal{M}_2 | y) = P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}\n\\]\nAuf der linken Seite haben wir das Verh√§ltnis der a-posteriori Wahrscheinlichkeiten der beiden Modelle. Auf der rechten Seite haben wir das Verh√§ltnis der Marginal Likelihoods der beiden Modelle, multipliziert mit den a-priori Wahrscheinlichkeiten jedes Modells. Die Marginal Likelihoods (auch bekannt als Modell-Evidenz) zeigen, wie gut jedes Modell die Daten erkl√§rt.\n\n\n\n\n\n\nMarginal Likelihoods\n\n\n\nDiese geben dar√ºber Auskunft, wie wahrscheinlich die Daten sind, wenn wir alle m√∂glichen Parameterwerte ber√ºcksichtigen. Die Marginal Likelihoods sind also die Wahrscheinlichkeit der Daten, gemittelt √ºber alle m√∂glichen Parameterwerte.\n\n\n\\[\n\\underbrace{\\frac{p(\\mathcal{M}_1 | y)} {p(\\mathcal{M}_2 | y)}}_\\text{Posterior odds} = \\underbrace{\\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}}_\\text{Ratio of marginal likelihoods} \\cdot \\underbrace{ \\frac{p(\\mathcal{M}_1)}{p(\\mathcal{M}_2)}}_\\text{Prior odds}\n\\]\n\\(\\frac{p(\\mathcal{M}_1)}{p(\\mathcal{M}_2)}\\) sind nun die Prior Odds, und \\(\\frac{p(\\mathcal{M}_1 | y)}{p(\\mathcal{M}_2 | y)}\\) sind die Posterior Odds. Diese sagen uns, welches Modell wir a-priori und a-posteriori f√ºr wahrscheinlicher halten. Da unsere a-priori √úberzeugungen aber subjektiv sein k√∂nnen, sind wir eigentlich nur an dem Verh√§ltnis der marginalen Likelihoods interessiert. Wir k√∂nnen annehmen, dass a-priori die beiden Modelle gleichwahrscheinlich sind; das heisst, wir setzen die Prior Odds auf 1 setzen. So erhalten wir\n\\[\n\\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}\n\\]\nDies ist der Bayes Factor. Falls \\(P(y | \\mathcal{M}_1)\\) gr√∂sser ist als \\(P(y | \\mathcal{M}_2)\\), dann ist der Bayes Factor gr√∂sser als 1. Falls \\(P(y | \\mathcal{M}_1)\\) kleiner ist als \\(P(y | \\mathcal{M}_2)\\), dann ist der Bayes Factor kleiner als 1. Der Bayes Factor gibt also direkt an, welches Modell die Daten besser erkl√§rt.\nWenn wir zwei Modelle \\(\\mathcal{M}_1\\) und \\(\\mathcal{M}_2\\) vergleichen, wird der Bayes Factor oftmals so geschrieben:\n\\[ BF_{12} = \\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}\\]\n\\(BF_{12}\\) ist also der Bayes Factor f√ºr \\(\\mathcal{M}_1\\) und gibt an um wieviel \\(\\mathcal{M}_1\\) die Daten besser ‚Äúerkl√§rt‚Äù.\nAls Beispiel, wenn wir ein \\(BF_{12} = 5\\) erhalten, bedeutet dies, dass die Daten 5 Mal wahrscheinlicher unter Modell 1 als unter Modell 2 aufgetreten sind. Umgekehrt, wenn \\(BF_{12} = 0.2\\), dann sind die Daten 5 Mal wahrscheinlicher unter Modell 2 aufgetreten.\nWenn wir \\(BF_{12} = 0.2\\) erhalten, ist es einfacher, Z√§hler und Nenner zu vertauschen:\n\\[ BF_{21} = \\frac{P(y | \\mathcal{M}_2)}{P(y | \\mathcal{M}_1)}\\]\nDie folgenden Interpretationen von Bayes Factors werden manchmal verwendet, obwohl es nicht wirklich notwendig ist, diese zu klassifizieren. Bayes Factors sind ein kontinuierliches Mass f√ºr Evidenz."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-3.html#hypothesentesten",
    "href": "pages/chapters/bayesian-statistics-3.html#hypothesentesten",
    "title": "Bayes Factors: Bayesianische Hypothesentests",
    "section": "Hypothesentesten",
    "text": "Hypothesentesten\nWir f√ºhren oft Modellvergleiche zwischen einer Nullhypothese \\(\\mathcal{H}_0\\) und einer alternativen Hypothese \\(\\mathcal{H}_1\\) durch (Die Begriffe ‚ÄúModell‚Äù und ‚ÄúHypothese‚Äù werden synonym verwendet). Eine Nullhypothese bedeutet, dass wir den Wert des Parameters auf einen bestimmten Wert festlegen, z.B. \\(\\theta = 0.5\\). Die alternative Hypothese bedeutet, dass wir den Wert des Parameters nicht festlegen, sondern eine a-priori Verteilung annehmen.\n\n\n\n\n\n\nAlternativhypothese\n\n\n\nIm Gegensatz zu NHST muss die Alternativhypothese spezifiziert werden. Mit anderen Worten, die Parameter m√ºssen eine a-priori Verteilung erhalten.\n\n\nIn JASP werden Bayes Factors (BF) so berichtet:\n\\[ BF_{10} = \\frac{P(y | \\mathcal{H}_1)}{P(y | \\mathcal{H}_0)}\\]\nDies ist ein BF f√ºr eine ungerichtete Alternative \\(\\mathcal{H}_1\\) gegen die Nullhypothese \\(\\mathcal{H}_0\\). Wenn wir einen gerichteten Test durchf√ºhren, dann wird der BF entweder so (\\(&gt;0\\)):\n\\[ BF_{+0} = \\frac{P(y | \\mathcal{H}_+)}{P(y | \\mathcal{H}_0)}\\]\noder so (\\(&lt;0\\)) berichtet. \\[ BF_{-0} = \\frac{P(y | \\mathcal{H}_-)}{P(y | \\mathcal{H}_0)}\\]\nWenn wir nun einen BF f√ºr die Nullhypothese wollen, k√∂nnen wir einfach den Kehrwert von \\(BF_{10}\\) nehmen:\n\\[ BF_{01} = \\frac{1}{BF_{10}}\\]\n\n\n\n\n\n\nSavage-Dickey Density Ratio\n\n\n\n\n\nWenn wir zwei genestete Modelle vergleichen, d.h. ein Modell mit 1 freiem Parameter und ein Nullmodell (in dem dieser Parameter auf einen bestimmten Wert festgelegt ist), k√∂nnen wir das Savage-Dickey Density Ratio verwenden, um den Bayes-Faktor zu berechnen.\n\nNullmodell (\\(\\mathcal{H}_0\\) or \\(\\mathcal{M}_0\\)): \\(\\theta = \\theta_0\\)\nAlternativmodell (\\(\\mathcal{H}_1\\) or \\(\\mathcal{M}_1\\)): \\(\\theta \\neq \\theta_0\\)\n\n\\(\\theta\\) braucht unter \\(\\mathcal{H}_1\\) eine a-priori Verteilung. Im Kartenspiel-Beispiel vom letzten Kapitel war dies eine Beta-Verteilung mit \\(\\alpha = 1\\) und \\(\\beta = 1\\): \\(\\theta \\sim \\text{Beta}(1, 1)\\). Diese Hypothese besagt, dass alle Parameterwerte gleich wahrscheinlich sind.\nDas Savage-Dickey Density Ratio ist eine verinfachte Methode, um einen Bayes Factor zu erhalten - wir m√ºssen einfach \\(\\mathcal{M}_1\\) betrachten, und die a-posterior Verteilung durch die a-prior Verteilung an der Stelle \\(\\theta_0\\) teilen.\nAls Beispiel: stellen Sie sich vor, dass eine Person 9 von 10 Ja/Nein Fragen korrekt beantwortet.\n\nlibrary(tidyverse)\n\n\nn_correct &lt;- 9\nn_questions &lt;- 10\n\nWir wollen wissen: wie wahrscheinlich ist es, dass die Person geraten hat (\\(\\theta=0.5\\))?\nWir nehmen nun eine uniforme a-priori Verteilung f√ºr \\(\\theta\\) an: \\[\np(\\theta) = Beta(1, 1)\n\\]\n\npd &lt;- tibble(\n    x = seq(0, 1, by = .01),\n    Prior = dbeta(x, 1, 1)\n)\nggplot(pd, aes(x, Prior)) +\n    geom_line(linewidth = 1.5) +\n    coord_cartesian(xlim = 0:1, ylim = c(0, 6), expand = 0.01) +\n    labs(y = \"Density\", x = bquote(theta))\n\n\n\n\nIm n√§chsten Schritt wenden wir Bayes Theorem an, um die a-posteriori Verteilung zu erhalten:\n\\[\np(\\theta|y) = Beta(1 + 9, 1 + 1)\n\\]\nUnser ‚ÄúTest-Wert‚Äù ist \\(Œ∏ = 0.5\\). Wir k√∂nnen nun sowohl die a-priori als auch die a-posteriori Verteilung an dieser Stelle auswerten:\nPrior:\n\n(dprior &lt;- dbeta(0.5, 1, 1))\n\n[1] 1\n\n\nPosterior:\n\n(dposterior &lt;- dbeta(0.5, 10, 2))\n\n[1] 0.1074219\n\n\nDer Bayes Factor f√ºr die Nullhypothese \\(BF_{01}\\) ist die Wahrscheinlichkeit der a-posteriori Verteilung geteilt durch die Wahrscheinlichkeit der a-priori Verteilung an der Stelle \\(\\theta_0\\):\n\nBF01 &lt;- dposterior / dprior\n\n\nBF01\n\n[1] 0.1074219\n\n\nDa eine Zahl \\(&lt;0\\) nicht so leicht interpretierbar ist, berechnen wir \\(BF_{10}\\):\n\n(BF10 &lt;- 1/BF01)\n\n[1] 9.309091\n\n\nDie Daten (9 von 10 Fragen richtig beantwortet) sind also \\(9.3\\) mal wahrscheinlicher unter der Alternativhypothese als unter der Nullhypothese.\nIn JASP wird der BF folgendermassen grafisch dargestellt. Wir plotten sowohl die a-priori als auch die a-posteriori Verteilung, und die Wahrscheinlichkeitsdichten an der Stelle \\(\\theta_0 = 0.5\\).\nDie Wahrscheinlichkeitsdichte von \\(\\theta_0\\) wird kleiner, nachdem wir die Daten ber√ºcksichtigt haben. Anders formuliert: Die Wahrscheinlichkeit von \\(\\theta_0\\) hat abgenommen, nachdem wir die Daten beobachtet haben. Dies erm√∂glicht uns zu schlussfolgern, dass die Daten (9 von 10) etwa 9 Mal wahrscheinlicher unter \\(\\mathcal{M_1}\\) sind.\n\npd &lt;- pd |&gt; \n    mutate(Posterior = dbeta(x, 1 + n_correct, 1 + (n_questions-n_correct)))\n\npdw &lt;- pd |&gt; \n  pivot_longer(names_to = \"Type\", \n               values_to = \"density\", \n               Prior:Posterior)\npdw |&gt; \n  ggplot(aes(x, density, col = Type)) +\n  geom_vline(xintercept = 0.5, linetype = \"dotted\") +\n  geom_line(linewidth = 1.5) +\n  scale_x_continuous(expand = expansion(0.01)) +\n  scale_color_viridis_d(end = 0.8) +\n  labs(y = \"Density\", x = bquote(theta)) +\n  annotate(\"point\", x = c(.5, .5), \n           y = c(pdw$density[pdw$x == .5]),\n           size = 4) +\n  annotate(\"label\",\n    x = c(.5, .5),\n    y = pdw$density[pdw$x == .5],\n    label = round(pdw$density[pdw$x == .5], 3),\n    vjust = -.5\n  )\n\n\n\n\n\nfilter(pd, x == .5) |&gt;\n  mutate(\n    BF01 = Posterior / Prior,\n    BF10 = 1 / BF01) \n\n# A tibble: 1 √ó 5\n      x Prior Posterior  BF01  BF10\n  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   0.5     1     0.107 0.107  9.31\n\n\n\n\n\n\n\n\n\n\n\nHands-on\n\n\n\nEine Student*in beantwortet 9 von 10 Fragen korrekt.\n\nWas ist die Evidenz daf√ºr, dass die Student*in geraten hat (Gl√ºck hatte)?\nWas ist die Evidenz daf√ºr, dass die Wahrscheinlichkeit einer korrekten Antwort der Student*in gr√∂sser als \\(0.5\\) ist?\n\nImportieren Sie den Datensatz ExamQuestions.csv ins JASP und f√ºhren Sie einen Bayesian binomial rate test durch."
  },
  {
    "objectID": "pages/chapters/bayesian-statistics-3.html#bayesian-t-test",
    "href": "pages/chapters/bayesian-statistics-3.html#bayesian-t-test",
    "title": "Bayes Factors: Bayesianische Hypothesentests",
    "section": "Bayesian t-Test",
    "text": "Bayesian t-Test\nUm einen Bayesianischen t-Test durchzuf√ºhren, m√ºssen wir ebenfalls Parameter sch√§tzen, und zwei Modelle miteinander vergleichen. Dies werden wir anhand zweier Beispiele in JASP demonstrieren.\n\n\n\n\n\n\nSmart Drug\n\n\n\nIn diesem Beispiel m√∂chten wir die IQ-Werte von zwei Gruppen vergleichen. Einer der Gruppen wurde ein Medikament zur Steigerung der Intelligenz verabreicht, die andere ist die Kontrollgruppe.\nImportieren Sie den Datensatz SmartDrug.csv ins JASP und f√ºhren Sie einen Bayesian t-test durch.\n\n\n\n\n\n\n\n\nHorizontal Eye Movements\n\n\n\n√ñffnen Sie den Datensatz Eye Movements in JASP: Open &gt; Data Library &gt; T-Tests &gt; Eye Movements. In diesem Datensatz wird die Anzahl erinnerter W√∂rter zwischen zwei Gruppen verglichen. In der einen Gruppe wurden die Probanden instruiert, w√§hrend der Erinnerungsphase auf einen zentralen Punkt zu fixieren; in der anderen Gruppe wurden die Probanden instruiert, horizontale Sakkaden auszuf√ºhren.\n\n\nEine sehr gute interaktive Visualisierung eines Bayesian two-sample t test finden Sie unter folgendem Link: üëâ rpsychologist.com/d3/bayes."
  },
  {
    "objectID": "pages/chapters/chatgpt.html",
    "href": "pages/chapters/chatgpt.html",
    "title": "ChatGPT",
    "section": "",
    "text": "Eventuell haben Sie in den letzten Wochen von ChatGPT geh√∂rt, vielleicht schon selber benutzt. Sowohl an Hochschulen als auch an Gymnasien stellt sich die brennende Frage, wie Lehrpersonen und Studierende/Sch√ºler damit umgehen sollen. Darf man ChatGPT benutzen? Werden die abgegeben √úbungen darauf untersucht, ob sie mit Hilfe k√ºnstlicher Intelligenz generiert wurden.\nWir versuchen hier, unsere Haltung in Bezug auf ChatGPT bekanntzugeben, und zu erkl√§ren, was ChatGPT kann, und wo es hilfreich sein k√∂nnte.\n\n\n\n\nChatGPT benutzt das Codex Modell von OpenAI, welches auf Programmiersprachen spezialisiert ist. Vor allem Python, aber auch R (und Matlab) Code spricht ChatGPT hervorragend.\n\n\n\nNein. ChatGPT besteht aus verschiedenen Komponent. Eines davon ist ein large language model (LLM), die weiteren Komponenten braucht es, um einen Chatbot zu kreieren, welcher menschen√§hnliche Konversationen f√ºhren kann.\nDas LLM hat im wesentlichen die Verteilung von Wortst√§mmen (Tokens) des Textkorpus (mit dem es trainiert wurde) gelernt. Die Aufgabe des LLM ist es, gegeben einen Input (Prompt) eine oder mehrere wahrscheinliche Vervollst√§ndigungen zu erzeugen. Wenn nun im Textkorpus Programmcode vorkam, wird das LLM syntaktisch korrekten Code zu generieren. Das LLM hat jedoch keine M√∂glichkeit, diesen Code auszuf√ºhren, auf Korrektheit zu √ºberpr√ºfen, oder √ºberhaupt herauszufinden, ob der Code sinnvoll ist.\nChatGPT kann mitunter hervorragenden Code generieren, aber ob der Code wirklich das macht, was er soll, liegt in der Verantwortung der Benutzer:in.\n\nImmer kritisch √ºberpr√ºfen, ob von ChatGPT generierter Code wirklich korrekt ist, und tut was verlangt wird!\n\n\n\n\nSie k√∂nnen ChatGPT helfen, gute Antworten zu erzeugen, in dem Sie gute Fragen stellen. Dies bedeutet, dass Sie in der Frage (Prompt) m√∂glichst viele Kontextinformationen mitliefern. Denken Sie daran, dass ChatGPT, gegeben dem Input und den Trainingsdaten, eine m√∂glichst wahrscheinliche Sequenz von Token erzeugt.\n\n\n\n\nWir gehen davon aus, dass Technologien wie ChatGPT nicht mehr vom modernen Unterricht wegzudenken sind, und es daher sinnvoll und notwendig ist, einen m√∂glichst guten Umgang damit zu erlernen.\n\n\n\n\n\n\nCaution\n\n\n\nChatGPT darf f√ºr die √úbungen genutzt werden.\n\n\nEs ist aus unserer Sicht jedoch sinnvoll, wenn Sie ChatGPT als eine von vielen m√∂glichen Quellen benutzen (wie z.B. Google, Stackoverflow), und diese auch als solche transparent angeben.\nAus unserer Sicht ist ChatGPT (und Codex) ein sehr wertvolles Tool. Sie sind jedoch daf√ºr verantwortlich, dass ihr Code ausf√ºhrbar ist. Dies wird beim Peer-Feedback eines der Kriterien sein. Das Ziel ist prim√§r, dass sie Code verstehen und anwenden k√∂nnen, nicht dass sie Code aus dem Nichts selber schreiben k√∂nnen. Dies ist √ºbrigens auch die Vorgehensweise vieler erfahrener Programmierer - oft wird zuerst mal gegoogelt und im Internet nachgeschaut, ob es schon L√∂sungsans√§tze gibt. ChatGPT macht im Prinzip nichts anderes.\n\n\n\nIm Prinzip ja, aber Sie w√ºrden dabei wahrscheinlich sehr wenig lernen. Den Umgang mit Computern und das Programmieren lernt man, indem man selber Code ausf√ºhrt, Fehler macht und versucht zu verstehen was der Fehler war. Das Ziel sollte sein, dass Sie jederzeit erkl√§ren k√∂nnten, was Ihr Code macht, oder wieso Sie ein bestimmtes Feedback gegeben haben. Ohne selber etwas daf√ºr zu tun wird der Lern efolg wahrscheinlich ausbleiben.\n\n\n\nChatGPT kann sowohl Code generieren als auch Code evaluieren. Sie k√∂nnen ChatGPT benutzen\n\num Vorschl√§ge zu erhalten, wenn Sie nicht weiterkommen.\num ein Ger√ºst f√ºr ein Programm zu erstellen.\num Code auf Lesbarkeit/Verst√§ndlichkeit zu √ºberpr√ºfen.\num Code kommentieren zu lassen.\num Code zu verstehen/bewerten zu lassen.\n\n\n\n\n\n\n\nCaution\n\n\n\nBitte √ºberpr√ºfen Sie aber immer kritisch den Output von ChatGPT, und stellen sie sicher, dass der Code tats√§chlich ausgef√ºhrt werden kann."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#was-kann-chatgpt",
    "href": "pages/chapters/chatgpt.html#was-kann-chatgpt",
    "title": "ChatGPT",
    "section": "",
    "text": "ChatGPT benutzt das Codex Modell von OpenAI, welches auf Programmiersprachen spezialisiert ist. Vor allem Python, aber auch R (und Matlab) Code spricht ChatGPT hervorragend.\n\n\n\nNein. ChatGPT besteht aus verschiedenen Komponent. Eines davon ist ein large language model (LLM), die weiteren Komponenten braucht es, um einen Chatbot zu kreieren, welcher menschen√§hnliche Konversationen f√ºhren kann.\nDas LLM hat im wesentlichen die Verteilung von Wortst√§mmen (Tokens) des Textkorpus (mit dem es trainiert wurde) gelernt. Die Aufgabe des LLM ist es, gegeben einen Input (Prompt) eine oder mehrere wahrscheinliche Vervollst√§ndigungen zu erzeugen. Wenn nun im Textkorpus Programmcode vorkam, wird das LLM syntaktisch korrekten Code zu generieren. Das LLM hat jedoch keine M√∂glichkeit, diesen Code auszuf√ºhren, auf Korrektheit zu √ºberpr√ºfen, oder √ºberhaupt herauszufinden, ob der Code sinnvoll ist.\nChatGPT kann mitunter hervorragenden Code generieren, aber ob der Code wirklich das macht, was er soll, liegt in der Verantwortung der Benutzer:in.\n\nImmer kritisch √ºberpr√ºfen, ob von ChatGPT generierter Code wirklich korrekt ist, und tut was verlangt wird!\n\n\n\n\nSie k√∂nnen ChatGPT helfen, gute Antworten zu erzeugen, in dem Sie gute Fragen stellen. Dies bedeutet, dass Sie in der Frage (Prompt) m√∂glichst viele Kontextinformationen mitliefern. Denken Sie daran, dass ChatGPT, gegeben dem Input und den Trainingsdaten, eine m√∂glichst wahrscheinliche Sequenz von Token erzeugt."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#darf-ich-chatgpt-benutzen",
    "href": "pages/chapters/chatgpt.html#darf-ich-chatgpt-benutzen",
    "title": "ChatGPT",
    "section": "",
    "text": "Wir gehen davon aus, dass Technologien wie ChatGPT nicht mehr vom modernen Unterricht wegzudenken sind, und es daher sinnvoll und notwendig ist, einen m√∂glichst guten Umgang damit zu erlernen.\n\n\n\n\n\n\nCaution\n\n\n\nChatGPT darf f√ºr die √úbungen genutzt werden.\n\n\nEs ist aus unserer Sicht jedoch sinnvoll, wenn Sie ChatGPT als eine von vielen m√∂glichen Quellen benutzen (wie z.B. Google, Stackoverflow), und diese auch als solche transparent angeben.\nAus unserer Sicht ist ChatGPT (und Codex) ein sehr wertvolles Tool. Sie sind jedoch daf√ºr verantwortlich, dass ihr Code ausf√ºhrbar ist. Dies wird beim Peer-Feedback eines der Kriterien sein. Das Ziel ist prim√§r, dass sie Code verstehen und anwenden k√∂nnen, nicht dass sie Code aus dem Nichts selber schreiben k√∂nnen. Dies ist √ºbrigens auch die Vorgehensweise vieler erfahrener Programmierer - oft wird zuerst mal gegoogelt und im Internet nachgeschaut, ob es schon L√∂sungsans√§tze gibt. ChatGPT macht im Prinzip nichts anderes."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#kann-chatgpt-f√ºr-mich-die-√ºbungen-schreiben-und-peer-feedback-geben",
    "href": "pages/chapters/chatgpt.html#kann-chatgpt-f√ºr-mich-die-√ºbungen-schreiben-und-peer-feedback-geben",
    "title": "ChatGPT",
    "section": "",
    "text": "Im Prinzip ja, aber Sie w√ºrden dabei wahrscheinlich sehr wenig lernen. Den Umgang mit Computern und das Programmieren lernt man, indem man selber Code ausf√ºhrt, Fehler macht und versucht zu verstehen was der Fehler war. Das Ziel sollte sein, dass Sie jederzeit erkl√§ren k√∂nnten, was Ihr Code macht, oder wieso Sie ein bestimmtes Feedback gegeben haben. Ohne selber etwas daf√ºr zu tun wird der Lern efolg wahrscheinlich ausbleiben."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#wie-kann-ich-chatgpt-sinnvoll-einsetzen",
    "href": "pages/chapters/chatgpt.html#wie-kann-ich-chatgpt-sinnvoll-einsetzen",
    "title": "ChatGPT",
    "section": "",
    "text": "ChatGPT kann sowohl Code generieren als auch Code evaluieren. Sie k√∂nnen ChatGPT benutzen\n\num Vorschl√§ge zu erhalten, wenn Sie nicht weiterkommen.\num ein Ger√ºst f√ºr ein Programm zu erstellen.\num Code auf Lesbarkeit/Verst√§ndlichkeit zu √ºberpr√ºfen.\num Code kommentieren zu lassen.\num Code zu verstehen/bewerten zu lassen.\n\n\n\n\n\n\n\nCaution\n\n\n\nBitte √ºberpr√ºfen Sie aber immer kritisch den Output von ChatGPT, und stellen sie sicher, dass der Code tats√§chlich ausgef√ºhrt werden kann."
  },
  {
    "objectID": "pages/chapters/data_visualization_1.html",
    "href": "pages/chapters/data_visualization_1.html",
    "title": "Grafiken erstellen mit ggplot\n",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nErstellen eines (reproduzierbaren) Data Reports mit Datenvisualisierungen zu unserem Experiment.\n\ndas Erstellen von R Markdown Files\ndas Verwenden des ggplot2-packages"
  },
  {
    "objectID": "pages/chapters/data_visualization_1.html#daten",
    "href": "pages/chapters/data_visualization_1.html#daten",
    "title": "Grafiken erstellen mit ggplot\n",
    "section": "Daten",
    "text": "Daten\nZuerst laden wir das tidyverse Package und lesen das im Ordner data_example gespeicherte .csv File ein und machen die Variable condition zu einem Faktor. Wir schauen uns die Daten mit glimpse() an. Passen Sie hierzu den Datei-Pfad an Ihren Ordner an.\n\nDer verwendete Datensatz stammt von Matejka and Fitzmaurice (2017).\n\nlibrary(tidyverse)\n\ndata &lt;- read.csv(\"data_example/DatasaurusDozen.csv\") %&gt;%\n    mutate(condition = as.factor(condition))\n\nglimpse(data)\n\nRows: 1,846\nColumns: 3\n$ condition &lt;fct&gt; away, away, away, away, away, away, away, away, away, away, ‚Ä¶\n$ value1    &lt;dbl&gt; 32.33111, 53.42146, 63.92020, 70.28951, 34.11883, 67.67072, ‚Ä¶\n$ value2    &lt;dbl&gt; 61.411101, 26.186880, 30.832194, 82.533649, 45.734551, 37.11‚Ä¶\n\n\nDatenformat\nAm einfachsten ist das plotten, wenn die Daten im long-Format vorliegen. Das bedeutet:\n\nJede Variable die gemessen/erhoben wird hat eine Spalte (z.B. Versuchspersonennummer, Reaktionszeit, Taste).\nJede Messung hat eine Zeile. In unserem PsychoPy-Experiment entspricht dies einer Zeile pro Trial.\n\nDie hier eingelesenen Daten sind schon im long-Format.\n\nFalls die Daten im wide-Format abgespeichert sind, lohnt es sich diese umzuformatieren z.B. mit pivot_longer().\nVariablen\nBevor wir weiterfahren, m√ºssen wir wissen, welche Variablen wir plotten m√∂chten und welches Skalenniveau diese Variablen haben. Je nach Anzahl Variablen und den entsprechenden Skalenniveaus eignen sich andere Grafik-Formen.\n\n\nCC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=724035\n\n\n\n\n\n\n\nHands-on\n\n\n\nSchauen Sie sich den Datensatz an.\n\nWie viele unterschiedliche Variablen gibt es?\nWie heissen die Variablen?\nWelches Skalenniveau haben sie?\n\n\n\nSubsetting\nManchmal m√∂chte man nur einen Teil der Daten plotten. Der aktuelle Datensatz enth√§lt beispielsweise verschiedene Bedingungen, jeweils mit Werten f√ºr Variable value1 und value2. Folgende 13 Bedingungen sind enthalten:\n\nunique(data$condition)\n\n [1] away       bullseye   circle     dino       dots       h_lines   \n [7] high_lines slant_down slant_up   star       v_lines    wide_lines\n[13] x_shape   \n13 Levels: away bullseye circle dino dots h_lines high_lines ... x_shape\n\n\n\n\n\n\n\n\n\n\n\n\nF√ºrs erste entscheiden wir uns f√ºr die Bedingung away.\n\ndata_away &lt;- data %&gt;%\n    filter(condition == \"away\")\n\nWir k√∂nnen f√ºr diese Bedingung zus√§tzlich summary statistics berechnen, hier Mittelwert und Standardabweichung.\n\ndata_away_summary &lt;- data %&gt;%\n    summarise(mean_v1 = mean(value1),\n              sd_v1 = sd(value1),\n              mean_v2 = mean(value2),\n              sd_v2 = sd(value2))\n\nglimpse(data_away_summary)\n\nRows: 1\nColumns: 4\n$ mean_v1 &lt;dbl&gt; 54.2657\n$ sd_v1   &lt;dbl&gt; 16.713\n$ mean_v2 &lt;dbl&gt; 47.8351\n$ sd_v2   &lt;dbl&gt; 26.84777\n\n\nDiese Werte geben Ihnen einen Anhaltspunkt, in welchem Bereich sich die Werte bewegen werden.\nPlot\nIn den folgenden Beispielen verwenden wir die Daten der Bedingung away. Wir geben in die Funktion ggplot als erstes Argument data = data_away ein.\n\nggplot(data = data_away)\n\n\n\n\nWir haben nun die Daten eingegeben, aber noch keine Formen und kein Mapping, deshalb ist die Grafik leer."
  },
  {
    "objectID": "pages/chapters/data_visualization_1.html#geom-formen",
    "href": "pages/chapters/data_visualization_1.html#geom-formen",
    "title": "Grafiken erstellen mit ggplot\n",
    "section": "Geom / Formen",
    "text": "Geom / Formen\nIn ggplot wird die Form mit geom_ hinzugef√ºgt. Beispielsweise werden mit geom_point() Punkte erstellt, mit geom_line() Linien, mit geom_boxplot Boxplots, usw. Bei der Wahl der passenden Form kommt es einerseits auf die Daten an. Sind die Daten nominal, ordinal, interval oder ratio skaliert? Wie viele Variablen werden gleichzeitig in die Grafik einbezogen? Andererseits ist es wichtig, was mit der Grafik gezeigt werden soll: Unterschiede? Gemeinsamkeiten? Ver√§nderungen √ºber Zeit?\nOft verwendete Formen sind:\n\nPunkte / Scatterplots - geom_point()\n\nLinien - geom_line()\n\n\nOder wenn zusammenfassende Werte geplottet werden sollen:\n\nHistogramme - geom_histogram()\n\nMittelwerte und Standardabweichungen - geom_pointrange()\n\nDichte - geom_density()\n\nBoxplots - geom_boxplot()\n\nViolinplots - geom_violin()\n\n\n\nEs gibt auch weitere Arten informative Arten der Darstellung wie heat maps oder shift functions, auf die wir in dieser Veranstaltung nicht eingehen.\n\n\n\n\n\n\nHands-on\n\n\n\nWelche geoms eignen sich f√ºr welches Skalenniveau und welche Variablenanzahl?\nüëâ Hier finden Sie das ggplot-Cheatsheet.\nSchauen Sie sich die verschiedenen Formen von Plots hier an.\n\n\nWenn wir nun aber\nggplot(data = data_away) +\n    geom_point()\nausf√ºhren w√ºrden, erg√§be das eine Fehlermeldung. Wir haben n√§mlich nicht angegeben, wie die Daten mit geom verbunden werden soll: Das mapping fehlt."
  },
  {
    "objectID": "pages/chapters/data_visualization_1.html#mapping",
    "href": "pages/chapters/data_visualization_1.html#mapping",
    "title": "Grafiken erstellen mit ggplot\n",
    "section": "Mapping",
    "text": "Mapping\nJede geom-Funktion in ggplot ben√∂tigt Angaben zum mapping. Damit wird definiert, wie die Variablen auf die Formen (aesthetics) gemappt werden sollen. Am einfachsten geht das, wenn wir dies zu Beginn festlegen (wir k√∂nnten es auch in der Funktion geom_ eingeben). Wir geben ein welche Variable auf der x-Achse und auf der y-Achse abgetragen werden soll. Eine weitere Variable k√∂nnten wir hier als group = ... oder color = ... einf√ºgen.\n\nggplot(data = data_away,\n       mapping = aes(x = value1,\n                     y = value2))\n\n\n\n\nJetzt k√∂nnen wir das geom hinzuf√ºgen:\n\nggplot(data = data_away,\n       mapping = aes(x = value1,\n                     y = value2)) +\n    geom_point()"
  },
  {
    "objectID": "pages/chapters/data_visualization_1.html#beschriftungen-und-themes",
    "href": "pages/chapters/data_visualization_1.html#beschriftungen-und-themes",
    "title": "Grafiken erstellen mit ggplot\n",
    "section": "Beschriftungen und Themes",
    "text": "Beschriftungen und Themes\nSch√∂nere und informativere Plots lassen sich gestalten, wenn wir einen Titel hinzuf√ºgen, die Achsenbeschriftung anpassen und das theme ver√§ndern:\n\nggplot(data = data_away,\n       mapping = aes(x = value1,\n                     y = value2)) +\n    geom_point() +\n    ggtitle (\"Ein etwas sch√∂nerer Plot\") +\n    xlab(\"Wert 1 [a.u.]\") +\n    ylab(\"Wert 2 [a.u.]\") +\n    theme_minimal()\n\n\n\n\n\nAuch theme_classic oder theme_bw eignen sich gut."
  },
  {
    "objectID": "pages/chapters/data_visualization_1.html#weitere-hilfreiche-informationen",
    "href": "pages/chapters/data_visualization_1.html#weitere-hilfreiche-informationen",
    "title": "Grafiken erstellen mit ggplot\n",
    "section": "Weitere hilfreiche Informationen",
    "text": "Weitere hilfreiche Informationen\n\nDokumentation von ggplot2\nKurzweilige, sehr informative Informationen und Videos √ºber das Erstellen von Grafiken in ggplot finden Sie hier: Website PsyTeachR: Data Skills for reproducible research\nHier ist der Start der PsyTeachR Videoliste von Lisa deBruine, dort finden sich auch hilfreiche Kurzvideos zu Themen von Daten einlesen bis zu statistischen Analysen. Beispielsweise zu Basic Plots, Common Plots und Plot Themes and Customization\nEinf√ºhrung in R von Andrew Ellis und Boris Mayer"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html",
    "href": "pages/chapters/data_visualization_2.html",
    "title": "Daten Visualisierung",
    "section": "",
    "text": "Datenvisualisierung ist ein wichtiger Schritt in der Analyse neurowissenschaftlicher Daten. Das grafische Darstellen von Informationen dient dazu die Datenkomplexit√§t zu reduzieren und wichtige Eigenschaften herauszuheben und zusammenzufassen.\nDabei geht es nicht nur darum Ergebnisse zu kommunizieren, sondern auch dazu Einsichten √ºber die Daten zu gewinnen: Auch wenn in den meisten wissenschaftlichen Artikeln nur wenige Grafiken gezeigt werden, wurden die Daten oft w√§hrend der Analyse zahlreiche Male visualisiert.\nWir schauen uns drei Kernaufgaben der Datenvisualisierung an:\nJe nachdem welchem Zweck eine Grafik dienen soll, m√ºssen andere Grafikeigenschaften ber√ºcksichtigt werden. Diagnostische Grafiken m√ºssen beispielsweise nicht sch√∂n aussehen. Eine ‚Äúgute‚Äù Grafik komprimiert die Information in den Daten so, dass Erkenntnisse gewonnen werden k√∂nnen.\nZuerst laden wir das tidyverse Package, lesen das gespeicherte .csv File ein und machen aus allen Variablen mit Text Faktoren.\n# Packages laden\nlibrary(tidyverse)\n\n# Daten einlesen (bitte den Pfad \"data_rdk/rdkdata_clean.csv\" verwenden)\ndata &lt;- read_csv(\"data_rdk/rdkdata_clean.csv\") |&gt;\n    mutate(across(where(is.character), as_factor)) |&gt;\n    mutate(id = as.factor(id))\n\n# Datensatz anschauen\ndata |&gt;\n    slice_head(n = 10)\n\n# A tibble: 10 √ó 11\n   id    trial_all block trial_inblock condition cue   direction choice response\n   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;     &lt;fct&gt;     &lt;dbl&gt;\n 1 511           0     0             0 neutral   none  right     right         1\n 2 511           1     0             1 neutral   none  left      left          0\n 3 511           2     0             2 invalid   right left      left          0\n 4 511           3     0             3 invalid   left  right     right         1\n 5 511           4     0             4 valid     right right     right         1\n 6 511           5     0             5 valid     right right     left          0\n 7 511           6     0             6 valid     right right     left          0\n 8 511           7     0             7 valid     right right     right         1\n 9 511           8     0             8 neutral   none  left      left          0\n10 511           9     0             9 neutral   none  left      right         1\n# ‚Ñπ 2 more variables: rt &lt;dbl&gt;, correct &lt;dbl&gt;"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#fehlende-werte",
    "href": "pages/chapters/data_visualization_2.html#fehlende-werte",
    "title": "Daten Visualisierung",
    "section": "Fehlende Werte",
    "text": "Fehlende Werte\nHierbei ist es wichtig, vor allem systematisch fehlende Datenpunkte zu entdecken: Fehlt bei einer Person die H√§lfte der Antworten? M√∂chten wir diese ausschliessen?\nDiese k√∂nnen mit dem Package naniar relativ schnell sichtbar gemacht werden.\n\nnaniar::vis_miss(data)\n\n\n\n\n\nBevor Sie das Package verwenden k√∂nnen, m√ºssen Sie dies erst herunterladen. Sie k√∂nnen dies unter dem Reiter Tools &gt; Install Packages ... tun oder in der Konsole mit install.packages(\"naniar\").\n\n\n\n\n\n\nHands-on\n\n\n\n\nWas sehen Sie in der Grafik?\nWeshalb fehlen nur Daten in der Reaktionszeitvariablen, aber keine in der Variable, die die Antwort angeben?\nWas ist zu tun?\n\n\n\n\n\n\n\n\n\nFehlende Werte\n\n\n\n\n\nWir hatten in √úbung 2 die response- Variable wie folgt umkodiert:\ndata &lt;- data |&gt; \n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"), \n    response = if_else(choice == \"right\", 1, 0))\nWenn wir Antworten mit ifelse kodieren, ergibt dies f√ºr keine Antwort auch die zweite Alternative (hier left). Sie k√∂nnen dies im Datensatz √ºberpr√ºfen: Alle Trials mit fehlenden Reaktionszeiten, sollten eine left-response aufweisen. Es w√§re empfehlenswerter gewesen 3 Varianten zuzulassen: right, left sowie NA.\nEin Ansatz k√∂nnte sein, dass wir die Trials, die keine Reaktionszeiten enthalten rausl√∂schen:\n\ndata &lt;- data |&gt;\n    filter(rt != \"NA\")\n\nnaniar::vis_miss(data)\n\n\n\n\nDrei wichtige Punkte:\n\nWir l√∂schen die Datenpunkte nicht aus den Rohdaten, sondern aus dem Datensatz, den wir f√ºr die Analysen verwenden. So k√∂nnen wir uns immer noch umentscheiden.\nDadurch, dass wir die Datenverarbeitung in reproduzierbarem Code geschrieben haben, konnten wir nun nachschauen, wo der Fehler entstanden ist und diesen korrigieren.\nEs macht nicht immer Sinn die Trials mit missing data zu l√∂schen! Dies muss von Fall zu Fall entschieden werden.\n\n\n\n\nWir berechnen nur f√ºr die kommenden Grafiken die Anzahl Trials pro Person, die accuracy, sowie die mittlere Reaktionszeit (wie im Kapitel Aggregierte Statistiken beschrieben).\n\nacc_rt_individual &lt;- data |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(correct),\n        accuracy = mean(correct),\n        median_rt = median(rt)\n    )\n\nNachdem wir Trials ohne Antwort ausgeschlossen haben, interessiert es uns, wie viele Trials jede Versuchsperson gel√∂st hat:\n\n# Plot: Anzahl Trials pro Bedingung f√ºr jede Versuchsperson \nacc_rt_individual |&gt; \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    theme_minimal()"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#aufgabenschwierigkeit-und-performanz-der-versuchspersonen",
    "href": "pages/chapters/data_visualization_2.html#aufgabenschwierigkeit-und-performanz-der-versuchspersonen",
    "title": "Daten Visualisierung",
    "section": "Aufgabenschwierigkeit und Performanz der Versuchspersonen",
    "text": "Aufgabenschwierigkeit und Performanz der Versuchspersonen\nBevor wir die Daten analysieren, m√∂chten wir wissen, ob die Personen die Aufgabe einigermassen gut l√∂sen konnten. In unserem Experiment erwarten wir in der neutralen Bedingung eine Genauigkeit (accuracy) √ºber dem Rateniveau von 50%. Wir plotten hierf√ºr die accuracy f√ºr jede Person und Bedingung.\n\n# Plot accuracy per person and condition\nacc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition, group = id)) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0.2, height = 0) +\n    scale_color_manual(values = c(invalid = \"tomato2\",\n                                 neutral = \"snow4\",\n                                 valid = \"skyblue3\")) +\n    labs(x = \"Cue\",\n         y = \"Proportion correct\",\n         title = \"Accuracy per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n\n\n\nUnd wir interessieren uns, wie die accuracy zwischen den Bedingungen zusammenh√§ngt. Daf√ºr f√ºgen wir Linien ein, die die accuracy- Werte pro Versuchsperson verbindet:\n\nacc_rt_individual |&gt; \n    ggplot(aes(x = condition, y = accuracy, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(invalid = \"tomato2\",\n                                 neutral = \"snow4\",\n                                 valid = \"skyblue3\")) +\n    labs(x = \"Cue\",\n         y = \"Proportion correct\",\n         title = \"Accuracy per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#extreme-datenpunkte-ausreisser",
    "href": "pages/chapters/data_visualization_2.html#extreme-datenpunkte-ausreisser",
    "title": "Daten Visualisierung",
    "section": "Extreme Datenpunkte (Ausreisser)",
    "text": "Extreme Datenpunkte (Ausreisser)\nWir k√∂nnen Visualisierungen auch verwenden, um extreme Datenpunkte zu identifizieren. Daf√ºr teilen wir hier die Accuracywerte in 3 Gruppen ein und plotten diese:\n\n# Trials nach accuracy einteilen\nacc_rt_individual_grouped &lt;- acc_rt_individual %&gt;% \n  mutate(\n    performance = case_when(\n      accuracy &gt; 0.5 ~ \"OK\",\n      accuracy &lt; 0.2 ~ \"very bad\",\n      TRUE ~ \"bad\") %&gt;% \n      factor(levels = c(\"OK\", \"bad\", \"very bad\")))\n\n# Outlier visualisieren\nacc_rt_individual_grouped %&gt;% \n    ggplot(aes(x = id, y = accuracy, color = performance, shape = performance)) +\n    geom_point(size = 2, alpha = 0.6) + \n    geom_point(data = filter(acc_rt_individual_grouped, performance != \"OK\"), \n               alpha = 0.9) + \n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray40\", \"steelblue\", \"red\")) +\n    geom_hline(yintercept = 0.5, linetype='dotted', col = 'black')+\n    annotate(\"text\", x = \"511\", y = 0.5, label = \"chance level\", vjust = -0.5, size = 3) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\nDasselbe k√∂nnte man f√ºr die Reaktionszeiten machen. Informationen dazu, wie Ausreisser in Reaktionszeiten gefunden und visualisiert werden k√∂nnen, finden Sie hier."
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#verlaufseffekte-erm√ºdung-und-lernen",
    "href": "pages/chapters/data_visualization_2.html#verlaufseffekte-erm√ºdung-und-lernen",
    "title": "Daten Visualisierung",
    "section": "Verlaufseffekte: Erm√ºdung und Lernen",
    "text": "Verlaufseffekte: Erm√ºdung und Lernen\nVerlaufseffekte k√∂nnen uns interessieren, weil wir starke Erm√ºdungs- oder Lerneffekte ausschliessen m√∂chten. Sie k√∂nnten aber auch inhaltlich interessant sein, dann w√§ren sie eher analytisch.\nIn unserem Experiment m√∂chten wir sicher sein, dass die Performanz sich nicht zu stark ver√§ndert √ºber die Zeit hinweg. Hierzu k√∂nnen wir beispielsweise die accuracy in den beiden Bl√∂cken plotten:\n\nacc_rt_individual_block &lt;- data |&gt;\n    group_by(id, condition, block) |&gt;\n    summarise(\n        accuracy = mean(correct)\n        )\n\nacc_rt_individual_block |&gt;\n    ggplot(aes(x = block, y = accuracy, group = id, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(invalid = \"tomato3\",\n                                  neutral = \"snow4\",\n                                  valid = \"skyblue3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n\n\n\n\nOder wir k√∂nnen die Reaktionszeiten √ºber die Zeit hinweg anschauen. Das tun wir hier f√ºr 3 Versuchspersonen.\n\n# Plot: Reaktionszeit √ºber die Trials hinweg (f√ºr 3 Versuchspersonen)\ndata |&gt;\n    filter(id %in% c(\"184\", \"238\", \"511\")) |&gt;\n    ggplot(aes(x = trial_all, y = rt, color = condition)) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_point(alpha = 0.5) +\n    scale_color_manual(values = c(invalid = \"tomato2\",\n                                 neutral = \"snow4\",\n                                 valid = \"skyblue3\")) +\n    facet_wrap(~ id) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\nHands-on\n\n\n\nBesprechen Sie 5 Minuten miteinander, was wir nun √ºber unsere Daten wissen.\n\nHaben die Versuchspersonen die Aufgaben l√∂sen k√∂nnen? War die Aufgabe zu einfach, zu schwierig? Denken Sie, die Personen waren motiviert?\nWelche Datens√§tze / Trials m√∂chten wir ausschliessen? (Dies m√ºsste eigentlich vor dem Anschauen der Daten entschieden werden, um zu verhindern, dass man Datenpunkte ausschliesst, welche die Hypothese nicht best√§tigen.)\nWie gut eignen sich die Daten, um die Forschungsfrage zu beantworten?\nWas k√∂nnte bei einem n√§chsten Experiment besser gemacht werden?"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#verteilung-der-rohdaten",
    "href": "pages/chapters/data_visualization_2.html#verteilung-der-rohdaten",
    "title": "Daten Visualisierung",
    "section": "Verteilung der Rohdaten",
    "text": "Verteilung der Rohdaten\nDaten von neurowissenschaftlichen Studien k√∂nnen wichtige Informationen enthalten, die ohne Grafiken √ºbersehen werden k√∂nnen (Rousselet, Pernet, and Wilcox (2017)). Das Visualisieren kann Muster zum Vorschein bringen, die durch statistische Auswertungen nicht sichtbar sind. Die Wichtigkeit von Datenvisualisierung f√ºr das Entdecken von Mustern in den Daten zeigte Francis Anscombe 1973 mit dem Anscombe‚Äôs Quartet. Dies diente als Inspiration f√ºr das Erstellen des ‚Äúk√ºnstlichen‚Äù Datensatzes DatasaurusDozen, welchen wir in der letzten Veranstaltung visualisiert haben. Verschiedene Rohwerte, k√∂nnen dieselben Mittelwerte, Standardabweichungen und Korrelationen ergeben. Nur wenn man die Rohwerte plottet erkennt man, wie unterschiedlich die Datenpunkte verteilt sind.\nDies wird ersichtlich, wenn wir die Mittelwerte und Standardabweichungen f√ºr jede Gruppe berechnen und plotten:\n\n# load DatasaurusDozen dataset (bitte den Pfad \"data_example/DatasaurusDozen.csv\" verwenden)\ndino_data &lt;- read.csv(\"data_example/DatasaurusDozen.csv\") %&gt;%\n    mutate(condition = as.factor(condition))\n\n# Plot mean and standard deviation for value 1 per condition \ndino_data |&gt;   \n    group_by(condition) |&gt;\n    summarise(mean_value1 = mean(value1),\n              sd_value1 = sd(value1)) |&gt;\n    ggplot(mapping = aes(x = mean_value1,\n                     y = condition)) +\n    geom_point() +\n    geom_errorbar(aes(xmin = mean_value1 - sd_value1, \n                      xmax = mean_value1 + sd_value1), \n                  width = 0.2) +\n    theme_minimal()\n\n\n\n\nUnd dann die Rohwerte visualisieren:\n\n# Plot raw values\ndino_data |&gt; \n    ggplot(aes(x = value1, y = value2)) +\n    geom_point(size = 1) +\n    facet_wrap(~condition) +\n    theme_minimal()\n\n\n\n\nHier sehen Sie das Ganze animiert:\n\n\nDatensatz und Visualisierung von Matejka and Fitzmaurice (2017)"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#zentrale-tendenz-und-verteilungsmasse",
    "href": "pages/chapters/data_visualization_2.html#zentrale-tendenz-und-verteilungsmasse",
    "title": "Daten Visualisierung",
    "section": "Zentrale Tendenz und Verteilungsmasse",
    "text": "Zentrale Tendenz und Verteilungsmasse\nMasse der zentralen Tendenz sind beispielsweise der Mittelwert, der Median und Modus. Wenn wir uns daf√ºr interessieren, wie sich die accuracy in Bezug auf alle Teilnehmenden verh√§lt, schauen wir uns die zentrale Tendenz √ºber alle Personen hinweg an. Es sollte nie nur die zentrale Tendenz, sondern immer auch ein passendes Verteilungsmass berichtet werden.\n\n\n\n\n\nDies k√∂nnen wir mit z.B. Boxplots tun. Diese zeigen uns den Median und die Quartile sowie Ausreisser an. Eine andere M√∂glichkeit Verteilungen anzuzeigen sind die Violinplots. Hier wurden mit geom_jitter() auch die Mittelwerte der einzelnen Personen im Plot eingef√ºgt.\n\n# Boxplot\np_boxplot &lt;- acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n    geom_boxplot(alpha = .5) +\n    geom_jitter(alpha = .25, width = .2) +\n    scale_fill_manual(values = c(invalid = \"tomato3\",\n                                 neutral = \"snow3\",\n                                 valid = \"skyblue3\")) +\n    labs(x = \"Cue\",\n         y = \"Proportion correct\",\n         title = \"Accuracy per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n# Violin Plot\np_violin &lt;- acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n    geom_violin(alpha = .5) +\n    geom_jitter(alpha = .25, width = .2) +\n    scale_fill_manual(values = c(invalid = \"tomato3\",\n                                 neutral = \"snow3\",\n                                 valid = \"skyblue3\")) +\n    labs(x = \"Cue\",\n         y = \"Proportion correct\",\n         title = \"Accuracy per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n# Kombinieren von 2 Plots in einer Grafik\nlibrary(patchwork)\np_boxplot + p_violin\n\n\n\n\nHier finden Sie weitere Code-Beispiele f√ºr das Plotten von Verteilungsmassen."
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#aggregierte-statistiken",
    "href": "pages/chapters/data_visualization_2.html#aggregierte-statistiken",
    "title": "Daten Visualisierung",
    "section": "Aggregierte Statistiken",
    "text": "Aggregierte Statistiken\nWie in die Kapitel Aggregierte Statistiken berechnen wir nun den Mittelwert und den within-subject Standardfehler f√ºr unseren Datensatz.\n\ndatasum_3 &lt;- data |&gt;\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\ndatasum_3 |&gt;\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=4, fill=\"white\") +\n    theme_minimal(base_size = 12)\n\n\n\n\nHier finden Sie Informationen, wie die Reaktionszeiten zusammengefasst und visualisiert werden k√∂nnten."
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#visualisieren-von-modellsch√§tzungen",
    "href": "pages/chapters/data_visualization_2.html#visualisieren-von-modellsch√§tzungen",
    "title": "Daten Visualisierung",
    "section": "Visualisieren von Modellsch√§tzungen",
    "text": "Visualisieren von Modellsch√§tzungen\nWenn f√ºr die statistische Analyse ein Modell gesch√§tzt wurde, kann auch dies visualisiert werden. Auf diese Form der Visualisierung wird hier aber nicht eingegangen. Wir lernen dies im Rahmen der noch kommenden Versanstaltungen kennen."
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#beschriftungen",
    "href": "pages/chapters/data_visualization_2.html#beschriftungen",
    "title": "Daten Visualisierung",
    "section": "Beschriftungen",
    "text": "Beschriftungen\nDie genaue Beschriftung und deren Lesbarkeit ist f√ºr diese Form von Grafiken zentral. Achten Sie sich auf Folgendes:\n\nDie Achsenbeschriftungen enthalten die verwendete Variable in Klartext (nicht den R Variablennamen) und wenn zutreffend auch die Masseinheit (z.B. Response Time [ms]).\nFarben / Formen usw. werden in einer Legende den Gruppen zugeordnet (Ausnahme: wenn Daten von einzelnen Personen geplottet werden, wird die Versuchspersonennummer nicht aufgef√ºrt).\nMasse der zentralen Tendenz und Varianzmasse werden beschrieben (z.B. Standardfehler oder Standardabweichung?)\n\nBeschriftungen k√∂nnen Sie einf√ºgen mit labs().\n\np_boxplot +\nlabs(x = \"hier kommt Label x [Masseinheit]\", \n     y = \"hier kommt Label y [Masseinheit]\",\n     title = \"Der Titel der Grafik\", \n     subtitle = \"Der Subtitel der Grafik\",\n     caption = \" Hier kommt eine Caption\")\n\n\n\n\n\n\n\n\n\n\nHands-on\n\n\n\nErstellen Sie ein Grafik. F√ºgen Sie mit labs() passende Beschriftungen hinzu. Gibt es noch weitere, oben nicht verwendete Optionen?"
  },
  {
    "objectID": "pages/chapters/data_visualization_2.html#merkmale-einer-guten-grafik",
    "href": "pages/chapters/data_visualization_2.html#merkmale-einer-guten-grafik",
    "title": "Daten Visualisierung",
    "section": "5 Merkmale einer guten Grafik",
    "text": "5 Merkmale einer guten Grafik\nEs gibt unz√§hlige Optionen die eigenen Daten zu visualisieren. Folgende Prinzipien helfen beim Erstellen einer informativen Grafik, die zur Kommunikation der Ergebnisse dient.\n\nDie Punkte 3-5 wurden aus dem Buch ‚ÄúThe Visual Display of Quantitative Information‚Äù von Edward Tufte, 1986 entnommen: Link.\n1. Eine Frage beantworten\nJede Grafik sollte mindestens eine teilweise aber auch mehrere Fragen beantworten.\nüëâ Welche Frage m√∂chte ich beantworten? Welche Form der Visualisierung beantwortet diese Frage am besten?\nHierbei kann es hilfreich sein den ‚ÄúArbeitstitel‚Äù der Grafik als Frage zu formulieren.\n2. Zielgruppe ber√ºcksichtigen\nBeim Erstellen der Grafik sollte beachtet werden, an wen sich die Grafik richtet. F√ºr eine Pr√§sentation m√ºssen die Achsenbeschriftungen vergr√∂ssert und die Grafik simpel gehalten werden. In einem wissenschaftlichen Artikel kann die Grafik komplexer gestaltet werden, da die Lesenden sich mehr Zeit zum Anschauen nehmen k√∂nnen. Zudem sollten hier die Vorgaben des Journals ber√ºcksichtigt werden. Auch wichtig ist das Verwenden von ‚Äúfarbenblind-freundlichen‚Äù Palletten, rot und gr√ºn ist z.B. eine schlechte Wahl.\nüëâ F√ºr welchen Zweck / f√ºr wen erstelle ich die Grafik? Wie ist das Vorwissen des Zielpublikums?\n\nF√ºr einen Fachartikel lohnt es sich, zu Beginn die Vorgaben der Fachzeitschrift zu ber√ºcksichtigen.\n3. Die Daten zeigen\nDas t√∂nt simpel, wird aber oft nicht ber√ºcksichtigt. Bei einer Grafik geht es in erster Linie um die Daten. Es sollte die simpelste Form gew√§hlt werden, welche die Informationen vermittelt. Oft braucht es keine ausgefallenen Grafikideen oder neuartigen Formate. Hierbei ist es wichtig, die Art der Daten zu ber√ºcksichtigen: Wie viele Variablen sind es? Sind diese kontinuierlich (z.B. Reaktionszeiten) oder diskret (z.B. Experimentalbedingungen)? Wie viele Dimensionen haben meine Daten? Mit zwei Achsen lassen sich zwei Dimensionen darstellen, zus√§tzlich k√∂nnen mit Farben und Formen noch weitere Dimensionen abgebildet werden (z.B. Millisekunden, Bedingung 1 und Bedingung 2). Es k√∂nnen Rohwerte geplottet werden oder summary statistics (z.B. Mittelwerte, Standardabweichungen)\nüëâ Welche Art Grafik eignet sich f√ºr meine Frage und meine Daten? Schauen Sie z.B. hier nach oder nutzen Sie das esquisse-Package.\n\nBeispiele f√ºr verschiedenen Plots in R sind z.B. histogram, boxplot, violin plot, scatter plot / correlogram, jitter plot, raincloud plot, percentiles / shift functions, area chart, heat map.\n4. Optimieren des data-ink ratios\nDas Daten-Tinte-Verh√§ltnis sollte so optimal wie m√∂glich sein. Das bedeutet, das idealerweite jeder Strich, jeder Punkt, jedes Textfeld Information beinhaltet. Alles was keine Information transportiert oder nur wiederholt kann weggelassen werden.\nüëâ Was kann ich weglassen?\n\nIn R kann zum Schluss des Plots + theme_minimal() hinzugef√ºgt werden, dies entfernt u.a. den grauen Hintergrund. Das Grau des Hintergrunds ist Farbe (ink), welche keine Information transportiert, das Weglassen l√§sst die Grafik ruhiger wirken.\n5. Feedback einholen und revidieren\nDas Erstellen einer guten Grafik ist iterativ, das heisst, sie wird immer wieder √ºberarbeitet, bis sie die Information m√∂glichst einfach, genau aber klar kommuniziert. Hierbei ist Feedback oft unerl√§sslich.\nüëâ Was denken andere √ºber Ihre Grafik?"
  },
  {
    "objectID": "pages/chapters/datacamp.html",
    "href": "pages/chapters/datacamp.html",
    "title": "DataCamp",
    "section": "",
    "text": "Im Rahmen dieser Lehrveranstaltung k√∂nnen alle Teilnehmende sich bei DataCamp registrieren\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL an. DataCamp Kurse auf unterschiedlichen Niveaus an; sowohl f√ºr Anf√§nger als auch f√ºr Fortgeschrittene gibt es ein breites Angebot an Kursen.\nSie k√∂nnen Sich unter folgendem Link mit Ihrer Uni Bern E-Mail Adresse (*unibe.ch) registrieren:\nüëâüèº DataCamp registration"
  },
  {
    "objectID": "pages/chapters/datacamp.html#datacamp",
    "href": "pages/chapters/datacamp.html#datacamp",
    "title": "DataCamp",
    "section": "",
    "text": "Im Rahmen dieser Lehrveranstaltung k√∂nnen alle Teilnehmende sich bei DataCamp registrieren\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL an. DataCamp Kurse auf unterschiedlichen Niveaus an; sowohl f√ºr Anf√§nger als auch f√ºr Fortgeschrittene gibt es ein breites Angebot an Kursen.\nSie k√∂nnen Sich unter folgendem Link mit Ihrer Uni Bern E-Mail Adresse (*unibe.ch) registrieren:\nüëâüèº DataCamp registration"
  },
  {
    "objectID": "pages/chapters/datacamp.html#hands-on-session",
    "href": "pages/chapters/datacamp.html#hands-on-session",
    "title": "DataCamp",
    "section": "Hands-on session",
    "text": "Hands-on session\nWir werden in der zweiten Sitzung mit Psychopy und Python ein Experiment erstellen. In Psychopy k√∂nnen Sie viel sehr √ºber die grafische Oberfl√§che; es gibt jedoch einige kleine Dinge, welche wir mit Python selber coden m√ºssen. Deshalb w√§re es f√ºr Sie hiflreich, wenn Sie sich vorher auf der DataCamp Website ein wenig mit Python vertraut machen.\n\n1 - Python Basics\nJe nachdem wie viel Erfahrung Sie mit Python haben, k√∂nnen Sie sich entweder f√ºr den Kurs ‚ÄúIntroduction to Python‚Äù oder ‚ÄúIntermediate Python‚Äù entscheiden.\nüëâüèº Introduction to Python\nüëâüèº Intermediate Python\nF√ºr fortgeschrittene empfehlen wir die Kurse:\nüëâüèº Python Data Science Toolbox (Part 1)\nüëâüèº Python Data Science Toolbox (Part 2)\nDiese Kurse sind nicht obligatorisch; Sie brauchen f√ºr PsychoPy wirklich nur Grundkenntnisse. Python ist aber sowohl in der Forschung als der Privatwirtschaft sehr beliebt und Sie werden es sicherlich noch √∂fters brauchen, wenn Sie sich mit Datenanalyse besch√§ftigen.\n\n\n2 - Python Code mit ChatGPT generieren\nDies ben√∂tigt einen ChatGPT Account; einen solchen k√∂nnen Sie bei OpenAI gratis erstellen.\nüëâüèº chat.openai.com/chat\nVersuchen Sie, mit ChatGPT ein paar Zeilen Python Code zu generieren. Sie k√∂nnen hierzu einige Beispiele als den DataCamp Kursen verwenden.\n\nKann ChatGPT die Aufgaben l√∂sen?\nWie kann Ihnen ChatGPT helfen, Code zu schreiben?\nWas m√ºssen Sie beachten, wenn Sie Code von ChatGPT verwenden?"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html",
    "href": "pages/chapters/experiment_stepbystep.html",
    "title": "Experiment erstellen: Step by step",
    "section": "",
    "text": "Schauen Sie sich in PsychoPy die verschiedenen m√∂glichen Bausteine f√ºr Experimente an. Versuchen Sie St√ºck f√ºr St√ºck das Experiment von Mulder et al. (2012) nachzubauen."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#allgemeine-informationen-zu-psychopy",
    "href": "pages/chapters/experiment_stepbystep.html#allgemeine-informationen-zu-psychopy",
    "title": "Experiment erstellen: Step by step",
    "section": "Allgemeine Informationen zu PsychoPy",
    "text": "Allgemeine Informationen zu PsychoPy\nHilfreiche Informationen zum Erstellen von Experimenten in PsychoPy finden Sie hier:\n\nPsychoPy Website\nWalk-through: Builder\nDiskussionsforum"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#random-dot-stimulus",
    "href": "pages/chapters/experiment_stepbystep.html#random-dot-stimulus",
    "title": "Experiment erstellen: Step by step",
    "section": "1. Random Dot Stimulus",
    "text": "1. Random Dot Stimulus\nErstellen Sie einen Random Dot Stimulus. Beachten Sie folgende Aspekte:\n\nTiming (Stimulusdauer): 1500 ms\nFarbe\nGr√∂sse: gut sichtbar\nKoh√§renz: 0.08\nField size: 75% des Displays\n\n(Die Bewegungsrichtung k√∂nnen Sie noch vernachl√§ssigen.)"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#trialschleife",
    "href": "pages/chapters/experiment_stepbystep.html#trialschleife",
    "title": "Experiment erstellen: Step by step",
    "section": "2. Trialschleife",
    "text": "2. Trialschleife\nErstellen Sie eine Trial-Schleife.\n\nFixation 1 (100/350/800/1200 ms) (Zur Vereinfachung k√∂nnen Sie hier auch nur einen Wert w√§hlen.)\nCue (1000 ms)\nFixation 2 (3400/4000/4500/5000 ms) (Zur Vereinfachung k√∂nnen Sie hier auch nur einen Wert w√§hlen.)\nDots (1500 ms)\nFeedback\nTiming (ITI: Inter-Trial-Intervall)\nAntwort der Versuchsperson aufnehmen\n\n(Die Variation der Bewegungsrichtung und des Vorwissens k√∂nnen Sie noch vernachl√§ssigen.)"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#bedingungen",
    "href": "pages/chapters/experiment_stepbystep.html#bedingungen",
    "title": "Experiment erstellen: Step by step",
    "section": "3. Bedingungen",
    "text": "3. Bedingungen\n\nVariieren Sie die Bewegungsrichtung der Random Dots mit dem conditions.csv file: Bewegungsrichtung ist zu 50% rechts, zu 50% links.\nVariieren Sie den Cue f√ºrs Vorwissen in jedem Trial mit dem conditions.csv file: Der Cue kann valide (4x), invalide (2x) oder neutral (4x) sein. Die Bewegungsrichtungen m√ºssen auf alle Bedingungen gleich verteilt sein."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#instruktion-und-debriefing",
    "href": "pages/chapters/experiment_stepbystep.html#instruktion-und-debriefing",
    "title": "Experiment erstellen: Step by step",
    "section": "4. Instruktion und Debriefing",
    "text": "4. Instruktion und Debriefing\n\nF√ºgen Sie zu Beginn des Experiments eine Instruktion hinzu.\nF√ºgen Sie am Ende des Experiments ein Debriefing hinzu."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#test",
    "href": "pages/chapters/experiment_stepbystep.html#test",
    "title": "Experiment erstellen: Step by step",
    "section": "5. Test",
    "text": "5. Test\nF√ºhren Sie das Experiment aus und schauen Sie sich den Datensatz an: Sind die untenstehenden Infos auf jeder Zeile vorhanden?\n\nVersuchspersonennummer\nRichtung des Stimulus\nCue / Vorwissen\nAntwort der Versuchsperson\nAntwortdauer der Versuchsperson"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#√ºbungsexperiment",
    "href": "pages/chapters/experiment_stepbystep.html#√ºbungsexperiment",
    "title": "Experiment erstellen: Step by step",
    "section": "6. √úbungsexperiment",
    "text": "6. √úbungsexperiment\n\nLaden Sie hier das Experiment f√ºr √úbung 1 herunter.\nVergleichen Sie das Experiment mit Ihrer Version, was f√§llt Ihnen auf?"
  },
  {
    "objectID": "pages/chapters/functions-loops.html",
    "href": "pages/chapters/functions-loops.html",
    "title": "Automatisieren",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nConditionals und Control Flow\nFunktionen erstellen\nLoops anwenden\nWir nun zwei Programmierkonzepte kennenlernen, die uns dabei helfen, Tasks zu automatisieren. Wir werden hier nicht in die Tiefe gehen; es geht uns vielmehr darum, Ihnen einen √úberblick zu geben, was Sie mit diesen Konzepten machen k√∂nnen. Falls Sie tiefer in die Materie einsteigen m√∂chten, gibt es entsprechende Kurse auf Datacamp."
  },
  {
    "objectID": "pages/chapters/functions-loops.html#alternativen-zu-for-loops",
    "href": "pages/chapters/functions-loops.html#alternativen-zu-for-loops",
    "title": "Automatisieren",
    "section": "Alternativen zu for-Loops",
    "text": "Alternativen zu for-Loops\nEs gibt in R mehrere M√∂glichkeiten, um √ºber Vektoren oder Listen zu iterieren, ohne dabei explizite for-Loops zu schreiben. Dies hat den Vorteil, dass der Code k√ºrzer und √ºbersichtlicher wird.\n\nlapply und sapply\n\nlapply und sapply sind zwei Funktionen, welche √ºber Listen iterieren. lapply und sapply sind sehr √§hnlich. lapply gibt eine Liste zur√ºck, w√§hrend sapply eine Liste retournieren kann.\nAls Beispiel wollen wir jedes Element eines Vektors verdoppeln (dies kann in R auch einfacher gemacht werden, aber dies ist nur ein √úbungsbeispiel).\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nMit for k√∂nnen wir dies wie folgt tun.\n\nfor (number in numbers) {\n    print(number * 2)\n}\n\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 10\n\n\nMit lapply und sapply haben wir zwei M√∂glichkeiten. Wir k√∂nnen entweder eine anonyme Funktion definieren, oder wir k√∂nnen eine Funktion zuerst definieren, und dann verwenden.\n\\(x) x * 2 definiert eine sogenannte anonyme Funktion. Diese Funktion nimmt ein Argument x und multipliziert es mit 2, erh√§lt aber keinen eigenen Namen. Folglich k√∂nnen wir diese Funktion nicht wiederverwenden.\n\nlapply(numbers, \\(x) x * 2)\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\nMit einer Funktion, die wir zuerst definieren, sieht unser Beispiel so aus.\n\ndouble &lt;- function(x) {\n    x * 2\n}\n\n\nlapply(numbers, double)\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\n\nsapply(numbers, double)\n\n[1]  2  4  6  8 10\n\n\nmap\nEine weitere M√∂glichkeit, √ºber Listen zu iterieren, ist die Funktion map. map ist eine Funktion aus dem Paket purrr (wird automatisch geladen, wenn tidyverse geladen wird). map gibt immer eine Liste zur√ºck.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.1     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nnumbers |&gt; map(double)\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\nWenn wir als Output einen Vektor haben wollen, m√ºssen wir die Funktion unlist() verwenden.\n\nnumbers |&gt; map(double) |&gt; unlist()\n\n[1]  2  4  6  8 10"
  },
  {
    "objectID": "pages/chapters/functions_and_loops-2.html",
    "href": "pages/chapters/functions_and_loops-2.html",
    "title": "Funktionen und Schleifen",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nMehrere Datens√§tze importieren\nEine Schleife (loop) zu schreiben\nEine eigene Funktion schreiben"
  },
  {
    "objectID": "pages/chapters/functions_and_loops-2.html#schleifen-loops",
    "href": "pages/chapters/functions_and_loops-2.html#schleifen-loops",
    "title": "Funktionen und Schleifen",
    "section": "Schleifen (loops)",
    "text": "Schleifen (loops)\nSchleifen erm√∂glichen das x-beliebige Wiederholen eines Schrittes z.B. statt dem einzelnen Einlesen eines Datensatzes, werden alle Datens√§tze in einem Ordner eingelesen auf einmal eingelesen.\nUm mehrere Datens√§tze einzulesen ben√∂tigen wir:\n\nEine Liste aller Datens√§tze, die man einlesen m√∂chte\nEine Schleife, die besagt, dass wir f√ºr jedes Objekt in der Liste etwas machen m√∂chten\nEine Aufgabe, die wir mit jedem Objekt ausf√ºhren m√∂chten\n\nMit einer Schleife sagt man dem Programm ‚ÄúF√ºhre f√ºr jeden Datensatz dieser Liste folgendes durch: Lade den Datensatz.‚Äù\nEine Schleife wird in R wie folgt formuliert:\n\nfor (var in seq){\n    expr\n}\n\nMit var ist eine Variable in einer Sequenz seq gemeint. Bei uns w√§re die Variable ein Name eines Datensatzes, und die Sequenz w√§re eine Liste mit Datens√§tzen (z.B. alle Files in einem Ordner). expr meint expression, also was wir mit dieser Variable tun wollen, in unserem Beispiel wollen wir den Datensatz √∂ffnen.\n\n\n\nInhalt\nBsp. Datensatz einlesen\n\n\n\nvar\nLaufvariable\nName des einzelnen Datensatzes\n\n\nseq\nSequenz/Vektor\nListe mit Namen aller Datens√§tze\n\n\nexpr\nSchritt/Aufgabe\n√ñffnen des Datensatzes\n\n\n\nNun m√ºssen wir statt var, seq und expr nat√ºrlich sinnvolle Variablen und Schritte einf√ºgen. Zuerst erstellen wir die Liste, √ºber die die Schleife laufen soll.\n\nmyFiles &lt;- list.files(path = \"../../data/rdk_decision_experiment/data\",  # Pfad des Ordners mit den Datens√§tzen\n                      pattern = \".csv\", # Endung der Datens√§tze, hier .csv\n                      full.names = TRUE) \n\nmyFiles # zeige die Liste\n\n[1] \"../../data/rdk_decision_experiment/data/JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"../../data/rdk_decision_experiment/data/NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"../../data/rdk_decision_experiment/data/rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"../../data/rdk_decision_experiment/data/sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"../../data/rdk_decision_experiment/data/SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"../../data/rdk_decision_experiment/data/VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"../../data/rdk_decision_experiment/data/VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"../../data/rdk_decision_experiment/data/VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"../../data/rdk_decision_experiment/data/VPN02_rdk-discrimination_2022_Mar_01_2208.csv\"\n\n\nDie Variable var k√∂nnen wir beliebig benennen, wir w√§hlen hier file. Danach k√∂nnen wir die Schleife erstellen, die f√ºr jedes file in myFiles den Schritt Daten laden mit read.csv ausf√ºhrt. Das sieht dann so aus:\n\nDiese Variable wird oft i oder j genannt.\n\nd &lt;- NULL # Vorbereiten des Datensatzes \n\nfor (file in myFiles){\n    dataset &lt;- read.csv(file)\n    d &lt;- rbind(d, dataset) # wir f√ºgen jeden neu eingelesenen Datensatz hinzu\n}"
  },
  {
    "objectID": "pages/chapters/functions_and_loops-2.html#funktionen",
    "href": "pages/chapters/functions_and_loops-2.html#funktionen",
    "title": "Funktionen und Schleifen",
    "section": "Funktionen",
    "text": "Funktionen\nStatt der Schleife, k√∂nnen wir es uns aber noch einfacher machen, in dem wir statt einer Schleide die Funktion mapverwenden. Funktionen sind sehr hilfreich, wenn man einen Schritt mehrmals machen will. Funktionen sind kleine Programme, denen man Infos geben muss (Parameter) und die dann immer dasselbe mit diesen Infos machen. Eine Funktion hat folgende Struktur:\n\nfunctionname &lt;- function(parameter) {\n  body\n}\n\nDie Funktion mean()zum Beispiel macht immer dasselbe mit den Zahlen, die man ihr f√ºttert.\n\nx &lt;- c(1, 21, 3, 234, 5) # verschiedene Zahlen\n\nmean(x)\n\n\n\n\n\n\n\nImportant\n\n\n\nWas macht die Funktion mean()?\nTipp: Geben Sie ?mean in Ihre R-Konsole ein.\n\nWas kann man bei der Funktion mean() als Parameter eingeben?\nMuss die eingegebene Variable x heissen? Probieren Sie aus.\nWas passiert, wenn man mean(x, trim = 1) eingibt?\nWas bedeutet na.rm? F√ºgen Sie im Vektor x ein NAhinzu und probieren Sie es aus.\n\n\n\nUm unsere Daten einzulesen verwenden wir die Funktion map vom Package purrr. Diese Funktion ist sehr praktisch. Sie nimmt als Parameter unsere Liste mit den Datens√§tzen und wendet f√ºr jeden Punkt in der Liste das an, was wir in Klammern angeben. Wir wollen Daten einlesen also schreiben wir hier: read.csv. Anschliessend m√ºssen wir die Listen noch zu einem Datensatz umwandeln indem wir alle untereinander anordnen, also die Listen reihenweise binden: list_rbind().\n\nFalls Sie das Package purrr noch nicht installiert haben, k√∂nnen Sie in der Konsole install.packages(\"purrr\") eingeben. Jedes Package muss nur einmal installiert werden. Will man es verwenden, muss es aber mit library(purrr) geladen werden. Statt list_rbindzu verwenden k√∂nnten wir auch map_dfrnutzen, dann w√§re der Code noch kompakter.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.0     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.1     ‚úî tibble    3.1.8\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(purrr)\n\nd &lt;- myFiles %&gt;%\n    map(read.csv) |&gt;\n    list_rbind()\n\nglimpse(d, width = 10)\n\nRows: 1,503\nColumns: 40\n$ cue                                        &lt;chr&gt; ‚Ä¶\n$ direction                                  &lt;chr&gt; ‚Ä¶\n$ practice_block_loop.thisRepN               &lt;int&gt; ‚Ä¶\n$ practice_block_loop.thisTrialN             &lt;int&gt; ‚Ä¶\n$ practice_block_loop.thisN                  &lt;int&gt; ‚Ä¶\n$ practice_block_loop.thisIndex              &lt;int&gt; ‚Ä¶\n$ main_blocks_loop.thisRepN                  &lt;int&gt; ‚Ä¶\n$ main_blocks_loop.thisTrialN                &lt;int&gt; ‚Ä¶\n$ main_blocks_loop.thisN                     &lt;int&gt; ‚Ä¶\n$ main_blocks_loop.thisIndex                 &lt;int&gt; ‚Ä¶\n$ static_isi.started                         &lt;dbl&gt; ‚Ä¶\n$ static_isi.stopped                         &lt;dbl&gt; ‚Ä¶\n$ fixation_pre.started                       &lt;dbl&gt; ‚Ä¶\n$ fixation_pre.stopped                       &lt;chr&gt; ‚Ä¶\n$ image.started                              &lt;dbl&gt; ‚Ä¶\n$ image.stopped                              &lt;chr&gt; ‚Ä¶\n$ fixation_post.started                      &lt;dbl&gt; ‚Ä¶\n$ fixation_post.stopped                      &lt;chr&gt; ‚Ä¶\n$ dots_background.started                    &lt;dbl&gt; ‚Ä¶\n$ dots_background.stopped                    &lt;chr&gt; ‚Ä¶\n$ dots_stimulus.started                      &lt;dbl&gt; ‚Ä¶\n$ dots_stimulus.stopped                      &lt;chr&gt; ‚Ä¶\n$ dots_keyboard_response.keys                &lt;chr&gt; ‚Ä¶\n$ dots_keyboard_response.started             &lt;dbl&gt; ‚Ä¶\n$ dots_keyboard_response.stopped             &lt;chr&gt; ‚Ä¶\n$ feedback_text.started                      &lt;dbl&gt; ‚Ä¶\n$ feedback_text.stopped                      &lt;chr&gt; ‚Ä¶\n$ dots_keyboard_response.rt                  &lt;dbl&gt; ‚Ä¶\n$ instruction_main_text.started              &lt;dbl&gt; ‚Ä¶\n$ instruction_main_text.stopped              &lt;chr&gt; ‚Ä¶\n$ instruction_main_keyboard_response.keys    &lt;chr&gt; ‚Ä¶\n$ instruction_main_keyboard_response.rt      &lt;dbl&gt; ‚Ä¶\n$ instruction_main_keyboard_response.started &lt;dbl&gt; ‚Ä¶\n$ instruction_main_keyboard_response.stopped &lt;chr&gt; ‚Ä¶\n$ Pseudonym                                  &lt;chr&gt; ‚Ä¶\n$ date                                       &lt;chr&gt; ‚Ä¶\n$ expName                                    &lt;chr&gt; ‚Ä¶\n$ psychopyVersion                            &lt;chr&gt; ‚Ä¶\n$ frameRate                                  &lt;dbl&gt; ‚Ä¶\n$ X                                          &lt;lgl&gt; ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html",
    "href": "pages/chapters/importing_data-2.html",
    "title": "Daten importieren: Teil 2",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nArbeitsschritte automatisieren: mehrere Datens√§tze automatisch importieren\nMit ChatGPT Code verstehen"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#alle-files-in-einem-ordner-auflisten",
    "href": "pages/chapters/importing_data-2.html#alle-files-in-einem-ordner-auflisten",
    "title": "Daten importieren: Teil 2",
    "section": "Alle Files in einem Ordner auflisten",
    "text": "Alle Files in einem Ordner auflisten\nZuerst erstellen wir mit list.files() eine Liste aller .csv Files im Ordner data.\n\ndatadir &lt;- \"data\"\n\ncsv_files &lt;- datadir |&gt;\n    list.files(pattern = \"csv\", full.names = TRUE)\n\n\ncsv_files\n\n[1] \"data/JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"data/NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"data/rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"data/sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"data/SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"data/VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"data/VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"data/VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"data/VPN02_rdk-discrimination_2022_Mar_01_2208.csv\"\n\n\ncsv_files enth√§lt nun die ‚ÄúPfade‚Äù zu allen .csv Files im Ordner data. Diese Pfade k√∂nnen nun einzeln and read_csv() √ºbergeben werden."
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#mit-for-loop",
    "href": "pages/chapters/importing_data-2.html#mit-for-loop",
    "title": "Daten importieren: Teil 2",
    "section": "Mit for-Loop",
    "text": "Mit for-Loop\nZuerst brauchen wir eine Liste, in die wir die Daten einlesen k√∂nnen. Wir erstellen eine Liste mit der L√§nge der Anzahl Files, die wir haben.\n\ndata_list &lt;- vector(\"list\", length(csv_files))\n\nNun k√∂nnen wir entweder √ºber die Elemente der Liste iterieren, oder √ºber die Indizes. Wir w√§hlen letzteres, da wir die Indizes sp√§ter f√ºr die Zuweisung der Daten verwenden k√∂nnen.\n\nfor (i in seq_along(csv_files)) {\n            df &lt;- read_csv(csv_files[i])\n            data_list[[i]] &lt;- df\n}\n\nDas Resultat ist eine Liste, in deren Elementen die neun csv Files gepesichert sind.\n\nlength(data_list)\n\n[1] 9\n\n\nDiese wollen wir nun zu einem Dataframe zusammenf√ºgen. Dazu k√∂nnen wir do.call() verwenden. do.call() nimmt eine Funktion und eine Liste als Argumente. Die Liste werden wiederum als Argumente der Funktion verwendet.\n\ndata_loop &lt;- do.call(rbind, data_list)\n\n\nhead(data_loop)\n\n# A tibble: 6 √ó 40\n  cue   direction practice_block_loop.thisRepN practice_block_loop.thisTrialN\n  &lt;chr&gt; &lt;chr&gt;                            &lt;dbl&gt;                          &lt;dbl&gt;\n1 none  right                                0                              0\n2 left  right                                0                              1\n3 right right                                0                              2\n4 left  left                                 0                              3\n5 none  left                                 0                              4\n6 right left                                 0                              5\n# ‚Ñπ 36 more variables: practice_block_loop.thisN &lt;dbl&gt;,\n#   practice_block_loop.thisIndex &lt;dbl&gt;, main_blocks_loop.thisRepN &lt;dbl&gt;,\n#   main_blocks_loop.thisTrialN &lt;dbl&gt;, main_blocks_loop.thisN &lt;dbl&gt;,\n#   main_blocks_loop.thisIndex &lt;dbl&gt;, static_isi.started &lt;dbl&gt;,\n#   static_isi.stopped &lt;dbl&gt;, fixation_pre.started &lt;dbl&gt;,\n#   fixation_pre.stopped &lt;chr&gt;, image.started &lt;dbl&gt;, image.stopped &lt;chr&gt;,\n#   fixation_post.started &lt;dbl&gt;, fixation_post.stopped &lt;chr&gt;, ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#mit-map-und-list_rbind",
    "href": "pages/chapters/importing_data-2.html#mit-map-und-list_rbind",
    "title": "Daten importieren: Teil 2",
    "section": "Mit map und list_rbind\n",
    "text": "Mit map und list_rbind\n\nDasselbe k√∂nnen wir auch mit map() machen. Da auch hier der Output eine Liste ist, m√ºssen wir diese auch zu einem Dataframe zusammenf√ºgen. Dazu k√∂nnen wir list_rbind() verwenden.\n\ndata &lt;- csv_files |&gt; \n    map(read_csv) |&gt;\n    list_rbind()\n\n\ndata |&gt;\n  slice_head(n = 20)\n\n# A tibble: 20 √ó 40\n   cue   direction practice_block_loop.thisRepN practice_block_loop.thisTrialN\n   &lt;chr&gt; &lt;chr&gt;                            &lt;dbl&gt;                          &lt;dbl&gt;\n 1 none  right                                0                              0\n 2 left  right                                0                              1\n 3 right right                                0                              2\n 4 left  left                                 0                              3\n 5 none  left                                 0                              4\n 6 right left                                 0                              5\n 7 &lt;NA&gt;  &lt;NA&gt;                                NA                             NA\n 8 right right                               NA                             NA\n 9 right right                               NA                             NA\n10 none  right                               NA                             NA\n11 none  right                               NA                             NA\n12 left  left                                NA                             NA\n13 none  right                               NA                             NA\n14 none  left                                NA                             NA\n15 left  left                                NA                             NA\n16 left  right                               NA                             NA\n17 none  right                               NA                             NA\n18 none  left                                NA                             NA\n19 left  left                                NA                             NA\n20 left  left                                NA                             NA\n# ‚Ñπ 36 more variables: practice_block_loop.thisN &lt;dbl&gt;,\n#   practice_block_loop.thisIndex &lt;dbl&gt;, main_blocks_loop.thisRepN &lt;dbl&gt;,\n#   main_blocks_loop.thisTrialN &lt;dbl&gt;, main_blocks_loop.thisN &lt;dbl&gt;,\n#   main_blocks_loop.thisIndex &lt;dbl&gt;, static_isi.started &lt;dbl&gt;,\n#   static_isi.stopped &lt;dbl&gt;, fixation_pre.started &lt;dbl&gt;,\n#   fixation_pre.stopped &lt;chr&gt;, image.started &lt;dbl&gt;, image.stopped &lt;chr&gt;,\n#   fixation_post.started &lt;dbl&gt;, fixation_post.stopped &lt;chr&gt;, ‚Ä¶\n\n\nNun k√∂nnen wir wie in Teil 1 die Practice Trials entfernen.\n\ndata  &lt;- data |&gt;  \n        filter(!is.na(main_blocks_loop.thisN)) |&gt;\n        select(-contains(\"practice_block_loop\"))"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#variablen-ausw√§hlen-und-umbennen",
    "href": "pages/chapters/importing_data-2.html#variablen-ausw√§hlen-und-umbennen",
    "title": "Daten importieren: Teil 2",
    "section": "Variablen ausw√§hlen und umbennen",
    "text": "Variablen ausw√§hlen und umbennen\nWir eliminieren die Variablen, die wir nicht brauchen (ISI, Fixationskreuz, Zeitangaben der Bilder, etc.).\n\ndata &lt;- data |&gt;\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\nZum Schluss geben wir den Variablen, die wir behalten, noch deskriptivere Namen.\n\ndata &lt;- data |&gt;\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\ndata |&gt;\n  slice_head(n = 20)\n\n# A tibble: 20 √ó 6\n   trial ID    cue   direction response    rt\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n 1     0 JH    right right     j        0.714\n 2     1 JH    right right     j        0.627\n 3     2 JH    none  right     f        0.670\n 4     3 JH    none  right     j        0.574\n 5     4 JH    left  left      j        0.841\n 6     5 JH    none  right     j        0.668\n 7     6 JH    none  left      j        1.12 \n 8     7 JH    left  left      f        0.640\n 9     8 JH    left  right     f        1.13 \n10     9 JH    none  right     j        1.03 \n11    10 JH    none  left      f        1.35 \n12    11 JH    left  left      f        0.688\n13    12 JH    left  left      f        0.721\n14    13 JH    none  left      f        0.655\n15    14 JH    right right     j        1.02 \n16    15 JH    none  right     j        1.12 \n17    16 JH    left  left      f        1.08 \n18    17 JH    right left      f        0.643\n19    18 JH    right right     j        0.716\n20    19 JH    left  left      f        0.578"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#neue-variablen-definieren",
    "href": "pages/chapters/importing_data-2.html#neue-variablen-definieren",
    "title": "Daten importieren: Teil 2",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\nEine Antwort ist korrekt, wenn die gew√§hlte Richtung der Richtung des Dot-Stimulus entspricht. Zuvor definieren wir zwei Variablen: choice besteht aus den Angaben ‚Äúright‚Äù und ‚Äúleft‚Äù, response ist eine numerische Version davon (0 = ‚Äúleft‚Äù, 1 = ‚Äúright‚Äù).\nKorrekte Antworten\n\ndata &lt;- data |&gt;\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\ncorrect ist TRUE wenn choice == direction, FALSE wenn nicht. Wir konvertieren diese logische Variable mit as.numeric() in eine numerische Variable. as.numeric() konvertiert TRUE in 1 und FALSE in 0.\n\n\n\n\n\n\nTip\n\n\n\n\nas.numeric(c(TRUE, FALSE))\n\n[1] 1 0\n\n\n\n\n\ndata &lt;- data |&gt;\n    mutate(correct = as.numeric(choice == direction))\n\n\nglimpse(data)\n\nRows: 1,440\nColumns: 8\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        &lt;chr&gt; \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", ‚Ä¶\n$ cue       &lt;chr&gt; \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", \"none\", \"l‚Ä¶\n$ direction &lt;chr&gt; \"right\", \"right\", \"right\", \"right\", \"left\", \"right\", \"left\",‚Ä¶\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    &lt;chr&gt; \"right\", \"right\", \"left\", \"right\", \"right\", \"right\", \"right\"‚Ä¶\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n\n\nWir schauen uns die ersten 20 Zeilen an.\n\ndata |&gt; \n  slice_head(n = 20)\n\n# A tibble: 20 √ó 8\n   trial ID    cue   direction response    rt choice correct\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     0 JH    right right            1 0.714 right        1\n 2     1 JH    right right            1 0.627 right        1\n 3     2 JH    none  right            0 0.670 left         0\n 4     3 JH    none  right            1 0.574 right        1\n 5     4 JH    left  left             1 0.841 right        0\n 6     5 JH    none  right            1 0.668 right        1\n 7     6 JH    none  left             1 1.12  right        0\n 8     7 JH    left  left             0 0.640 left         1\n 9     8 JH    left  right            0 1.13  left         0\n10     9 JH    none  right            1 1.03  right        1\n11    10 JH    none  left             0 1.35  left         1\n12    11 JH    left  left             0 0.688 left         1\n13    12 JH    left  left             0 0.721 left         1\n14    13 JH    none  left             0 0.655 left         1\n15    14 JH    right right            1 1.02  right        1\n16    15 JH    none  right            1 1.12  right        1\n17    16 JH    left  left             0 1.08  left         1\n18    17 JH    right left             0 0.643 left         1\n19    18 JH    right right            1 0.716 right        1\n20    19 JH    left  left             0 0.578 left         1\n\n\nCue-Bedingungsvariable\nNun brauchen wir eine Variable, die angibt, ob die Bedingung ‚Äúneutral‚Äù, ‚Äúvalid‚Äù oder ‚Äúinvalid‚Äù ist. Wir erstellen eine neue Variable condition und f√ºllen sie mit case_when() mit den Werten ‚Äúneutral‚Äù, ‚Äúvalid‚Äù oder ‚Äúinvalid‚Äù. case_when() erlaubt, mehrere if_else()-Bedingungen zu kombinieren. So wird hier der Variablen condition der Wert neutral zugewiesen, wenn cue == \"none\" ist. Falls cue == direction ist, wird der Wert valid zugewiesen. Falls cue != direction ist, wird der Wert invalid zugewiesen.\n\ndata &lt;- data |&gt;\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\ndata |&gt; \n  slice_head(n = 20)\n\n# A tibble: 20 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n11    10 JH    none  left             0 1.35  left         1 neutral  \n12    11 JH    left  left             0 0.688 left         1 valid    \n13    12 JH    left  left             0 0.721 left         1 valid    \n14    13 JH    none  left             0 0.655 left         1 neutral  \n15    14 JH    right right            1 1.02  right        1 valid    \n16    15 JH    none  right            1 1.12  right        1 neutral  \n17    16 JH    left  left             0 1.08  left         1 valid    \n18    17 JH    right left             0 0.643 left         1 invalid  \n19    18 JH    right right            1 0.716 right        1 valid    \n20    19 JH    left  left             0 0.578 left         1 valid    \n\n\nDaten als CSV speichern\nAn dieser Stelle speichern wir den neu kreierten Datensatz als .csv File in einen Ordner names data_clean. Somit k√∂nnen wir zu einem sp√§teren Zeitpunkt die Daten einfach importieren, ohne die ganzen Schritte wiederholen zu m√ºssen.\n\ndata |&gt; write_csv(file = \"data_clean/rdkdata.csv\")"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#gruppierungsvariablen",
    "href": "pages/chapters/importing_data-2.html#gruppierungsvariablen",
    "title": "Daten importieren: Teil 2",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\nAlle Gruppierungsvariablen sollten nun zu Faktoren konvertiert werden.\n\ndata &lt;- data |&gt;\n    mutate(across(where(is.character), as_factor))\n\n\nglimpse(data)\n\nRows: 1,440\nColumns: 9\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        &lt;fct&gt; JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, ‚Ä¶\n$ cue       &lt;fct&gt; right, right, none, none, left, none, none, left, left, none‚Ä¶\n$ direction &lt;fct&gt; right, right, right, right, left, right, left, left, right, ‚Ä¶\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    &lt;fct&gt; right, right, left, right, right, right, right, left, left, ‚Ä¶\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ condition &lt;fct&gt; valid, valid, neutral, neutral, valid, neutral, neutral, val‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#daten-√ºberpr√ºfen",
    "href": "pages/chapters/importing_data-2.html#daten-√ºberpr√ºfen",
    "title": "Daten importieren: Teil 2",
    "section": "Daten √ºberpr√ºfen",
    "text": "Daten √ºberpr√ºfen\nWir √ºberpr√ºfen, ob die Daten korrekt sind. Dazu schauen wir uns die Anzahl der Trials pro Person und pro Bedingung an. Sie k√∂nnen mehr Zeilen anzeigen, indem sie n = in der Funktion slice_head() √§ndern.\n\ndata |&gt; \n  group_by(ID, condition) |&gt;\n  summarise(n_trials = n()) |&gt;\n  slice_head(n = 20)\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 27 √ó 3\n# Groups:   ID [9]\n   ID    condition n_trials\n   &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;\n 1 JH    valid           64\n 2 JH    neutral         80\n 3 JH    invalid         16\n 4 NS    valid           64\n 5 NS    neutral         80\n 6 NS    invalid         16\n 7 rh    valid           64\n 8 rh    neutral         80\n 9 rh    invalid         16\n10 sb    valid           64\n# ‚Ñπ 17 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#accuracy-pro-personbedingung",
    "href": "pages/chapters/importing_data-2.html#accuracy-pro-personbedingung",
    "title": "Daten importieren: Teil 2",
    "section": "Accuracy pro Person/Bedingung",
    "text": "Accuracy pro Person/Bedingung\nNun berechnen wir pro Person und pro Bedingung die Anzahl der korrekten Antworten und die Accuracy. Die Accuracy ist die Anzahl der korrekten Antworten geteilt durch die Anzahl der Trials.\n\naccuracy &lt;- data |&gt;\n    group_by(ID, condition) |&gt;\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\n\n\naccuracy\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   &lt;fct&gt; &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 JH    valid        64       60    0.938\n 2 JH    neutral      80       66    0.825\n 3 JH    invalid      16       13    0.812\n 4 NS    valid        64       58    0.906\n 5 NS    neutral      80       56    0.7  \n 6 NS    invalid      16       11    0.688\n 7 rh    valid        64       61    0.953\n 8 rh    neutral      80       64    0.8  \n 9 rh    invalid      16        2    0.125\n10 sb    valid        64       62    0.969\n# ‚Ñπ 17 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#visualisieren",
    "href": "pages/chapters/importing_data-2.html#visualisieren",
    "title": "Daten importieren: Teil 2",
    "section": "Visualisieren",
    "text": "Visualisieren\n\naccuracy |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per person/condition\") +\n  facet_wrap(~ID) +\n  theme_linedraw(base_size = 28) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "pages/chapters/importing_data.html",
    "href": "pages/chapters/importing_data.html",
    "title": "Daten importieren: Teil 1",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nMit RStudio arbeiten\nEinzelne Psychopy .csv Datens√§tze importieren\nVariablen ausw√§hlen/umbenennen\nNeue Variablen berechnen\nMehrere Datens√§tze importieren\nMit ChatGPT Code verstehen"
  },
  {
    "objectID": "pages/chapters/importing_data.html#csv-file-importieren",
    "href": "pages/chapters/importing_data.html#csv-file-importieren",
    "title": "Daten importieren: Teil 1",
    "section": "CSV File importieren",
    "text": "CSV File importieren\nWir werden nun das File ZZ_rdk-discrimination_2022_Mar_07_1403.csv aus dem testdata Ordner einlesen. Bevor wir das tun, ist es sinnvoll, sich das File z.B. in Excel anschauen.\n\n\n\n\n\n\nTip\n\n\n\n√ñffnen Sie ZZ_rdk-discrimination_2022_Mar_07_1403.csv in Excel.\nWas steht in den Spalten? Was steht in den Zeilen?\n\n\nNun k√∂nnen Sie entweder √ºber die GUI-Option (Menu &gt; File &gt; Import Dataset &gt; From text (readr)) oder direkt das File einlesen.\n\ntestdata &lt;- read_csv(\"testdata/ZZ_rdk-discrimination_2022_Mar_07_1403.csv\") \n\nVariablen √ºberpr√ºfen\n\nglimpse(testdata)\n\nRows: 167\nColumns: 39\n$ cue                                        &lt;chr&gt; \"none\", \"left\", \"right\", \"l‚Ä¶\n$ direction                                  &lt;chr&gt; \"right\", \"right\", \"right\", ‚Ä¶\n$ practice_block_loop.thisRepN               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, NA, NA, N‚Ä¶\n$ practice_block_loop.thisTrialN             &lt;dbl&gt; 0, 1, 2, 3, 4, 5, NA, NA, N‚Ä¶\n$ practice_block_loop.thisN                  &lt;dbl&gt; 0, 1, 2, 3, 4, 5, NA, NA, N‚Ä¶\n$ practice_block_loop.thisIndex              &lt;dbl&gt; 5, 2, 1, 0, 4, 3, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisRepN                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisTrialN                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisN                     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisIndex                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ static_isi.started                         &lt;dbl&gt; 0.01033428, 0.03202713, 0.0‚Ä¶\n$ static_isi.stopped                         &lt;dbl&gt; 2.010334, 2.032027, 2.03217‚Ä¶\n$ fixation_pre.started                       &lt;dbl&gt; 26.79425, 36.16522, 44.7852‚Ä¶\n$ fixation_pre.stopped                       &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ image.started                              &lt;dbl&gt; 27.19849, 36.28205, 46.0032‚Ä¶\n$ image.stopped                              &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ fixation_post.started                      &lt;dbl&gt; 28.17814, 37.28240, 47.0037‚Ä¶\n$ fixation_post.stopped                      &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_background.started                    &lt;dbl&gt; 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_background.stopped                    &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_stimulus.started                      &lt;dbl&gt; 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_stimulus.stopped                      &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_keyboard_response.keys                &lt;chr&gt; \"None\", \"f\", \"j\", \"f\", \"Non‚Ä¶\n$ dots_keyboard_response.started             &lt;dbl&gt; 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_keyboard_response.stopped             &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ feedback_text.started                      &lt;dbl&gt; 33.70200, 42.28899, 52.9229‚Ä¶\n$ feedback_text.stopped                      &lt;chr&gt; \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_keyboard_response.rt                  &lt;dbl&gt; NA, 0.9339199, 0.8488816, 0‚Ä¶\n$ instruction_main_text.started              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 81.‚Ä¶\n$ instruction_main_text.stopped              &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"No‚Ä¶\n$ instruction_main_keyboard_response.keys    &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"sp‚Ä¶\n$ instruction_main_keyboard_response.rt      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 3.1‚Ä¶\n$ instruction_main_keyboard_response.started &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 81.‚Ä¶\n$ instruction_main_keyboard_response.stopped &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"No‚Ä¶\n$ Pseudonym                                  &lt;chr&gt; \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ‚Ä¶\n$ date                                       &lt;chr&gt; \"2022_Mar_07_1403\", \"2022_M‚Ä¶\n$ expName                                    &lt;chr&gt; \"rdk-discrimination\", \"rdk-‚Ä¶\n$ psychopyVersion                            &lt;chr&gt; \"03.02.21\", \"03.02.21\", \"03‚Ä¶\n$ frameRate                                  &lt;dbl&gt; 59.9, 59.9, 59.9, 59.9, 59.‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data.html#practice-trials-l√∂schen",
    "href": "pages/chapters/importing_data.html#practice-trials-l√∂schen",
    "title": "Daten importieren: Teil 1",
    "section": "Practice Trials l√∂schen",
    "text": "Practice Trials l√∂schen\nVielleicht haben Sie bemerkt, dass die ersten 6 Zeilen √úbungstrials sind. Diese wollen wir nicht analysieren, und k√∂nnen folglich gel√∂scht werden.\n\n\n\n\ncue\ndirection\npractice_block_loop.thisRepN\npractice_block_loop.thisTrialN\npractice_block_loop.thisN\npractice_block_loop.thisIndex\nmain_blocks_loop.thisRepN\nmain_blocks_loop.thisTrialN\nmain_blocks_loop.thisN\nmain_blocks_loop.thisIndex\nstatic_isi.started\nstatic_isi.stopped\nfixation_pre.started\nfixation_pre.stopped\nimage.started\nimage.stopped\nfixation_post.started\nfixation_post.stopped\ndots_background.started\ndots_background.stopped\ndots_stimulus.started\ndots_stimulus.stopped\ndots_keyboard_response.keys\ndots_keyboard_response.started\ndots_keyboard_response.stopped\nfeedback_text.started\nfeedback_text.stopped\ndots_keyboard_response.rt\ninstruction_main_text.started\ninstruction_main_text.stopped\ninstruction_main_keyboard_response.keys\ninstruction_main_keyboard_response.rt\ninstruction_main_keyboard_response.started\ninstruction_main_keyboard_response.stopped\nPseudonym\ndate\nexpName\npsychopyVersion\nframeRate\n\n\n\nnone\nright\n0\n0\n0\n5\nNA\nNA\nNA\nNA\n0.0103343\n2.010334\n26.79425\nNone\n27.19849\nNone\n28.17814\nNone\n32.18642\nNone\n32.18642\nNone\nNone\n32.18642\nNone\n33.70200\nNone\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nleft\nright\n0\n1\n1\n2\nNA\nNA\nNA\nNA\n0.0320271\n2.032027\n36.16522\nNone\n36.28205\nNone\n37.28240\nNone\n41.30145\nNone\n41.30145\nNone\nf\n41.30145\nNone\n42.28899\nNone\n0.9339199\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nright\n0\n2\n2\n1\nNA\nNA\nNA\nNA\n0.0321732\n2.032173\n44.78521\nNone\n46.00329\nNone\n47.00374\nNone\n52.01072\nNone\n52.01072\nNone\nj\n52.01072\nNone\n52.92295\nNone\n0.8488816\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nleft\nleft\n0\n3\n3\n0\nNA\nNA\nNA\nNA\n0.0321533\n2.032153\n55.39138\nNone\n56.19407\nNone\n57.22527\nNone\n61.23181\nNone\n61.23181\nNone\nf\n61.23181\nNone\n62.21611\nNone\n0.9396018\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nnone\nleft\n0\n4\n4\n4\nNA\nNA\nNA\nNA\n0.0321391\n2.032139\n64.71204\nNone\n64.81315\nNone\n65.84603\nNone\n69.25240\nNone\n69.25240\nNone\nNone\n69.25240\nNone\n70.78541\nNone\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nleft\n0\n5\n5\n3\nNA\nNA\nNA\nNA\n0.0323178\n2.032318\n73.24960\nNone\n74.45209\nNone\n75.48391\nNone\n79.99045\nNone\n79.99045\nNone\nf\n79.99045\nNone\n80.80311\nNone\n0.7490084\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n81.30346\nNone\nspace\n3.187924\n81.30346\nNone\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nright\nNA\nNA\nNA\nNA\n0\n0\n0\n18\n0.0160001\n2.016000\n86.52245\nNone\n86.89231\nNone\n87.92302\nNone\n92.92987\nNone\n92.92987\nNone\nj\n92.92987\nNone\n93.70924\nNone\n0.7136441\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nright\nNA\nNA\nNA\nNA\n0\n1\n1\n31\n0.0318162\n2.031816\n96.17699\nNone\n96.54602\nNone\n97.57770\nNone\n101.58423\nNone\n101.58423\nNone\nj\n101.58423\nNone\n102.26673\nNone\n0.6271285\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nnone\nright\nNA\nNA\nNA\nNA\n0\n2\n2\n66\n0.0321148\n2.032115\n104.76463\nNone\n105.13302\nNone\n106.16508\nNone\n110.67183\nNone\n110.67183\nNone\nf\n110.67183\nNone\n111.38828\nNone\n0.6703410\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nnone\nright\nNA\nNA\nNA\nNA\n0\n3\n3\n75\n0.0321121\n2.032112\n113.88535\nNone\n115.08794\nNone\n116.11989\nNone\n119.52612\nNone\n119.52612\nNone\nj\n119.52612\nNone\n120.15512\nNone\n0.5738488\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nleft\nleft\nNA\nNA\nNA\nNA\n0\n4\n4\n13\n0.0321118\n2.032112\n122.62295\nNone\n123.82583\nNone\n124.85742\nNone\n129.36397\nNone\n129.36397\nNone\nj\n129.36397\nNone\n130.25975\nNone\n0.8405913\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\n\n\n\nDie Variable main_blocks_loop.thisN ist die Trialnummer. Diese k√∂nnen wir verwenden, um die Zeilen auszuschliessen, die nicht zum Main Block geh√∂ren ‚Äì bei den √úbungstrials ist der Wert NA.\n\n\n\n\nmain_blocks_loop.thisRepN\nmain_blocks_loop.thisTrialN\nmain_blocks_loop.thisN\nmain_blocks_loop.thisIndex\n\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\n0\n0\n0\n18\n\n\n0\n1\n1\n31\n\n\n0\n2\n2\n66\n\n\n0\n3\n3\n75\n\n\n0\n4\n4\n13\n\n\n\n\n\nMit folgendem Code filtern wir zuerst, so dass , bei wir nur noch Zeilen behalten, bei denen nicht der Wert NA in der Spalte main_blocks_loop.thisN steht. Dann w√§hlen wir alle Spalten ausser practice_block_loop.\n\ntestdata &lt;- testdata |&gt; \n    filter(!is.na(main_blocks_loop.thisN)) |&gt;\n    select(-contains(\"practice_block_loop\"))\n\n\n\n\n\n\n\nChatGPT\n\n\n\nFalls Code nicht verst√§ndlich finden, k√∂nnen Sie ChatGPT fragen. Benutzen Sie folgenden Prompt:\nWhat does the following R code do? \n\ntestdata &lt;- testdata |&gt; \n    filter(!is.na(main_blocks_loop.thisN)) |&gt;\n    select(-contains(\"practice_block_loop\"))"
  },
  {
    "objectID": "pages/chapters/importing_data.html#variablen-ausw√§hlen",
    "href": "pages/chapters/importing_data.html#variablen-ausw√§hlen",
    "title": "Daten importieren: Teil 1",
    "section": "Variablen ausw√§hlen",
    "text": "Variablen ausw√§hlen\nDie folgenden Variablen enthalten Informationen zu den Inter-Trial Intervallen, Fixationskreuzen, Feedback, etc, und sind f√ºr uns an dieser Stelle nicht interessant.\n\ntestdata |&gt;\n    select(contains(\"static\"),\n           contains(\"fixation\"),\n           contains(\"image\"),\n           contains(\"instruction\"),\n           contains(\"feedback\"))\n\n# A tibble: 160 √ó 16\n   static_isi.started static_isi.stopped fixation_pre.started\n                &lt;dbl&gt;              &lt;dbl&gt;                &lt;dbl&gt;\n 1             0.0160               2.02                 86.5\n 2             0.0318               2.03                 96.2\n 3             0.0321               2.03                105. \n 4             0.0321               2.03                114. \n 5             0.0321               2.03                123. \n 6             0.0321               2.03                133. \n 7             0.0321               2.03                142. \n 8             0.0321               2.03                152. \n 9             0.0321               2.03                161. \n10             0.0321               2.03                172. \n# ‚Ñπ 150 more rows\n# ‚Ñπ 13 more variables: fixation_pre.stopped &lt;chr&gt;, fixation_post.started &lt;dbl&gt;,\n#   fixation_post.stopped &lt;chr&gt;, image.started &lt;dbl&gt;, image.stopped &lt;chr&gt;,\n#   instruction_main_text.started &lt;dbl&gt;, instruction_main_text.stopped &lt;chr&gt;,\n#   instruction_main_keyboard_response.keys &lt;chr&gt;,\n#   instruction_main_keyboard_response.rt &lt;dbl&gt;,\n#   instruction_main_keyboard_response.started &lt;dbl&gt;, ‚Ä¶\n\n\nMit select k√∂nnen wir alle Variablen ausser diesen ausw√§hlen.\n\ntestdata &lt;- testdata |&gt;\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\ntestdata\n\n# A tibble: 160 √ó 19\n   cue   direction main_blocks_loop.thisRepN main_blocks_loop.thisTrialN\n   &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt;                       &lt;dbl&gt;\n 1 right right                             0                           0\n 2 right right                             0                           1\n 3 none  right                             0                           2\n 4 none  right                             0                           3\n 5 left  left                              0                           4\n 6 none  right                             0                           5\n 7 none  left                              0                           6\n 8 left  left                              0                           7\n 9 left  right                             0                           8\n10 none  right                             0                           9\n# ‚Ñπ 150 more rows\n# ‚Ñπ 15 more variables: main_blocks_loop.thisN &lt;dbl&gt;,\n#   main_blocks_loop.thisIndex &lt;dbl&gt;, dots_background.started &lt;dbl&gt;,\n#   dots_background.stopped &lt;chr&gt;, dots_stimulus.started &lt;dbl&gt;,\n#   dots_stimulus.stopped &lt;chr&gt;, dots_keyboard_response.keys &lt;chr&gt;,\n#   dots_keyboard_response.started &lt;dbl&gt;, dots_keyboard_response.stopped &lt;chr&gt;,\n#   dots_keyboard_response.rt &lt;dbl&gt;, Pseudonym &lt;chr&gt;, date &lt;chr&gt;, ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data.html#variablen-umbenennen",
    "href": "pages/chapters/importing_data.html#variablen-umbenennen",
    "title": "Daten importieren: Teil 1",
    "section": "Variablen umbenennen",
    "text": "Variablen umbenennen\nNun wollen Variablen identifizieren, die uns interessieren. Diese wollen wir umbenennen.\n\ntestdata &lt;- testdata |&gt;\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\ntestdata\n\n# A tibble: 160 √ó 6\n   trial ID    cue   direction response    rt\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n 1     0 ZZ    right right     j        0.714\n 2     1 ZZ    right right     j        0.627\n 3     2 ZZ    none  right     f        0.670\n 4     3 ZZ    none  right     j        0.574\n 5     4 ZZ    left  left      j        0.841\n 6     5 ZZ    none  right     j        0.668\n 7     6 ZZ    none  left      j        1.12 \n 8     7 ZZ    left  left      f        0.640\n 9     8 ZZ    left  right     f        1.13 \n10     9 ZZ    none  right     j        1.03 \n# ‚Ñπ 150 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data.html#neue-variablen-definieren",
    "href": "pages/chapters/importing_data.html#neue-variablen-definieren",
    "title": "Daten importieren: Teil 1",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\nNun wollen wir zwei neue Variablen erstellen: eine ‚Äúcharacter‚Äù Variable, die uns sagt, ob ‚Äúrechts‚Äù oder ‚Äúlinks‚Äù entschieden wurde, und eine numerische Variable mit derselben Information. Je nachdem, ob wir die Daten grafisch darstellen oder analysieren wollen, brauchen wir beide Variablen.\n\ntestdata &lt;- testdata |&gt;\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\nFolgender Code l√∂st das gleiche Problem mit der Funktion as.numeric(). Fragen Sie ruhig ChatGPT, falls Sie den Code nicht verstehen.\n\ntestdata &lt;- testdata |&gt;\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = as.numeric(choice == \"right\"))\n\nWir erstellen ausserdem hier eine Variable, welche angibt, ob der Cue valid, invalid oder neutral war. Ein Cue ist genau dann valide, wenn er dieselbe Richtung hat wie der Random Dot Stimulus, d.h. wenn cue == direction.\n\ntestdata &lt;- testdata |&gt;\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\n\n\n\n\nChatGPT\n\n\n\nWhat does the R function case_when() do?\n\n\nZum Schluss erstellen wir noch eine Variable, welche festh√§lt, ob die Antwort der Versuchsperson korrekt war.\n\ntestdata &lt;- testdata |&gt;\n    mutate(correct = as.numeric(choice == direction))"
  },
  {
    "objectID": "pages/chapters/importing_data.html#gruppierungsvariablen",
    "href": "pages/chapters/importing_data.html#gruppierungsvariablen",
    "title": "Daten importieren: Teil 1",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\n\nglimpse(testdata)\n\nRows: 160\nColumns: 9\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        &lt;chr&gt; \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", ‚Ä¶\n$ cue       &lt;chr&gt; \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", \"none\", \"l‚Ä¶\n$ direction &lt;chr&gt; \"right\", \"right\", \"right\", \"right\", \"left\", \"right\", \"left\",‚Ä¶\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    &lt;chr&gt; \"right\", \"right\", \"left\", \"right\", \"right\", \"right\", \"right\"‚Ä¶\n$ condition &lt;chr&gt; \"valid\", \"valid\", \"neutral\", \"neutral\", \"valid\", \"neutral\", ‚Ä¶\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n\n\n\ntestdata &lt;- testdata |&gt;\n    mutate_if(is.character, as.factor)\n\n\nglimpse(testdata)\n\nRows: 160\nColumns: 9\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        &lt;fct&gt; ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ‚Ä¶\n$ cue       &lt;fct&gt; right, right, none, none, left, none, none, left, left, none‚Ä¶\n$ direction &lt;fct&gt; right, right, right, right, left, right, left, left, right, ‚Ä¶\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    &lt;fct&gt; right, right, left, right, right, right, right, left, left, ‚Ä¶\n$ condition &lt;fct&gt; valid, valid, neutral, neutral, valid, neutral, neutral, val‚Ä¶\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data.html#accuracy-pro-bedingung",
    "href": "pages/chapters/importing_data.html#accuracy-pro-bedingung",
    "title": "Daten importieren: Teil 1",
    "section": "Accuracy pro Bedingung",
    "text": "Accuracy pro Bedingung\nWir k√∂nnen nun die accuracy in jeder Cue-Bedingung berechnen. Es gibt hier zwei M√∂glichkeiten: wir berechen die Anzahl Trials (N), und die Anzahl korrekter Antworten (ncorrect) separat. Der Anteil korrekter Antworten ist dann einfach ncorrect/N. Dasselbe Ergebnis erhalten wir, wenn wir einfach den Mittelwert der korrekten Antworten nehmen.\n\ntestaccuracy &lt;- testdata |&gt;\n    group_by(condition) |&gt;\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = ncorrect/N,\n              accuracy2 = mean(correct))\n\ntestaccuracy\n\n# A tibble: 3 √ó 5\n  condition     N ncorrect accuracy accuracy2\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 invalid      16       13    0.812     0.812\n2 neutral      80       66    0.825     0.825\n3 valid        64       60    0.938     0.938"
  },
  {
    "objectID": "pages/chapters/loesung-4-signal-detection.html",
    "href": "pages/chapters/loesung-4-signal-detection.html",
    "title": "√úbung 4",
    "section": "",
    "text": "Aufgaben\n\n\n\n\n\nDie √úbung 4 besteht aus den zwei folgenden Aufgaben:\n1. RMarkdown-File erstellen und ausf√ºhren: In diesem File werden die Daten eingelesen, SDT Kennzahlen und damit eine Grafik erstellt. Das RMarkdown-File muss von einer anderen Person ausgef√ºhrt werden k√∂nnen (Reproduzierbarkeit) und gut kommentiert sein. Zeit: 1 Woche.\n2. Peer Feedback: Mittels Ilias wird Ihnen das RMarkdown-File und die Grafik einer anderen Person zugeordnet. Ihr Auftrag ist es, dieses RMarkdown-File auszuf√ºhren und Feedback zu geben. Zeit: 1 Woche."
  },
  {
    "objectID": "pages/chapters/loesung-4-signal-detection.html#kommentare-code",
    "href": "pages/chapters/loesung-4-signal-detection.html#kommentare-code",
    "title": "√úbung 4",
    "section": "Kommentare & Code",
    "text": "Kommentare & Code\nAchten Sie darauf, dass Sie den Code in den Codefeldern schreiben und den Text ausserhalb. W√§hlen Sie aus, welche die Codechunks ausgef√ºhrt / angezeigt werden sollen."
  },
  {
    "objectID": "pages/chapters/loesung-4-signal-detection.html#aufgaben-1",
    "href": "pages/chapters/loesung-4-signal-detection.html#aufgaben-1",
    "title": "√úbung 4",
    "section": "Aufgaben",
    "text": "Aufgaben\n\nLaden Sie n√∂tige Packages.\nLaden Sie die Daten unseres Experiments. Sie finden den Datensatz rdkdata_clean.csv f√ºr diese √úbung im Projektordner dataviz &gt; data_rdk.\nMachen Sie Textvariablen und die Personen-Id-Variable zu Faktoren und schauen Sie den Datensatz kurz an (mit slice_head() oder glimpse()), um zu √ºberpr√ºfen, ob die Daten richtig eingelesen wurden.\n\nIhre Aufgabe ist es eine Forschungsfrage zu dem vorhandenen Datensatz zu stellen, dazu eine Grafik zu plotten und die Antwort damit zu visualisieren, sowie in schriftlicher Form zu geben.\n\nBeschreiben Sie in Textform, welche Frage Sie mit Ihrer Grafik beantworten m√∂chten.\nFalls n√∂tig: Bearbeiten Sie den Datensatz / erstellen Sie einen neuen Datensatz f√ºr die Grafik.\nErstellen Sie die Grafik, und lassen Sie diese anzeigen.\nSpeichern Sie die Grafik zus√§tzlich als .jpg oder .png ab. So kann Ihr Peer Reviewer auch bei nicht funktionierendem Code R√ºckmeldung zur Grafik geben.\nF√ºgen Sie der Grafik passende Beschriftungen hinzu.\nBeantworten Sie Ihre Forschungsfrage schriftlich."
  },
  {
    "objectID": "pages/chapters/loesung-4-signal-detection.html#rey-auditory-verbal-learning-test",
    "href": "pages/chapters/loesung-4-signal-detection.html#rey-auditory-verbal-learning-test",
    "title": "√úbung 4",
    "section": "Rey auditory verbal learning test",
    "text": "Rey auditory verbal learning test\nIn dieser √úbung werden wir die Sensitivit√§t und den Bias f√ºr zwei Gruppen von Patienten untersuchen, die sich in ihrem Risiko f√ºr Alzheimer-Krankheit unterscheiden. Bei 60 Patienten wurde die Anwesenheit von Beta-Amyloid durch einen Bluttest\nThese data come from a clinical setting, and involve memory ability tests for 60 patients using the Rey auditory verbal learning test (RALVT: Bean, 2011) - in the recognition task, the patients study a set of 15 words, and tested on 30 words, made up of 15 old and 15 new words ‚Ä¢ Patients also had a cerebrospinal fluid measurement taken to classify their levels beta amyloid as ‚Äúpositive‚Äù or ‚Äúnegative‚Äù - amyloid positivity is thought to be a pre-symptomatic indicator of Alzheimer‚Äôs disease"
  },
  {
    "objectID": "pages/chapters/loesung-4-signal-detection.html#code",
    "href": "pages/chapters/loesung-4-signal-detection.html#code",
    "title": "√úbung 4",
    "section": "Code",
    "text": "Code\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.2     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\ndf &lt;- read_csv(\"data/amyloidSDT.csv\")\n\nRows: 60 Columns: 6\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): group\ndbl (5): ID, hit, miss, fa, cr\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nadd_half_count &lt;- function(count) {\n  count + 0.5\n}\n\n\ndf &lt;- df |&gt; \n  mutate(across(c(hit, miss, fa, cr), add_half_count))\n\n\ndf &lt;- df |&gt;\n    mutate(\n        hit_rate = hit / (hit + miss),\n        fa_rate = fa / (fa + cr)\n    )\n\n\ndf |&gt; \n  ggplot(aes(fa_rate, hit_rate, color = group)) +\n  geom_abline(intercept = 0, slope = 1, linetype = 2) +\n  geom_jitter() +\n  scale_color_viridis_d(direction = -1, begin = 0.1, end = 0.8) +\n      facet_wrap(~ group) +\n      xlim(c(0, 1)) +\n      theme_linedraw()\n\n\n\n\n\ndf &lt;- df |&gt;\n    mutate(\n        zhr = qnorm(hit_rate),\n        zfa = qnorm(fa_rate)\n    )\n\n\ndf &lt;- df |&gt;\n    mutate(\n        dprime = zhr - zfa,\n        k = -zfa,\n        c = -0.5 * (zhr + zfa)\n    )\n\n\ndf &lt;- df |&gt;\n    mutate(across(c(dprime, k, c), \\(x) round(x, 2)))\n\n\ndf\n\n# A tibble: 60 √ó 13\n      ID group   hit  miss    fa    cr hit_rate fa_rate   zhr   zfa dprime     k\n   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     1 Nega‚Ä¶  13.5   2.5   0.5  15.5    0.844  0.0312 1.01  -1.86   2.87  1.86\n 2     2 Nega‚Ä¶  12.5   3.5   1.5  14.5    0.781  0.0938 0.776 -1.32   2.09  1.32\n 3     3 Nega‚Ä¶  14.5   1.5   0.5  15.5    0.906  0.0312 1.32  -1.86   3.18  1.86\n 4     4 Nega‚Ä¶  12.5   3.5   1.5  14.5    0.781  0.0938 0.776 -1.32   2.09  1.32\n 5     5 Nega‚Ä¶  11.5   4.5   2.5  13.5    0.719  0.156  0.579 -1.01   1.59  1.01\n 6     6 Nega‚Ä¶  12.5   3.5   1.5  14.5    0.781  0.0938 0.776 -1.32   2.09  1.32\n 7     7 Nega‚Ä¶  10.5   5.5   2.5  13.5    0.656  0.156  0.402 -1.01   1.41  1.01\n 8     8 Nega‚Ä¶  13.5   2.5   1.5  14.5    0.844  0.0938 1.01  -1.32   2.33  1.32\n 9     9 Nega‚Ä¶  12.5   3.5   0.5  15.5    0.781  0.0312 0.776 -1.86   2.64  1.86\n10    10 Nega‚Ä¶  12.5   3.5   2.5  13.5    0.781  0.156  0.776 -1.01   1.79  1.01\n# ‚Ñπ 50 more rows\n# ‚Ñπ 1 more variable: c &lt;dbl&gt;\n\n\n\nse &lt;- function(x) {\n  sd(x) / sqrt(length(x))\n}\n\n\ndprimes &lt;- df |&gt;\n  select(group, dprime) |&gt; \n  group_by(group) |&gt; \n  summarize(mean = mean(dprime),\n            se = se(dprime))\n\n\ncs &lt;- df |&gt; \n  select(group, c) |&gt; \n  group_by(group) |&gt; \n  summarize(mean = mean(c),\n            se = se(c))\n\n\np_dprimes &lt;- dprimes |&gt;\n  ggplot(aes(x=group, y=mean, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se), colour=\"black\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylab(\"Sensitivity\")\n\n\np_cs &lt;- cs |&gt;\n    ggplot(aes(x=group, y=mean, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se), colour=\"black\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylab(\"Bias\")\n\n\nlibrary(patchwork)\n\n\np_dprimes + p_cs\n\n\n\n\n\nfor healthy amyloid negative patients on the left, and potentially impaired amyloid positive patients on the right\nthe basic data change of more misses, but not many more false alarms, is captured by the model"
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html",
    "href": "pages/chapters/psychopy_experiments.html",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "",
    "text": "Neurowissenschaftliche Experimente m√ºssen exakt auf die Fragestellung zugeschnitten werden um aussagekr√§ftige Daten zu liefern. Deshalb programmieren die meisten Forschenden ihre Experimentalparadigmen selbst. So k√∂nnen beispielsweise Instruktionen oder verwendete Stimuli, deren Gr√∂sse und Anzeigedauer pr√§zise definiert werden. In dieser Sitzung erstellen wir mit PsychoPy ein perzeptuelles Entscheidungsexperiment, √§hnlich dem Experiment aus Mulder et al. (2012). Dieses neurowissenschaftliche Experiment untersucht den Einfluss von Vorwissen auf Entscheidungsverhalten von Menschen sowie die dazugeh√∂rigen neuronalen Korrelate."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#ablauf",
    "href": "pages/chapters/psychopy_experiments.html#ablauf",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Ablauf",
    "text": "Ablauf\nDas Experiment besteht aus der Instruktion, mehreren Versuchsbl√∂cken und der Nachbesprechung. Die Anweisungen und die Nachbesprechung sind Textanzeigen, w√§hrend die Versuche (und die Versuchsbl√∂cke) etwas komplizierter sind."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#trial",
    "href": "pages/chapters/psychopy_experiments.html#trial",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Trial",
    "text": "Trial\nZun√§chst wird ein Fixationskreuz entweder f√ºr 100 ms, 350 ms, 800 ms oder 1200 ms angezeigt. Die tats√§chliche Dauer wird f√ºr jeden Versuch randomisiert. Eine solche Randomisierung kann nicht √ºber die Benutzeroberfl√§che vorgenommen werden, sondern erfordert ein kleines St√ºck Python-Code. Sehen Sie sich den Codeblock der Routine Fixation_pre_cue an, um zu erfahren, wie dies erreicht werden kann.\n\nDas Experiment wurde im Scanner und ausserhalb durchgef√ºhrt. Die beiden Version unterscheiden sich ganz stark in ihrem Timing. Wir implementieren hier die Scanner Version des Tasks.\n\nAnschlie√üend wird f√ºr 1000 ms ein Hinweis (cue) pr√§sentiert. Dabei kann es sich entweder um einen Pfeil handeln, der nach rechts zeigt, einen Pfeil, der nach links zeigt, oder einen einfachen Kreis (f√ºr die Kontrollbedingung). Der Codeblock in der Cue-Routine legt den tats√§chlichen Hinweis f√ºr jeden Versuch auf der Grundlage der Schleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz pr√§sentiert - dieses Mal f√ºr entweder 3400 ms, 4000 ms, 4500 ms oder 5000 ms. Wie beim ersten Fixationskreuz wird die tats√§chliche Dauer zuf√§llig gew√§hlt.\nNach dem zweiten Fixationskreuz wird f√ºr 1500 ms der eigentliche Stimulus angezeigt: ein random dot kinematogram (RDK). Die Punkte bewegen sich entweder nach rechts oder nach links mit einem Koh√§renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs wird durch die Schleifenvariable direction bestimmt und im Codeblock der Routine Dots festgelegt. Die Teilnehmer m√ºssen entscheiden, welche Richtung sie wahrnehmen, und k√∂nnen ihre Antwort durch Dr√ºcken der linken oder rechten Pfeiltaste auf der Tastatur eingeben.\nSchlie√ülich wird ein Feedback-Bildschirm angezeigt. Wenn der Teilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis ‚Äúzu schnell‚Äù angezeigt. Wurde w√§hrend des gesamten Stimulus keine Antwort erfasst, wird das Wort ‚Äúmiss‚Äù angezeigt. War die Antwort richtig, wird ‚Äú+5 Punkte‚Äù angezeigt, war sie falsch, wird ‚Äú+0 Punkte‚Äù angezeigt."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "href": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Experimentalschleife: main_blocks_loop",
    "text": "Experimentalschleife: main_blocks_loop\nMit loops in PsychoPy haben wir die M√∂glichkeit, eine oder mehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt, um denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber jedes Mal mit anderen Werten f√ºr die loop variables. Eine Schleife wiederholt also einen Versuch einige Male, wobei die Schleifenvariablen bei jeder Wiederholung ge√§ndert werden. Der Versuch selbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen, ob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird nur die main_blocks_loop erkl√§rt, aber das Prinzip gilt auch f√ºr die practice_block_loop.\nUm die verschiedenen Werte f√ºr die Schleifenvariablen zu definieren, m√ºssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop Variablen cue und direction. Das Stichwort kann entweder left, right oder none, sein, w√§hrend die Richtung left oder right sein kann.\nIn der Benutzeroberfl√§che k√∂nnen wir die Variablen loopType und nReps f√ºr die Schleife angeben, wenn wir sie anklicken. Mit ersterer k√∂nnen wir steuern, ob wir z.B. die Zeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach unten ablaufen lassen wollen, w√§hrend die letztere definiert, wie oft jede Zeile der Bedingungsdatei wiederholt werden soll.\nF√ºr die main_blocks_loop haben wir eine Bedingungsdatei mit 80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen entsprechen. In der einen H√§lfte der neutralen Trials bewegen sich die Punkte nach rechts, in der anderen H√§lfte nach links. Bei den voreingenommenen Versuchen sind 32 der Hinweise g√ºltig (d.¬†h. sie stimmen mit der Bewegungsrichtung der Punkte √ºberein) und 16 ung√ºltig, wobei sich die Punkte sowohl bei g√ºltigen als auch bei ung√ºltigen Hinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der Versuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so dass alle diese Reihen zweimal durchlaufen werden (insgesamt 160 Versuche), und die Variable ‚ÄúloopType‚Äù wird auf random gesetzt, so dass die Versuche in zuf√§lliger Reihenfolge durchgef√ºhrt werden."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#daten",
    "href": "pages/chapters/psychopy_experiments.html#daten",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Daten",
    "text": "Daten\nWenn man die default-Einstellungen nicht √§ndert, speichert PsychoPy die Daten automatisch in einem trial-by-trial CSV File. Das bedeutet, dass jeder Trial 1 Zeile generiert. Das CSV File erh√§lt einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es m√∂glich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV Files werden in einem Ordner mit dem Name data abgelegt.\n\nBei der Wahl vom Datenfile-Namen empfiehlt es sich immer Datum und Uhrzeit anzuh√§ngen. Dies verhindert, dass Daten √ºberschrieben werden, wenn z.B. eine Versuchspersonen-ID falsch eingetippt oder doppelt vergeben wird."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "href": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Degrees of Visual Angle",
    "text": "Degrees of Visual Angle\nOftmals werden Gr√∂ssenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abh√§ngig sind. Degrees of visual angle gibt die wahrgenommene Gr√∂sse des Stimulus an, und ber√ºcksichtigt die Gr√∂sse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von üëâ OpenSesame. √úblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem üëâ Link mehr Information.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm f√ºr die Erstellung behavioraler Experimente."
  },
  {
    "objectID": "pages/chapters/reproducibility.html",
    "href": "pages/chapters/reproducibility.html",
    "title": "Reproducibility",
    "section": "",
    "text": "Die Replikationskrise hat in der Psychologie, aber auch in den kognitiven Neurowissenschaften ein Umdenken ausgel√∂st. Reproduzierbarkeit und Replizierbarkeit sind zu wichtigen Konzepten f√ºr nachhaltige Forschung geworden. Die Begriffe werden verwirrenderweise aber oft unterschiedlich definiert (Plesser (2018)).\n\nReplizierbarkeit\nReplizierbarkeit (replicability) bedeutet, dass ein Experiment von einer anderen Forschungsgruppe mit einer neuen Stichprobe durchgef√ºhrt werden kann, und √§hnliche oder dieselben Resultate hervorbringt, wie die Originalstudie. Wird eine Studie mehrmals repliziert, steigt die Wahrscheinlichkeit, dass kein Zufallsbefund vorliegt.\n\nReplicability refers to the ability of a researcher to duplicate the results of a prior study if the same procedures are followed but new data are collected. Cacioppo et al. (2015)\n\n\n\nReproduzierbarkeit\nReproduzierbarkeit (reproducibility) h√§ngt eng mit der Replizierbarkeit zusammen, ist aber nicht dasselbe. Der Begriff wird teilweise sehr allgemein verwendet, und bedeutet so dass Forschungsergebnisse wiederholt gefunden werden auch von anderen Forschenden mit neuen Stichproben.\nReproduzierbarkeit im engeren Sinn hingegen bezieht sich darauf, ob die durchgef√ºhrte Analyse wiederholt werden kann. Die Reproduzierbarkeit ist somit hoch, wenn Forschende die Daten und Datenanalyseskripts bereitstellen und andere Forschende damit dieselben Analysen durchf√ºhren k√∂nnen und zu gleichen Resultaten kommen.\n\nReproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator. That is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results‚Ä¶. Reproducibility is a minimum necessary condition for a finding to be believable and informative. Cacioppo et al. (2015)\n\nUm die Begriffe zusammenzufassen schlugen Goodman, Fanelli, and Ionnidis (2016) vor von Reproduzierbarkeit der Methoden (Daten und Prozesse k√∂nnen exakt wiederholt werden), Reproduzierbarkeit der Resultate (andere Studien kommen auf dieselben Resultate) und Reproduzierbarkeit der wissenschaftlichen Schlussfolgerung (bei Repetition der Analyse oder der Experimente werden dieselben Schl√ºsse gezogen) zu sprechens.\nGrunds√§tzlich besteht das Ziel, dass in der Forschung m√∂glichst viel Evidenz f√ºr eine Schlussfolgerung gesammelt werden kann. Dies gelingt, wenn die Prozesse transparent, fehlerfrei und wiederholbar sind.\n\n\nHindernisse bei der Reproduzierbarkeit\nReproduzierbarkeit kann laut Nosek et al. (2022) vor allem aus zwei Gr√ºnden nicht gegeben sein: Weil die Daten/Skripte nicht zur Verf√ºgung stehen, oder weil diese Fehler enthalten:\n\nIn principle, all reported evidence should be reproducible. If someone applies the same analysis to the same data, the same result should occur. Reproducibility tests can fail for two reasons. A process reproducibility failure occurs when the original analysis cannot be repeated because of the unavailability of data, code, information needed to recreate the code, or necessary software or tools. An outcome reproducibility failure occurs when the reanalysis obtains a different result than the one reported originally. This can occur because of an error in either the original or the reproduction study.\n\nF√ºhrt die Reproduktion nicht zum selben Resultat, l√∂st das Zweifel am Forschungsergebnis aus. Wenn die Reproduzierbarkeit am Prozess scheitert, etwa weil die Daten nicht vorhanden sind, kann kein Schluss gezogen werden, ob die Resultate stimmen.\n\nAchieving reproducibility is a basic foundation of credibility, and yet many efforts to test reproducibility reveal success rates below 100%. ‚Ä¶ Whereas an outcome reproducibility failure suggests that the original result may be wrong, a process reproducibility failure merely indicates that the original result cannot be verified. Either reason challenges credibility and increases uncertainty about the value of investing additional resources to replicate or extend the findings (Nuijten et al.¬†2018). Sharing data and code reduces process reproducibility failures (Kidwell et al.¬†2016), which can reveal more outcome reproducibility failures (Hardwicke et al.¬†2018, 2021; Wicherts et al.¬†2011). Nosek et al. (2022)\n\nDas Teilen von Daten und Datenverarbeitungsskripten erh√∂ht die Wahrscheinlichkeit, dass m√∂gliche Fehler im Prozess gefunden werden, da auch andere Forschende die Daten/Skripts verwenden k√∂nnen. Das ist vorerst unangenehm, geh√∂rt aber zum Prozess der Wissenschaft dazu. Reproduzierbarkeit erh√∂ht also indirekt auch die Replizierbarkeit.\n\n\nTools f√ºr Reproduzierbarkeit\nF√ºr reproduzierbare Forschung gibt es inzwischen viele gute Tools:\n\nWebsite der Open Science Foundation: Eine kostenfreie und unkomplizierte M√∂glichkeit Daten und Skripts zu teilen, und diese in Projekten abzulegen. Es l√§sst sich daf√ºr sogar ein doi erstellen. Auch Preregistrationsformulare sind hier implementiert.\n\nBeim Ver√∂ffentlichen von wissenschaftlichen Artikeln ist es empfohlen, die Daten (falls anonymisiert m√∂glich) sowie die Analyseskripts mitzuver√∂ffentlichen.\n\nF√ºr Datens√§tze gelten die FAIR Guiding Principles (Wilkinson et al. (2016)):\n\nF indability: Es ist klar unter welchen Umst√§nden und wie die Daten zug√§nglich sind\nA ccessibility: Daten sind zug√§nglich bzw. es ist klar wo sie zu finden w√§ren\nI nteroperability: Verwendbare Datenformate/strukturen\nR eusability: gute Beschreibung des Datensatzes/der enthaltenen Variablen\n\n\n\nHier finden Sie weitere Informationen zu FAIR.\n\n\nF√ºr Neuroimaging-Daten gibt es beispielsweise vorgegebene Konventionen, wie ein Datensatz und die Verarbeitungsskripts abgespeichert werden. Ein Beispiel daf√ºr ist Brain Imaging Data Structure (BIDS). So k√∂nnen Datens√§tze mit einer f√ºr alle verst√§ndlichen Struktur ver√∂ffentlicht und geteilt werden.\n\n\nHier finden Sie weitere Informationen zu BIDS.\n\n\nF√ºr das Ver√∂ffentlichen von Analyseskripts eignen sich Formate wie RMarkdown in R, oder LiveScripts in MATLAB sehr gut. Aber auch .r-Skripte, wie Sie sie in dieser Veranstaltung verwenden k√∂nnen ver√∂ffentlicht werden.\n\n\nHier finden Sie eine sehr gut erkl√§rte Einf√ºhrung zu RMarkdown.\n\n\n\nCode kommentieren\nDas Teilen von Skripts macht am meisten Sinn, wenn sie verst√§ndlich strukturiert und kommentiert sind. Beim Kommentieren von Code sollte folgendes beachtet werden:\n\nKommentare sollten geschrieben werden, wenn der Code erstellt wird und laufend √ºberarbeitet werden. Oft wird es sonst nicht nachgeholt.\nWenn man nicht genau kommentieren kann, was man im Code macht, dann ist evtl. der Code unklar, oder man versteht ihn noch nicht. Vielleicht kann man Variablennamen vereinfachen/pr√§zisieren und es braucht weniger Kommentare?\nWenn Code kopiert wird, sollte die Quelle angegeben werden.\nVor dem Ver√∂ffentlichen, lohnt es sich jemanden den Code ausf√ºhren lassen. So zeigt sich wo noch unklare Stellen sind, die Kommentare ben√∂tigen.\n\n\n\n\n\n\nReferences\n\nCacioppo, J. T., R. M. Kaplan, J. A. Krosnick, J. L. Olds, and H. Dean. 2015. ‚ÄúSocial, Behavioral, and Economic Sciences Perspectives on Robust and Reliable Science.‚Äù Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences.\n\n\nGoodman, Steven N., Daniele Fanelli, and John P. A. Ionnidis. 2016. ‚ÄúWhat Does Research Reproducibility Mean?‚Äù Science Translational Medicine 341. https://doi.org/10.1126/scitranslmed.aaf5027.\n\n\nNosek, Brian A, Tom E Hardwicke, Hannah Moshontz, Aur√©lien Allard, Katherine S Corker, Anna Dreber, Fiona Fidler, et al. 2022. ‚ÄúReplicability, Robustness, and Reproducibility in Psychological Science.‚Äù Annual Review of Psychology 73: 719‚Äì48. https://doi.org/10.1146/annurev-psych-020821-114157.\n\n\nPlesser, Hans E. 2018. ‚ÄúReproducibility Vs. Replicability: A Brief History of a Confused Terminology.‚Äù Frontiers in Neuroinformatics 11 (January): 76. https://doi.org/10.3389/fninf.2017.00076.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. ‚ÄúThe FAIR Guiding Principles for Scientific Data Management and Stewardship.‚Äù Scientific Data 3 (1): 160018. https://doi.org/10.1038/sdata.2016.18.\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis2023,\n  author = {Ellis, Andrew and Wyssen, Gerda},\n  title = {Reproducibility},\n  date = {2023-03-20},\n  url = {https://kogpsy.github.io/neuroscicomplabFS23//pages/chapters/reproducibility.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nEllis, Andrew, and Gerda Wyssen. 2023. ‚ÄúReproducibility.‚Äù\nMarch 20, 2023. https://kogpsy.github.io/neuroscicomplabFS23//pages/chapters/reproducibility.html."
  },
  {
    "objectID": "pages/chapters/rmarkdown.html",
    "href": "pages/chapters/rmarkdown.html",
    "title": "R Markdown",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nErstellen eines (reproduzierbaren) Data Reports mit Datenvisualisierungen zu unserem Experiment.\nIn der heutigen Sitzung lernen wir die Basics, die man braucht um einen Data Report in R Markdown erstellen zu k√∂nnen.\n\nR Markdown File erstellen\nR Markdown File ausf√ºhren (knitten)\nTitel und Layout anpassen\nText schreiben in R Markdown\nCode verwenden in R Markdown"
  },
  {
    "objectID": "pages/chapters/rmarkdown.html#r-markdown-file-erstellen-und-ausf√ºhren",
    "href": "pages/chapters/rmarkdown.html#r-markdown-file-erstellen-und-ausf√ºhren",
    "title": "R Markdown",
    "section": "R Markdown File erstellen und ausf√ºhren",
    "text": "R Markdown File erstellen und ausf√ºhren\nZuerst erstellen wir ein R Markdown File und schauen uns die wichtigsten Funktionen an. Wir w√§hlen als Outputformat html.\n\n\n\n\n\n\nHands-on\n\n\n\n\nLaden Sie hier den Projektordner herunter und entzippen Sie diesen.\n√ñffnen Sie das Projekt und erstellen Sie unter File &gt; New File &gt; R Markdown ... ein neues RMarkdown-File.\nGeben Sie einen Titel und Ihren Namen ein und w√§hlen Sie HTMLals Output-Format\nSpeichern Sie dass Dokument unter dem Namen rmarkdown_exampleab.\n\n\n\n\nWeiterf√ºhrende Informationen:\nüëâ Einf√ºhrung in die Verwendung von R/RStudio/Notebooks im Rahmen des Psychologie Studiums von Andrew Ellis und Boris Mayer Einf√ºhrung in R\nüëâ Sehr kompakte, praxisnahe Einf√ºhrung in R Markdown von Danielle Navarro (Slidedeck in englisch) Einf√ºhrung in R Markdown\n\nWenn Sie die obigen Schritte ausgef√ºhrt haben, beantworten Sie bitte folgende Fragen:\n\n\n\n\n\n\nAufgabe 1\n\n\n\nWelches Format (Endung) hat das abgespeicherte R Markdown Skript nun in Ihrem Ordner?\n\n\n\n\n\n\n\n\nL√∂sung 1\n\n\n\n\n\n.Rmd f√ºr R Markdown"
  },
  {
    "objectID": "pages/chapters/rmarkdown.html#knitten",
    "href": "pages/chapters/rmarkdown.html#knitten",
    "title": "R Markdown",
    "section": "Knitten",
    "text": "Knitten\nMit Knit f√ºhren wir das R Markdown Skript nun aus und erstellen so (wie vorher ausgew√§hlt) ein html-File.\n\n\n\n\n\n\nAufgabe 2\n\n\n\nF√ºhren Sie das File mit Knit aus und vergleichen Sie das R Markdown Skript mit dem Output den Sie erhalten haben. Was f√§llt Ihnen auf?\n\nWas ist nicht mehr zu sehen?\nWas ist zus√§tzlich zu sehen?\nWas hat sich im Projekt-Ordner ver√§ndert?\n\n\n\n\n\n\n\n\n\nL√∂sung 2\n\n\n\n\n\nNicht mehr zu sehen ist der vollst√§ndige YAML-header, ganz oben im R Markdown Skript.\nAuch nicht mehr zu sehen ist die ‚ÄúUmrandung‚Äù des Code-Snippets.\nNeu sieht man nun den Output des Codes.\nIm Projektordner wurde ein .html-File erstellt. Sie k√∂nnen dieses √∂ffnen, um zu schauen wie das aussieht."
  },
  {
    "objectID": "pages/chapters/rmarkdown.html#yaml-header",
    "href": "pages/chapters/rmarkdown.html#yaml-header",
    "title": "R Markdown",
    "section": "YAML header",
    "text": "YAML header\nZu Beginn des R Markdown Skripts finden Sie den YAML header. Hier werden Informationen zu Titel, Autor:Innen, Datum, Outputformat, Literaturverzeichnis und Layout festgelegt.\n\nYAML: Yet Another Markdown Language\n\nDas Layout kann unter themege√§ndert werden. Das kann beispielsweise wie folgt aussehen:\noutput:\n  html_document:\n    theme: cosmo\nAchtung: Einr√ºckungen m√ºssen stimmen! Hier wurde das theme namens cosmo ausgew√§hlt. M√∂gliche andere themessind z.B. default, cerulean, journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, yeti.\n\n\n\n\n\n\nHands-on\n\n\n\n\nGeben Sie dem Dokument einen neuen Titel z.B. R Markdown Einf√ºhrung\n√Ñndern Sie das Layout so, dass es Ihnen gef√§llt."
  },
  {
    "objectID": "pages/chapters/rmarkdown.html#text-erstellen-in-r-markdown",
    "href": "pages/chapters/rmarkdown.html#text-erstellen-in-r-markdown",
    "title": "R Markdown",
    "section": "Text erstellen in R Markdown",
    "text": "Text erstellen in R Markdown\nText kann in R Markdown Files nicht nur geschrieben, sondern auch relativ simpel formatiert werden.\nüëâ Hier k√∂nnen Sie das Cheatsheet herunterladen. Auf der rechten Seite finden Sie die Informationen f√ºr die Textformatierung.\nKnitten Sie das Skript immer wieder um zu √ºberpr√ºfen, ob alles passt. Es empfiehlt sich anfangs h√§ufig zu knitten, so findet man den Fehler schneller, weil man noch weiss, was man ver√§ndert hat.\n\n\n\n\n\n\nHands-on\n\n\n\n\nL√∂schen Sie alles bis auf den YAML-Header\nSchreiben Sie im Textbereich eine √úberschrift f√ºr ein Kapitel, ein Unterkapitel und normalen Text.\nSchreiben Sie im Text etwas kursiv und etwas fett.\nErstellen Sie im Textbereich eine Liste mit 3 Punkten.\nF√ºgen Sie die Formel a^2 + b^2 = c^2 in den Text ein. Verwenden Sie daf√ºr zwei Dollarzeichen am Anfang und am Ende. Was passiert? Schreiben Sie alpha innerhalb von Dollarzeichen, was passiert?\nF√ºgen Sie einen Link ein, knitten Sie das File und schauen Sie ob der Link funktioniert. K√∂nnen Sie einen Link nur mit einem unterstrichenen Text anzeigen, so dass die Linkadresse nicht sichtbar ist?\nF√ºgen Sie ein Bild ein. Sie k√∂nnen beispielsweise das Bild logo_landing.png aus dem Projektordner nutzen oder ein eigenes verwenden."
  },
  {
    "objectID": "pages/chapters/rmarkdown.html#code-erstellen-in-r-markdown",
    "href": "pages/chapters/rmarkdown.html#code-erstellen-in-r-markdown",
    "title": "R Markdown",
    "section": "Code erstellen in R Markdown",
    "text": "Code erstellen in R Markdown\nNun erstellen wir Code. Zuerst f√ºgen wir ein Code-Chunk ein, darin muss der Code stehen um ausgef√ºhrt zu werden. Dies k√∂nnen Sie unter Code &gt; Insert Chunk tun oder Ctrl+Alt+ I dr√ºcken. Code-Chunks werden mit ``` begonnen und beendet. In den geschweiften Klammern steht r, das bedeutet das der Code in der Sprache R geschrieben ist. In dieser Klammer k√∂nnen wir dem Code-Chunk einen Namen geben und bestimmen, ob der Code ausgef√ºhrt und angezeigt wird, und ob der Output des Codes angezeigt werden soll.\nSie k√∂nnen mit dem gr√ºnen Pfeil den Code-Chunk ausf√ºhren. Aber auch einzelne Zeilen k√∂nnen ausgef√ºhrt werden, genau so wie in einem .R- Skript.\n\n\n\n\n\n\nHands-on\n\n\n\n\nErstellen Sie einen Code-Chunk, der ausgef√ºhrt, aber nicht angezeigt wird. Erstellen Sie eine Variable mit dem Namen numbers, die 10 Zahlen enth√§lt.\nErstellen Sie ein Code-Chunk, der ausgef√ºhrt wird und dessen Output angezeigt wird. Berechnen Sie in diesem Chunk den Mittelwert und die Standardabweichung von numbers.\n\nüëâ Schauen Sie daf√ºr nochmals im Cheatsheet nach oder dr√ºcken Sie auf das Zahnr√§dchen-Symbol beim Code-Chunk.\n\nErstellen Sie einen Plot mit plot(numbers).\nKnitten Sie das File, um zu √ºberpr√ºfen, ob alles funktioniert"
  },
  {
    "objectID": "pages/chapters/signal-detection-1.html",
    "href": "pages/chapters/signal-detection-1.html",
    "title": "Einf√ºhrung",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nSimple bin√§re Entscheidungen mit Signal Detection Theory modellieren\nKonzepte der Signal Detection Theorie (SDT)\nSDT mit R simulieren"
  },
  {
    "objectID": "pages/chapters/signal-detection-1.html#theorie",
    "href": "pages/chapters/signal-detection-1.html#theorie",
    "title": "Einf√ºhrung",
    "section": "Theorie",
    "text": "Theorie\nDie zentrale Fragestellung der SDT lautet: was ist der (unbekannte) Zustand der Welt, angesichts der verrauschten Daten, die von den Sinnessystemen bereitgestellt werden?\nIn einem Modell macht es Sinn, sicherzustellen, dass das Problem einfach ist ‚Äì wir beschr√§nken die Welt auf zwei m√∂gliche Zust√§nde. Diese k√∂nnen als Hypothesen betrachtet werden.\n\n\n\n\n\n\nBeispiele\n\n\n\n\nSignal / Rauschen\nLinks / Rechts\nGed√§chtnis: alt (schon gesehen) / neu (noch nie gesehen)\n\n\n\nWir werden nun die Signal Detection Theorie anhand eine Beispiels durchgehen. Dieses werden wir aus zwei Perspektiven betrachten: 1) aus der Perspektive einer Person, welche die Aufgabe hat, Stimuli in zwei Klassen zu klassifizieren und 2) aus der Perspektive eines Modells, das die Leistung der Person in der Aufgabe vorhersagt.\nDie Perspektive der Versuchsperson\nWir betrachten ein Experiment, bei dem eine Person einen Stimulus in eine von zwei m√∂glichen Kategorien einordnen muss; dies k√∂nnte ein Random Dot Experiment sein, bei dem die Stimuli entweder nach links oder rechts bewegt sind, oder ein Ged√§chtnisexperiment, bei dem die Stimuli entweder alt (schon gesehen wurden) oder neu sind.\nDie Aufgabe der Person ist es, eine bin√§re Klassifikation mit den Antwortoptionen alt und neu durchzuf√ºhren. Die Antwortoptionen entsprechen den beiden m√∂glichen Zust√§nden der Welt, oder genauer gesagt, Hypothesen der Person √ºber die m√∂glichen Zust√§nde der Welt.\nGegeben den Reiz hat die Person zwei Antwortm√∂glichkeiten. Daher betrachten wir nur die Ja-Antworten, wenn der Reiz alt (Treffer) oder neu (Falschalarme) ist.\nAnnahmen\n\nDie Person verarbeitet den Stimulus (in diesem Fall ein Wort oder ein Bild) und gelangt zu einer internen Repr√§sentation des Stimulus. Diese interne Repr√§sentation ist nicht deterministisch, sondern variiert zuf√§llig. Die interne Repr√§sentation demzufolge eine Zufallsvariable \\(X\\). Wir nehmen an, dass die interne Repr√§sentation normalverteilt ist, mit einer bekannten Standardabweichung \\(\\sigma\\) (der Einfachheit halber nehmen wir an, dass \\(\\sigma=1\\)).\nDie Zufallsvariable \\(X\\) repr√§sentiert die Information, die die Person √ºber den Stimulus hat, also die Evidenz.\nDie Person weiss, dass die \\(X\\) aus einer von zwei Verteilungen gezogen wurde, die sich nur in ihrer Lage (in ihrem Mittelwert) unterscheiden. Welche Verteilung es war, weiss die Person jedoch nicht ‚Äì dies muss sie anhand eines Kriteriums entscheiden.\nDie Person hat ein Kriterium \\(k\\), das sie verwendet, um zu entscheiden, ob der Stimulus alt oder neu ist. Eine einfache Entscheidungsregel lautet: Wenn \\(X &gt; k\\), dann ist der Stimulus alt, andernfalls ist er neu.\n\n\nBeispiel Recognition Memory: Wenn der Versuchsperson ein Bild gezeigt wird, ruft dies ein Gef√ºhl von ‚ÄòVertrautheit‚Äô (familiarity) hervor. Dies ist eine latente Variable.\n\n\n\n\n\nNoch nie gesehene Stimuli (neu) produzieren eine niedrige Vertrautheit (familiarity), w√§hrend alte Stimuli eine hohe Vertrautheit produzieren. Um einen Stimulus zu klassifizieren, braucht die Person eine Entscheidungsregel.\n\n\n\n\n\nEine einfache Entscheidungsregel lautet: Wenn die Vertrautheit gr√∂sser als das Kriterium ist, wenn also \\(x &gt; k\\), dann ist der Stimulus alt, andernfalls ist er neu.\nDie Perspektive des/der externen Beobachter*in\nDie Leistung der Versuchsperson kann durch die Wahrscheinlichkeit beschrieben werden, dass sie einen Treffer (Hit) oder einen False Alarm produziert. Diese Wahrscheinlichkeiten werden als Hit Rate und False Alarm Rate bezeichnet. Die Hit Rate ist die Wahrscheinlichkeit, dass die Person einen Treffer produziert, wenn der Stimulus alt ist. Die False Alarm Rate ist die Wahrscheinlichkeit, dass die Person einen Falschalarm produziert, wenn der Stimulus neu ist.\nDie Antworten der Versuchspersonen k√∂nnen in einer Tabelle zusammengefasst werden, mit vier m√∂glichen Ergebnissen. Wir nennen hier die Antwortoptionen der Einfachheit halber ja und nein; die Frage an die Versuchsperson lautet: ‚ÄúHast du den Stimulus schon einmal gesehen?‚Äù.\n\n\n\nSignal\n\n\n\n\nAntwort\nJa\nNein\n\n\nJa\nHit\nFalse alarm (FA)\n\n\nNein\nMiss\nCorrect rejection (CR)\n\n\n\n\n\nHit: Stimulus ist alt, Antwort ist Ja\n\nMiss: Stimulus ist alt, Antwort ist Nein\n\n\nFalse alarm: Stimulus ist neu, Antwort ist Ja\n\nCorrect rejection: Stimulus is neu, Antwort ist Nein\n\n\nAls Forscher*in interessiert uns nicht nur, wie oft die Versuchsperson Hits und False ALarms produziert, sondern vor allem folgende Fragen:\n\nWie gut kann die Person Stimuli klassifizieren?\nHat die Person eine Vorliebe f√ºr eine der beiden Antwortoptionen?\n\nDiese beiden Fragen k√∂nnen wir mit den Signal Detection Theory (SDT) Parametern beschreiben.\nDie beiden wichtigsten SDT Parameter sind \\(d'\\) und \\(c\\). \\(d'\\) ist ein Mass daf√ºr, wie weit auseinander die Verteilungen der beiden Stimuluskategorien liegen. \\(c\\) ist ein Mass daf√ºr, ob eine Voreingenommenheit (bias) f√ºr eine der beiden Antwortoptionen besteht. Genauer gesagt ist \\(c\\) der Abstand vom tats√§chlichen Kriterium zum Punkt welcher genau zwischen den Verteilungen liegt.\nUm diese beiden Parameter aus den beobachteten Antworth√§ufigkeiten zu sch√§tzen, m√ºssen wir zuerst die relativen H√§ufigkeiten der Hits und der False Alarms sch√§tzen.\nDie Hits sind die korrekten Antworten auf alte Stimuli. Dies bedeutet, dass wir z√§hlen, wie oft bei einem alten Stimulus die Antwort ja war. Die False Alarms sind die inkorrekten Antworten auf neue Stimuli. Dies bedeutet, dass wir z√§hlen, wie oft bei einem neuen Stimulus die Antwort ja war. \\[ p_{H} = \\frac{Hits}{Hits + Misses} \\] \\[ p_{FA} = \\frac{False Alarms}{False Alarms + Correct Rejections} \\]\nSchauen wir uns die Grafik an: Wenn der Stimulus neu ist, dann werden wir mit einer Wahrscheinlichkeit von \\(p_{FA}\\) einen False Alarm produzieren.\n\\[ p_{FA} = P(y = 1 | X = 0) = 1 - \\Phi(k) \\]\n\\(k\\) ist die die von der Person willk√ºrlich gesetzte Klassifikationsgrenze. \\(\\Phi\\) ist die Verteilungsfunktion der Normalverteilung.\n\n\n\n\n\n\nImportant\n\n\n\n\\(\\Phi(k)\\) gibt hier die Wahrscheinlichkeit, dass eine Zufallsvariable \\(x\\) kleiner als \\(k\\) ist. Wir wollen eigentlich wissen, was die Wahrscheinlichkeit ist, dass \\(x\\) gr√∂sser als \\(k\\) ist ‚Äì diese ist \\(1 - \\Phi(k)\\).\n\n\n\n\n\n\n\nWenn der Stimulus alt ist, dann werden wir mit einer Wahrscheinlichkeit von \\(p_{H}\\) einen Hit produzieren.\n\\[ p_{H} = P(y = 1 | X=1) = 1 - \\Phi(k-d') \\]\n\n\n\n\n\nWir k√∂nnen das auch in einer Gleichung schreiben:\n\\[ P(y = 1 | X = x) = 1 - \\Phi(k-d'X) = \\Phi(-k + d'X) \\] wo \\(X\\) eine Indikatorvariable ist, d.h. sie nimmt den Wert 1 f√ºr alt und 0 f√ºr neu.\nDie Gleichung gibt die bedingte Wahrheitswahrscheinlichkeit f√ºr eine ja Antwort, gegeben den Stimulus. Ist der Stimulus alt, dann ist \\(X = 1\\) und \\(d'X = d'\\), ist der Stimulus neu, dann ist \\(X = 0\\) und \\(d'X = 0\\).\nHier sind beide Verteilungen nochmals in einer Grafik zusammengefasst:\n\n\n\n\n\nUnser Ziel ist es, die Parameter \\(d'\\) und \\(c\\) zu sch√§tzen, d.h. wir wollen wissen: Wie weit liegen die Mittelwerte der Verteilung auseinander, und wo hat die Person ihr Kriterium gesetzt? Wir k√∂nnen dies mit folgenden Gleichung machen:\nKriterium k: Hier wollen wir wissen: Wo liegt der Wert, f√ºr den die Wahrscheinlichkeit, √ºber \\(k\\) zu liegen, \\(p_{FA}\\) entspricht? Wir brauchen daf√ºr die Umkehrfunktion der Verteilungsfunktion \\(\\Phi\\): \\(\\phi^{-1}\\).\n\n\n\n\n\n\nVerteilungen in R\n\n\n\n\n\nDie Verteilungsfunktion der Normalverteilung heisst in R pnorm(). Die Umkehrfunktion dazu heisst Quantilfunktion und heisst in R qnorm().\nDie verwandten Funktionen sind die Dichtefunktion dnorm() und rnorm(), mit der wir Zufallszahlen aus der Normalverteilung ziehen k√∂nnen.\nDie kumulative Verteilungsfunktion:\n\n\n\n\n\nDie Quantilfunktion sieht so aus:\n\n\n\n\n\n\n\n\nWir k√∂nnen nun umformen: \\[ p_{FA} = P(y = 1 | X = 0) = 1 - \\Phi(k) \\] \\[ \\Phi(k) = 1 - p_{FA} \\]\n\\[ k = \\phi^{-1}(1-p_{FA}) = -\\phi^{-1}(p_{FA}) \\]\nWir interessieren uns nun aber f√ºr den Abstand zum optimalen Kriterium: dieser Parameter wird \\(c\\) genannt. Im optimalen Fall ist \\(c = 0\\), und \\(k=\\frac{d'}{2}\\). Dann w√§ren die Miss- und Fehlalarmrate gleich gross (anhand der Grafik selber √ºberpr√ºfen). \\(c\\) ist also der Durchschnitt der Hit- und False Alarm Rate, mit \\(-1\\) multipliziert. Negative Werte von \\(c\\) bedeuten, dass die Person tendenziell mehr Fehlalarme produziert als Misses, positive Werte bedeuten, dass die Person tendenziell mehr Misses produziert als Fehlalarme.\n\\[ c = -\\frac{1}{2} \\left[\\phi^{-1}(p_{H}) + \\phi^{-1}(p_{FA})\\right] \\]\nF√ºr \\(d'\\) gilt:\n\\[ d' = k - \\phi^{-1}(1-p_{H}) = \\phi^{-1}(p_{H}) - \\phi^{-1}(p_{FA}) \\]\noder anders ausgedr√ºckt: \\[ d' = \\phi^{-1}(P(y = 1 | old)) - \\phi^{-1}(P(y = 1 | new)) \\]\nund in Worten:\n\\(d'\\) = Z-Score der Hit Rate - Z-Score der False Alarm Rate.\n\n\n\n\n\n\nTip\n\n\n\nDer Begriff Z-Score wird oftmals verwendet, und die Quantile einer Standardnormalverteilung zu bezeichnen.\n\n\n\\(d'\\) quantifiziert die Sensitivit√§t eines Beobachters bei der Unterscheidung zwischen zwei Stimulusklassen. Ein gr√∂√üerer \\(d'\\)-Wert zeigt eine gr√∂ssere Sensitivit√§t an. Dies bedeutet, dass die Verteilungen der beiden Stimulusklassen st√§rker voneinander getrennt sind und somit leichter unterscheidbar sind."
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html",
    "href": "pages/chapters/signal-detection-2.html",
    "title": "SDT anwenden",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nSDT auf einen Datensatz mit mehreren Bedingungen anwenden.\nSensitivit√§t \\(d'\\) und Bias \\(c\\) grafisch darstellen und zwischen ‚Äòwithin‚Äô-Bedingungen vergleichen."
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#daten-importieren",
    "href": "pages/chapters/signal-detection-2.html#daten-importieren",
    "title": "SDT anwenden",
    "section": "Daten importieren",
    "text": "Daten importieren\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.2     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWir importieren die Daten aus dem RDK Experiment.\n\ndf &lt;- read_csv(\"data/rdkdata_clean.csv\")\n\nRows: 7163 Columns: 11\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (4): condition, cue, direction, choice\ndbl (7): id, trial_all, block, trial_inblock, response, rt, correct\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nZur Sicherheit schauen wir uns die ersten 10 Zeilen an.\n\ndf\n\n# A tibble: 7,163 √ó 11\n      id trial_all block trial_inblock condition cue   direction choice response\n   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1   511         0     0             0 neutral   none  right     right         1\n 2   511         1     0             1 neutral   none  left      left          0\n 3   511         2     0             2 invalid   right left      left          0\n 4   511         3     0             3 invalid   left  right     right         1\n 5   511         4     0             4 valid     right right     right         1\n 6   511         5     0             5 valid     right right     left          0\n 7   511         6     0             6 valid     right right     left          0\n 8   511         7     0             7 valid     right right     right         1\n 9   511         8     0             8 neutral   none  left      left          0\n10   511         9     0             9 neutral   none  left      right         1\n# ‚Ñπ 7,153 more rows\n# ‚Ñπ 2 more variables: rt &lt;dbl&gt;, correct &lt;dbl&gt;"
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#daten-vorbereiten",
    "href": "pages/chapters/signal-detection-2.html#daten-vorbereiten",
    "title": "SDT anwenden",
    "section": "Daten vorbereiten",
    "text": "Daten vorbereiten\nDie Variablen id, condition, cue, direction, choice sind kategorisch. Wir konvertieren sie zu Faktoren.\n\ndf  &lt;- df |&gt;\n  mutate(across(c(id, condition, cue, direction, choice), as_factor))"
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#signal-detection-theory-kennzahlen-berechnen",
    "href": "pages/chapters/signal-detection-2.html#signal-detection-theory-kennzahlen-berechnen",
    "title": "SDT anwenden",
    "section": "Signal Detection Theory Kennzahlen berechnen",
    "text": "Signal Detection Theory Kennzahlen berechnen\nDie Vpn sollten die Richtung des RDKs angeben; diese war entweder ‚Äòright‚Äô oder ‚Äòleft‚Äô und ist in der Variablen choice gespeichert. Wir k√∂nnen die Antworten der Vpn mit der tats√§chlichen Richtung des RDKs vergleichen, um zu bestimmen, ob die Vpn richtig oder falsch geantwortet haben. Wir k√∂nnen die Antworten der Vpn und die Richtung des RDKs in vier Kategorien einteilen: Hit, Miss, False Alarm, und Correct Rejection.\nWir definieren nun korrekte rechts-Antworten als Hit, falsche rechts-Antworten als Miss, korrekte links-Antworten als Correct Rejection, und falsche links-Antworten als False Alarm.\n\nDies ist willk√ºrlich - wir k√∂nnten genauso gut links und rechts vertauschen.\n\ndf &lt;- df |&gt;\n    mutate(type = case_when(\n        direction == \"right\" & choice == \"right\" ~ \"Hit\",\n        direction == \"right\" & choice == \"left\" ~ \"Miss\",\n        direction == \"left\" & choice == \"left\" ~ \"CR\",\n        direction == \"left\" & choice == \"right\" ~ \"FA\"\n    ))\n\nNun z√§hlen wir die Anzahl Hit, Miss, FA, und CR f√ºr jede Vp und Bedingung. Wir k√∂nnen dies mit count() machen.\n\ndf_cue &lt;- df |&gt;\n      group_by(id, cue) |&gt;\n      count(type)\n\n\ndf_cue\n\n# A tibble: 525 √ó 4\n# Groups:   id, cue [135]\n   id    cue   type      n\n   &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt;\n 1 184   none  CR       31\n 2 184   none  FA        9\n 3 184   none  Hit      19\n 4 184   none  Miss     21\n 5 184   right CR        5\n 6 184   right FA        3\n 7 184   right Hit      15\n 8 184   right Miss     17\n 9 184   left  CR       19\n10 184   left  FA       13\n# ‚Ñπ 515 more rows\n\n\nAnschliessend k√∂nnen wir die Daten mit pivot_wider() in ein wide Format umwandeln, so dass jede Kennzahl eine eigene Spalte erh√§lt.\n\ndf_cue  &lt;- df_cue |&gt;\n    pivot_wider(names_from = type, values_from = n) \n\n\ndf_cue\n\n# A tibble: 135 √ó 6\n# Groups:   id, cue [135]\n   id    cue      CR    FA   Hit  Miss\n   &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 184   none     31     9    19    21\n 2 184   right     5     3    15    17\n 3 184   left     19    13     3     5\n 4 185   none     19    21    20    20\n 5 185   right     5     3    21    11\n 6 185   left     15    17     3     5\n 7 238   none     28    12    12    28\n 8 238   right     3     5    15    17\n 9 238   left     26     6    NA     8\n10 239   none     34     6    23    17\n# ‚Ñπ 125 more rows\n\n\nEs gibt noch NA Werte - deis bedeutet, dass die Vp keine Antworten des entsprechenden Typs gegeben hat. Diese NAs m√ºssen wir durch 0 ersetzen, damit wir die Kennzahlen berechnen k√∂nnen.\n\nreplace_NA &lt;- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n} \n\n\ndf_cue &lt;- df_cue |&gt;\n  mutate(across(c(Hit, Miss, FA, CR), replace_NA))\n\n\ndf_cue\n\n# A tibble: 135 √ó 6\n# Groups:   id, cue [135]\n   id    cue      CR    FA   Hit  Miss\n   &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 184   none     31     9    19    21\n 2 184   right     5     3    15    17\n 3 184   left     19    13     3     5\n 4 185   none     19    21    20    20\n 5 185   right     5     3    21    11\n 6 185   left     15    17     3     5\n 7 238   none     28    12    12    28\n 8 238   right     3     5    15    17\n 9 238   left     26     6     0     8\n10 239   none     34     6    23    17\n# ‚Ñπ 125 more rows\n\n\nNun berechnen wir die relativen H√§ufigkeiten, mit denen Hit und FA auftreten.\n\n\n\n\n\n\nTip\n\n\n\nDie Hit Rate ist die Anzahl Hits geteilt durch die Anzahl Hits und Misses (wie oft hat die Versuchsperson korrekterweise ‚Äòrechts‚Äô gesagt, wenn der Stimulus tats√§chlich ‚Äòrechts‚Äô war?) Die False Alarm Rate ist die Anzahl FAs geteilt durch die Anzahl FAs und CRs (wie oft hat die Versuchsperson f√§lschlicherweise ‚Äòrechts‚Äô gesagt, wenn der Stimulus tats√§chlich ‚Äòlinks‚Äô war?).\n\n\n\ndf_cue  &lt;- df_cue |&gt;\n    mutate(hit_rate = Hit/(Hit + Miss),\n           fa_rate = FA/(FA + CR))\n\n\ndf_cue\n\n# A tibble: 135 √ó 8\n# Groups:   id, cue [135]\n   id    cue      CR    FA   Hit  Miss hit_rate fa_rate\n   &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 184   none     31     9    19    21    0.475   0.225\n 2 184   right     5     3    15    17    0.469   0.375\n 3 184   left     19    13     3     5    0.375   0.406\n 4 185   none     19    21    20    20    0.5     0.525\n 5 185   right     5     3    21    11    0.656   0.375\n 6 185   left     15    17     3     5    0.375   0.531\n 7 238   none     28    12    12    28    0.3     0.3  \n 8 238   right     3     5    15    17    0.469   0.625\n 9 238   left     26     6     0     8    0       0.188\n10 239   none     34     6    23    17    0.575   0.15 \n# ‚Ñπ 125 more rows\n\n\nNun gibts es noch eine kleines Problem: Falls es irgendwo eine hit_rate oder eine fa_rate von 0 oder 1 gibt, k√∂nnen wir nicht weiterrechnen. Relative H√§ufigkeiten sind Sch√§tzungen von Wahrscheinlichkeiten und m√ºssen daher zwischen 0 oder 1 liegen. Wir k√∂nnen dieses Problem l√∂sen, indem wir die hit_rate und fa_rate um einen kleinen Wert erh√∂hen oder verringern, falls sie 0 oder 1 sind.\n\ncorrect_zero_one &lt;- function(rate, e = 0.001) {\n    if (identical(rate, 0)) {\n        rate = rate + e\n    } else if (identical(rate, 1)) {\n        rate = rate - e\n    }\n    rate\n}\n\n\ndf_cue &lt;- df_cue |&gt;\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))\n\n\ndf_cue\n\n# A tibble: 135 √ó 8\n# Groups:   id, cue [135]\n   id    cue      CR    FA   Hit  Miss hit_rate fa_rate\n   &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 184   none     31     9    19    21    0.475   0.225\n 2 184   right     5     3    15    17    0.469   0.375\n 3 184   left     19    13     3     5    0.375   0.406\n 4 185   none     19    21    20    20    0.5     0.525\n 5 185   right     5     3    21    11    0.656   0.375\n 6 185   left     15    17     3     5    0.375   0.531\n 7 238   none     28    12    12    28    0.3     0.3  \n 8 238   right     3     5    15    17    0.469   0.625\n 9 238   left     26     6     0     8    0.001   0.188\n10 239   none     34     6    23    17    0.575   0.15 \n# ‚Ñπ 125 more rows\n\n\nDamit wir nun \\(d'\\) und \\(c\\) berechnen k√∂nnen, m√ºssen die hit_rate und fa_rate in \\(z\\)-Werte umgewandelt werden.\n\ndf_cue &lt;- df_cue |&gt;\n  mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\n\nMit den z-transformierten Werten k√∂nnen wir nun \\(d'\\) und \\(c\\) berechnen.\n\\[ c = -\\frac{1}{2} \\left[\\phi^{-1}(p_{H}) + \\phi^{-1}(p_{FA})\\right] =  -\\frac{1}{2} \\left[zH + zFA\\right] \\] \\[ d' = k - \\phi^{-1}(1-p_{H}) = \\phi^{-1}(p_{H}) - \\phi^{-1}(p_{FA}) = zH - zFA \\]\n\ndf_cue &lt;- df_cue |&gt;\n  mutate(dprime = zhr - zfa,\n         k = -zfa,\n         c = -0.5 * (zhr + zfa)) |&gt;\n    mutate(across(c(dprime, k, c), \\(x) round(x, 2)))"
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#grafische-darstellung-von-bias-und-sensitivit√§t",
    "href": "pages/chapters/signal-detection-2.html#grafische-darstellung-von-bias-und-sensitivit√§t",
    "title": "SDT anwenden",
    "section": "Grafische Darstellung von Bias und Sensitivit√§t",
    "text": "Grafische Darstellung von Bias und Sensitivit√§t\nUm einen √úberblick zu gewinnen, stellen wir \\(c\\) und \\(d'\\) grafisch dar. Wir erarten hier, dass die Sensitivit√§t unver√§ndert bleibt, da wir diese nicht manipuliert haben. Der Bias sollte sich jedoch zwischen den Bedingungen unterscheiden. In der neutralen Bedingung, d.h. wenn kein Hinweisreiz gegeben wurde, sollte der Bias bei 0 liegen. Falls der Hinweisreiz die Vp dazu bringt, eher ‚Äòrechts‚Äô zu antworten, sollte der Bias negativ sein. Falls der Hinweisreiz die Vp dazu bringt, eher ‚Äòlinks‚Äô zu antworten, sollte der Bias positiv sein.\nIn folgendem Veranschaulichung liegt das Kriterium \\(k\\) links der Mitte zwischen beiden Verteilungen. Folglich wird \\(c = k - d' &lt;0\\). Ein negativer Bias f√ºhrt dazu, dass die Person eher eine ‚Äòrechts‚Äô-Antwort gibt.\n\n\n\n\n\nTats√§chlich scheint es eine Tendenz zu geben, dass der ‚Äòrechts‚Äô Hinweis zu einem negativen Bias f√ºhrt, w√§hrend der ‚Äòlinks‚Äô Hinweis zu einem positiven Bias f√ºhrt - die Variabilit√§t zwischen den Versuchspersonen ist jedoch gross, und es scheint einige Personen zu geben, welche genau das Gegenteil zeigen. Es scheint jedoch auch einige Personen zu geben, welche systematisch falsch geantwortet haben (negative Sensitivit√§t).\n\nDa die Durchf√ºhrung unseres Experiments schlecht kontrolliert wurde (am eigenen Laptop) gehen wir hier nicht n√§her darauf ein. In einem richtigen Experiment w√ºrden wir solche Daten nicht zulassen.\n\ndf_cue |&gt;\n  ggplot(aes(x = c, y = dprime)) +\n      geom_hline(yintercept = 0, color = \"blue\", linetype = 2) +\n      geom_vline(xintercept = 0, color = \"blue\", linetype = 2) +\n      geom_jitter(size = 1) +\n      facet_wrap(~ cue) +\n      labs(x = \"c\", y = \"d'\") +\n      ggtitle(\"Bias vs. sensitivity\") +\n      theme_linedraw()"
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#mittelwerte-und-standardfehler",
    "href": "pages/chapters/signal-detection-2.html#mittelwerte-und-standardfehler",
    "title": "SDT anwenden",
    "section": "Mittelwerte und Standardfehler",
    "text": "Mittelwerte und Standardfehler\nNun wollen wir, wie im Kapitel zum Thema ‚Äòaggregierte Statistiken‚Äô, die Bedingungen bez√ºglich der Sensitivit√§t und des Bias vergleichen. Wir m√ºssen ber√ºcksichtigen, dass jede Person in 3 Bedingungen getestet wurde - die Art des Hinweisreizes ist also ein within-Faktor.\nWir w√§hlen zuerst die relevanten Variablen aus.\n\nsdt_final &lt;- df_cue |&gt;\n    select(id, cue, dprime, k, c)\n\nNun berechnen wir die Mittelwerte und die within-person-Standardfehler der Mittelwerte f√ºr den Bias und die Sensitivit√§t.\n\ncs &lt;- sdt_final |&gt;\n    select(id, cue, c) |&gt;\n    Rmisc::summarySEwithin(measurevar = \"c\",\n                           withinvars = \"cue\",\n                           idvar = \"id\",\n                           na.rm = FALSE,\n                           conf.interval = 0.95)\n\n\ndprimes &lt;- sdt_final |&gt;\n    select(id, cue, dprime) |&gt;\n    Rmisc::summarySEwithin(measurevar = \"dprime\",\n                           withinvars = \"cue\",\n                           idvar = \"id\",\n                           na.rm = FALSE,\n                           conf.interval = 0.95)"
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#plots",
    "href": "pages/chapters/signal-detection-2.html#plots",
    "title": "SDT anwenden",
    "section": "Plots",
    "text": "Plots\nAls Beispiel nehmen wir hier den Bias. Wir stellen die Mittelwerte als Linienplot dar, und zus√§tzlich als Punkte mit Fehlerbalken. Die Punkte sind die Mittelwerte, die Fehlerbalken die Standardfehler der Mittelwerte.\n\ncs |&gt;\n    ggplot(aes(x = cue, y = c, group = 1)) + \n    geom_hline(yintercept = 0, \n               linetype = \"dashed\",\n               color = \"grey60\") +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = c - ci,\n                                   ymax = c + ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ggtitle(\"c (bias)\")\n\n\n\n\nZusatzlich k√∂nnen wir die Datenpunkte plotten; diese sind jedoch im Dataframe sdt_final gespeichert, und nicht im Dataframe cs. Daher benutzen wir das Argument data = sdt_final in geom_jitter.\n\ncs |&gt;\n    ggplot(aes(x = cue, y = c, group = 1)) + \n    geom_hline(yintercept = 0, \n               linetype = \"dashed\",\n               color = \"grey60\") +\n    geom_jitter(aes(cue, c), alpha = 0.3, data = sdt_final, width = 0.05) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = c - ci,\n                                   ymax = c + ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ggtitle(\"c (bias)\")\n\n\n\n\nMit dem patchwork Package k√∂nnen wir die beiden Plots kombinieren.\n\nlibrary(patchwork)\n    \np_dprime &lt;- dprimes |&gt;\n      ggplot(aes(x = cue, y = dprime, group = 1)) +\n      geom_jitter(aes(cue, dprime), alpha = 0.1, data = sdt_final, width = 0.05) +\n      geom_line() +\n      geom_errorbar(width = 0.1, aes(ymin = dprime - ci,\n                                       ymax = dprime + ci)) +\n      geom_point(shape = 21, size = 3, fill = \"white\") +\n          ggtitle(\"Sensitivity\")\n      \np_bias &lt;- cs |&gt;\n        ggplot(aes(x = cue, y = c, group = 1)) + \n        geom_jitter(aes(cue, c), alpha = 0.1, data = sdt_final, width = 0.05) +\n        geom_hline(yintercept = 0, \n                   linetype = \"dashed\",\n                   color = \"grey60\") +\n          geom_line() +\n          geom_errorbar(width = 0.1, aes(ymin = c - ci,\n                                       ymax = c + ci)) +\n        geom_point(shape = 21, size = 3, fill = \"white\") +\n        ggtitle(\"Bias\")\n  \np_dprime / p_bias\n\n\n\n\nFalls Ihnen diese Darstellung nicht gef√§llt, k√∂nnen Sie die Grafiken mit + auch nebeneinander anordnen.\n\n\n\n\n\n\nTip\n\n\n\nMit / werden die Grafiken untereinander angeordnet, mit + nebeneinander.\n\n\n\np_dprime + p_bias"
  },
  {
    "objectID": "pages/chapters/signal-detection-2.html#zusammenfassung",
    "href": "pages/chapters/signal-detection-2.html#zusammenfassung",
    "title": "SDT anwenden",
    "section": "Zusammenfassung",
    "text": "Zusammenfassung\nDie Bedingungen unterscheiden sich bez√ºglich der Sensitivit√§t kaum. Bez√ºglich des Bias sehen wir das erwartete Muster; in der neutralen Bedingung ist der Bias √ºber die Personen aggregiert nahe bei 0, in der ‚Äòrechts‚Äô-Bedingung negativ und in der ‚Äòlinks‚Äô-Bedingung positiv. Ob dies einer statistischen Untersuchung standh√§lt k√∂nnten z.B. wir mit einer ‚Äòrepeated-measures‚Äô ANOVA untersuchen."
  },
  {
    "objectID": "pages/chapters/software.html",
    "href": "pages/chapters/software.html",
    "title": "Programmiersprachen",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit dem Einsatz vom Computern im Bereich Cognitive Neuroscience. Es ist nicht Ziel dieses Kurses, EEG oder fMRI Daten zu analysieren (daf√ºr gibt es eigene Kurse); wir werden uns stattdessen mit Daten aus Verhaltensexperimenten besch√§ftigen. Dies sind zum Beispiel bin√§re Antworten oder Reaktionszeiten, welche wir mit entsprechenden Modellen untersuchen werden. Unsere Anwendungsbeispiele werden immer aus der neurowissenschaftlichen Forschung stammen; der Fokus wird aber vor allem der Umgang mit Computern sein. Unser Ziel ist es, dass Sie nach dem Abschluss dieses Kurses eine neurowissenschaftliches Paper lesen k√∂nnen, und die darin verwendeten Experimente nachvollziehen k√∂nnen. Sie k√∂nnten eventuell sogar das Experiment selber programmieren, und die Daten analysieren."
  },
  {
    "objectID": "pages/chapters/software.html#ziel-dieses-kurses",
    "href": "pages/chapters/software.html#ziel-dieses-kurses",
    "title": "Programmiersprachen",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit dem Einsatz vom Computern im Bereich Cognitive Neuroscience. Es ist nicht Ziel dieses Kurses, EEG oder fMRI Daten zu analysieren (daf√ºr gibt es eigene Kurse); wir werden uns stattdessen mit Daten aus Verhaltensexperimenten besch√§ftigen. Dies sind zum Beispiel bin√§re Antworten oder Reaktionszeiten, welche wir mit entsprechenden Modellen untersuchen werden. Unsere Anwendungsbeispiele werden immer aus der neurowissenschaftlichen Forschung stammen; der Fokus wird aber vor allem der Umgang mit Computern sein. Unser Ziel ist es, dass Sie nach dem Abschluss dieses Kurses eine neurowissenschaftliches Paper lesen k√∂nnen, und die darin verwendeten Experimente nachvollziehen k√∂nnen. Sie k√∂nnten eventuell sogar das Experiment selber programmieren, und die Daten analysieren."
  },
  {
    "objectID": "pages/chapters/software.html#programmiersprachen",
    "href": "pages/chapters/software.html#programmiersprachen",
    "title": "Programmiersprachen",
    "section": "Programmiersprachen",
    "text": "Programmiersprachen\nProgrammiersprachen sind essentielle Werkzeuge f√ºr die Neurowissenschaftliche Forschung. Wir werden uns zuerst einen kurzen √úberblick √ºber drei h√§ufig verwendete Programmiersprachen (Matlab, Python und R) verschaffen und kurz deren Verwendungszwecke und Vor- und Nachteile diskutieren.\n\nMatlab\nMatlab ist ein Software f√ºr numerische Anwendung, welche in den Ingenieurwissenschaften, Naturwissenschaften und der Mathematik weit verbreitet ist.\n\nüëçüèº St√§rken:\n\nLeistungsstarke Matrix- und Vektoroperationen, gut geeignet f√ºr Matrix-basierte Operationen, die in der Neurowissenschaftlichen Forschung h√§ufig vorkommen.\nUmfangreiche Bibliothek von integrierten Funktionen f√ºr wissenschaftliches Rechnen.\n\n\n\nüëéüèº Schw√§chen:\n\nTeuer\nWeniger flexibel als Python oder R in Bezug auf Datenarten und Strukturen.\nMatlab is kommerziell und propriet√§r. Dies bedeutet man muss teuere Lizenzen kaufen, und der Source Code der Software ist nicht offen.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nSignalverarbeitung\nVisualisierung\nViele fMRI Forscher arbeiten mit Matlab, da es daf√ºr eine spezielle Toolbox gibt: SPM\nExperimente programmieren, z.B. mit Psychtoolbox\n\n\n\nBeispielcode:\nload('data.mat')\nfs = 1000;\nt = (0:numel(data)-1)/fs;\nplot(t, data)\n\n\n\nPython\nPython ist eine allgemeine (general purpose) Programmiersprache, die in vielen verschiedenen Bereichen wie wissenschaftlichem Rechnen, Datenanalyse und maschinellem Lernen weit verbreitet ist.\n\nüëçüèº St√§rken:\n\nEine Vielzahl von Bibliotheken und Modulen wie NumPy, SciPy und Pandas, die leistungsstarke Werkzeuge f√ºr wissenschaftliches Rechnen und Datenanalyse bieten.\nDatenanalysewerkzeuge wie Pandas-Dataframes, die Seaborn-Visualisierungsbibliothek, und Jupyter Notebooks.\nOpen-source und kostenlos\n\n\n\nüëéüèº Schw√§chen:\n\nKann in einigen numerischen Berechnungen langsamer sein als Matlab.\nDa Python eine allgemeine Sprache ist, muss man f√ºr numerische Anwendungen immer verschiedene Packages importieren (z.B.) numpy, wenn man damit rechnen will. Dies f√ºhrt zu weniger gut lesbarem Code.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nVisualisierung\nMachine learning und K√ºnstliche Intelligenz\nExperimente programmieren, z.B. mit PsychoPy\n\n\n\nBeispielcode:\nimport pandas as pd\nimport seaborn as sns\ndata = pd.read_csv('data.csv')\nsns.lineplot(data=data, x='time', y='voltage')\n\n\n\nR\nR ist eine Programmiersprache und Umgebung f√ºr statistisches Rechnen und Grafiken.\n\nüëçüèº St√§rken:\n\nEntwickelt von Statistikern f√ºr statistisches Rechnen und Grafiken.\nEine gro√üe Bibliothek von statistischen Werkzeugen und Paketen, einschliesslich Visualisierungspackages (grammar of graphics).\nOpen-source und kostenlos\ntidyverse Packages f√ºr Data Wrangling (sehr elegante Syntax, um mit Daten zu arbeiten).\n\n\n\nüëéüèº Schw√§chen:\n\nSteilere Lernkurve als Python.\nKann in einigen numerischen Berechnungen langsamer sein als Matlab oder Python.\nEntwickelt von Statistiker (nicht von Software Designers). R gilt als sehr idiosynkratisch.\n\n\n\nTypische Anwendung:\n\nStatistische Analyse\nDatenvisualisierung. R hat eine sehr gute Bibliothek f√ºr Grafiken, die ggplot2 Bibliothek. Diese Bibliothek verwendet die sogenannte grammar of graphics (GoG) - eine Methode, um Daten in Grafiken zu visualisieren. Die GoG ist eine sehr elegante und effiziente Methode, um Daten zu visualisieren.\n\n\n\nBeispielcode:\nlibrary(tidyverse)\ndata &lt;- read.csv('data.csv')\nggplot(data, aes(x=time, y=voltage)) + geom_line()\n\n\n\nFazit\nMatlab, Python und R sind leistungsstarke Werkzeuge f√ºr die neurowissenschaftliche Forschung. Die Wahl der Sprache h√§ngt unter anderem von der spezifischen Aufgabe ab. Weitere Faktoren ist Tradition: bestimmte Gruppen bevorzugen eher eine Sprache als andere. So ist Matlab unter Ingenieuren weit verbreiten und R unter Statistikern. Python ist im Bereich K√ºnstliche Intelligenz und Machine Learning die beliebteste Sprache. Eine neuere Sprache ist Julia - diese vereint die Vorteile aller oben genannten Sprachen (ohne viele deren Nachteile), ist aber weniger weit verbreitet.\nUm mehr zu erfahren, erkunden Sie die umfangreichen Online-Ressourcen und Dokumentationen f√ºr jede Sprache."
  },
  {
    "objectID": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "href": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "title": "Programmiersprachen",
    "section": "In dieser Veranstaltung verwendete Software",
    "text": "In dieser Veranstaltung verwendete Software\nWir haben uns entschieden, in dieser Veranstaltung Python zu verwenden, um ein Experiment zu erstellen, und R f√ºr die Analyse der Daten. Matlab wird nicht verwendet; einerseits da es kommerziell ist, andererseits weil es aus unserer Sicht nicht die beste Wahl f√ºr die Analyse von Verhaltensdaten ist. Ausserdem ist es schon schwierig genug, eine Programmiersprache zu lernen, ohne gleichzeitig noch zwei weitere zu lernen."
  },
  {
    "objectID": "pages/chapters/software.html#python-1",
    "href": "pages/chapters/software.html#python-1",
    "title": "Programmiersprachen",
    "section": "Python",
    "text": "Python\nWenn Sie Python suf Ihrem Rechner installieren wollen, k√∂nnen Sie entweder den offiziellen Installer https://www.python.org/downloads/ downloaden, oder die Anaconda Distribution https://www.anaconda.com/products/distribution verwenden. Die Anaconda Distribution ist eine Python-Distribution, die viele n√ºtzliche Pakete enth√§lt, die f√ºr wissenschaftliches Rechnen und Datenanalyse verwendet werden. Wenn man tats√§chlich mit Python arbeiten will, empfiehlt es sich, die Anaconda Distribution zu benutzen. Wir werden in dieser Veranstaltung Python benutzen, um ein Experiment zu programmieren. Daf√ºr reicht es aus, den PsychoPy Installer zu verwenden; diesen finden Sie unter diesem Link: PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen Benutzeroberfl√§che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/chapters/software.html#r-1",
    "href": "pages/chapters/software.html#r-1",
    "title": "Programmiersprachen",
    "section": "R",
    "text": "R\nAb der vierten Sitzung werden wir viel mit R arbeiten, um Daten aufzubereiten und grafisch darzustellen. Daf√ºr m√ºssen Sie die aktuelle Version von R installieren. Diese ist zurzeit R 4.2.2, und kann unter folgender URL geladen werden:\nR üëâ https://cloud.r-project.org/\nWir empfehlen f√ºr die Arbeit mit R die RStudio IDE zu verwenden. Diese ist kostenlos und kann unter folgender URL heruntergeladen werden:\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "pages/chapters/software.html#lernen",
    "href": "pages/chapters/software.html#lernen",
    "title": "Programmiersprachen",
    "section": "Lernen",
    "text": "Lernen\nDataCamp"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html",
    "href": "pages/chapters/summarizing-data.html",
    "title": "Aggregierte Statistiken",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nZusammenfassende Statistiken berechnen.\nIn within-subject Designs aggregierte Statistiken berechnen.\nStandardfehler berechnen, welche Messwiederholungen ber√ºcksichtigen.\nWir haben in den vorherigen Kapiteln gesehen, wie wir Daten aus Verhaltensexperimenten in R einlesen und bearbeiten k√∂nnen. In diesem Kapitel werden wir uns mit der Frage besch√§ftigen, wie wir zusammenfassende Statistiken erstellen k√∂nnen, um diese grafisch darzustellen und zu interpretieren. Da wir uns in den Neurowissenschaften meist mit within-subject Designs besch√§ftigen, werden wir uns in diesem Kapitel auf Messwiederholungsdaten konzentrieren."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#individuell-f√ºr-jede-person-in-jeder-bedingung",
    "href": "pages/chapters/summarizing-data.html#individuell-f√ºr-jede-person-in-jeder-bedingung",
    "title": "Aggregierte Statistiken",
    "section": "Individuell f√ºr jede Person in jeder Bedingung",
    "text": "Individuell f√ºr jede Person in jeder Bedingung\n\naccuracy_individual &lt;- data |&gt;\n    group_by(ID, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(correct),\n        accuracy = mean(correct)\n    )\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\naccuracy_individual\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   &lt;fct&gt; &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 JH    valid        64       60    0.938\n 2 JH    neutral      80       66    0.825\n 3 JH    invalid      16       13    0.812\n 4 NS    valid        64       58    0.906\n 5 NS    neutral      80       56    0.7  \n 6 NS    invalid      16       11    0.688\n 7 rh    valid        64       61    0.953\n 8 rh    neutral      80       64    0.8  \n 9 rh    invalid      16        2    0.125\n10 sb    valid        64       62    0.969\n# ‚Ñπ 17 more rows\n\n\n\naccuracy_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per person/condition\") +\n  facet_wrap(~ID) +\n  theme_linedraw(base_size = 14) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-bedingung-√ºber-alle-personen-aggregiert",
    "href": "pages/chapters/summarizing-data.html#pro-bedingung-√ºber-alle-personen-aggregiert",
    "title": "Aggregierte Statistiken",
    "section": "Pro Bedingung, √ºber alle Personen aggregiert",
    "text": "Pro Bedingung, √ºber alle Personen aggregiert\n\naccuracy_aggregated &lt;- data |&gt;\n    group_by(condition) |&gt;\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\naccuracy_aggregated\n\n# A tibble: 3 √ó 4\n  condition     N ncorrect accuracy\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 valid       576      475    0.825\n2 neutral     720      453    0.629\n3 invalid     144       56    0.389\n\n\n\naccuracy_aggregated |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = 1), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per condition\") +\n  theme_linedraw(base_size = 14) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nHands-on\n\n\n\nWir beurteilen Sie die beiden obenstehenden Plots. Was f√§llt Ihnen auf? Sind die Mittelwerte aussagekr√§ftig?\n\n\n\n\n\n\n\n\nL√∂sung\n\n\n\n\n\nEs fehlt eine Darstellung der Unsicherheit, die wir in der Sch√§tzung des Mittelwerts haben."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#standardfehler",
    "href": "pages/chapters/summarizing-data.html#standardfehler",
    "title": "Aggregierte Statistiken",
    "section": "Standardfehler",
    "text": "Standardfehler\nWir wollen wir nicht mehr nur den Mittelwert betrachten, sondern auch die Standardabweichung und den Standardfehler. Letzteres ist eine Mass f√ºr die Unsicherheit, die wir in der Sch√§tzung des Mittelwerts haben. Leider gibt es keine Funktion in R, die uns den Standardfehler berechnet. Der Standardfehler ist definiert als die Standardabweichung geteilt durch die Wurzel aus der Anzahl der Datenpunkte: \\[SE = sd/ \\sqrt{n}\\].\nWir k√∂nnen eine solche Funktion einfach selber definieren. sd() berechnet die Standardabweichung eines Vektors, und die Anzahl Datenpunkte ist die L√§nge des Vektors (length()), den wir als Argument √ºbergeben.\n\nse &lt;- function(x) {\n  sd(x) / sqrt(length(x))\n}"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-bedingung-√ºber-alle-personen-aggregiert-1",
    "href": "pages/chapters/summarizing-data.html#pro-bedingung-√ºber-alle-personen-aggregiert-1",
    "title": "Aggregierte Statistiken",
    "section": "Pro Bedingung, √ºber alle Personen aggregiert",
    "text": "Pro Bedingung, √ºber alle Personen aggregiert\nEine M√∂glichkeit w√§re, die Anzahl korrekter Entscheidungen in jeder Bedingung insgesamt, d.h. √ºber alle Personen aggregiert, zu berechnen. Wir berechnen dabei den Standardfehler des Mittelwertes um ein Mass f√ºr die Unsicherheit zu enthalten, mit der wir die Mittelwerte sch√§tzen k√∂nnen.\n\ndata |&gt;\n    group_by(condition) |&gt;\n            summarise(\n                  n = n(),\n                  ncorrect = sum(correct),\n                  accuracy = mean(correct),\n                  se = se(correct)\n            )\n\n# A tibble: 3 √ó 5\n  condition     n ncorrect accuracy     se\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 valid       576      475    0.825 0.0159\n2 neutral     720      453    0.629 0.0180\n3 invalid     144       56    0.389 0.0408\n\n\n\n\n\n\n\n\nHands-on\n\n\n\n\nWas sagen uns diese Kennzahlen?\nWelche Informationen gehen dabei verloren?\n√úberlegen Sie sich, was wir genau berechnet haben."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#ein-exkurs-√ºber-within-person-standardfehler",
    "href": "pages/chapters/summarizing-data.html#ein-exkurs-√ºber-within-person-standardfehler",
    "title": "Aggregierte Statistiken",
    "section": "Ein Exkurs √ºber within-person Standardfehler",
    "text": "Ein Exkurs √ºber within-person Standardfehler\n\n\n\n\n\n\nWithin-person Standardfehler berechnen\n\n\n\n\n\nFolgender Code erstellt einen Dataframe mit 10 Personen, die jeweils zu zwei Messzeitpunkten getestet werden. Es handelt sich also um ein within-subject Design.\n\nlibrary(tidyverse)\n\ndfw &lt;- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |&gt;\n    mutate(subject = as_factor(subject))\n\nDer Dataframe ist im wide Format ‚Äì um die Daten zu analysieren, ist das long Format besser geeignet. Wir konvertieren vom wide ins long Format mit der Funktion pivot_longer().\n\ndfw\n\n# A tibble: 10 √ó 3\n   subject pretest posttest\n   &lt;fct&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 1          59.4     64.5\n 2 2          46.4     52.4\n 3 3          46       49.7\n 4 4          49       48.7\n 5 5          32.5     37.4\n 6 6          45.2     49.5\n 7 7          60.3     59.9\n 8 8          54.3     54.1\n 9 9          45.4     49.6\n10 10         38.9     48.5\n\n\n\ndfl &lt;- dfw |&gt;\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |&gt;\n    mutate(condition = as_factor(condition))\n\n\ndfl\n\n# A tibble: 20 √ó 3\n   subject condition value\n   &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;\n 1 1       pretest    59.4\n 2 1       posttest   64.5\n 3 2       pretest    46.4\n 4 2       posttest   52.4\n 5 3       pretest    46  \n 6 3       posttest   49.7\n 7 4       pretest    49  \n 8 4       posttest   48.7\n 9 5       pretest    32.5\n10 5       posttest   37.4\n11 6       pretest    45.2\n12 6       posttest   49.5\n13 7       pretest    60.3\n14 7       posttest   59.9\n15 8       pretest    54.3\n16 8       posttest   54.1\n17 9       pretest    45.4\n18 9       posttest   49.6\n19 10      pretest    38.9\n20 10      posttest   48.5\n\n\nWas uns hier interessiert ist vor allem die ‚ÄúVerbesserung‚Äù jeder Person vom ersten zum zweiten Messzeitpunkt. Diese k√∂nnen wir grafisch darstellen.\n\n# Use a consistent y range\nymax &lt;- max(dfl$value)\nymin &lt;- min(dfl$value)\n\n\n# Plot the individuals\ndfl |&gt;\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWir stellen fest, dass fast jede Person zum zweiten Messzeitpunkt einen h√∂heren Wert als beim ersten aufweist. Gleichzeitig gibt es aber auch erhebliche Unterschiede zwischen den Personen in Bezug auf ihren Anfangswert. Diese interindividuellen Unterschiede sind aber hier nicht von Interesse. Wir k√∂nnen davon ausgehen, dass diese Unterschiede auf ‚Äústabile‚Äù Eigenschaften der Personen zur√ºckzuf√ºhren sind. Die Personen sind also eine Quelle der Variabilit√§t, die unsere Fragestellung ‚Äúst√∂rt‚Äù - diese lautet: wie ist die √Ñnderung zwischen den beiden Zeitpunkten?\nWir k√∂nnen so tun, als ob der Messzeitpunkt eine between-subject Variable w√§re. In diesem Fall w√ºrden wir die Standardfehler wie folgt berechnen.\n\ndflsum_between_1 &lt;- dfl |&gt;\n    group_by(condition) |&gt;\n    summarize(\n        mean = mean(value),\n        se = se(value)\n    )\n\ndflsum_between_1\n\n# A tibble: 2 √ó 3\n  condition  mean    se\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pretest    47.7  2.72\n2 posttest   51.4  2.29\n\n\nEine Alternative dazu bietet die Funktion summarySE() aus dem Rmisc Package.\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between &lt;- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\nDie Fehlerbalken im folgenden Plot ber√ºcksichtigen folgendermassen nicht die Tatsachen, dass ein grosser Anteil der Variabilit√§t auf ‚Äústabile‚Äù Personenunterschiede zur√ºckzuf√ºhren ist. In diesem Fall sind die ‚Äúerrorbars‚Äù sehr gross, und es sieht so aus, als ob es keinen feststellbaren Unterschied zwischen den Zeitpunkten gibt. Wir vermuten aber aufgrund der individuellen Grafiken, dass es sehr wohl einen Unterschied gibt.\n\ndflsum_between |&gt;\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWenn wir nur die Unterschiede zwischen den Personen ber√ºcksichtigen k√∂nnten, h√§tten wir in diesem Fall kleinere Standardfehler, da wir sozusagen die Personenvariabilit√§t subtrahieren k√∂nnen.\nIm Rmisc Package gibt es eine solche Funktion: mit summarySEwithin() k√∂nnen wir korrekt Standardfehler in within-subject Designs berechnen.\n\ndflsum &lt;- dfl |&gt;\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\nDie resultierenden Fehlerbalken sind nun kleiner.\n\ndflsum |&gt;\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60) +\n    ggtitle(\"Correct within standard errors\")\n\n\n\n\nWenn wir beide Varianten zusammen darstellen, wird der Unterschiedlich offentsichtlich. In dieser Grafik sind die between Standardfehler in rot eingezeichnet; die within Standardfehler sind in schwarz.\n\ndflsum_between |&gt;\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"black\", data = dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWas wir hier machen ist eigentlich einfach. Um die within Standardfehler zu berechnen, m√ºssen wir zuerst die personen-spezifische Mittelwerte von den Daten subtrahieren, und den Gesamtmittelwert (grand mean) addieren. Dies k√∂nnen wir entweder mit mutate(), oder mit der Funktion normDataWithin() machen.\nMit mutate():\n\ndf_norm &lt;- dfl |&gt;\n    mutate(grand_mean = mean(value)) |&gt;\n    group_by(subject) |&gt;\n    mutate(person_mean = mean(value),\n           value_normed = value - person_mean + grand_mean)\n\ndf_norm\n\n# A tibble: 20 √ó 6\n# Groups:   subject [10]\n   subject condition value grand_mean person_mean value_normed\n   &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 1       pretest    59.4       49.6        62.0         47.0\n 2 1       posttest   64.5       49.6        62.0         52.1\n 3 2       pretest    46.4       49.6        49.4         46.6\n 4 2       posttest   52.4       49.6        49.4         52.6\n 5 3       pretest    46         49.6        47.8         47.7\n 6 3       posttest   49.7       49.6        47.8         51.4\n 7 4       pretest    49         49.6        48.8         49.7\n 8 4       posttest   48.7       49.6        48.8         49.4\n 9 5       pretest    32.5       49.6        35.0         47.1\n10 5       posttest   37.4       49.6        35.0         52.0\n11 6       pretest    45.2       49.6        47.4         47.4\n12 6       posttest   49.5       49.6        47.4         51.7\n13 7       pretest    60.3       49.6        60.1         49.8\n14 7       posttest   59.9       49.6        60.1         49.4\n15 8       pretest    54.3       49.6        54.2         49.7\n16 8       posttest   54.1       49.6        54.2         49.5\n17 9       pretest    45.4       49.6        47.5         47.5\n18 9       posttest   49.6       49.6        47.5         51.7\n19 10      pretest    38.9       49.6        43.7         44.8\n20 10      posttest   48.5       49.6        43.7         54.4\n\n\nMit normDataWithin():\n\ndfNorm_long &lt;- Rmisc::normDataWithin(data=dfl, \n                                     idvar=\"subject\",    \n                                     measurevar=\"value\")\ndfNorm_long\n\n   subject condition value valueNormed\n1        1   pretest  59.4      47.035\n2        1  posttest  64.5      52.135\n3       10   pretest  38.9      44.785\n4       10  posttest  48.5      54.385\n5        2   pretest  46.4      46.585\n6        2  posttest  52.4      52.585\n7        3   pretest  46.0      47.735\n8        3  posttest  49.7      51.435\n9        4   pretest  49.0      49.735\n10       4  posttest  48.7      49.435\n11       5   pretest  32.5      47.135\n12       5  posttest  37.4      52.035\n13       6   pretest  45.2      47.435\n14       6  posttest  49.5      51.735\n15       7   pretest  60.3      49.785\n16       7  posttest  59.9      49.385\n17       8   pretest  54.3      49.685\n18       8  posttest  54.1      49.485\n19       9   pretest  45.4      47.485\n20       9  posttest  49.6      51.685\n\n\nWenn wir nun die ‚Äúnormierten‚Äù Daten plotten, sind die Unterschiede zwischen den Personen ‚Äúverschwunden‚Äù, weil wir eben die Daten normiert haben.\n\ndf_norm |&gt; \n    ggplot(aes(x=condition, y=value_normed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin, ymax)\n\n\n\n\nDie Argumente der Funktion summarySEwithin() sind folgende:\n\n\nmeasurevar: die outcome` Variable\n\nwithinvars: eine o(oder mehrere) within-subject Variablen\n\nidvar: die Gruppierungsvariable der within-subject Variablen (Versuchsperson)\n\nna.rm: sollen fehlende Werte ignoriert werden?\n\n\nconf.interval: der gew√ºnschte Konfidenzintervall (default: 0.95)\n\nIm Output erhalten wir die Mittelwerte der outcome Variablen f√ºr jede Stufe der within-Variable, sowie Standardabweichungen, Standardfehler und Konfidenzintervalle.\n\ndflsum &lt;- dfl |&gt;\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\nZum Vergleich: die Berechnung der Standardfehler in dflsum ber√ºcksichtigt die Tatsache, dass Personen sich von Anfang an unterscheiden, und subtrahiert von jedem Datenpunkt den Mittelwert der Person.\n\ndflsum\n\n  condition  N value       sd        se       ci\n1   pretest 10 47.74 2.262361 0.7154214 1.618396\n2  posttest 10 51.43 2.262361 0.7154214 1.618396\n\n\nBei der Berechnung der Standardfehler in dflsum_between haben wir im Prinzip so getan, als seien die Messzeitpunkte unabh√§ngig voneinander. Wir haben also die Standardfehler in dflsum_between so berechnet, als ob wir die Daten in zwei unabh√§ngige Gruppen aufgeteilt h√§tten.\n\ndflsum_between\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#accuracy-mit-within-person-standardfehler",
    "href": "pages/chapters/summarizing-data.html#accuracy-mit-within-person-standardfehler",
    "title": "Aggregierte Statistiken",
    "section": "Accuracy mit within-person Standardfehler",
    "text": "Accuracy mit within-person Standardfehler\nWir k√∂nnen nun dieses Prinzip auf unsere RDK daten anwenden. Die messwiederholte Variable ist nun nicht mehr der Messzeitunkt, sondern die cue-Bedingung, und die outcome Variable ist accuracy, also die Proportion korrekter Antworten.\n\naccuracy_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nAuch hier stellen wir fest, dass es scheinbar einen Trend gibt, dass die Proportion korrekter Antworten in der valid Bedingung hoch, und in der invalid Bedingung niedrig ist. In der neutral Bedingung liegt die accuracy dazwischen.\nOhne Ber√ºcksichtigung der Messwiederholungen erhalten wir folgende Standarfehler:\nVon Hand berechnet:\n\ndatasum &lt;- data |&gt;\n   group_by(condition) |&gt; \n   summarise(N = n(),\n             accuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n# A tibble: 3 √ó 5\n  condition     N accuracy    sd     se\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 valid       576    0.825 0.381 0.0159\n2 neutral     720    0.629 0.483 0.0180\n3 invalid     144    0.389 0.489 0.0408\n\n\nMit der Funktion summarySE():\n\ndatasum_2 &lt;- data |&gt;\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n  condition   N   correct        sd         se         ci\n1     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n\n\nWenn wir nun die within Standardfehler berechnen, erhalten wir folgende Ergebnisse:\n\ndatasum_3 &lt;- data |&gt;\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n  condition   N   correct        sd         se         ci\n1     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n\n\n\np_accuracy &lt;- datasum_3 |&gt;\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-versuchsperson",
    "href": "pages/chapters/summarizing-data.html#pro-versuchsperson",
    "title": "Aggregierte Statistiken",
    "section": "Pro Versuchsperson",
    "text": "Pro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und Standarabweichung zusammen. Wenn wir Daten anhand mehrerer statistischer Kennzahlen zusammenfassen m√∂chten, k√∂nnen wir dies entweder manuell machen, oder die Funktion across() verwenden.\nEinfachere Version:\n\nby_subj &lt;- data |&gt; \n  drop_na(rt) |&gt; \n  group_by(ID, condition) |&gt;  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\nKomplizierte Version:\n\nfuns &lt;- list(mean = mean, median = median, sd = sd, se = se)\n\nby_subj &lt;- data %&gt;%\n  drop_na(rt) |&gt; \n  group_by(ID, condition) %&gt;% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\nby_subj \n\n# A tibble: 27 √ó 6\n# Groups:   ID [9]\n   ID    condition  mean median     sd      se\n   &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 JH    valid     0.696  0.658 0.190  0.0240 \n 2 JH    neutral   0.799  0.733 0.202  0.0226 \n 3 JH    invalid   0.775  0.739 0.163  0.0421 \n 4 NS    valid     0.738  0.715 0.191  0.0240 \n 5 NS    neutral   0.885  0.844 0.201  0.0226 \n 6 NS    invalid   0.894  0.913 0.207  0.0518 \n 7 rh    valid     0.443  0.390 0.185  0.0233 \n 8 rh    neutral   0.525  0.503 0.0841 0.00941\n 9 rh    invalid   0.423  0.389 0.151  0.0378 \n10 sb    valid     0.386  0.349 0.175  0.0218 \n# ‚Ñπ 17 more rows\n\n\n\nby_subj |&gt; \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\nWir k√∂nnen selbstverst√§ndlich auch die indivuellen mittleren Reaktionszeiten mit Standardfehler plotten:\n\nby_subj |&gt; \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#√ºber-versuchsperson-aggregiert",
    "href": "pages/chapters/summarizing-data.html#√ºber-versuchsperson-aggregiert",
    "title": "Aggregierte Statistiken",
    "section": "√úber Versuchsperson aggregiert",
    "text": "√úber Versuchsperson aggregiert\n\nrtsum &lt;- data |&gt;\n  drop_na(rt) |&gt; \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n  condition   N        rt        sd         se         ci\n1     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n\n\n\np_rt &lt;- rtsum |&gt;\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\np_rt\n\n\n\n\nWir haben oben die beiden Grafiken als Variablen p_accuracy und p_rt gespeichert. Nun k√∂nnen wir diese Grafiken mit dem patchwork Package kombinieren.\npatchwork muss zuerst installiert werden: install.packages(\"patchwork\")\n\nlibrary(patchwork)\n\n\np_accuracy / p_rt"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html",
    "href": "pages/chapters/uebung-4-signal-detection.html",
    "title": "√úbung 4",
    "section": "",
    "text": "RStudio Projekt\n\n\n\nüëâ RStudio Projekt f√ºr diese √úbung herunterladen\nSie finden darin ein Rmarkdown-File, welches Sie bearbeiten m√ºssen, und den Datensatz."
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#einleitung",
    "href": "pages/chapters/uebung-4-signal-detection.html#einleitung",
    "title": "√úbung 4",
    "section": "Einleitung",
    "text": "Einleitung\nIn √úbung 4 arbeiten wir mit einem klinischen Datensatz. Das Ziel ist es, Sensitivit√§t und Bias f√ºr zwei Gruppen von insgesamt 60 Patienten zu untersuchen, die sich in ihrem Risiko f√ºr Alzheimer-Krankheit unterscheiden.\nDie Anwesenheit von Beta-Amyloid wurde durch einen Bluttest untersucht. Ein positiver Beta-Amyloid Test gilt als pr√§symptomatischer Indikator f√ºr die Alzheimer-Krankheit.\nAufgrund dieses Bluttests wurden die Patienten in zwei Gruppen eingeteilt. Es soll nun untersucht werden, ob sich die beiden in ihrer Ged√§chtnisleistung unterscheiden.\nDazu wurde der ‚ÄúRey auditory verbal learning test‚Äù (Bean 2011) durchgef√ºhrt.\nIn diesem Test m√ºssen Patienten zuerst eine Liste bestehend aus 15 W√∂rtern lernen. Sie werden danach mit 30 W√∂rtern getestet (15 alte, 15 neue W√∂rter) und m√ºssen angeben, ob ein Wort auf der Liste war oder nicht (alt/neu).\nDie Antworten der Patienten wurden bereits als als korrekte oder inkorrekte ‚ÄòJa‚Äô-Antworten klassifiziert (hits und false alarms)."
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#packages-laden",
    "href": "pages/chapters/uebung-4-signal-detection.html#packages-laden",
    "title": "√úbung 4",
    "section": "Packages laden",
    "text": "Packages laden\n\nlibrary(tidyverse)\nlibrary(patchwork)"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#daten-laden",
    "href": "pages/chapters/uebung-4-signal-detection.html#daten-laden",
    "title": "√úbung 4",
    "section": "Daten laden",
    "text": "Daten laden\n\nd &lt;- read_csv(\"data/amyloidSDT.csv\")\n\nRows: 60 Columns: 6\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): group\ndbl (5): ID, hit, miss, fa, cr\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWir empfehlen, immer zuerst die Daten anzuschauen.\n\nd\n\n# A tibble: 60 √ó 6\n      ID group      hit  miss    fa    cr\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 Negative    13     2     0    15\n 2     2 Negative    12     3     1    14\n 3     3 Negative    14     1     0    15\n 4     4 Negative    12     3     1    14\n 5     5 Negative    11     4     2    13\n 6     6 Negative    12     3     1    14\n 7     7 Negative    10     5     2    13\n 8     8 Negative    13     2     1    14\n 9     9 Negative    12     3     0    15\n10    10 Negative    12     3     2    13\n# ‚Ñπ 50 more rows\n\n\nIm Datensatz halben wir folgende Variablen:\n\n\nID: Patienten-ID\n\ngroup: Indikator f√ºr Beta-Amyloid Bluttest (Negative oder Positive)\n\nhit: Anzahl hits\n\nmiss: Anzahl misses\n\nfa: Anzahl false alarms\n\ncr: Anzahl correct rejections\n\nIm Datensatz gibt es es einige Nullen ‚Äì z.B. hat die Person mit der ID 1 keine False Alarms. Dies ist problematisch, weil wir die relative H√§ufigkeiten von Hits (hit_rate) und False Alarms (fa_rate) berechnen und diese anschliessend z-transformieren wollen. Die fa_rate ist der Anteil ‚ÄòJa‚Äô-Antworten wenn das Wort tats√§chlich gar nicht auf der Liste war, also fa / (fa + cr). Bei der ersten Person w√§re dies 0/(0 + 15) = 0.\nDas Problem ist nun, dass wir hier mit der relativen H√§ufigkeit eine Wahrscheinlichkeit sch√§tzen - eine Wahrscheinlichkeit darf aber nicht \\(0\\) sein, sondern liegt zwischen \\(-\\infty\\) und \\(\\infty\\). Wenn wir qnorm() (die Quantilfunktion der Normalverteilung) auf den Wert \\(0\\) anwenden, erhalten wir:\n\nqnorm(0)\n\n[1] -Inf\n\n\nDamit k√∂nnen wir nicht weiterrechnen. Wir wenden daher einen Trick an: wir addieren einfach zu jeder Zelle im Datensatz den Wert \\(0.5\\). Somit erhalten wir f√ºr die fa_rate der ersten Person:\n\n0 + 0.5 / (0 + 0.5 + 15 + 0.5)\n\n[1] 0.03125\n\n\nDies bedeutet, dass wir einen kleine Wahrscheinlichkeit erhalten; diese ist aber nicht Null. Diesen Wert k√∂nnen wir nun in qnorm() einsetzen.\n\nqnorm(0.03125)\n\n[1] -1.862732"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#den-wert-0-ersetzen",
    "href": "pages/chapters/uebung-4-signal-detection.html#den-wert-0-ersetzen",
    "title": "√úbung 4",
    "section": "Den Wert 0 ersetzen",
    "text": "Den Wert 0 ersetzen\n\nadd_half_count &lt;- function(count) {\n    count + 0.5\n}\n\n\nd &lt;- d |&gt;\n    mutate(across(c(hit, miss, fa, cr), add_half_count))\n\n\nd\n\n# A tibble: 60 √ó 6\n      ID group      hit  miss    fa    cr\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 Negative  13.5   2.5   0.5  15.5\n 2     2 Negative  12.5   3.5   1.5  14.5\n 3     3 Negative  14.5   1.5   0.5  15.5\n 4     4 Negative  12.5   3.5   1.5  14.5\n 5     5 Negative  11.5   4.5   2.5  13.5\n 6     6 Negative  12.5   3.5   1.5  14.5\n 7     7 Negative  10.5   5.5   2.5  13.5\n 8     8 Negative  13.5   2.5   1.5  14.5\n 9     9 Negative  12.5   3.5   0.5  15.5\n10    10 Negative  12.5   3.5   2.5  13.5\n# ‚Ñπ 50 more rows"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#hit-und-false-alarm-rate-berechnen",
    "href": "pages/chapters/uebung-4-signal-detection.html#hit-und-false-alarm-rate-berechnen",
    "title": "√úbung 4",
    "section": "Hit und False Alarm Rate berechnen",
    "text": "Hit und False Alarm Rate berechnen\n\nd &lt;- d |&gt;\n    mutate(\n        hit_rate = hit / (hit + miss),\n        fa_rate = fa / (fa + cr)\n    )"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#hit-rate-vs-false-alarm-rate",
    "href": "pages/chapters/uebung-4-signal-detection.html#hit-rate-vs-false-alarm-rate",
    "title": "√úbung 4",
    "section": "Hit Rate vs False Alarm Rate",
    "text": "Hit Rate vs False Alarm Rate\nBevor wir die SDT Kennzahlen berechnen, stellen wir die hit rate und false alarm rate grafisch dar:\n\nd |&gt;\n      ggplot(aes(fa_rate, hit_rate, color = group)) +\n      geom_abline(intercept = 0, slope = 1, linetype = 2) +\n      geom_jitter() +\n      scale_color_viridis_d(direction = -1, begin = 0.1, end = 0.8) +\n      facet_wrap(~ group) +\n      xlim(c(0, 1)) +\n      theme_linedraw()"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#d-und-bias-berechnen",
    "href": "pages/chapters/uebung-4-signal-detection.html#d-und-bias-berechnen",
    "title": "√úbung 4",
    "section": "d‚Äô und bias berechnen",
    "text": "d‚Äô und bias berechnen\n\nd &lt;- d |&gt;\n    mutate(\n        zhr = qnorm(hit_rate),\n        zfa = qnorm(fa_rate)\n    )\n\n\nd &lt;- d |&gt;\n    mutate(\n        dprime = zhr - zfa,\n        k = -zfa,\n        c = -0.5 * (zhr + zfa)\n    )\n\nWir runden nun dprime, k und c auf zwei Nachkommastellen.\n\nd &lt;- d |&gt;\n    mutate(across(c(dprime, k, c), \\(x) round(x, 2)))\n\n\nd\n\n# A tibble: 60 √ó 13\n      ID group   hit  miss    fa    cr hit_rate fa_rate   zhr   zfa dprime     k\n   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     1 Nega‚Ä¶  13.5   2.5   0.5  15.5    0.844  0.0312 1.01  -1.86   2.87  1.86\n 2     2 Nega‚Ä¶  12.5   3.5   1.5  14.5    0.781  0.0938 0.776 -1.32   2.09  1.32\n 3     3 Nega‚Ä¶  14.5   1.5   0.5  15.5    0.906  0.0312 1.32  -1.86   3.18  1.86\n 4     4 Nega‚Ä¶  12.5   3.5   1.5  14.5    0.781  0.0938 0.776 -1.32   2.09  1.32\n 5     5 Nega‚Ä¶  11.5   4.5   2.5  13.5    0.719  0.156  0.579 -1.01   1.59  1.01\n 6     6 Nega‚Ä¶  12.5   3.5   1.5  14.5    0.781  0.0938 0.776 -1.32   2.09  1.32\n 7     7 Nega‚Ä¶  10.5   5.5   2.5  13.5    0.656  0.156  0.402 -1.01   1.41  1.01\n 8     8 Nega‚Ä¶  13.5   2.5   1.5  14.5    0.844  0.0938 1.01  -1.32   2.33  1.32\n 9     9 Nega‚Ä¶  12.5   3.5   0.5  15.5    0.781  0.0312 0.776 -1.86   2.64  1.86\n10    10 Nega‚Ä¶  12.5   3.5   2.5  13.5    0.781  0.156  0.776 -1.01   1.79  1.01\n# ‚Ñπ 50 more rows\n# ‚Ñπ 1 more variable: c &lt;dbl&gt;"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#aggregierte-kennzahlen",
    "href": "pages/chapters/uebung-4-signal-detection.html#aggregierte-kennzahlen",
    "title": "√úbung 4",
    "section": "Aggregierte Kennzahlen",
    "text": "Aggregierte Kennzahlen\n\nse &lt;- function(x) {\n  sd(x) / sqrt(length(x))\n}\n\n\ndprimes &lt;- d |&gt;\n  select(group, dprime) |&gt; \n  group_by(group) |&gt; \n  summarize(mean = mean(dprime),\n            se = se(dprime))\n\n\ncs &lt;- d |&gt; \n  select(group, c) |&gt; \n  group_by(group) |&gt; \n  summarize(mean = mean(c),\n            se = se(c))"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#grafische-darstellung-von-d-und-bias",
    "href": "pages/chapters/uebung-4-signal-detection.html#grafische-darstellung-von-d-und-bias",
    "title": "√úbung 4",
    "section": "Grafische Darstellung von d' und bias\n",
    "text": "Grafische Darstellung von d' und bias\n\n\np_dprimes &lt;- dprimes |&gt;\n  ggplot(aes(x=group, y=mean, group=1)) +\n    geom_jitter(aes(group, dprime), alpha = 0.1, data = d, width = 0.05) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se), colour=\"black\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylab(\"Sensitivity\")\n\n\np_cs &lt;- cs |&gt;\n    ggplot(aes(x=group, y=mean, group=1)) +\n    geom_jitter(aes(group, c), alpha = 0.1, data = d, width = 0.05) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=mean-se, ymax=mean+se), colour=\"black\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylab(\"Bias\")\n\n\np_dprimes + p_cs"
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#fragen",
    "href": "pages/chapters/uebung-4-signal-detection.html#fragen",
    "title": "√úbung 4",
    "section": "Fragen",
    "text": "Fragen\nBitte versuchen Sie, folgende Fragen so gut wie m√∂glich zu beantworten. Schreiben Sie Ihre Antworten direkt unter die Fragen.\nFrage 1\n\nWie unterscheiden sich die Gruppen in der hit rate und false alarm rate (siehe erste Grafik)?\n\nAntwort:\nFrage 2\n\nWie unterscheidet sich die Sensitivit√§t zwischen den Gruppen im RALVT? Was k√∂nnte das bedeuten? Denken Sie, dass der Unterschied von relevanter Gr√∂sse ist?\n\nAntwort:\nFrage 3\n\nWie unterscheidet sich die Antworttendenz zwischen den Gruppen im RALVT? Was k√∂nnte das bedeuten? Denken Sie, dass der Unterschied von relevanter Gr√∂sse ist?\n\nAntwort:\nFrage 4\n\nWie denken Sie h√§ngen Sensitivit√§t und Antworttendenz in diesem Experiment zusammen? Was k√∂nnten die Gr√ºnde sein? Was passiert, wenn d‚Äô kleiner wird, das Kriterium k aber konstant bleibt? Eventuell hilft diese Grafik, um dar√ºber nachzudenken."
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#fragen-f√ºr-peer-review",
    "href": "pages/chapters/uebung-4-signal-detection.html#fragen-f√ºr-peer-review",
    "title": "√úbung 4",
    "section": "Fragen f√ºr Peer Review",
    "text": "Fragen f√ºr Peer Review\n√ñffnen Sie das .Rmd-File und f√ºhren Sie es mit Knit oder von oben bis unten aus und schreiben Sie zu den Antworten eine R√ºckmeldung in ein Word/Text-File."
  },
  {
    "objectID": "pages/chapters/uebung-4-signal-detection.html#hochladen",
    "href": "pages/chapters/uebung-4-signal-detection.html#hochladen",
    "title": "√úbung 4",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie Ihr Peer Review anschliessend als Word/Text-File auf Ilias hoch."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html",
    "href": "pages/chapters/uebung_1_experiment.html",
    "title": "√úbung 1",
    "section": "",
    "text": "In dieser √úbung f√ºhren Sie mit zwei Personen das Random Dot Experiment durch und laden die Datens√§tze hoch. In dieser √úbung gibt es kein Peer Feedback. Die erhobenen Daten werden wir dann in den kommenden Sitzungen verwenden."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#random-dot-experiment-durchf√ºhren",
    "href": "pages/chapters/uebung_1_experiment.html#random-dot-experiment-durchf√ºhren",
    "title": "√úbung 1",
    "section": "Random Dot Experiment durchf√ºhren",
    "text": "Random Dot Experiment durchf√ºhren\n\nDas fertige Experiment befindet sich auf Github. Sie k√∂nnen es unter diesem Link downloaden. (Wenn Sie auf den gr√ºnen Button Code klicken, kann man das Experiment als Zip-Datei herunterladen: Download ZIP)\nF√ºhren Sie das Experiment ein- oder mehrere Male selber durch. Kontrollieren Sie, ob ein Datensatz gespeichert wird.\nTesten Sie zwei Personen (Alter zwischen 20 und 60 Jahre). Diese Personen sollten die Hypothese nicht kennen (also keine Mitstudierende aus dem ComputerLab)."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#datenabgabe",
    "href": "pages/chapters/uebung_1_experiment.html#datenabgabe",
    "title": "√úbung 1",
    "section": "Datenabgabe",
    "text": "Datenabgabe\n\nDaten abgeben: Zippen Sie bitte die .csv-Datens√§tze der getesteten Personen (nicht von den Selbsttests) und laden Sie das ZIP File bis in 10 Tagen auf ILIAS."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#trouble-shooting",
    "href": "pages/chapters/uebung_1_experiment.html#trouble-shooting",
    "title": "√úbung 1",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nBitte Fehlermeldung im Fenster genau durchlesen. Dort finden Sie Hinweise darauf, was schief gelaufen ist.\nDas Experiment startet nicht.\n\nUnter Einstellungen (Radsymbol) den Reiter Basic ausw√§hlen. Bei Use PsychoPy version die laufende PsychoPy Version ausw√§hlen (z.B. 2022.2.5).\n\nDas Experiment startet zwar, der Bildschirm ist aber dann einfach f√ºr eine kurze Zeit grau und das Fenster schliesst sich wieder.\n\nZugriffsrechte gegeben?\nUnter Einstellungen (Radsymbol) den Reiter Input ausw√§hlen. Keyboard Backend auf PsychToolbox statt ioHub."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html",
    "href": "pages/chapters/uebung_2_data_wrangling.html",
    "title": "√úbung 2",
    "section": "",
    "text": "Die √úbung 2 besteht aus den zwei folgenden Aufgaben:\n1. Skript erstellen und ausf√ºhren: In diesem Skript werden die Daten unseres PsychoPy-Experiments eingelesen, Variablen erstellt und erste Werte berechnet. Das Skript muss von einer anderen Person ausgef√ºhrt werden k√∂nnen (Reproduzierbarkeit) und gut kommentiert sein. Zeit: 1 Woche.\n2. Peer Feedback: Mittels Ilias wird Ihnen ein Skript einer anderen Person zugeordnet. Ihr Auftrag ist es, dieses Skript auszuf√ºhren und dazu Feedback zu geben. Zeit: 1 Woche."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung",
    "href": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung",
    "title": "√úbung 2",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nLaden Sie zuerst das RStudio Projekt f√ºr √úbung 2 herunter. Dieses muss ‚Äúentzippt‚Äù werden. In dem Projektordner finden Sie den Ordner data. Darin befinden sich alle Datens√§tze des PsychoPy Experiments. Das Projekt kann durch einen Doppelklick auf das Projekt-File uebung-2.Rproj ge√∂ffnet werden.\n\n\n\n\n\n\n\nWichtig\n\n\n\nüëâ RStudio Projekt f√ºr √úbung 2 herunterladen\n\n\n\nProjekte erm√∂glichen, relative Pfade. So stellen wir sicher, dass andere Personen, die dieses Projekt √∂ffnen, dieses File auch sehen und ausf√ºhren k√∂nnen.\n\n\n√ñffnen Sie das File uebung-2_script.r. Dieses File k√∂nnen Sie genau so verwenden und nach Bearbeitung speichern. F√ºgen Sie dem Filenamen Ihre Initialen an, das k√∂nnte dann so aussehen: uebung-2_script_gw.r.\n\n\nPraktischer ist es mit RMarkdown zu arbeiten. Das werden wir in den n√§chsten Wochen lernen. Daf√ºr eignen sich z.B. .qmd-Files. Hier kann f√ºr Text die Markdown-Syntax verwendet werden, und der Code wird in Code-Blocks geschrieben."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#kommentare-code",
    "href": "pages/chapters/uebung_2_data_wrangling.html#kommentare-code",
    "title": "√úbung 2",
    "section": "Kommentare & Code",
    "text": "Kommentare & Code\n\nKommentare werden mit #davor gekennzeichnet, so weiss R, dass dies Text und nicht ausf√ºhrbarer Code ist. Verwenden Sie also vor jedem Kommentar am Anfang der Zeile ein #.\nKommentieren Sie mit knappen, genauen Angaben. So weiss Ihr Peer Reviewer, was das Skript machen wird und was das Ziel des Codes ist."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#aufgaben",
    "href": "pages/chapters/uebung_2_data_wrangling.html#aufgaben",
    "title": "√úbung 2",
    "section": "Aufgaben",
    "text": "Aufgaben\n\nGehen Sie das Skript durch. Das Skript enth√§lt ein ‚ÄúGer√ºst‚Äù an Code, mit dem Sie arbeiten k√∂nnen. Sie k√∂nnen auch den Code der Website √ºbernehmen und etwas anpassen, wenn n√∂tig. √úberall wo ___ steht, m√ºssen Sie das Fehlende einf√ºgen. Manchmal ist das ein Kommentar. Manchmal ist es ein Codest√ºck.\nSie finden hier Infos dazu, wie die Daten bearbeitet werden k√∂nnen."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#reproduzierbar-machen",
    "href": "pages/chapters/uebung_2_data_wrangling.html#reproduzierbar-machen",
    "title": "√úbung 2",
    "section": "Reproduzierbar machen",
    "text": "Reproduzierbar machen\nSobald Sie den Code und die Kommentare erg√§nzt haben, ist es wichtig, das Skript auf seine Reproduzierbarkeit zu testen.\n\nL√∂schen Sie die Variablen im Workspace. Verwenden Sie dazu z.B. das ‚ÄúBesen‚Äù-Icon unter Environment oder nutzen Sie unter dem Reiter Session den Befehl Clear Workspace. F√ºhren Sie danach das Skript nochmals von oben bis unten aus.\nPr√ºfen Sie, ob alle Pfade relativ, also nicht an Ihren Rechner gebunden sind.\nPr√ºfen Sie, ob alles gut und verst√§ndlich kommentiert ist.\nPr√ºfen Sie, ob Sie die 3 Werte f√ºr Accuracy pro Bedingung (f√ºr valide, invalide und neutral) als Kommentar in das Skript geschrieben haben."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#hochladen",
    "href": "pages/chapters/uebung_2_data_wrangling.html#hochladen",
    "title": "√úbung 2",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie das uebung-2_script_initialen.r - Skript auf Ilias hoch."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#trouble-shooting",
    "href": "pages/chapters/uebung_2_data_wrangling.html#trouble-shooting",
    "title": "√úbung 2",
    "section": "Trouble Shooting",
    "text": "Trouble Shooting\nPackages updaten\n\nUpdaten Sie alle packages mit update.packages(ask = FALSE) in der Konsole. Oder unter dem Reiter Tools &gt; Check for Package Updates ...\n\nProbleme mit read_csv\n\nVerwenden Sie read.csv() als Alternative\n\nFalls nichts hilft ‚Ä¶\n\nFragen Sie Mitstudierende. Ziemlich sicher hat jemand dieses Problem schon gel√∂st.\nSchreiben Sie eine Mail mit folgenden Infos:\n\nOutput von sessionInfo() in derKonsole\nausgef√ºhrter Code\nFehlermeldung\nwas haben Sie schon versucht als L√∂sung?"
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung-1",
    "href": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung-1",
    "title": "√úbung 2",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nLesen Sie hier die Peer Feedback-Grunds√§tze durch.\nLaden Sie das Ihnen zugeordnete .r-Skript herunter und speichern Sie es in Ihr R-Projektordner, wo sich auch das Projekt-File uebung-2.Rproj und Ihr eigenens .r-Skript befindet.\n√ñffnen Sie das Projekt. L√∂schen Sie alle gespeicherten Variablen im Workspace. Verwenden Sie dazu z.B. das ‚ÄúBesen‚Äù-Icon unter Environment oder nutzen Sie unter dem Reiter Session den Befehl Clear Workspace."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#fragen-f√ºr-peer-review",
    "href": "pages/chapters/uebung_2_data_wrangling.html#fragen-f√ºr-peer-review",
    "title": "√úbung 2",
    "section": "Fragen f√ºr Peer Review",
    "text": "Fragen f√ºr Peer Review\n√ñffnen Sie das .r-Skript und f√ºhren Sie es von oben bis unten aus und schreiben Sie zu folgenden Punkten eine R√ºckmeldung in ein Word/Text-File.\n1. Reproduzierbarkeit des Codes\n\nIst das Skript ausf√ºhrbar?\nWenn nein: Wo genau gibt es eine Fehlermeldung, weshalb kommt diese und wie k√∂nnte diese behoben werden?\nStimmen die 3 Accuracy pro Bedingung- Werte mit den im Kommentar beschriebenen Werten √ºberein?\nStimmen die Werte mit den von Ihnen selber errechneten Werten √ºberein?\n\n2. Kommentierung/Implementierung des Codes\n\nGeben Sie mit mind. 5 S√§tzen R√ºckmeldung zum .r-Skript. M√∂gliche Themen k√∂nnten z.B. sein: War der Code angemessen kommentiert? Was war gut? Was h√§tte man besser machen k√∂nnen? Sind Ihnen an den Daten √§hnliche Dinge aufgefallen? Haben Sie etwas gelernt von dem gereviewten Skript? Oder haben Sie etwas besser gel√∂st gehabt in Ihrem Skript? Haben Sie Vorschl√§ge? usw."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#hochladen-1",
    "href": "pages/chapters/uebung_2_data_wrangling.html#hochladen-1",
    "title": "√úbung 2",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie Ihr Peer Review anschliessend als Word/Text-File auf Ilias hoch."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html",
    "href": "pages/chapters/uebung_3_data_visualization.html",
    "title": "√úbung 3",
    "section": "",
    "text": "Die √úbung 3 besteht aus den zwei folgenden Aufgaben:\n1. RMarkdown-File erstellen und ausf√ºhren: In diesem Skript werden die Daten unseres PsychoPy-Experiments eingelesen und damit eine Grafik erstellt. Das Skript muss von einer anderen Person ausgef√ºhrt werden k√∂nnen (Reproduzierbarkeit) und gut kommentiert sein. Zeit: 1 Woche.\n2. Peer Feedback: Mittels Ilias wird Ihnen das RMarkdown-File und die Grafik einer anderen Person zugeordnet. Ihr Auftrag ist es, dieses RMarkdown-File auszuf√ºhren und Feedback zu geben. Zeit: 1 Woche."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#vorbereitung",
    "href": "pages/chapters/uebung_3_data_visualization.html#vorbereitung",
    "title": "√úbung 3",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\n\n\n\n\n\nWichtig\n\n\n\nüëâ Falls Sie noch keinen Projektordner dataviz haben: RStudio Projekt f√ºr √úbung 3 herunterladen und entzippen.\nüëâ Falls Sie den Datensatz rdkdata_clean.csv nicht im Ordner data_rdk haben: Datensatz rdkdata_clean.csv laden und im Ordner dataviz vom RStudio-Projektordner dataviz speichern.\n\n\n\n√ñffnen Sie das RStudio-Projekt dataviz.\n√ñffnen Sie unter File &gt; New File &gt; R Markdown ... ein neues RMarkdown-File.\nGeben Sie einen Titel und Ihren Namen ein und w√§hlen Sie HTMLals Output-Format.\nErstellen Sie ein RMarkdown-File uebung-3_dataviz.Rmd und w√§hlen Sie html als Output. Geben Sie unter Autor Complab ein, damit das File anonymisiert ist.\nL√∂schen Sie alles ausser den YAML header (alles unter dem zweiten ---)"
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#kommentare-code",
    "href": "pages/chapters/uebung_3_data_visualization.html#kommentare-code",
    "title": "√úbung 3",
    "section": "Kommentare & Code",
    "text": "Kommentare & Code\nAchten Sie darauf, dass Sie den Code in den Codefeldern schreiben und den Text ausserhalb. W√§hlen Sie aus, welche die Codechunks ausgef√ºhrt / angezeigt werden sollen."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#aufgaben",
    "href": "pages/chapters/uebung_3_data_visualization.html#aufgaben",
    "title": "√úbung 3",
    "section": "Aufgaben",
    "text": "Aufgaben\n\nLaden Sie n√∂tige Packages.\nLaden Sie die Daten unseres Experiments. Sie finden den Datensatz rdkdata_clean.csv f√ºr diese √úbung im Projektordner dataviz &gt; data_rdk.\nMachen Sie Textvariablen und die Personen-Id-Variable zu Faktoren und schauen Sie den Datensatz kurz an (mit slice_head() oder glimpse()), um zu √ºberpr√ºfen, ob die Daten richtig eingelesen wurden.\nIhre Aufgabe ist es eine Forschungsfrage zu dem vorhandenen Datensatz zu stellen, dazu eine Grafik zu plotten und die Antwort damit zu visualisieren, sowie in schriftlicher Form zu geben.\n\nBeschreiben Sie in Textform, welche Frage Sie mit Ihrer Grafik beantworten m√∂chten.\nFalls n√∂tig: Bearbeiten Sie den Datensatz / erstellen Sie einen neuen Datensatz f√ºr die Grafik.\nErstellen Sie die Grafik, und lassen Sie diese anzeigen.\nSpeichern Sie die Grafik zus√§tzlich als .jpg oder .png ab. So kann Ihr Peer Reviewer auch bei nicht funktionierendem Code R√ºckmeldung zur Grafik geben.\nF√ºgen Sie der Grafik passende Beschriftungen hinzu.\nBeantworten Sie Ihre Forschungsfrage schriftlich."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#reproduzierbar-machen",
    "href": "pages/chapters/uebung_3_data_visualization.html#reproduzierbar-machen",
    "title": "√úbung 3",
    "section": "Reproduzierbar machen",
    "text": "Reproduzierbar machen\nSobald Sie Text und Code geschrieben haben, ist es wichtig, das Skript auf seine Reproduzierbarkeit zu testen.\n\nL√∂schen Sie die Variablen im Workspace. Verwenden Sie dazu z.B. das ‚ÄúBesen‚Äù-Icon unter Environment oder nutzen Sie unter dem Reiter Session den Befehl Clear Workspace. F√ºhren Sie danach das Skript nochmals von oben bis unten aus.\nPr√ºfen Sie, ob alle Pfade relativ, also nicht an Ihren Rechner gebunden sind.\nPr√ºfen Sie, ob alles gut und verst√§ndlich kommentiert ist."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#grafik-abspeichern",
    "href": "pages/chapters/uebung_3_data_visualization.html#grafik-abspeichern",
    "title": "√úbung 3",
    "section": "Grafik abspeichern",
    "text": "Grafik abspeichern\nSpeichern Sie die Grafik zus√§tzlich als .jpg oder .png ab. So kann Ihr Peer Reviewer auch bei nicht funktionierendem Code R√ºckmeldung zur Grafik geben."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#hochladen",
    "href": "pages/chapters/uebung_3_data_visualization.html#hochladen",
    "title": "√úbung 3",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie das uebung-3_dataviz.Rmd und die Grafik auf Ilias hoch."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#trouble-shooting",
    "href": "pages/chapters/uebung_3_data_visualization.html#trouble-shooting",
    "title": "√úbung 3",
    "section": "Trouble Shooting",
    "text": "Trouble Shooting\nPackages updaten\n\nUpdaten Sie alle packages mit update.packages(ask = FALSE) in der Konsole. Oder unter dem Reiter Tools &gt; Check for Package Updates ...\n\nProbleme mit read_csv\n\nVerwenden Sie read.csv() als Alternative\n\nFalls nichts hilft ‚Ä¶\n\nFragen Sie Mitstudierende. Ziemlich sicher hat jemand dieses Problem schon gel√∂st.\nSchreiben Sie eine Mail mit folgenden Infos:\n\nOutput von sessionInfo() in derKonsole\nausgef√ºhrter Code\nFehlermeldung\nwas haben Sie schon versucht als L√∂sung?"
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#vorbereitung-1",
    "href": "pages/chapters/uebung_3_data_visualization.html#vorbereitung-1",
    "title": "√úbung 3",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nLesen Sie hier die Peer Feedback-Grunds√§tze durch.\nLaden Sie das Ihnen zugeordnete .Rmd-Skript herunter und speichern Sie es in Ihren data_viz R-Projektordner, wo sich auch Ihr eigenens .Rmd-Skript befindet.\nLaden Sie auch die Grafik herunter.\n√ñffnen Sie das Projekt. L√∂schen Sie alle gespeicherten Variablen im Workspace. Verwenden Sie dazu z.B. das ‚ÄúBesen‚Äù-Icon unter Environment oder nutzen Sie unter dem Reiter Session den Befehl Clear Workspace."
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#fragen-f√ºr-peer-review",
    "href": "pages/chapters/uebung_3_data_visualization.html#fragen-f√ºr-peer-review",
    "title": "√úbung 3",
    "section": "Fragen f√ºr Peer Review",
    "text": "Fragen f√ºr Peer Review\n√ñffnen Sie das .Rmd-Skript und f√ºhren Sie es mit Knit oder von oben bis unten aus und schreiben Sie zu folgenden Punkten eine R√ºckmeldung in ein Word/Text-File.\n1. Reproduzierbarkeit des Codes\nGeben Sie mit mind. 5 S√§tzen R√ºckmeldung zum .Rmd-Skript.\n\nIst das Skript ausf√ºhrbar? Wenn nein: Wo genau gibt es eine Fehlermeldung, weshalb kommt diese und wie k√∂nnte diese behoben werden?\nWar der Code angemessen kommentiert? Was war gut? Was h√§tte man besser machen k√∂nnen?\nHaben Sie etwas gelernt von dem gereviewten Skript? Oder haben Sie etwas besser gel√∂st gehabt in Ihrem Skript?\nHaben Sie Vorschl√§ge? usw.\n\n2. Datenvisualisierung Geben Sie R√ºckmeldung zur Grafik. Beachten Sie dabei die Punkte aus dem Kapitel Kommunikation: Forschungsergebnisse visualisieren. Schreiben Sie zu jedem Punkt mindestens 1 Satz / Stichworte:\n\nWaren die Beschriftungen genau und passend?\nFragestellung und Beantwortung. War der gew√§hlte Plot passend? War er informativ? G√§be es Alternativen?\nWurden die Daten angemessen abgebildet?\nData-Ink-Ratio gut gel√∂st? Was fehlte? Was war vielleicht zu viel?\n√Ñsthetik?"
  },
  {
    "objectID": "pages/chapters/uebung_3_data_visualization.html#hochladen-1",
    "href": "pages/chapters/uebung_3_data_visualization.html#hochladen-1",
    "title": "√úbung 3",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie Ihr Peer Review anschliessend als Word/Text-File auf Ilias hoch."
  },
  {
    "objectID": "pages/exercises/exercise_01.html",
    "href": "pages/exercises/exercise_01.html",
    "title": "√úbung 1",
    "section": "",
    "text": "Note\n\n\n\nDiese √úbung muss nicht abgegeben werden; sie dient als Vorbereitung f√ºr die folgende Sitzung.\n\n\n\n\nInstallieren Sie PsychoPy von der Website. PsychoPy ist ein Open-Source Programm f√ºr MacOS, Windows und Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente (Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren k√∂nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI Scanner und mit EEG verwenden.\nPsychoPy üëâ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das ‚ÄúStandalone package‚Äù f√ºr MacOS oder Windows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu bereiten ‚Äî es ist daher (zurzeit noch) besser, die Version 2021.2.3 zu installieren.\n\n\n\n\n\nWas verstehen Sie unter folgenen Begriffen:\n\n\nModel-based Neuroscience\nEvidence accumulation\n\n\nWas k√∂nnte man unter Vorwissen (prior knowledge) verstehen? In welchen Kontexten k√∂nnte es bei Entscheidungen n√ºtzlich sein, Vorwissen zu benutzen?"
  },
  {
    "objectID": "pages/exercises/exercise_01.html#aufgabe-1",
    "href": "pages/exercises/exercise_01.html#aufgabe-1",
    "title": "√úbung 1",
    "section": "",
    "text": "Installieren Sie PsychoPy von der Website. PsychoPy ist ein Open-Source Programm f√ºr MacOS, Windows und Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente (Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren k√∂nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI Scanner und mit EEG verwenden.\nPsychoPy üëâ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das ‚ÄúStandalone package‚Äù f√ºr MacOS oder Windows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu bereiten ‚Äî es ist daher (zurzeit noch) besser, die Version 2021.2.3 zu installieren."
  },
  {
    "objectID": "pages/exercises/exercise_01.html#aufgabe-2",
    "href": "pages/exercises/exercise_01.html#aufgabe-2",
    "title": "√úbung 1",
    "section": "",
    "text": "Was verstehen Sie unter folgenen Begriffen:\n\n\nModel-based Neuroscience\nEvidence accumulation\n\n\nWas k√∂nnte man unter Vorwissen (prior knowledge) verstehen? In welchen Kontexten k√∂nnte es bei Entscheidungen n√ºtzlich sein, Vorwissen zu benutzen?"
  },
  {
    "objectID": "pages/exercises/exercise_02.html",
    "href": "pages/exercises/exercise_02.html",
    "title": "√úbung 2",
    "section": "",
    "text": "Note\n\n\n\nDie Daten, welche Sie in dieser √úbung sammeln, m√ºssen abgegeben werden; wir werden diese im Verlauf des Semesters analysieren. Bitte die Datenfiles in einem ZIP File bis 8. M√§rz auf ILIAS hochladen.\n\n\n\n\n\nDas fertige Experiment befindet sich auf Github. Sie k√∂nnen es unter diesem Link downloaden. üëâ LINK.\nF√ºhren Sie das Experiment ein- oder mehrere Male selber durch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen Testperson und laden Sie das ZIP FIle auf ILIAS."
  },
  {
    "objectID": "pages/exercises/exercise_02.html#bias-rdk-experiment-durchf√ºhren",
    "href": "pages/exercises/exercise_02.html#bias-rdk-experiment-durchf√ºhren",
    "title": "√úbung 2",
    "section": "",
    "text": "Das fertige Experiment befindet sich auf Github. Sie k√∂nnen es unter diesem Link downloaden. üëâ LINK.\nF√ºhren Sie das Experiment ein- oder mehrere Male selber durch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen Testperson und laden Sie das ZIP FIle auf ILIAS."
  },
  {
    "objectID": "pages/solutions/solution_03.html",
    "href": "pages/solutions/solution_03.html",
    "title": "√úbung 3: L√∂sung",
    "section": "",
    "text": "In dieser Aufgabe bearbeiten Sie Daten aus einem Detektionssexperiment. Versuchspersonen mussten in zwei Bedingungen (bias und no_bias) ein Signal, welches in Rauschen eingebettet war, detektieren. Im Datensatz sind folgende Variablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable f√ºr Signal (0: absent, 1: present)\ncorrect: Indikatorvariable f√ºr korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\n\n\nAufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\nd &lt;- read_csv(\"data/data-exercise-03.csv\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nRows: 5,756\nColumns: 6\n$ subject        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2‚Ä¶\n$ condition      &lt;chr&gt; \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\",‚Ä¶\n$ signal_present &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0‚Ä¶\n$ correct        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1‚Ä¶\n$ rt             &lt;dbl&gt; 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.370, 0.559,‚Ä¶\n$ trial_num      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, ‚Ä¶\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd &lt;- d |&gt;\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants &lt;- d |&gt;\n    group_by(subject, condition) |&gt;\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions &lt;- d |&gt;\n    group_by(condition) |&gt;\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\nsum_stats_participants &lt;-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(outlier_P = (mean_P - mean_C) &gt; 2 * sd_C)\n\n\n# show outlier participants\nsum_stats_participants |&gt;\n    filter(outlier_P == 1) |&gt;\n    show()\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer Bedingung mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegt. Dies bedeutet, dass sich in excluded keine Personen befinden, und der Dataframe folglich \\(0\\) Zeilen hat.\n\nexcluded &lt;- sum_stats_participants |&gt;\n    filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nDer n√§chste Schritt w√§re also nicht unbedingt notwendig.\n\nd_cleaned &lt;- d |&gt;\n    filter(!(subject %in% excluded$subject)) |&gt;\n    mutate(subject = fct_drop(subject))\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4 Standardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn l√§nger gebraucht haben, als 4 Standardabweichungen √ºber dem Bedingungsmittelwert. Das bedeutet (rt - mean_C) &gt; 4 * sd_C, und nicht abs(rt - mean_C) &gt; 4 * sd_C. Letzteres w√ºrde auch Trials als Ausreisser identifizieren, welche 4 Standardabweichungen unter dem Bedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies bedeutet, wir brauchen rt &lt; 0.100, und nicht rt &lt; 100.\n\nd_cleaned &lt;- d_cleaned |&gt;\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) &gt; 4 * sd_C ~ \"too slow\",\n            rt &lt; 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |&gt;\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt;\n    filter(trial_type != \"OK\")\n\n# A tibble: 165 √ó 9\n   subject condition signal_present correct     rt trial_‚Ä¶¬π mean_C  sd_C trial‚Ä¶¬≤\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  \n 1 2       bias                   0       1 4.08          1  0.697 0.751 too sl‚Ä¶\n 2 2       bias                   1       1 0.035        41  0.697 0.751 too fa‚Ä¶\n 3 2       bias                   0       1 6.92         50  0.697 0.751 too sl‚Ä¶\n 4 2       bias                   0       1 0.085        51  0.697 0.751 too fa‚Ä¶\n 5 2       bias                   0       1 0.033        70  0.697 0.751 too fa‚Ä¶\n 6 2       bias                   0       1 5.09         74  0.697 0.751 too sl‚Ä¶\n 7 2       bias                   0       1 6.59         94  0.697 0.751 too sl‚Ä¶\n 8 2       bias                   0       1 5.09        121  0.697 0.751 too sl‚Ä¶\n 9 2       bias                   1       1 0.077       138  0.697 0.751 too fa‚Ä¶\n10 3       no_bias                1       0 0.0958        4  0.691 0.773 too fa‚Ä¶\n# ‚Ä¶ with 155 more rows, and abbreviated variable names ¬π‚Äãtrial_num, ¬≤‚Äãtrial_type\n\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756 Datenpunkte.\n\nnrow(d_cleaned)\n\n[1] 5756\n\n\n\nd_cleaned &lt;- d_cleaned |&gt;\n    filter(trial_type == \"OK\") |&gt;\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\nNach dem Entfernen haben wir noch 5591.\n\nnrow(d_cleaned)\n\n[1] 5591\n\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt; write_csv(\"data/data-cleaned.csv\")"
  },
  {
    "objectID": "pages/solutions/solution_03.html#aufgaben",
    "href": "pages/solutions/solution_03.html#aufgaben",
    "title": "√úbung 3: L√∂sung",
    "section": "",
    "text": "Aufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\nd &lt;- read_csv(\"data/data-exercise-03.csv\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nRows: 5,756\nColumns: 6\n$ subject        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2‚Ä¶\n$ condition      &lt;chr&gt; \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\",‚Ä¶\n$ signal_present &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0‚Ä¶\n$ correct        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1‚Ä¶\n$ rt             &lt;dbl&gt; 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.370, 0.559,‚Ä¶\n$ trial_num      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, ‚Ä¶\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd &lt;- d |&gt;\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants &lt;- d |&gt;\n    group_by(subject, condition) |&gt;\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions &lt;- d |&gt;\n    group_by(condition) |&gt;\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\nsum_stats_participants &lt;-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(outlier_P = (mean_P - mean_C) &gt; 2 * sd_C)\n\n\n# show outlier participants\nsum_stats_participants |&gt;\n    filter(outlier_P == 1) |&gt;\n    show()\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer Bedingung mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegt. Dies bedeutet, dass sich in excluded keine Personen befinden, und der Dataframe folglich \\(0\\) Zeilen hat.\n\nexcluded &lt;- sum_stats_participants |&gt;\n    filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nDer n√§chste Schritt w√§re also nicht unbedingt notwendig.\n\nd_cleaned &lt;- d |&gt;\n    filter(!(subject %in% excluded$subject)) |&gt;\n    mutate(subject = fct_drop(subject))\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4 Standardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn l√§nger gebraucht haben, als 4 Standardabweichungen √ºber dem Bedingungsmittelwert. Das bedeutet (rt - mean_C) &gt; 4 * sd_C, und nicht abs(rt - mean_C) &gt; 4 * sd_C. Letzteres w√ºrde auch Trials als Ausreisser identifizieren, welche 4 Standardabweichungen unter dem Bedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies bedeutet, wir brauchen rt &lt; 0.100, und nicht rt &lt; 100.\n\nd_cleaned &lt;- d_cleaned |&gt;\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) &gt; 4 * sd_C ~ \"too slow\",\n            rt &lt; 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |&gt;\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt;\n    filter(trial_type != \"OK\")\n\n# A tibble: 165 √ó 9\n   subject condition signal_present correct     rt trial_‚Ä¶¬π mean_C  sd_C trial‚Ä¶¬≤\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  \n 1 2       bias                   0       1 4.08          1  0.697 0.751 too sl‚Ä¶\n 2 2       bias                   1       1 0.035        41  0.697 0.751 too fa‚Ä¶\n 3 2       bias                   0       1 6.92         50  0.697 0.751 too sl‚Ä¶\n 4 2       bias                   0       1 0.085        51  0.697 0.751 too fa‚Ä¶\n 5 2       bias                   0       1 0.033        70  0.697 0.751 too fa‚Ä¶\n 6 2       bias                   0       1 5.09         74  0.697 0.751 too sl‚Ä¶\n 7 2       bias                   0       1 6.59         94  0.697 0.751 too sl‚Ä¶\n 8 2       bias                   0       1 5.09        121  0.697 0.751 too sl‚Ä¶\n 9 2       bias                   1       1 0.077       138  0.697 0.751 too fa‚Ä¶\n10 3       no_bias                1       0 0.0958        4  0.691 0.773 too fa‚Ä¶\n# ‚Ä¶ with 155 more rows, and abbreviated variable names ¬π‚Äãtrial_num, ¬≤‚Äãtrial_type\n\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756 Datenpunkte.\n\nnrow(d_cleaned)\n\n[1] 5756\n\n\n\nd_cleaned &lt;- d_cleaned |&gt;\n    filter(trial_type == \"OK\") |&gt;\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\nNach dem Entfernen haben wir noch 5591.\n\nnrow(d_cleaned)\n\n[1] 5591\n\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt; write_csv(\"data/data-cleaned.csv\")"
  }
]