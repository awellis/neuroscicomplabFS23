[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "FrÃ¼hjahrssemester 2023"
  },
  {
    "objectID": "pages/admin/01_overview.html",
    "href": "pages/admin/01_overview.html",
    "title": "Ãœbersicht",
    "section": "",
    "text": "In diesem Kurs beschÃ¤ftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses Forschungsgebiets. Das bedeutet, wir analysieren Daten aus Verhaltensexperimenten â€” sowohl mit herkÃ¶mmlichen statistischen Verfahren, als auch mit mathematischen Modellen. Die Resultate dieser Analysen kÃ¶nnen wiederum in der Analyse bildgebender Verfahren oder EEG benutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Themen daraus aufgreifen. Das Buch ist auf SpringerLink verfÃ¼gbar: An Introduction to Model-Based Cognitive Neuroscience.\n\nWir werden folgende Themen im Laufe des Semester behandeln:\n\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. binÃ¤re Daten, Reaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinfÃ¼hrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von Entscheidungsverhalten)"
  },
  {
    "objectID": "pages/admin/01_overview.html#experimente",
    "href": "pages/admin/01_overview.html#experimente",
    "title": "Ãœbersicht",
    "section": "Experimente",
    "text": "Experimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen BenutzeroberflÃ¤che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/admin/01_overview.html#datenanalyse",
    "href": "pages/admin/01_overview.html#datenanalyse",
    "title": "Ãœbersicht",
    "section": "Datenanalyse",
    "text": "Datenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu analysieren werden wir R verwenden. Sie sollten daher die aktuelle Version von R installieren (Version r paste(R.Version()[c(\"major\", \"minor\")], collapse = \".\")), sowie RStudio.\nR ğŸ‘‰ https://cloud.r-project.org/\nRStudio ğŸ‘‰ https://www.rstudio.com/products/rstudio/download/#download\nFÃ¼r Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, Ã¤hnlich wie Jamovi, mit dem sich simple Bayesianische Tests durchfÃ¼hren lassen.\nJASP ğŸ‘‰ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R aus benutzen. Die dafÃ¼r benÃ¶tigte Software werden wir im Verlauf des Semesters installieren."
  },
  {
    "objectID": "pages/admin/03_zulip_forum.html",
    "href": "pages/admin/03_zulip_forum.html",
    "title": "Zulip Forum",
    "section": "",
    "text": "Wir benutzen in dieser Veranstaltung Zulip als Diskussionforum. Zulip hat einige Vorteile gegenÃ¼ber ILIAS und Email:\n\nZulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum fÃ¼r die Vormittags- und Nachmittagsveranstaltungen.\nDie Diskussion ist fÃ¼r alle Teilnehmer*innen sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron) stattfinden.\n\nBitte erstellen Sie unter diesem Link einen Account. Sie mÃ¼ssen dafÃ¼r Ihre Uni Emailadresse verwenden. Account erstellen ğŸ‘‰ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, kÃ¶nnen Sie sich unter folgendem Link einloggen. Zulip Forum ğŸ‘‰ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App fÃ¼r alle gÃ¤ngigen Betriebssysteme erhÃ¤ltlich. Apps ğŸ‘‰ zulip.com/apps\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Ellis, Andrew},\n  title = {Zulip {Forum}},\n  url = {https://kogpsy.github.io/neuroscicomplabFS23//pages/admin/03_zulip_forum.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nEllis, Andrew. n.d. â€œZulip Forum.â€ https://kogpsy.github.io/neuroscicomplabFS23//pages/admin/03_zulip_forum.html."
  },
  {
    "objectID": "pages/admin/dozierende.html",
    "href": "pages/admin/dozierende.html",
    "title": "Dozierende",
    "section": "",
    "text": "Andrew ist Data Scientist an der Berner Fachhochschule und Wissenschaftlicher Mitarbeiter an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre der Uni Bern. An der BFH beschÃ¤ftigt er sich hauptsÃ¤chlich mit der Verwendung kÃ¼nstlicher Intelligenz in der Lehre, und versucht ein intelligentes Tutoring-System zu entwickeln.\nğŸ“¬ Email: andrew.ellis@unibe.ch\nğŸ”— Website: www.kog.psy.unibe.ch/ueber_uns/personen/dr_ellis_andrew"
  },
  {
    "objectID": "pages/admin/dozierende.html#andrew-ellis",
    "href": "pages/admin/dozierende.html#andrew-ellis",
    "title": "Dozierende",
    "section": "",
    "text": "Andrew ist Data Scientist an der Berner Fachhochschule und Wissenschaftlicher Mitarbeiter an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre der Uni Bern. An der BFH beschÃ¤ftigt er sich hauptsÃ¤chlich mit der Verwendung kÃ¼nstlicher Intelligenz in der Lehre, und versucht ein intelligentes Tutoring-System zu entwickeln.\nğŸ“¬ Email: andrew.ellis@unibe.ch\nğŸ”— Website: www.kog.psy.unibe.ch/ueber_uns/personen/dr_ellis_andrew"
  },
  {
    "objectID": "pages/admin/dozierende.html#gerda-wyssen",
    "href": "pages/admin/dozierende.html#gerda-wyssen",
    "title": "Dozierende",
    "section": "Gerda Wyssen",
    "text": "Gerda Wyssen\nGerda arbeitet an ihrer Dissertation an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre. Sie untersucht den Einfluss von Gleichgewichts- und Bewegungsinformationen auf rÃ¤umliches Denken. Hierzu nutzt sie die Moog Bewegungsplattform oder das starke Magnetfeld eines 7T MRI Scanners. Besonders faszinierend findet sie Bewegungsillusionen.\nğŸ“¬ Email: gerda.wyssen@unibe.ch\nğŸ”— Website: www.kog.psy.unibe.ch/ueber_uns/personen/m_sc_wyssen_gerda"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html",
    "href": "pages/admin/leistungsnachweise.html",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Unsere Veranstaltungen werden so aufgebaut sein, dass wir etwa die HÃ¤lfte der Zeit Inhalt prÃ¤sentieren; die andere HÃ¤lfte ist praktischen Hands-on Sessions gewidmet. Dies wird jedoch stark vom jeweiligen Inhalt anhÃ¤ngig sein. Wir denken, dass der Umgang mit Programmiersprachen und Datenanalyse am besten gelernt wird, indem man selber ausprobiert. Deshalb werden wir versuchen, die Theorie auf das NÃ¶tigste zu beschrÃ¤nken, und uns mehr auf praktische Anwendungen zu fokussieren."
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#hands-on-sessions",
    "href": "pages/admin/leistungsnachweise.html#hands-on-sessions",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Unsere Veranstaltungen werden so aufgebaut sein, dass wir etwa die HÃ¤lfte der Zeit Inhalt prÃ¤sentieren; die andere HÃ¤lfte ist praktischen Hands-on Sessions gewidmet. Dies wird jedoch stark vom jeweiligen Inhalt anhÃ¤ngig sein. Wir denken, dass der Umgang mit Programmiersprachen und Datenanalyse am besten gelernt wird, indem man selber ausprobiert. Deshalb werden wir versuchen, die Theorie auf das NÃ¶tigste zu beschrÃ¤nken, und uns mehr auf praktische Anwendungen zu fokussieren."
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "href": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "title": "Leistungskontrollen",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nLeistungsnachweise werden in Form von Ãœbungen erbracht. Es wird insgesamt 5 Ãœbungen geben â€“ davon mÃ¼ssen alle abgegeben werden. Die Ãœbungen werden in den Veranstaltungen angekÃ¼ndigt und in den entsprechenden Ordner auf ILIAS hochgeladen. Je nach Umfang der Ãœbung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens eine Woche betragen.\nDie Evaluation der Ãœbungen erfolgt in Form von Peer-Feedback; dies bedeutet, dass Sie nach dem Abgabetermin aufgefordert werden, zu den Ãœbungen von zufÃ¤llig ausgewÃ¤hlten Mitstudierenden Feedback zu geben. Danach erhalten Sie selber von anderen Mitstudierenden Feedback zu Ihrer Ãœbung. Das Peer-Feedback ist somit Teil des Leistungsnachweises. Auf Ilias finden Sie Informationen zur Art und Form des Feedbacks passend zur Ãœbung. GrundsÃ¤tzliche Guidelines zum Peer-Feedback finden Sie untenstehend.\nILIAS (Montag) ğŸ‘‰ 468703-FS2023-1\nILIAS (Donnerstag) ğŸ‘‰ 468703-FS2023-0"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "href": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "title": "Leistungskontrollen",
    "section": "Peer Feedback Guidelines",
    "text": "Peer Feedback Guidelines\nWissenschaftliche Artikel werden von Forschenden aus denselben/Ã¤hnlichen Forschungsgebieten begutachtet. In diesem Kurs wÃ¤hlen wir fÃ¼r das Feedback zu den Ãœbungen ebenfalls dieses Prinzip des peer review. FÃ¼r jede Ãœbung erhalten Sie einen klaren Begutachtungsauftrag mit Fragen wie z.B. Was wÃ¼rde die Grafik informativer machen?. Wir bitten Sie, beim Verfassen des Peer-Feedbacks folgende Richtlinien zu beachten:\n\nbe kind: Seien Sie freundlich. WÃ¤hlen Sie Ihre RÃ¼ckmeldungspunkte sorgfÃ¤ltig. Nehmen Sie sich Zeit und geben Sie nicht sehr knappes, verspÃ¤tetes oder gar kein Feedback. Schreiben Sie was Ihnen positiv aufgefallen ist und unbedingt beibehalten werden sollte.\nbe specific: Beschreiben Sie das Problem oder die Kritikpunkte prÃ¤zise und spezifisch (statt z.B. â€œCode lÃ¤uft nichtâ€ kÃ¶nnten Sie schreiben â€œin Zeile 34 gibt es eine Fehlermeldung, es scheint die Variable wurde falsch benannt, â€¦â€)\nbe helpful: Seien Sie konstruktiv. Es gibt immer etwas was verbessert werden kÃ¶nnte. Beschreiben Sie diese Punkte und fÃ¼gen Sie bestenfalls einen LÃ¶sungsansatz oder -vorschlag hinzu (statt z.B. â€œdie Farben sind nicht geeignet fÃ¼r farbenblinde Personenâ€ kÃ¶nnten Sie schreiben â€œdie viridis Palette wÃ¼rde die Grafik fÃ¼r farbenblinde Personen zugÃ¤nglich machenâ€).\n\nWertvolles Feedback zu geben benÃ¶tigt Zeit. Deshalb planen Sie sich bitte ca. 1 Lektion fÃ¼r das jeweilige Peer Feedback ein."
  },
  {
    "objectID": "pages/admin/syllabus.html",
    "href": "pages/admin/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Sitzungen\nAn den 14 Sitzungen werden wir voraussichtlich diese Themen behandeln (kleine Ã„nderungen vorbehalten).\n\n1 EinfÃ¼hrung\nSitzung 1\n\nWir schauen uns ein paar in den Neurowissenschaften verwendeten Programmiersprachen (Python, R, Matlab) an, und diskutieren ChatGPT.\nEinfÃ¼hrung in DataCamp (fÃ¼r Python/R).\n\n\n\n\n\n\n\nImportant\n\n\n\nAuf DataCamp den Python EinfÃ¼hrungskurs ausprobieren.\n\n\n\n\n2 Experimente mit Python programmieren\nSitzungen 2 und 3\n\nWir erstellen selber ein Experiment mit Python und PsychoPy.\n\n\n\n3 Data Wrangling\nSitzungen 4, 5 und 6\n\nWir schauen uns an, wie wir mit R die Daten aus unserem selber programmierten Experiment einlesen und bearbeiten kÃ¶nnen, um damit statistische Analysen durchzufÃ¼hren.\n\n\n\n4 Visualisieren\nSitzungen 7 und 8\n\nRmarkdown\nExplorative Datenanalyse und grafische Darstellung mit mit R package ggplot2.\n\n\n\n5 Signal Detection Theory\nSitzungen 9 und 10\n\nWir verwenden ein in den Neurowissenschaften und der Psychologie beliebtes Modell fÃ¼r kategoriale oder ordinale Verhaltensdaten, um Daten aus unserem Experiment zu analysieren.\n\n\n\n\n6 Bayesianische Datenanalyse\nSitzungen 11, 12, 13, und 14\n\nIm letzten Thema geht es um einen modernen Ansatz in der Statistik, welcher auf den Axiomen der Wahrscheinlichkeitstheorie beruht, und einige Vorteile gegenÃ¼ber der herkÃ¶mmlichen (frequentistischen) Statistik bietet. Wir werden hier mit dem Programm Jasp arbeiten.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "pages/chapters/chatgpt.html",
    "href": "pages/chapters/chatgpt.html",
    "title": "ChatGPT",
    "section": "",
    "text": "Eventuell haben Sie in den letzten Wochen von ChatGPT gehÃ¶rt, vielleicht schon selber benutzt. Sowohl an Hochschulen als auch an Gymnasien stellt sich die brennende Frage, wie Lehrpersonen und Studierende/SchÃ¼ler damit umgehen sollen. Darf man ChatGPT benutzen? Werden die abgegeben Ãœbungen darauf untersucht, ob sie mit Hilfe kÃ¼nstlicher Intelligenz generiert wurden.\nWir versuchen hier, unsere Haltung in Bezug auf ChatGPT bekanntzugeben, und zu erklÃ¤ren, was ChatGPT kann, und wo es hilfreich sein kÃ¶nnte.\n\n\n\n\nChatGPT benutzt das Codex Modell von OpenAI, welches auf Programmiersprachen spezialisiert ist. Vor allem Python, aber auch R (und Matlab) Code spricht ChatGPT hervorragend.\n\n\n\nNein. ChatGPT besteht aus verschiedenen Komponent. Eines davon ist ein large language model (LLM), die weiteren Komponenten braucht es, um einen Chatbot zu kreieren, welcher menschenÃ¤hnliche Konversationen fÃ¼hren kann.\nDas LLM hat im wesentlichen die Verteilung von WortstÃ¤mmen (Tokens) des Textkorpus (mit dem es trainiert wurde) gelernt. Die Aufgabe des LLM ist es, gegeben einen Input (Prompt) eine oder mehrere wahrscheinliche VervollstÃ¤ndigungen zu erzeugen. Wenn nun im Textkorpus Programmcode vorkam, wird das LLM syntaktisch korrekten Code zu generieren. Das LLM hat jedoch keine MÃ¶glichkeit, diesen Code auszufÃ¼hren, auf Korrektheit zu Ã¼berprÃ¼fen, oder Ã¼berhaupt herauszufinden, ob der Code sinnvoll ist.\nChatGPT kann mitunter hervorragenden Code generieren, aber ob der Code wirklich das macht, was er soll, liegt in der Verantwortung der Benutzer:in.\n\nImmer kritisch Ã¼berprÃ¼fen, ob von ChatGPT generierter Code wirklich korrekt ist, und tut was verlangt wird!\n\n\n\n\nSie kÃ¶nnen ChatGPT helfen, gute Antworten zu erzeugen, in dem Sie gute Fragen stellen. Dies bedeutet, dass Sie in der Frage (Prompt) mÃ¶glichst viele Kontextinformationen mitliefern. Denken Sie daran, dass ChatGPT, gegeben dem Input und den Trainingsdaten, eine mÃ¶glichst wahrscheinliche Sequenz von Token erzeugt.\n\n\n\n\nWir gehen davon aus, dass Technologien wie ChatGPT nicht mehr vom modernen Unterricht wegzudenken sind, und es daher sinnvoll und notwendig ist, einen mÃ¶glichst guten Umgang damit zu erlernen.\n\n\n\n\n\n\nDanger\n\n\n\nChatGPT darf fÃ¼r die Ãœbungen genutzt werden.\n\n\nEs ist aus unserer Sicht jedoch sinnvoll, wenn Sie ChatGPT als eine von vielen mÃ¶glichen Quellen benutzen (wie z.B. Google, Stackoverflow), und diese auch als solche transparent angeben.\nAus unserer Sicht ist ChatGPT (und Codex) ein sehr wertvolles Tool. Sie sind jedoch dafÃ¼r verantwortlich, dass ihr Code ausfÃ¼hrbar ist. Dies wird beim Peer-Feedback eines der Kriterien sein. Das Ziel ist primÃ¤r, dass sie Code verstehen und anwenden kÃ¶nnen, nicht dass sie Code aus dem Nichts selber schreiben kÃ¶nnen. Dies ist Ã¼brigens auch die Vorgehensweise vieler erfahrener Programmierer - oft wird zuerst mal gegoogelt und im Internet nachgeschaut, ob es schon LÃ¶sungsansÃ¤tze gibt. ChatGPT macht im Prinzip nichts anderes.\n\n\n\nIm Prinzip ja, aber Sie wÃ¼rden dabei wahrscheinlich sehr wenig lernen. Den Umgang mit Computern und das Programmieren lernt man, indem man selber Code ausfÃ¼hrt, Fehler macht und versucht zu verstehen was der Fehler war. Das Ziel sollte sein, dass Sie jederzeit erklÃ¤ren kÃ¶nnten, was Ihr Code macht, oder wieso Sie ein bestimmtes Feedback gegeben haben. Ohne selber etwas dafÃ¼r zu tun wird der Lern efolg wahrscheinlich ausbleiben.\n\n\n\nChatGPT kann sowohl Code generieren als auch Code evaluieren. Sie kÃ¶nnen ChatGPT benutzen\n\num VorschlÃ¤ge zu erhalten, wenn Sie nicht weiterkommen.\num ein GerÃ¼st fÃ¼r ein Programm zu erstellen.\num Code auf Lesbarkeit/VerstÃ¤ndlichkeit zu Ã¼berprÃ¼fen.\num Code kommentieren zu lassen.\num Code zu verstehen/bewerten zu lassen.\n\n\n\n\n\n\n\nDanger\n\n\n\nBitte Ã¼berprÃ¼fen Sie aber immer kritisch den Output von ChatGPT, und stellen sie sicher, dass der Code tatsÃ¤chlich ausgefÃ¼hrt werden kann."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#was-kann-chatgpt",
    "href": "pages/chapters/chatgpt.html#was-kann-chatgpt",
    "title": "ChatGPT",
    "section": "",
    "text": "ChatGPT benutzt das Codex Modell von OpenAI, welches auf Programmiersprachen spezialisiert ist. Vor allem Python, aber auch R (und Matlab) Code spricht ChatGPT hervorragend.\n\n\n\nNein. ChatGPT besteht aus verschiedenen Komponent. Eines davon ist ein large language model (LLM), die weiteren Komponenten braucht es, um einen Chatbot zu kreieren, welcher menschenÃ¤hnliche Konversationen fÃ¼hren kann.\nDas LLM hat im wesentlichen die Verteilung von WortstÃ¤mmen (Tokens) des Textkorpus (mit dem es trainiert wurde) gelernt. Die Aufgabe des LLM ist es, gegeben einen Input (Prompt) eine oder mehrere wahrscheinliche VervollstÃ¤ndigungen zu erzeugen. Wenn nun im Textkorpus Programmcode vorkam, wird das LLM syntaktisch korrekten Code zu generieren. Das LLM hat jedoch keine MÃ¶glichkeit, diesen Code auszufÃ¼hren, auf Korrektheit zu Ã¼berprÃ¼fen, oder Ã¼berhaupt herauszufinden, ob der Code sinnvoll ist.\nChatGPT kann mitunter hervorragenden Code generieren, aber ob der Code wirklich das macht, was er soll, liegt in der Verantwortung der Benutzer:in.\n\nImmer kritisch Ã¼berprÃ¼fen, ob von ChatGPT generierter Code wirklich korrekt ist, und tut was verlangt wird!\n\n\n\n\nSie kÃ¶nnen ChatGPT helfen, gute Antworten zu erzeugen, in dem Sie gute Fragen stellen. Dies bedeutet, dass Sie in der Frage (Prompt) mÃ¶glichst viele Kontextinformationen mitliefern. Denken Sie daran, dass ChatGPT, gegeben dem Input und den Trainingsdaten, eine mÃ¶glichst wahrscheinliche Sequenz von Token erzeugt."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#darf-ich-chatgpt-benutzen",
    "href": "pages/chapters/chatgpt.html#darf-ich-chatgpt-benutzen",
    "title": "ChatGPT",
    "section": "",
    "text": "Wir gehen davon aus, dass Technologien wie ChatGPT nicht mehr vom modernen Unterricht wegzudenken sind, und es daher sinnvoll und notwendig ist, einen mÃ¶glichst guten Umgang damit zu erlernen.\n\n\n\n\n\n\nDanger\n\n\n\nChatGPT darf fÃ¼r die Ãœbungen genutzt werden.\n\n\nEs ist aus unserer Sicht jedoch sinnvoll, wenn Sie ChatGPT als eine von vielen mÃ¶glichen Quellen benutzen (wie z.B. Google, Stackoverflow), und diese auch als solche transparent angeben.\nAus unserer Sicht ist ChatGPT (und Codex) ein sehr wertvolles Tool. Sie sind jedoch dafÃ¼r verantwortlich, dass ihr Code ausfÃ¼hrbar ist. Dies wird beim Peer-Feedback eines der Kriterien sein. Das Ziel ist primÃ¤r, dass sie Code verstehen und anwenden kÃ¶nnen, nicht dass sie Code aus dem Nichts selber schreiben kÃ¶nnen. Dies ist Ã¼brigens auch die Vorgehensweise vieler erfahrener Programmierer - oft wird zuerst mal gegoogelt und im Internet nachgeschaut, ob es schon LÃ¶sungsansÃ¤tze gibt. ChatGPT macht im Prinzip nichts anderes."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#kann-chatgpt-fÃ¼r-mich-die-Ã¼bungen-schreiben-und-peer-feedback-geben",
    "href": "pages/chapters/chatgpt.html#kann-chatgpt-fÃ¼r-mich-die-Ã¼bungen-schreiben-und-peer-feedback-geben",
    "title": "ChatGPT",
    "section": "",
    "text": "Im Prinzip ja, aber Sie wÃ¼rden dabei wahrscheinlich sehr wenig lernen. Den Umgang mit Computern und das Programmieren lernt man, indem man selber Code ausfÃ¼hrt, Fehler macht und versucht zu verstehen was der Fehler war. Das Ziel sollte sein, dass Sie jederzeit erklÃ¤ren kÃ¶nnten, was Ihr Code macht, oder wieso Sie ein bestimmtes Feedback gegeben haben. Ohne selber etwas dafÃ¼r zu tun wird der Lern efolg wahrscheinlich ausbleiben."
  },
  {
    "objectID": "pages/chapters/chatgpt.html#wie-kann-ich-chatgpt-sinnvoll-einsetzen",
    "href": "pages/chapters/chatgpt.html#wie-kann-ich-chatgpt-sinnvoll-einsetzen",
    "title": "ChatGPT",
    "section": "",
    "text": "ChatGPT kann sowohl Code generieren als auch Code evaluieren. Sie kÃ¶nnen ChatGPT benutzen\n\num VorschlÃ¤ge zu erhalten, wenn Sie nicht weiterkommen.\num ein GerÃ¼st fÃ¼r ein Programm zu erstellen.\num Code auf Lesbarkeit/VerstÃ¤ndlichkeit zu Ã¼berprÃ¼fen.\num Code kommentieren zu lassen.\num Code zu verstehen/bewerten zu lassen.\n\n\n\n\n\n\n\nDanger\n\n\n\nBitte Ã¼berprÃ¼fen Sie aber immer kritisch den Output von ChatGPT, und stellen sie sicher, dass der Code tatsÃ¤chlich ausgefÃ¼hrt werden kann."
  },
  {
    "objectID": "pages/chapters/datacamp.html",
    "href": "pages/chapters/datacamp.html",
    "title": "DataCamp",
    "section": "",
    "text": "Im Rahmen dieser Lehrveranstaltung kÃ¶nnen alle Teilnehmende sich bei DataCamp registrieren\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL an. DataCamp Kurse auf unterschiedlichen Niveaus an; sowohl fÃ¼r AnfÃ¤nger als auch fÃ¼r Fortgeschrittene gibt es ein breites Angebot an Kursen.\nSie kÃ¶nnen Sich unter folgendem Link mit Ihrer Uni Bern E-Mail Adresse (*unibe.ch) registrieren:\nğŸ‘‰ğŸ¼ DataCamp registration"
  },
  {
    "objectID": "pages/chapters/datacamp.html#datacamp",
    "href": "pages/chapters/datacamp.html#datacamp",
    "title": "DataCamp",
    "section": "",
    "text": "Im Rahmen dieser Lehrveranstaltung kÃ¶nnen alle Teilnehmende sich bei DataCamp registrieren\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL an. DataCamp Kurse auf unterschiedlichen Niveaus an; sowohl fÃ¼r AnfÃ¤nger als auch fÃ¼r Fortgeschrittene gibt es ein breites Angebot an Kursen.\nSie kÃ¶nnen Sich unter folgendem Link mit Ihrer Uni Bern E-Mail Adresse (*unibe.ch) registrieren:\nğŸ‘‰ğŸ¼ DataCamp registration"
  },
  {
    "objectID": "pages/chapters/datacamp.html#hands-on-session",
    "href": "pages/chapters/datacamp.html#hands-on-session",
    "title": "DataCamp",
    "section": "Hands-on session",
    "text": "Hands-on session\nWir werden in der zweiten Sitzung mit Psychopy und Python ein Experiment erstellen. In Psychopy kÃ¶nnen Sie viel sehr Ã¼ber die grafische OberflÃ¤che; es gibt jedoch einige kleine Dinge, welche wir mit Python selber coden mÃ¼ssen. Deshalb wÃ¤re es fÃ¼r Sie hiflreich, wenn Sie sich vorher auf der DataCamp Website ein wenig mit Python vertraut machen.\n\n1 - Python Basics\nJe nachdem wie viel Erfahrung Sie mit Python haben, kÃ¶nnen Sie sich entweder fÃ¼r den Kurs â€œIntroduction to Pythonâ€ oder â€œIntermediate Pythonâ€ entscheiden.\nğŸ‘‰ğŸ¼ Introduction to Python\nğŸ‘‰ğŸ¼ Intermediate Python\nFÃ¼r fortgeschrittene empfehlen wir die Kurse:\nğŸ‘‰ğŸ¼ Python Data Science Toolbox (Part 1)\nğŸ‘‰ğŸ¼ Python Data Science Toolbox (Part 2)\nDiese Kurse sind nicht obligatorisch; Sie brauchen fÃ¼r PsychoPy wirklich nur Grundkenntnisse. Python ist aber sowohl in der Forschung als der Privatwirtschaft sehr beliebt und Sie werden es sicherlich noch Ã¶fters brauchen, wenn Sie sich mit Datenanalyse beschÃ¤ftigen.\n\n\n2 - Python Code mit ChatGPT generieren\nDies benÃ¶tigt einen ChatGPT Account; einen solchen kÃ¶nnen Sie bei OpenAI gratis erstellen.\nğŸ‘‰ğŸ¼ chat.openai.com/chat\nVersuchen Sie, mit ChatGPT ein paar Zeilen Python Code zu generieren. Sie kÃ¶nnen hierzu einige Beispiele als den DataCamp Kursen verwenden.\n\nKann ChatGPT die Aufgaben lÃ¶sen?\nWie kann Ihnen ChatGPT helfen, Code zu schreiben?\nWas mÃ¼ssen Sie beachten, wenn Sie Code von ChatGPT verwenden?"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html",
    "href": "pages/chapters/experiment_stepbystep.html",
    "title": "Experiment erstellen: Step by step",
    "section": "",
    "text": "Schauen Sie sich in PsychoPy die verschiedenen mÃ¶glichen Bausteine fÃ¼r Experimente an. Versuchen Sie StÃ¼ck fÃ¼r StÃ¼ck das Experiment von Mulder et al. (2012) nachzubauen."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#allgemeine-informationen-zu-psychopy",
    "href": "pages/chapters/experiment_stepbystep.html#allgemeine-informationen-zu-psychopy",
    "title": "Experiment erstellen: Step by step",
    "section": "Allgemeine Informationen zu PsychoPy",
    "text": "Allgemeine Informationen zu PsychoPy\nHilfreiche Informationen zum Erstellen von Experimenten in PsychoPy finden Sie hier:\n\nPsychoPy Website\nWalk-through: Builder\nDiskussionsforum"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#random-dot-stimulus",
    "href": "pages/chapters/experiment_stepbystep.html#random-dot-stimulus",
    "title": "Experiment erstellen: Step by step",
    "section": "1. Random Dot Stimulus",
    "text": "1. Random Dot Stimulus\nErstellen Sie einen Random Dot Stimulus. Beachten Sie folgende Aspekte:\n\nTiming (Stimulusdauer): 1500 ms\nFarbe\nGrÃ¶sse: gut sichtbar\nKohÃ¤renz: 0.08\nField size: 75% des Displays\n\n(Die Bewegungsrichtung kÃ¶nnen Sie noch vernachlÃ¤ssigen.)"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#trialschleife",
    "href": "pages/chapters/experiment_stepbystep.html#trialschleife",
    "title": "Experiment erstellen: Step by step",
    "section": "2. Trialschleife",
    "text": "2. Trialschleife\nErstellen Sie eine Trial-Schleife.\n\nFixation 1 (100/350/800/1200 ms) (Zur Vereinfachung kÃ¶nnen Sie hier auch nur einen Wert wÃ¤hlen.)\nCue (1000 ms)\nFixation 2 (3400/4000/4500/5000 ms) (Zur Vereinfachung kÃ¶nnen Sie hier auch nur einen Wert wÃ¤hlen.)\nDots (1500 ms)\nFeedback\nTiming (ITI: Inter-Trial-Intervall)\nAntwort der Versuchsperson aufnehmen\n\n(Die Variation der Bewegungsrichtung und des Vorwissens kÃ¶nnen Sie noch vernachlÃ¤ssigen.)"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#bedingungen",
    "href": "pages/chapters/experiment_stepbystep.html#bedingungen",
    "title": "Experiment erstellen: Step by step",
    "section": "3. Bedingungen",
    "text": "3. Bedingungen\n\nVariieren Sie die Bewegungsrichtung der Random Dots mit dem conditions.csv file: Bewegungsrichtung ist zu 50% rechts, zu 50% links.\nVariieren Sie den Cue fÃ¼rs Vorwissen in jedem Trial mit dem conditions.csv file: Der Cue kann valide (4x), invalide (2x) oder neutral (4x) sein. Die Bewegungsrichtungen mÃ¼ssen auf alle Bedingungen gleich verteilt sein."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#instruktion-und-debriefing",
    "href": "pages/chapters/experiment_stepbystep.html#instruktion-und-debriefing",
    "title": "Experiment erstellen: Step by step",
    "section": "4. Instruktion und Debriefing",
    "text": "4. Instruktion und Debriefing\n\nFÃ¼gen Sie zu Beginn des Experiments eine Instruktion hinzu.\nFÃ¼gen Sie am Ende des Experiments ein Debriefing hinzu."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#test",
    "href": "pages/chapters/experiment_stepbystep.html#test",
    "title": "Experiment erstellen: Step by step",
    "section": "5. Test",
    "text": "5. Test\nFÃ¼hren Sie das Experiment aus und schauen Sie sich den Datensatz an: Sind die untenstehenden Infos auf jeder Zeile vorhanden?\n\nVersuchspersonennummer\nRichtung des Stimulus\nCue / Vorwissen\nAntwort der Versuchsperson\nAntwortdauer der Versuchsperson"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#Ã¼bungsexperiment",
    "href": "pages/chapters/experiment_stepbystep.html#Ã¼bungsexperiment",
    "title": "Experiment erstellen: Step by step",
    "section": "6. Ãœbungsexperiment",
    "text": "6. Ãœbungsexperiment\n\nLaden Sie hier das Experiment fÃ¼r Ãœbung 1 herunter.\nVergleichen Sie das Experiment mit Ihrer Version, was fÃ¤llt Ihnen auf?"
  },
  {
    "objectID": "pages/chapters/functions-loops.html",
    "href": "pages/chapters/functions-loops.html",
    "title": "Automatisieren",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nConditionals und Control Flow\nFunktionen erstellen\nLoops anwenden\nWir nun zwei Programmierkonzepte kennenlernen, die uns dabei helfen, Tasks zu automatisieren. Wir werden hier nicht in die Tiefe gehen; es geht uns vielmehr darum, Ihnen einen Ãœberblick zu geben, was Sie mit diesen Konzepten machen kÃ¶nnen. Falls Sie tiefer in die Materie einsteigen mÃ¶chten, gibt es entsprechende Kurse auf Datacamp."
  },
  {
    "objectID": "pages/chapters/functions-loops.html#alternativen-zu-for-loops",
    "href": "pages/chapters/functions-loops.html#alternativen-zu-for-loops",
    "title": "Automatisieren",
    "section": "Alternativen zu for-Loops",
    "text": "Alternativen zu for-Loops\nEs gibt in R mehrere MÃ¶glichkeiten, um Ã¼ber Vektoren oder Listen zu iterieren, ohne dabei explizite for-Loops zu schreiben. Dies hat den Vorteil, dass der Code kÃ¼rzer und Ã¼bersichtlicher wird.\n\nlapply und sapply\n\nlapply und sapply sind zwei Funktionen, welche Ã¼ber Listen iterieren. lapply und sapply sind sehr Ã¤hnlich. lapply gibt eine Liste zurÃ¼ck, wÃ¤hrend sapply eine Liste retournieren kann.\nAls Beispiel wollen wir jedes Element eines Vektors verdoppeln (dies kann in R auch einfacher gemacht werden, aber dies ist nur ein Ãœbungsbeispiel).\n\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\nMit for kÃ¶nnen wir dies wie folgt tun.\n\nfor (number in numbers) {\n    print(number * 2)\n}\n\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 10\n\n\nMit lapply und sapply haben wir zwei MÃ¶glichkeiten. Wir kÃ¶nnen entweder eine anonyme Funktion definieren, oder wir kÃ¶nnen eine Funktion zuerst definieren, und dann verwenden.\n\\(x) x * 2 definiert eine sogenannte anonyme Funktion. Diese Funktion nimmt ein Argument x und multipliziert es mit 2, erhÃ¤lt aber keinen eigenen Namen. Folglich kÃ¶nnen wir diese Funktion nicht wiederverwenden.\n\nlapply(numbers, \\(x) x * 2)\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\nMit einer Funktion, die wir zuerst definieren, sieht unser Beispiel so aus.\n\ndouble &lt;- function(x) {\n    x * 2\n}\n\n\nlapply(numbers, double)\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\n\nsapply(numbers, double)\n\n[1]  2  4  6  8 10\n\n\nmap\nEine weitere MÃ¶glichkeit, Ã¼ber Listen zu iterieren, ist die Funktion map. map ist eine Funktion aus dem Paket purrr (wird automatisch geladen, wenn tidyverse geladen wird). map gibt immer eine Liste zurÃ¼ck.\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.2.1\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nnumbers |&gt; map(double)\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\nWenn wir als Output einen Vektor haben wollen, mÃ¼ssen wir die Funktion unlist() verwenden.\n\nnumbers |&gt; map(double) |&gt; unlist()\n\n[1]  2  4  6  8 10"
  },
  {
    "objectID": "pages/chapters/functions_and_loops-2.html",
    "href": "pages/chapters/functions_and_loops-2.html",
    "title": "Funktionen und Schleifen",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nMehrere DatensÃ¤tze importieren\nEine Schleife (loop) zu schreiben\nEine eigene Funktion schreiben"
  },
  {
    "objectID": "pages/chapters/functions_and_loops-2.html#schleifen-loops",
    "href": "pages/chapters/functions_and_loops-2.html#schleifen-loops",
    "title": "Funktionen und Schleifen",
    "section": "Schleifen (loops)",
    "text": "Schleifen (loops)\nSchleifen ermÃ¶glichen das x-beliebige Wiederholen eines Schrittes z.B. statt dem einzelnen Einlesen eines Datensatzes, werden alle DatensÃ¤tze in einem Ordner eingelesen auf einmal eingelesen.\nUm mehrere DatensÃ¤tze einzulesen benÃ¶tigen wir:\n\nEine Liste aller DatensÃ¤tze, die man einlesen mÃ¶chte\nEine Schleife, die besagt, dass wir fÃ¼r jedes Objekt in der Liste etwas machen mÃ¶chten\nEine Aufgabe, die wir mit jedem Objekt ausfÃ¼hren mÃ¶chten\n\nMit einer Schleife sagt man dem Programm â€œFÃ¼hre fÃ¼r jeden Datensatz dieser Liste folgendes durch: Lade den Datensatz.â€\nEine Schleife wird in R wie folgt formuliert:\n\nfor (var in seq){\n    expr\n}\n\nMit var ist eine Variable in einer Sequenz seq gemeint. Bei uns wÃ¤re die Variable ein Name eines Datensatzes, und die Sequenz wÃ¤re eine Liste mit DatensÃ¤tzen (z.B. alle Files in einem Ordner). expr meint expression, also was wir mit dieser Variable tun wollen, in unserem Beispiel wollen wir den Datensatz Ã¶ffnen.\n\n\n\nInhalt\nBsp. Datensatz einlesen\n\n\n\nvar\nLaufvariable\nName des einzelnen Datensatzes\n\n\nseq\nSequenz/Vektor\nListe mit Namen aller DatensÃ¤tze\n\n\nexpr\nSchritt/Aufgabe\nÃ–ffnen des Datensatzes\n\n\n\nNun mÃ¼ssen wir statt var, seq und expr natÃ¼rlich sinnvolle Variablen und Schritte einfÃ¼gen. Zuerst erstellen wir die Liste, Ã¼ber die die Schleife laufen soll.\n\nmyFiles &lt;- list.files(path = \"../../data/rdk_decision_experiment/data\",  # Pfad des Ordners mit den DatensÃ¤tzen\n                      pattern = \".csv\", # Endung der DatensÃ¤tze, hier .csv\n                      full.names = TRUE) \n\nmyFiles # zeige die Liste\n\n[1] \"../../data/rdk_decision_experiment/data/JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"../../data/rdk_decision_experiment/data/NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"../../data/rdk_decision_experiment/data/rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"../../data/rdk_decision_experiment/data/sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"../../data/rdk_decision_experiment/data/SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"../../data/rdk_decision_experiment/data/VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"../../data/rdk_decision_experiment/data/VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"../../data/rdk_decision_experiment/data/VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"../../data/rdk_decision_experiment/data/VPN02_rdk-discrimination_2022_Mar_01_2208.csv\"\n\n\nDie Variable var kÃ¶nnen wir beliebig benennen, wir wÃ¤hlen hier file. Danach kÃ¶nnen wir die Schleife erstellen, die fÃ¼r jedes file in myFiles den Schritt Daten laden mit read.csv ausfÃ¼hrt. Das sieht dann so aus:\n\nDiese Variable wird oft i oder j genannt.\n\nd &lt;- NULL # Vorbereiten des Datensatzes \n\nfor (file in myFiles){\n    dataset &lt;- read.csv(file)\n    d &lt;- rbind(d, dataset) # wir fÃ¼gen jeden neu eingelesenen Datensatz hinzu\n}"
  },
  {
    "objectID": "pages/chapters/functions_and_loops-2.html#funktionen",
    "href": "pages/chapters/functions_and_loops-2.html#funktionen",
    "title": "Funktionen und Schleifen",
    "section": "Funktionen",
    "text": "Funktionen\nStatt der Schleife, kÃ¶nnen wir es uns aber noch einfacher machen, in dem wir statt einer Schleide die Funktion mapverwenden. Funktionen sind sehr hilfreich, wenn man einen Schritt mehrmals machen will. Funktionen sind kleine Programme, denen man Infos geben muss (Parameter) und die dann immer dasselbe mit diesen Infos machen. Eine Funktion hat folgende Struktur:\n\nfunctionname &lt;- function(parameter) {\n  body\n}\n\nDie Funktion mean()zum Beispiel macht immer dasselbe mit den Zahlen, die man ihr fÃ¼ttert.\n\nx &lt;- c(1, 21, 3, 234, 5) # verschiedene Zahlen\n\nmean(x)\n\n\n\n\n\n\n\nImportant\n\n\n\nWas macht die Funktion mean()?\nTipp: Geben Sie ?mean in Ihre R-Konsole ein.\n\nWas kann man bei der Funktion mean() als Parameter eingeben?\nMuss die eingegebene Variable x heissen? Probieren Sie aus.\nWas passiert, wenn man mean(x, trim = 1) eingibt?\nWas bedeutet na.rm? FÃ¼gen Sie im Vektor x ein NAhinzu und probieren Sie es aus.\n\n\n\nUm unsere Daten einzulesen verwenden wir die Funktion map vom Package purrr. Diese Funktion ist sehr praktisch. Sie nimmt als Parameter unsere Liste mit den DatensÃ¤tzen und wendet fÃ¼r jeden Punkt in der Liste das an, was wir in Klammern angeben. Wir wollen Daten einlesen also schreiben wir hier: read.csv. Anschliessend mÃ¼ssen wir die Listen noch zu einem Datensatz umwandeln indem wir alle untereinander anordnen, also die Listen reihenweise binden: list_rbind().\n\nFalls Sie das Package purrr noch nicht installiert haben, kÃ¶nnen Sie in der Konsole install.packages(\"purrr\") eingeben. Jedes Package muss nur einmal installiert werden. Will man es verwenden, muss es aber mit library(purrr) geladen werden. Statt list_rbindzu verwenden kÃ¶nnten wir auch map_dfrnutzen, dann wÃ¤re der Code noch kompakter.\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.0     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.1     âœ” tibble    3.1.8\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(purrr)\n\nd &lt;- myFiles %&gt;%\n    map(read.csv) |&gt;\n    list_rbind()\n\nglimpse(d, width = 10)\n\nRows: 1,503\nColumns: 40\n$ cue                                        &lt;chr&gt; â€¦\n$ direction                                  &lt;chr&gt; â€¦\n$ practice_block_loop.thisRepN               &lt;int&gt; â€¦\n$ practice_block_loop.thisTrialN             &lt;int&gt; â€¦\n$ practice_block_loop.thisN                  &lt;int&gt; â€¦\n$ practice_block_loop.thisIndex              &lt;int&gt; â€¦\n$ main_blocks_loop.thisRepN                  &lt;int&gt; â€¦\n$ main_blocks_loop.thisTrialN                &lt;int&gt; â€¦\n$ main_blocks_loop.thisN                     &lt;int&gt; â€¦\n$ main_blocks_loop.thisIndex                 &lt;int&gt; â€¦\n$ static_isi.started                         &lt;dbl&gt; â€¦\n$ static_isi.stopped                         &lt;dbl&gt; â€¦\n$ fixation_pre.started                       &lt;dbl&gt; â€¦\n$ fixation_pre.stopped                       &lt;chr&gt; â€¦\n$ image.started                              &lt;dbl&gt; â€¦\n$ image.stopped                              &lt;chr&gt; â€¦\n$ fixation_post.started                      &lt;dbl&gt; â€¦\n$ fixation_post.stopped                      &lt;chr&gt; â€¦\n$ dots_background.started                    &lt;dbl&gt; â€¦\n$ dots_background.stopped                    &lt;chr&gt; â€¦\n$ dots_stimulus.started                      &lt;dbl&gt; â€¦\n$ dots_stimulus.stopped                      &lt;chr&gt; â€¦\n$ dots_keyboard_response.keys                &lt;chr&gt; â€¦\n$ dots_keyboard_response.started             &lt;dbl&gt; â€¦\n$ dots_keyboard_response.stopped             &lt;chr&gt; â€¦\n$ feedback_text.started                      &lt;dbl&gt; â€¦\n$ feedback_text.stopped                      &lt;chr&gt; â€¦\n$ dots_keyboard_response.rt                  &lt;dbl&gt; â€¦\n$ instruction_main_text.started              &lt;dbl&gt; â€¦\n$ instruction_main_text.stopped              &lt;chr&gt; â€¦\n$ instruction_main_keyboard_response.keys    &lt;chr&gt; â€¦\n$ instruction_main_keyboard_response.rt      &lt;dbl&gt; â€¦\n$ instruction_main_keyboard_response.started &lt;dbl&gt; â€¦\n$ instruction_main_keyboard_response.stopped &lt;chr&gt; â€¦\n$ Pseudonym                                  &lt;chr&gt; â€¦\n$ date                                       &lt;chr&gt; â€¦\n$ expName                                    &lt;chr&gt; â€¦\n$ psychopyVersion                            &lt;chr&gt; â€¦\n$ frameRate                                  &lt;dbl&gt; â€¦\n$ X                                          &lt;lgl&gt; â€¦"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html",
    "href": "pages/chapters/importing_data-2.html",
    "title": "Daten importieren: Teil 2",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nArbeitsschritte automatisieren: mehrere DatensÃ¤tze automatisch importieren\nMit ChatGPT Code verstehen"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#alle-files-in-einem-ordner-auflisten",
    "href": "pages/chapters/importing_data-2.html#alle-files-in-einem-ordner-auflisten",
    "title": "Daten importieren: Teil 2",
    "section": "Alle Files in einem Ordner auflisten",
    "text": "Alle Files in einem Ordner auflisten\nZuerst erstellen wir mit list.files() eine Liste aller .csv Files im Ordner data.\n\ndatadir &lt;- \"data\"\n\ncsv_files &lt;- datadir |&gt;\n    list.files(pattern = \"csv\", full.names = TRUE)\n\n\ncsv_files\n\n[1] \"data/JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"data/NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"data/rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"data/sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"data/SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"data/VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"data/VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"data/VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"data/VPN02_rdk-discrimination_2022_Mar_01_2208.csv\"\n\n\ncsv_files enthÃ¤lt nun die â€œPfadeâ€ zu allen .csv Files im Ordner data. Diese Pfade kÃ¶nnen nun einzeln and read_csv() Ã¼bergeben werden."
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#mit-for-loop",
    "href": "pages/chapters/importing_data-2.html#mit-for-loop",
    "title": "Daten importieren: Teil 2",
    "section": "Mit for-Loop",
    "text": "Mit for-Loop\nZuerst brauchen wir eine Liste, in die wir die Daten einlesen kÃ¶nnen. Wir erstellen eine Liste mit der LÃ¤nge der Anzahl Files, die wir haben.\n\ndata_list &lt;- vector(\"list\", length(csv_files))\n\nNun kÃ¶nnen wir entweder Ã¼ber die Elemente der Liste iterieren, oder Ã¼ber die Indizes. Wir wÃ¤hlen letzteres, da wir die Indizes spÃ¤ter fÃ¼r die Zuweisung der Daten verwenden kÃ¶nnen.\n\nfor (i in seq_along(csv_files)) {\n            df &lt;- read_csv(csv_files[i])\n            data_list[[i]] &lt;- df\n}\n\nDas Resultat ist eine Liste, in deren Elementen die neun csv Files gepesichert sind.\n\nlength(data_list)\n\n[1] 9\n\n\nDiese wollen wir nun zu einem Dataframe zusammenfÃ¼gen. Dazu kÃ¶nnen wir do.call() verwenden. do.call() nimmt eine Funktion und eine Liste als Argumente. Die Liste werden wiederum als Argumente der Funktion verwendet.\n\ndata_loop &lt;- do.call(rbind, data_list)\n\n\nhead(data_loop)\n\n# A tibble: 6 Ã— 40\n  cue   directâ€¦Â¹ practâ€¦Â² practâ€¦Â³ practâ€¦â´ practâ€¦âµ main_â€¦â¶ main_â€¦â· main_â€¦â¸ main_â€¦â¹\n  &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 none  right          0       0       0       5      NA      NA      NA      NA\n2 left  right          0       1       1       2      NA      NA      NA      NA\n3 right right          0       2       2       1      NA      NA      NA      NA\n4 left  left           0       3       3       0      NA      NA      NA      NA\n5 none  left           0       4       4       4      NA      NA      NA      NA\n6 right left           0       5       5       3      NA      NA      NA      NA\n# â€¦ with 30 more variables: static_isi.started &lt;dbl&gt;, static_isi.stopped &lt;dbl&gt;,\n#   fixation_pre.started &lt;dbl&gt;, fixation_pre.stopped &lt;chr&gt;,\n#   image.started &lt;dbl&gt;, image.stopped &lt;chr&gt;, fixation_post.started &lt;dbl&gt;,\n#   fixation_post.stopped &lt;chr&gt;, dots_background.started &lt;dbl&gt;,\n#   dots_background.stopped &lt;chr&gt;, dots_stimulus.started &lt;dbl&gt;,\n#   dots_stimulus.stopped &lt;chr&gt;, dots_keyboard_response.keys &lt;chr&gt;,\n#   dots_keyboard_response.started &lt;dbl&gt;, â€¦"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#mit-map-und-list_rbind",
    "href": "pages/chapters/importing_data-2.html#mit-map-und-list_rbind",
    "title": "Daten importieren: Teil 2",
    "section": "Mit map und list_rbind\n",
    "text": "Mit map und list_rbind\n\nDasselbe kÃ¶nnen wir auch mit map() machen. Da auch hier der Output eine Liste ist, mÃ¼ssen wir diese auch zu einem Dataframe zusammenfÃ¼gen. Dazu kÃ¶nnen wir list_rbind() verwenden.\n\ndata &lt;- csv_files |&gt; \n    map(read_csv) |&gt;\n    list_rbind()\n\n\ndata |&gt;\n  slice_head(n = 20)\n\n# A tibble: 20 Ã— 40\n   cue   direcâ€¦Â¹ practâ€¦Â² practâ€¦Â³ practâ€¦â´ practâ€¦âµ main_â€¦â¶ main_â€¦â· main_â€¦â¸ main_â€¦â¹\n   &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 none  right         0       0       0       5      NA      NA      NA      NA\n 2 left  right         0       1       1       2      NA      NA      NA      NA\n 3 right right         0       2       2       1      NA      NA      NA      NA\n 4 left  left          0       3       3       0      NA      NA      NA      NA\n 5 none  left          0       4       4       4      NA      NA      NA      NA\n 6 right left          0       5       5       3      NA      NA      NA      NA\n 7 &lt;NA&gt;  &lt;NA&gt;         NA      NA      NA      NA      NA      NA      NA      NA\n 8 right right        NA      NA      NA      NA       0       0       0      18\n 9 right right        NA      NA      NA      NA       0       1       1      31\n10 none  right        NA      NA      NA      NA       0       2       2      66\n11 none  right        NA      NA      NA      NA       0       3       3      75\n12 left  left         NA      NA      NA      NA       0       4       4      13\n13 none  right        NA      NA      NA      NA       0       5       5      62\n14 none  left         NA      NA      NA      NA       0       6       6      41\n15 left  left         NA      NA      NA      NA       0       7       7      15\n16 left  right        NA      NA      NA      NA       0       8       8      32\n17 none  right        NA      NA      NA      NA       0       9       9      68\n18 none  left         NA      NA      NA      NA       0      10      10      40\n19 left  left         NA      NA      NA      NA       0      11      11       1\n20 left  left         NA      NA      NA      NA       0      12      12       3\n# â€¦ with 30 more variables: static_isi.started &lt;dbl&gt;, static_isi.stopped &lt;dbl&gt;,\n#   fixation_pre.started &lt;dbl&gt;, fixation_pre.stopped &lt;chr&gt;,\n#   image.started &lt;dbl&gt;, image.stopped &lt;chr&gt;, fixation_post.started &lt;dbl&gt;,\n#   fixation_post.stopped &lt;chr&gt;, dots_background.started &lt;dbl&gt;,\n#   dots_background.stopped &lt;chr&gt;, dots_stimulus.started &lt;dbl&gt;,\n#   dots_stimulus.stopped &lt;chr&gt;, dots_keyboard_response.keys &lt;chr&gt;,\n#   dots_keyboard_response.started &lt;dbl&gt;, â€¦\n\n\nNun kÃ¶nnen wir wie in Teil 1 die Practice Trials entfernen.\n\ndata  &lt;- data |&gt;  \n        filter(!is.na(main_blocks_loop.thisN)) |&gt;\n        select(-contains(\"practice_block_loop\"))"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#variablen-auswÃ¤hlen-und-umbennen",
    "href": "pages/chapters/importing_data-2.html#variablen-auswÃ¤hlen-und-umbennen",
    "title": "Daten importieren: Teil 2",
    "section": "Variablen auswÃ¤hlen und umbennen",
    "text": "Variablen auswÃ¤hlen und umbennen\nWir eliminieren die Variablen, die wir nicht brauchen (ISI, Fixationskreuz, Zeitangaben der Bilder, etc.).\n\ndata &lt;- data |&gt;\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\nZum Schluss geben wir den Variablen, die wir behalten, noch deskriptivere Namen.\n\ndata &lt;- data |&gt;\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\ndata |&gt;\n  slice_head(n = 20)\n\n# A tibble: 20 Ã— 6\n   trial ID    cue   direction response    rt\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n 1     0 JH    right right     j        0.714\n 2     1 JH    right right     j        0.627\n 3     2 JH    none  right     f        0.670\n 4     3 JH    none  right     j        0.574\n 5     4 JH    left  left      j        0.841\n 6     5 JH    none  right     j        0.668\n 7     6 JH    none  left      j        1.12 \n 8     7 JH    left  left      f        0.640\n 9     8 JH    left  right     f        1.13 \n10     9 JH    none  right     j        1.03 \n11    10 JH    none  left      f        1.35 \n12    11 JH    left  left      f        0.688\n13    12 JH    left  left      f        0.721\n14    13 JH    none  left      f        0.655\n15    14 JH    right right     j        1.02 \n16    15 JH    none  right     j        1.12 \n17    16 JH    left  left      f        1.08 \n18    17 JH    right left      f        0.643\n19    18 JH    right right     j        0.716\n20    19 JH    left  left      f        0.578"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#neue-variablen-definieren",
    "href": "pages/chapters/importing_data-2.html#neue-variablen-definieren",
    "title": "Daten importieren: Teil 2",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\nEine Antwort ist korrekt, wenn die gewÃ¤hlte Richtung der Richtung des Dot-Stimulus entspricht. Zuvor definieren wir zwei Variablen: choice besteht aus den Angaben â€œrightâ€ und â€œleftâ€, response ist eine numerische Version davon (0 = â€œleftâ€, 1 = â€œrightâ€).\nKorrekte Antworten\n\ndata &lt;- data |&gt;\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\ncorrect ist TRUE wenn choice == direction, FALSE wenn nicht. Wir konvertieren diese logische Variable mit as.numeric() in eine numerische Variable. as.numeric() konvertiert TRUE in 1 und FALSE in 0.\n\n\n\n\n\n\nTip\n\n\n\n\nas.numeric(c(TRUE, FALSE))\n\n[1] 1 0\n\n\n\n\n\ndata &lt;- data |&gt;\n    mutate(correct = as.numeric(choice == direction))\n\n\nglimpse(data)\n\nRows: 1,440\nColumns: 8\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17â€¦\n$ ID        &lt;chr&gt; \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", â€¦\n$ cue       &lt;chr&gt; \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", \"none\", \"lâ€¦\n$ direction &lt;chr&gt; \"right\", \"right\", \"right\", \"right\", \"left\", \"right\", \"left\",â€¦\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, â€¦\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667â€¦\n$ choice    &lt;chr&gt; \"right\", \"right\", \"left\", \"right\", \"right\", \"right\", \"right\"â€¦\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n\n\nWir schauen uns die ersten 20 Zeilen an.\n\ndata |&gt; \n  slice_head(n = 20)\n\n# A tibble: 20 Ã— 8\n   trial ID    cue   direction response    rt choice correct\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     0 JH    right right            1 0.714 right        1\n 2     1 JH    right right            1 0.627 right        1\n 3     2 JH    none  right            0 0.670 left         0\n 4     3 JH    none  right            1 0.574 right        1\n 5     4 JH    left  left             1 0.841 right        0\n 6     5 JH    none  right            1 0.668 right        1\n 7     6 JH    none  left             1 1.12  right        0\n 8     7 JH    left  left             0 0.640 left         1\n 9     8 JH    left  right            0 1.13  left         0\n10     9 JH    none  right            1 1.03  right        1\n11    10 JH    none  left             0 1.35  left         1\n12    11 JH    left  left             0 0.688 left         1\n13    12 JH    left  left             0 0.721 left         1\n14    13 JH    none  left             0 0.655 left         1\n15    14 JH    right right            1 1.02  right        1\n16    15 JH    none  right            1 1.12  right        1\n17    16 JH    left  left             0 1.08  left         1\n18    17 JH    right left             0 0.643 left         1\n19    18 JH    right right            1 0.716 right        1\n20    19 JH    left  left             0 0.578 left         1\n\n\nCue-Bedingungsvariable\nNun brauchen wir eine Variable, die angibt, ob die Bedingung â€œneutralâ€, â€œvalidâ€ oder â€œinvalidâ€ ist. Wir erstellen eine neue Variable condition und fÃ¼llen sie mit case_when() mit den Werten â€œneutralâ€, â€œvalidâ€ oder â€œinvalidâ€. case_when() erlaubt, mehrere if_else()-Bedingungen zu kombinieren. So wird hier der Variablen condition der Wert neutral zugewiesen, wenn cue == \"none\" ist. Falls cue == direction ist, wird der Wert valid zugewiesen. Falls cue != direction ist, wird der Wert invalid zugewiesen.\n\ndata &lt;- data |&gt;\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\ndata |&gt; \n  slice_head(n = 20)\n\n# A tibble: 20 Ã— 9\n   trial ID    cue   direction response    rt choice correct condition\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n11    10 JH    none  left             0 1.35  left         1 neutral  \n12    11 JH    left  left             0 0.688 left         1 valid    \n13    12 JH    left  left             0 0.721 left         1 valid    \n14    13 JH    none  left             0 0.655 left         1 neutral  \n15    14 JH    right right            1 1.02  right        1 valid    \n16    15 JH    none  right            1 1.12  right        1 neutral  \n17    16 JH    left  left             0 1.08  left         1 valid    \n18    17 JH    right left             0 0.643 left         1 invalid  \n19    18 JH    right right            1 0.716 right        1 valid    \n20    19 JH    left  left             0 0.578 left         1 valid    \n\n\nDaten als CSV speichern\nAn dieser Stelle speichern wir den neu kreierten Datensatz als .csv File in einen Ordner names data_clean. Somit kÃ¶nnen wir zu einem spÃ¤teren Zeitpunkt die Daten einfach importieren, ohne die ganzen Schritte wiederholen zu mÃ¼ssen.\n\ndata |&gt; write_csv(file = \"data_clean/rdkdata.csv\")"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#gruppierungsvariablen",
    "href": "pages/chapters/importing_data-2.html#gruppierungsvariablen",
    "title": "Daten importieren: Teil 2",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\nAlle Gruppierungsvariablen sollten nun zu Faktoren konvertiert werden.\n\ndata &lt;- data |&gt;\n    mutate(across(where(is.character), as_factor))\n\n\nglimpse(data)\n\nRows: 1,440\nColumns: 9\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17â€¦\n$ ID        &lt;fct&gt; JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, â€¦\n$ cue       &lt;fct&gt; right, right, none, none, left, none, none, left, left, noneâ€¦\n$ direction &lt;fct&gt; right, right, right, right, left, right, left, left, right, â€¦\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, â€¦\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667â€¦\n$ choice    &lt;fct&gt; right, right, left, right, right, right, right, left, left, â€¦\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n$ condition &lt;fct&gt; valid, valid, neutral, neutral, valid, neutral, neutral, valâ€¦"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#daten-Ã¼berprÃ¼fen",
    "href": "pages/chapters/importing_data-2.html#daten-Ã¼berprÃ¼fen",
    "title": "Daten importieren: Teil 2",
    "section": "Daten Ã¼berprÃ¼fen",
    "text": "Daten Ã¼berprÃ¼fen\nWir Ã¼berprÃ¼fen, ob die Daten korrekt sind. Dazu schauen wir uns die Anzahl der Trials pro Person und pro Bedingung an. Sie kÃ¶nnen mehr Zeilen anzeigen, indem sie n = in der Funktion slice_head() Ã¤ndern.\n\ndata |&gt; \n  group_by(ID, condition) |&gt;\n  summarise(n_trials = n()) |&gt;\n  slice_head(n = 20)\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 27 Ã— 3\n# Groups:   ID [9]\n   ID    condition n_trials\n   &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;\n 1 JH    valid           64\n 2 JH    neutral         80\n 3 JH    invalid         16\n 4 NS    valid           64\n 5 NS    neutral         80\n 6 NS    invalid         16\n 7 rh    valid           64\n 8 rh    neutral         80\n 9 rh    invalid         16\n10 sb    valid           64\n# â€¦ with 17 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#accuracy-pro-personbedingung",
    "href": "pages/chapters/importing_data-2.html#accuracy-pro-personbedingung",
    "title": "Daten importieren: Teil 2",
    "section": "Accuracy pro Person/Bedingung",
    "text": "Accuracy pro Person/Bedingung\nNun berechnen wir pro Person und pro Bedingung die Anzahl der korrekten Antworten und die Accuracy. Die Accuracy ist die Anzahl der korrekten Antworten geteilt durch die Anzahl der Trials.\n\naccuracy &lt;- data |&gt;\n    group_by(ID, condition) |&gt;\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\n\n\naccuracy\n\n# A tibble: 27 Ã— 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   &lt;fct&gt; &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 JH    valid        64       60    0.938\n 2 JH    neutral      80       66    0.825\n 3 JH    invalid      16       13    0.812\n 4 NS    valid        64       58    0.906\n 5 NS    neutral      80       56    0.7  \n 6 NS    invalid      16       11    0.688\n 7 rh    valid        64       61    0.953\n 8 rh    neutral      80       64    0.8  \n 9 rh    invalid      16        2    0.125\n10 sb    valid        64       62    0.969\n# â€¦ with 17 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data-2.html#visualisieren",
    "href": "pages/chapters/importing_data-2.html#visualisieren",
    "title": "Daten importieren: Teil 2",
    "section": "Visualisieren",
    "text": "Visualisieren\n\naccuracy |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per person/condition\") +\n  facet_wrap(~ID) +\n  theme_linedraw(base_size = 28) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "pages/chapters/importing_data.html",
    "href": "pages/chapters/importing_data.html",
    "title": "Daten importieren: Teil 1",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nMit RStudio arbeiten\nEinzelne Psychopy .csv DatensÃ¤tze importieren\nVariablen auswÃ¤hlen/umbenennen\nNeue Variablen berechnen\nMehrere DatensÃ¤tze importieren\nMit ChatGPT Code verstehen"
  },
  {
    "objectID": "pages/chapters/importing_data.html#csv-file-importieren",
    "href": "pages/chapters/importing_data.html#csv-file-importieren",
    "title": "Daten importieren: Teil 1",
    "section": "CSV File importieren",
    "text": "CSV File importieren\nWir werden nun das File ZZ_rdk-discrimination_2022_Mar_07_1403.csv aus dem testdata Ordner einlesen. Bevor wir das tun, ist es sinnvoll, sich das File z.B. in Excel anschauen.\n\n\n\n\n\n\nTip\n\n\n\nÃ–ffnen Sie ZZ_rdk-discrimination_2022_Mar_07_1403.csv in Excel.\nWas steht in den Spalten? Was steht in den Zeilen?\n\n\nNun kÃ¶nnen Sie entweder Ã¼ber die GUI-Option (Menu &gt; File &gt; Import Dataset &gt; From text (readr)) oder direkt das File einlesen.\n\ntestdata &lt;- read_csv(\"testdata/ZZ_rdk-discrimination_2022_Mar_07_1403.csv\") \n\nVariablen Ã¼berprÃ¼fen\n\nglimpse(testdata)\n\nRows: 167\nColumns: 39\n$ cue                                        &lt;chr&gt; \"none\", \"left\", \"right\", \"lâ€¦\n$ direction                                  &lt;chr&gt; \"right\", \"right\", \"right\", â€¦\n$ practice_block_loop.thisRepN               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, NA, NA, Nâ€¦\n$ practice_block_loop.thisTrialN             &lt;dbl&gt; 0, 1, 2, 3, 4, 5, NA, NA, Nâ€¦\n$ practice_block_loop.thisN                  &lt;dbl&gt; 0, 1, 2, 3, 4, 5, NA, NA, Nâ€¦\n$ practice_block_loop.thisIndex              &lt;dbl&gt; 5, 2, 1, 0, 4, 3, NA, NA, Nâ€¦\n$ main_blocks_loop.thisRepN                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,â€¦\n$ main_blocks_loop.thisTrialN                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,â€¦\n$ main_blocks_loop.thisN                     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,â€¦\n$ main_blocks_loop.thisIndex                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA,â€¦\n$ static_isi.started                         &lt;dbl&gt; 0.01033428, 0.03202713, 0.0â€¦\n$ static_isi.stopped                         &lt;dbl&gt; 2.010334, 2.032027, 2.03217â€¦\n$ fixation_pre.started                       &lt;dbl&gt; 26.79425, 36.16522, 44.7852â€¦\n$ fixation_pre.stopped                       &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ image.started                              &lt;dbl&gt; 27.19849, 36.28205, 46.0032â€¦\n$ image.stopped                              &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ fixation_post.started                      &lt;dbl&gt; 28.17814, 37.28240, 47.0037â€¦\n$ fixation_post.stopped                      &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ dots_background.started                    &lt;dbl&gt; 32.18642, 41.30145, 52.0107â€¦\n$ dots_background.stopped                    &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ dots_stimulus.started                      &lt;dbl&gt; 32.18642, 41.30145, 52.0107â€¦\n$ dots_stimulus.stopped                      &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ dots_keyboard_response.keys                &lt;chr&gt; \"None\", \"f\", \"j\", \"f\", \"Nonâ€¦\n$ dots_keyboard_response.started             &lt;dbl&gt; 32.18642, 41.30145, 52.0107â€¦\n$ dots_keyboard_response.stopped             &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ feedback_text.started                      &lt;dbl&gt; 33.70200, 42.28899, 52.9229â€¦\n$ feedback_text.stopped                      &lt;chr&gt; \"None\", \"None\", \"None\", \"Noâ€¦\n$ dots_keyboard_response.rt                  &lt;dbl&gt; NA, 0.9339199, 0.8488816, 0â€¦\n$ instruction_main_text.started              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 81.â€¦\n$ instruction_main_text.stopped              &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"Noâ€¦\n$ instruction_main_keyboard_response.keys    &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"spâ€¦\n$ instruction_main_keyboard_response.rt      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 3.1â€¦\n$ instruction_main_keyboard_response.started &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 81.â€¦\n$ instruction_main_keyboard_response.stopped &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"Noâ€¦\n$ Pseudonym                                  &lt;chr&gt; \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZâ€¦\n$ date                                       &lt;chr&gt; \"2022_Mar_07_1403\", \"2022_Mâ€¦\n$ expName                                    &lt;chr&gt; \"rdk-discrimination\", \"rdk-â€¦\n$ psychopyVersion                            &lt;chr&gt; \"03.02.21\", \"03.02.21\", \"03â€¦\n$ frameRate                                  &lt;dbl&gt; 59.9, 59.9, 59.9, 59.9, 59.â€¦"
  },
  {
    "objectID": "pages/chapters/importing_data.html#practice-trials-lÃ¶schen",
    "href": "pages/chapters/importing_data.html#practice-trials-lÃ¶schen",
    "title": "Daten importieren: Teil 1",
    "section": "Practice Trials lÃ¶schen",
    "text": "Practice Trials lÃ¶schen\nVielleicht haben Sie bemerkt, dass die ersten 6 Zeilen Ãœbungstrials sind. Diese wollen wir nicht analysieren, und kÃ¶nnen folglich gelÃ¶scht werden.\n\nlibrary(kableExtra)\n\ntestdata |&gt; \n  slice_head(n = 12) |&gt; \n  kbl() |&gt; \n  kable_paper(\"striped\", full_width = FALSE) |&gt; \n  column_spec(2:7, bold = TRUE) |&gt; \n  row_spec(1:6, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\ncue\ndirection\npractice_block_loop.thisRepN\npractice_block_loop.thisTrialN\npractice_block_loop.thisN\npractice_block_loop.thisIndex\nmain_blocks_loop.thisRepN\nmain_blocks_loop.thisTrialN\nmain_blocks_loop.thisN\nmain_blocks_loop.thisIndex\nstatic_isi.started\nstatic_isi.stopped\nfixation_pre.started\nfixation_pre.stopped\nimage.started\nimage.stopped\nfixation_post.started\nfixation_post.stopped\ndots_background.started\ndots_background.stopped\ndots_stimulus.started\ndots_stimulus.stopped\ndots_keyboard_response.keys\ndots_keyboard_response.started\ndots_keyboard_response.stopped\nfeedback_text.started\nfeedback_text.stopped\ndots_keyboard_response.rt\ninstruction_main_text.started\ninstruction_main_text.stopped\ninstruction_main_keyboard_response.keys\ninstruction_main_keyboard_response.rt\ninstruction_main_keyboard_response.started\ninstruction_main_keyboard_response.stopped\nPseudonym\ndate\nexpName\npsychopyVersion\nframeRate\n\n\n\nnone\nright\n0\n0\n0\n5\nNA\nNA\nNA\nNA\n0.0103343\n2.010334\n26.79425\nNone\n27.19849\nNone\n28.17814\nNone\n32.18642\nNone\n32.18642\nNone\nNone\n32.18642\nNone\n33.70200\nNone\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nleft\nright\n0\n1\n1\n2\nNA\nNA\nNA\nNA\n0.0320271\n2.032027\n36.16522\nNone\n36.28205\nNone\n37.28240\nNone\n41.30145\nNone\n41.30145\nNone\nf\n41.30145\nNone\n42.28899\nNone\n0.9339199\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nright\n0\n2\n2\n1\nNA\nNA\nNA\nNA\n0.0321732\n2.032173\n44.78521\nNone\n46.00329\nNone\n47.00374\nNone\n52.01072\nNone\n52.01072\nNone\nj\n52.01072\nNone\n52.92295\nNone\n0.8488816\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nleft\nleft\n0\n3\n3\n0\nNA\nNA\nNA\nNA\n0.0321533\n2.032153\n55.39138\nNone\n56.19407\nNone\n57.22527\nNone\n61.23181\nNone\n61.23181\nNone\nf\n61.23181\nNone\n62.21611\nNone\n0.9396018\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nnone\nleft\n0\n4\n4\n4\nNA\nNA\nNA\nNA\n0.0321391\n2.032139\n64.71204\nNone\n64.81315\nNone\n65.84603\nNone\n69.25240\nNone\n69.25240\nNone\nNone\n69.25240\nNone\n70.78541\nNone\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nleft\n0\n5\n5\n3\nNA\nNA\nNA\nNA\n0.0323178\n2.032318\n73.24960\nNone\n74.45209\nNone\n75.48391\nNone\n79.99045\nNone\n79.99045\nNone\nf\n79.99045\nNone\n80.80311\nNone\n0.7490084\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n81.30346\nNone\nspace\n3.187924\n81.30346\nNone\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nright\nNA\nNA\nNA\nNA\n0\n0\n0\n18\n0.0160001\n2.016000\n86.52245\nNone\n86.89231\nNone\n87.92302\nNone\n92.92987\nNone\n92.92987\nNone\nj\n92.92987\nNone\n93.70924\nNone\n0.7136441\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nright\nright\nNA\nNA\nNA\nNA\n0\n1\n1\n31\n0.0318162\n2.031816\n96.17699\nNone\n96.54602\nNone\n97.57770\nNone\n101.58423\nNone\n101.58423\nNone\nj\n101.58423\nNone\n102.26673\nNone\n0.6271285\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nnone\nright\nNA\nNA\nNA\nNA\n0\n2\n2\n66\n0.0321148\n2.032115\n104.76463\nNone\n105.13302\nNone\n106.16508\nNone\n110.67183\nNone\n110.67183\nNone\nf\n110.67183\nNone\n111.38828\nNone\n0.6703410\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nnone\nright\nNA\nNA\nNA\nNA\n0\n3\n3\n75\n0.0321121\n2.032112\n113.88535\nNone\n115.08794\nNone\n116.11989\nNone\n119.52612\nNone\n119.52612\nNone\nj\n119.52612\nNone\n120.15512\nNone\n0.5738488\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\nleft\nleft\nNA\nNA\nNA\nNA\n0\n4\n4\n13\n0.0321118\n2.032112\n122.62295\nNone\n123.82583\nNone\n124.85742\nNone\n129.36397\nNone\n129.36397\nNone\nj\n129.36397\nNone\n130.25975\nNone\n0.8405913\nNA\nNA\nNA\nNA\nNA\nNA\nZZ\n2022_Mar_07_1403\nrdk-discrimination\n03.02.21\n59.9\n\n\n\n\n\n\nUm den obigen Code auszufÃ¼hren, brauchen Sie das Package kableExtra.\nDie Variable main_blocks_loop.thisN ist die Trialnummer. Diese kÃ¶nnen wir verwenden, um die Zeilen auszuschliessen, die nicht zum Main Block gehÃ¶ren.\n\ntestdata |&gt; \n  slice_head(n = 12) |&gt; \n  select(starts_with(\"main_block\")) |&gt; \n  kbl() |&gt; \n  kable_paper(\"striped\", full_width = FALSE) |&gt; \n  row_spec(1:7, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\nmain_blocks_loop.thisRepN\nmain_blocks_loop.thisTrialN\nmain_blocks_loop.thisN\nmain_blocks_loop.thisIndex\n\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\nNA\nNA\nNA\nNA\n\n\n0\n0\n0\n18\n\n\n0\n1\n1\n31\n\n\n0\n2\n2\n66\n\n\n0\n3\n3\n75\n\n\n0\n4\n4\n13\n\n\n\n\n\nMit folgendem Code filtern wir zuerst, so dass , bei wir nur noch Zeilen behalten, bei denen nicht der Wert NA in der Spalte main_blocks_loop.thisN steht. Dann wÃ¤hlen wir alle Spalten ausser practice_block_loop.\n\ntestdata &lt;- testdata |&gt; \n    filter(!is.na(main_blocks_loop.thisN)) |&gt;\n    select(-contains(\"practice_block_loop\"))\n\n\n\n\n\n\n\nChatGPT\n\n\n\nFalls Code nicht verstÃ¤ndlich finden, kÃ¶nnen Sie ChatGPT fragen. Benutzen Sie folgenden Prompt:\nWhat does the following R code do? \n\ntestdata &lt;- testdata |&gt; \n    filter(!is.na(main_blocks_loop.thisN)) |&gt;\n    select(-contains(\"practice_block_loop\"))"
  },
  {
    "objectID": "pages/chapters/importing_data.html#variablen-auswÃ¤hlen",
    "href": "pages/chapters/importing_data.html#variablen-auswÃ¤hlen",
    "title": "Daten importieren: Teil 1",
    "section": "Variablen auswÃ¤hlen",
    "text": "Variablen auswÃ¤hlen\nDie folgenden Variablen enthalten Informationen zu den Inter-Trial Intervallen, Fixationskreuzen, Feedback, etc, und sind fÃ¼r uns an dieser Stelle nicht interessant.\n\ntestdata |&gt;\n    select(contains(\"static\"),\n           contains(\"fixation\"),\n           contains(\"image\"),\n           contains(\"instruction\"),\n           contains(\"feedback\"))\n\n# A tibble: 160 Ã— 16\n   static_isi.â€¦Â¹ statiâ€¦Â² fixatâ€¦Â³ fixatâ€¦â´ fixatâ€¦âµ fixatâ€¦â¶ imageâ€¦â· imageâ€¦â¸ instrâ€¦â¹\n           &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        0.0160    2.02    86.5 None       87.9 None       86.9 None         NA\n 2        0.0318    2.03    96.2 None       97.6 None       96.5 None         NA\n 3        0.0321    2.03   105.  None      106.  None      105.  None         NA\n 4        0.0321    2.03   114.  None      116.  None      115.  None         NA\n 5        0.0321    2.03   123.  None      125.  None      124.  None         NA\n 6        0.0321    2.03   133.  None      135.  None      134.  None         NA\n 7        0.0321    2.03   142.  None      144.  None      143.  None         NA\n 8        0.0321    2.03   152.  None      154.  None      153.  None         NA\n 9        0.0321    2.03   161.  None      163.  None      162.  None         NA\n10        0.0321    2.03   172.  None      173.  None      172.  None         NA\n# â€¦ with 150 more rows, 7 more variables: instruction_main_text.stopped &lt;chr&gt;,\n#   instruction_main_keyboard_response.keys &lt;chr&gt;,\n#   instruction_main_keyboard_response.rt &lt;dbl&gt;,\n#   instruction_main_keyboard_response.started &lt;dbl&gt;,\n#   instruction_main_keyboard_response.stopped &lt;chr&gt;,\n#   feedback_text.started &lt;dbl&gt;, feedback_text.stopped &lt;chr&gt;, and abbreviated\n#   variable names Â¹â€‹static_isi.started, Â²â€‹static_isi.stopped, â€¦\n\n\nMit select kÃ¶nnen wir alle Variablen ausser diesen auswÃ¤hlen.\n\ntestdata &lt;- testdata |&gt;\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\ntestdata\n\n# A tibble: 160 Ã— 19\n   cue   direcâ€¦Â¹ main_â€¦Â² main_â€¦Â³ main_â€¦â´ main_â€¦âµ dots_â€¦â¶ dots_â€¦â· dots_â€¦â¸ dots_â€¦â¹\n   &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1 right right         0       0       0      18    92.9 None       92.9 None   \n 2 right right         0       1       1      31   102.  None      102.  None   \n 3 none  right         0       2       2      66   111.  None      111.  None   \n 4 none  right         0       3       3      75   120.  None      120.  None   \n 5 left  left          0       4       4      13   129.  None      129.  None   \n 6 none  right         0       5       5      62   139.  None      139.  None   \n 7 none  left          0       6       6      41   148.  None      148.  None   \n 8 left  left          0       7       7      15   158.  None      158.  None   \n 9 left  right         0       8       8      32   168.  None      168.  None   \n10 none  right         0       9       9      68   178.  None      178.  None   \n# â€¦ with 150 more rows, 9 more variables: dots_keyboard_response.keys &lt;chr&gt;,\n#   dots_keyboard_response.started &lt;dbl&gt;, dots_keyboard_response.stopped &lt;chr&gt;,\n#   dots_keyboard_response.rt &lt;dbl&gt;, Pseudonym &lt;chr&gt;, date &lt;chr&gt;,\n#   expName &lt;chr&gt;, psychopyVersion &lt;chr&gt;, frameRate &lt;dbl&gt;, and abbreviated\n#   variable names Â¹â€‹direction, Â²â€‹main_blocks_loop.thisRepN,\n#   Â³â€‹main_blocks_loop.thisTrialN, â´â€‹main_blocks_loop.thisN,\n#   âµâ€‹main_blocks_loop.thisIndex, â¶â€‹dots_background.started, â€¦"
  },
  {
    "objectID": "pages/chapters/importing_data.html#variablen-umbenennen",
    "href": "pages/chapters/importing_data.html#variablen-umbenennen",
    "title": "Daten importieren: Teil 1",
    "section": "Variablen umbenennen",
    "text": "Variablen umbenennen\nNun wollen Variablen identifizieren, die uns interessieren. Diese wollen wir umbenennen.\n\ntestdata &lt;- testdata |&gt;\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\ntestdata\n\n# A tibble: 160 Ã— 6\n   trial ID    cue   direction response    rt\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n 1     0 ZZ    right right     j        0.714\n 2     1 ZZ    right right     j        0.627\n 3     2 ZZ    none  right     f        0.670\n 4     3 ZZ    none  right     j        0.574\n 5     4 ZZ    left  left      j        0.841\n 6     5 ZZ    none  right     j        0.668\n 7     6 ZZ    none  left      j        1.12 \n 8     7 ZZ    left  left      f        0.640\n 9     8 ZZ    left  right     f        1.13 \n10     9 ZZ    none  right     j        1.03 \n# â€¦ with 150 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data.html#neue-variablen-definieren",
    "href": "pages/chapters/importing_data.html#neue-variablen-definieren",
    "title": "Daten importieren: Teil 1",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\nNun wollen wir zwei neue Variablen erstellen: eine â€œcharacterâ€ Variable, die uns sagt, ob â€œrechtsâ€ oder â€œlinksâ€ entschieden wurde, und eine numerische Variable mit derselben Information. Je nachdem, ob wir die Daten grafisch darstellen oder analysieren wollen, brauchen wir beide Variablen.\n\ntestdata &lt;- testdata |&gt;\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\nFolgender Code lÃ¶st das gleiche Problem mit der Funktion as.numeric(). Fragen Sie ruhig ChatGPT, falls Sie den Code nicht verstehen.\n\ntestdata &lt;- testdata |&gt;\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = as.numeric(choice == \"right\"))\n\nWir erstellen ausserdem hier eine Variable, welche angibt, ob der Cue valid, invalid oder neutral war. Ein Cue ist genau dann valide, wenn er dieselbe Richtung hat wie der Random Dot Stimulus, d.h. wenn cue == direction.\n\ntestdata &lt;- testdata |&gt;\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\n\n\n\n\nChatGPT\n\n\n\nWhat does the R function case_when() do?\n\n\nZum Schluss erstellen wir noch eine Variable, welche festhÃ¤lt, ob die Antwort der Versuchsperson korrekt war.\n\ntestdata &lt;- testdata |&gt;\n    mutate(correct = as.numeric(choice == direction))"
  },
  {
    "objectID": "pages/chapters/importing_data.html#gruppierungsvariablen",
    "href": "pages/chapters/importing_data.html#gruppierungsvariablen",
    "title": "Daten importieren: Teil 1",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\n\nglimpse(testdata)\n\nRows: 160\nColumns: 9\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17â€¦\n$ ID        &lt;chr&gt; \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", â€¦\n$ cue       &lt;chr&gt; \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", \"none\", \"lâ€¦\n$ direction &lt;chr&gt; \"right\", \"right\", \"right\", \"right\", \"left\", \"right\", \"left\",â€¦\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, â€¦\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667â€¦\n$ choice    &lt;chr&gt; \"right\", \"right\", \"left\", \"right\", \"right\", \"right\", \"right\"â€¦\n$ condition &lt;chr&gt; \"valid\", \"valid\", \"neutral\", \"neutral\", \"valid\", \"neutral\", â€¦\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n\n\n\ntestdata &lt;- testdata |&gt;\n    mutate_if(is.character, as.factor)\n\n\nglimpse(testdata)\n\nRows: 160\nColumns: 9\n$ trial     &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17â€¦\n$ ID        &lt;fct&gt; ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, â€¦\n$ cue       &lt;fct&gt; right, right, none, none, left, none, none, left, left, noneâ€¦\n$ direction &lt;fct&gt; right, right, right, right, left, right, left, left, right, â€¦\n$ response  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, â€¦\n$ rt        &lt;dbl&gt; 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667â€¦\n$ choice    &lt;fct&gt; right, right, left, right, right, right, right, left, left, â€¦\n$ condition &lt;fct&gt; valid, valid, neutral, neutral, valid, neutral, neutral, valâ€¦\n$ correct   &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦"
  },
  {
    "objectID": "pages/chapters/importing_data.html#accuracy-pro-bedingung",
    "href": "pages/chapters/importing_data.html#accuracy-pro-bedingung",
    "title": "Daten importieren: Teil 1",
    "section": "Accuracy pro Bedingung",
    "text": "Accuracy pro Bedingung\nWir kÃ¶nnen nun die accuracy in jeder Cue-Bedingung berechnen. Es gibt hier zwei MÃ¶glichkeiten: wir berechen die Anzahl Trials (N), und die Anzahl korrekter Antworten (ncorrect) separat. Der Anteil korrekter Antworten ist dann einfach ncorrect/N. Dasselbe Ergebnis erhalten wir, wenn wir einfach den Mittelwert der korrekten Antworten nehmen.\n\ntestaccuracy &lt;- testdata |&gt;\n    group_by(condition) |&gt;\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = ncorrect/N,\n              accuracy2 = mean(correct))\n\ntestaccuracy\n\n# A tibble: 3 Ã— 5\n  condition     N ncorrect accuracy accuracy2\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 invalid      16       13    0.812     0.812\n2 neutral      80       66    0.825     0.825\n3 valid        64       60    0.938     0.938"
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html",
    "href": "pages/chapters/psychopy_experiments.html",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "",
    "text": "Neurowissenschaftliche Experimente mÃ¼ssen exakt auf die Fragestellung zugeschnitten werden um aussagekrÃ¤ftige Daten zu liefern. Deshalb programmieren die meisten Forschenden ihre Experimentalparadigmen selbst. So kÃ¶nnen beispielsweise Instruktionen oder verwendete Stimuli, deren GrÃ¶sse und Anzeigedauer prÃ¤zise definiert werden. In dieser Sitzung erstellen wir mit PsychoPy ein perzeptuelles Entscheidungsexperiment, Ã¤hnlich dem Experiment aus Mulder et al. (2012). Dieses neurowissenschaftliche Experiment untersucht den Einfluss von Vorwissen auf Entscheidungsverhalten von Menschen sowie die dazugehÃ¶rigen neuronalen Korrelate."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#ablauf",
    "href": "pages/chapters/psychopy_experiments.html#ablauf",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Ablauf",
    "text": "Ablauf\nDas Experiment besteht aus der Instruktion, mehreren VersuchsblÃ¶cken und der Nachbesprechung. Die Anweisungen und die Nachbesprechung sind Textanzeigen, wÃ¤hrend die Versuche (und die VersuchsblÃ¶cke) etwas komplizierter sind."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#trial",
    "href": "pages/chapters/psychopy_experiments.html#trial",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Trial",
    "text": "Trial\nZunÃ¤chst wird ein Fixationskreuz entweder fÃ¼r 100 ms, 350 ms, 800 ms oder 1200 ms angezeigt. Die tatsÃ¤chliche Dauer wird fÃ¼r jeden Versuch randomisiert. Eine solche Randomisierung kann nicht Ã¼ber die BenutzeroberflÃ¤che vorgenommen werden, sondern erfordert ein kleines StÃ¼ck Python-Code. Sehen Sie sich den Codeblock der Routine Fixation_pre_cue an, um zu erfahren, wie dies erreicht werden kann.\n\nDas Experiment wurde im Scanner und ausserhalb durchgefÃ¼hrt. Die beiden Version unterscheiden sich ganz stark in ihrem Timing. Wir implementieren hier die Scanner Version des Tasks.\n\nAnschlieÃŸend wird fÃ¼r 1000 ms ein Hinweis (cue) prÃ¤sentiert. Dabei kann es sich entweder um einen Pfeil handeln, der nach rechts zeigt, einen Pfeil, der nach links zeigt, oder einen einfachen Kreis (fÃ¼r die Kontrollbedingung). Der Codeblock in der Cue-Routine legt den tatsÃ¤chlichen Hinweis fÃ¼r jeden Versuch auf der Grundlage der Schleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz prÃ¤sentiert - dieses Mal fÃ¼r entweder 3400 ms, 4000 ms, 4500 ms oder 5000 ms. Wie beim ersten Fixationskreuz wird die tatsÃ¤chliche Dauer zufÃ¤llig gewÃ¤hlt.\nNach dem zweiten Fixationskreuz wird fÃ¼r 1500 ms der eigentliche Stimulus angezeigt: ein random dot kinematogram (RDK). Die Punkte bewegen sich entweder nach rechts oder nach links mit einem KohÃ¤renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs wird durch die Schleifenvariable direction bestimmt und im Codeblock der Routine Dots festgelegt. Die Teilnehmer mÃ¼ssen entscheiden, welche Richtung sie wahrnehmen, und kÃ¶nnen ihre Antwort durch DrÃ¼cken der linken oder rechten Pfeiltaste auf der Tastatur eingeben.\nSchlieÃŸlich wird ein Feedback-Bildschirm angezeigt. Wenn der Teilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis â€œzu schnellâ€ angezeigt. Wurde wÃ¤hrend des gesamten Stimulus keine Antwort erfasst, wird das Wort â€œmissâ€ angezeigt. War die Antwort richtig, wird â€œ+5 Punkteâ€ angezeigt, war sie falsch, wird â€œ+0 Punkteâ€ angezeigt."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "href": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Experimentalschleife: main_blocks_loop",
    "text": "Experimentalschleife: main_blocks_loop\nMit loops in PsychoPy haben wir die MÃ¶glichkeit, eine oder mehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt, um denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber jedes Mal mit anderen Werten fÃ¼r die loop variables. Eine Schleife wiederholt also einen Versuch einige Male, wobei die Schleifenvariablen bei jeder Wiederholung geÃ¤ndert werden. Der Versuch selbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen, ob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird nur die main_blocks_loop erklÃ¤rt, aber das Prinzip gilt auch fÃ¼r die practice_block_loop.\nUm die verschiedenen Werte fÃ¼r die Schleifenvariablen zu definieren, mÃ¼ssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop Variablen cue und direction. Das Stichwort kann entweder left, right oder none, sein, wÃ¤hrend die Richtung left oder right sein kann.\nIn der BenutzeroberflÃ¤che kÃ¶nnen wir die Variablen loopType und nReps fÃ¼r die Schleife angeben, wenn wir sie anklicken. Mit ersterer kÃ¶nnen wir steuern, ob wir z.B. die Zeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach unten ablaufen lassen wollen, wÃ¤hrend die letztere definiert, wie oft jede Zeile der Bedingungsdatei wiederholt werden soll.\nFÃ¼r die main_blocks_loop haben wir eine Bedingungsdatei mit 80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen entsprechen. In der einen HÃ¤lfte der neutralen Trials bewegen sich die Punkte nach rechts, in der anderen HÃ¤lfte nach links. Bei den voreingenommenen Versuchen sind 32 der Hinweise gÃ¼ltig (d.Â h. sie stimmen mit der Bewegungsrichtung der Punkte Ã¼berein) und 16 ungÃ¼ltig, wobei sich die Punkte sowohl bei gÃ¼ltigen als auch bei ungÃ¼ltigen Hinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der Versuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so dass alle diese Reihen zweimal durchlaufen werden (insgesamt 160 Versuche), und die Variable â€œloopTypeâ€ wird auf random gesetzt, so dass die Versuche in zufÃ¤lliger Reihenfolge durchgefÃ¼hrt werden."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#daten",
    "href": "pages/chapters/psychopy_experiments.html#daten",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Daten",
    "text": "Daten\nWenn man die default-Einstellungen nicht Ã¤ndert, speichert PsychoPy die Daten automatisch in einem trial-by-trial CSV File. Das bedeutet, dass jeder Trial 1 Zeile generiert. Das CSV File erhÃ¤lt einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es mÃ¶glich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV Files werden in einem Ordner mit dem Name data abgelegt.\n\nBei der Wahl vom Datenfile-Namen empfiehlt es sich immer Datum und Uhrzeit anzuhÃ¤ngen. Dies verhindert, dass Daten Ã¼berschrieben werden, wenn z.B. eine Versuchspersonen-ID falsch eingetippt oder doppelt vergeben wird."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "href": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Degrees of Visual Angle",
    "text": "Degrees of Visual Angle\nOftmals werden GrÃ¶ssenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abhÃ¤ngig sind. Degrees of visual angle gibt die wahrgenommene GrÃ¶sse des Stimulus an, und berÃ¼cksichtigt die GrÃ¶sse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von ğŸ‘‰ OpenSesame. Ãœblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem ğŸ‘‰ Link mehr Information.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm fÃ¼r die Erstellung behavioraler Experimente."
  },
  {
    "objectID": "pages/chapters/reproducibility.html",
    "href": "pages/chapters/reproducibility.html",
    "title": "Reproducibility",
    "section": "",
    "text": "Die Replikationskrise hat in der Psychologie, aber auch in den kognitiven Neurowissenschaften ein Umdenken ausgelÃ¶st. Reproduzierbarkeit und Replizierbarkeit sind zu wichtigen Konzepten fÃ¼r nachhaltige Forschung geworden. Die Begriffe werden verwirrenderweise aber oft unterschiedlich definiert (Plesser (2018)).\n\nReplizierbarkeit\nReplizierbarkeit (replicability) bedeutet, dass ein Experiment von einer anderen Forschungsgruppe mit einer neuen Stichprobe durchgefÃ¼hrt werden kann, und Ã¤hnliche oder dieselben Resultate hervorbringt, wie die Originalstudie. Wird eine Studie mehrmals repliziert, steigt die Wahrscheinlichkeit, dass kein Zufallsbefund vorliegt.\n\nReplicability refers to the ability of a researcher to duplicate the results of a prior study if the same procedures are followed but new data are collected. Cacioppo et al. (2015)\n\n\n\nReproduzierbarkeit\nReproduzierbarkeit (reproducibility) hÃ¤ngt eng mit der Replizierbarkeit zusammen, ist aber nicht dasselbe. Der Begriff wird teilweise sehr allgemein verwendet, und bedeutet so dass Forschungsergebnisse wiederholt gefunden werden auch von anderen Forschenden mit neuen Stichproben.\nReproduzierbarkeit im engeren Sinn hingegen bezieht sich darauf, ob die durchgefÃ¼hrte Analyse wiederholt werden kann. Die Reproduzierbarkeit ist somit hoch, wenn Forschende die Daten und Datenanalyseskripts bereitstellen und andere Forschende damit dieselben Analysen durchfÃ¼hren kÃ¶nnen und zu gleichen Resultaten kommen.\n\nReproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator. That is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same resultsâ€¦. Reproducibility is a minimum necessary condition for a finding to be believable and informative. Cacioppo et al. (2015)\n\nUm die Begriffe zusammenzufassen schlugen Goodman, Fanelli, and Ionnidis (2016) vor von Reproduzierbarkeit der Methoden (Daten und Prozesse kÃ¶nnen exakt wiederholt werden), Reproduzierbarkeit der Resultate (andere Studien kommen auf dieselben Resultate) und Reproduzierbarkeit der wissenschaftlichen Schlussfolgerung (bei Repetition der Analyse oder der Experimente werden dieselben SchlÃ¼sse gezogen) zu sprechens.\nGrundsÃ¤tzlich besteht das Ziel, dass in der Forschung mÃ¶glichst viel Evidenz fÃ¼r eine Schlussfolgerung gesammelt werden kann. Dies gelingt, wenn die Prozesse transparent, fehlerfrei und wiederholbar sind.\n\n\nHindernisse bei der Reproduzierbarkeit\nReproduzierbarkeit kann laut Nosek et al. (2022) vor allem aus zwei GrÃ¼nden nicht gegeben sein: Weil die Daten/Skripte nicht zur VerfÃ¼gung stehen, oder weil diese Fehler enthalten:\n\nIn principle, all reported evidence should be reproducible. If someone applies the same analysis to the same data, the same result should occur. Reproducibility tests can fail for two reasons. A process reproducibility failure occurs when the original analysis cannot be repeated because of the unavailability of data, code, information needed to recreate the code, or necessary software or tools. An outcome reproducibility failure occurs when the reanalysis obtains a different result than the one reported originally. This can occur because of an error in either the original or the reproduction study.\n\nFÃ¼hrt die Reproduktion nicht zum selben Resultat, lÃ¶st das Zweifel am Forschungsergebnis aus. Wenn die Reproduzierbarkeit am Prozess scheitert, etwa weil die Daten nicht vorhanden sind, kann kein Schluss gezogen werden, ob die Resultate stimmen.\n\nAchieving reproducibility is a basic foundation of credibility, and yet many efforts to test reproducibility reveal success rates below 100%. â€¦ Whereas an outcome reproducibility failure suggests that the original result may be wrong, a process reproducibility failure merely indicates that the original result cannot be verified. Either reason challenges credibility and increases uncertainty about the value of investing additional resources to replicate or extend the findings (Nuijten et al.Â 2018). Sharing data and code reduces process reproducibility failures (Kidwell et al.Â 2016), which can reveal more outcome reproducibility failures (Hardwicke et al.Â 2018, 2021; Wicherts et al.Â 2011). Nosek et al. (2022)\n\nDas Teilen von Daten und Datenverarbeitungsskripten erhÃ¶ht die Wahrscheinlichkeit, dass mÃ¶gliche Fehler im Prozess gefunden werden, da auch andere Forschende die Daten/Skripts verwenden kÃ¶nnen. Das ist vorerst unangenehm, gehÃ¶rt aber zum Prozess der Wissenschaft dazu. Reproduzierbarkeit erhÃ¶ht also indirekt auch die Replizierbarkeit.\n\n\nTools fÃ¼r Reproduzierbarkeit\nFÃ¼r reproduzierbare Forschung gibt es inzwischen viele gute Tools:\n\nWebsite der Open Science Foundation: Eine kostenfreie und unkomplizierte MÃ¶glichkeit Daten und Skripts zu teilen, und diese in Projekten abzulegen. Es lÃ¤sst sich dafÃ¼r sogar ein doi erstellen. Auch Preregistrationsformulare sind hier implementiert.\n\nBeim VerÃ¶ffentlichen von wissenschaftlichen Artikeln ist es empfohlen, die Daten (falls anonymisiert mÃ¶glich) sowie die Analyseskripts mitzuverÃ¶ffentlichen.\n\nFÃ¼r DatensÃ¤tze gelten die FAIR Guiding Principles (Wilkinson et al. (2016)):\n\nF indability: Es ist klar unter welchen UmstÃ¤nden und wie die Daten zugÃ¤nglich sind\nA ccessibility: Daten sind zugÃ¤nglich bzw. es ist klar wo sie zu finden wÃ¤ren\nI nteroperability: Verwendbare Datenformate/strukturen\nR eusability: gute Beschreibung des Datensatzes/der enthaltenen Variablen\n\n\n\nHier finden Sie weitere Informationen zu FAIR.\n\n\nFÃ¼r Neuroimaging-Daten gibt es beispielsweise vorgegebene Konventionen, wie ein Datensatz und die Verarbeitungsskripts abgespeichert werden. Ein Beispiel dafÃ¼r ist Brain Imaging Data Structure (BIDS). So kÃ¶nnen DatensÃ¤tze mit einer fÃ¼r alle verstÃ¤ndlichen Struktur verÃ¶ffentlicht und geteilt werden.\n\n\nHier finden Sie weitere Informationen zu BIDS.\n\n\nFÃ¼r das VerÃ¶ffentlichen von Analyseskripts eignen sich Formate wie RMarkdown in R, oder LiveScripts in MATLAB sehr gut. Aber auch .r-Skripte, wie Sie sie in dieser Veranstaltung verwenden kÃ¶nnen verÃ¶ffentlicht werden.\n\n\nHier finden Sie eine sehr gut erklÃ¤rte EinfÃ¼hrung zu RMarkdown.\n\n\n\nCode kommentieren\nDas Teilen von Skripts macht am meisten Sinn, wenn sie verstÃ¤ndlich strukturiert und kommentiert sind. Beim Kommentieren von Code sollte folgendes beachtet werden:\n\nKommentare sollten geschrieben werden, wenn der Code erstellt wird und laufend Ã¼berarbeitet werden. Oft wird es sonst nicht nachgeholt.\nWenn man nicht genau kommentieren kann, was man im Code macht, dann ist evtl. der Code unklar, oder man versteht ihn noch nicht. Vielleicht kann man Variablennamen vereinfachen/prÃ¤zisieren und es braucht weniger Kommentare?\nWenn Code kopiert wird, sollte die Quelle angegeben werden.\nVor dem VerÃ¶ffentlichen, lohnt es sich jemanden den Code ausfÃ¼hren lassen. So zeigt sich wo noch unklare Stellen sind, die Kommentare benÃ¶tigen.\n\n\n\n\n\n\nReferences\n\nCacioppo, J. T., R. M. Kaplan, J. A. Krosnick, J. L. Olds, and H. Dean. 2015. â€œSocial, Behavioral, and Economic Sciences Perspectives on Robust and Reliable Science.â€ Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences.\n\n\nGoodman, Steven N., Daniele Fanelli, and John P. A. Ionnidis. 2016. â€œWhat Does Research Reproducibility Mean?â€ Science Translational Medicine 341. https://doi.org/10.1126/scitranslmed.aaf5027.\n\n\nNosek, Brian A, Tom E Hardwicke, Hannah Moshontz, AurÃ©lien Allard, Katherine S Corker, Anna Dreber, Fiona Fidler, et al. 2022. â€œReplicability, Robustness, and Reproducibility in Psychological Science.â€ Annual Review of Psychology 73: 719â€“48. https://doi.org/10.1146/annurev-psych-020821-114157.\n\n\nPlesser, Hans E. 2018. â€œReproducibility Vs. Replicability: A Brief History of a Confused Terminology.â€ Frontiers in Neuroinformatics 11 (January): 76. https://doi.org/10.3389/fninf.2017.00076.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. â€œThe FAIR Guiding Principles for Scientific Data Management and Stewardship.â€ Scientific Data 3 (1): 160018. https://doi.org/10.1038/sdata.2016.18.\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis2023,\n  author = {Ellis, Andrew and Wyssen, Gerda},\n  title = {Reproducibility},\n  date = {2023-03-20},\n  url = {https://kogpsy.github.io/neuroscicomplabFS23//pages/chapters/reproducibility.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nEllis, Andrew, and Gerda Wyssen. 2023. â€œReproducibility.â€\nMarch 20, 2023. https://kogpsy.github.io/neuroscicomplabFS23//pages/chapters/reproducibility.html."
  },
  {
    "objectID": "pages/chapters/software.html",
    "href": "pages/chapters/software.html",
    "title": "Programmiersprachen",
    "section": "",
    "text": "In diesem Kurs beschÃ¤ftigen wir uns im weiteren Sinne mit dem Einsatz vom Computern im Bereich Cognitive Neuroscience. Es ist nicht Ziel dieses Kurses, EEG oder fMRI Daten zu analysieren (dafÃ¼r gibt es eigene Kurse); wir werden uns stattdessen mit Daten aus Verhaltensexperimenten beschÃ¤ftigen. Dies sind zum Beispiel binÃ¤re Antworten oder Reaktionszeiten, welche wir mit entsprechenden Modellen untersuchen werden. Unsere Anwendungsbeispiele werden immer aus der neurowissenschaftlichen Forschung stammen; der Fokus wird aber vor allem der Umgang mit Computern sein. Unser Ziel ist es, dass Sie nach dem Abschluss dieses Kurses eine neurowissenschaftliches Paper lesen kÃ¶nnen, und die darin verwendeten Experimente nachvollziehen kÃ¶nnen. Sie kÃ¶nnten eventuell sogar das Experiment selber programmieren, und die Daten analysieren."
  },
  {
    "objectID": "pages/chapters/software.html#ziel-dieses-kurses",
    "href": "pages/chapters/software.html#ziel-dieses-kurses",
    "title": "Programmiersprachen",
    "section": "",
    "text": "In diesem Kurs beschÃ¤ftigen wir uns im weiteren Sinne mit dem Einsatz vom Computern im Bereich Cognitive Neuroscience. Es ist nicht Ziel dieses Kurses, EEG oder fMRI Daten zu analysieren (dafÃ¼r gibt es eigene Kurse); wir werden uns stattdessen mit Daten aus Verhaltensexperimenten beschÃ¤ftigen. Dies sind zum Beispiel binÃ¤re Antworten oder Reaktionszeiten, welche wir mit entsprechenden Modellen untersuchen werden. Unsere Anwendungsbeispiele werden immer aus der neurowissenschaftlichen Forschung stammen; der Fokus wird aber vor allem der Umgang mit Computern sein. Unser Ziel ist es, dass Sie nach dem Abschluss dieses Kurses eine neurowissenschaftliches Paper lesen kÃ¶nnen, und die darin verwendeten Experimente nachvollziehen kÃ¶nnen. Sie kÃ¶nnten eventuell sogar das Experiment selber programmieren, und die Daten analysieren."
  },
  {
    "objectID": "pages/chapters/software.html#programmiersprachen",
    "href": "pages/chapters/software.html#programmiersprachen",
    "title": "Programmiersprachen",
    "section": "Programmiersprachen",
    "text": "Programmiersprachen\nProgrammiersprachen sind essentielle Werkzeuge fÃ¼r die Neurowissenschaftliche Forschung. Wir werden uns zuerst einen kurzen Ãœberblick Ã¼ber drei hÃ¤ufig verwendete Programmiersprachen (Matlab, Python und R) verschaffen und kurz deren Verwendungszwecke und Vor- und Nachteile diskutieren.\n\nMatlab\nMatlab ist ein Software fÃ¼r numerische Anwendung, welche in den Ingenieurwissenschaften, Naturwissenschaften und der Mathematik weit verbreitet ist.\n\nğŸ‘ğŸ¼ StÃ¤rken:\n\nLeistungsstarke Matrix- und Vektoroperationen, gut geeignet fÃ¼r Matrix-basierte Operationen, die in der Neurowissenschaftlichen Forschung hÃ¤ufig vorkommen.\nUmfangreiche Bibliothek von integrierten Funktionen fÃ¼r wissenschaftliches Rechnen.\n\n\n\nğŸ‘ğŸ¼ SchwÃ¤chen:\n\nTeuer\nWeniger flexibel als Python oder R in Bezug auf Datenarten und Strukturen.\nMatlab is kommerziell und proprietÃ¤r. Dies bedeutet man muss teuere Lizenzen kaufen, und der Source Code der Software ist nicht offen.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nSignalverarbeitung\nVisualisierung\nViele fMRI Forscher arbeiten mit Matlab, da es dafÃ¼r eine spezielle Toolbox gibt: SPM\nExperimente programmieren, z.B. mit Psychtoolbox\n\n\n\nBeispielcode:\nload('data.mat')\nfs = 1000;\nt = (0:numel(data)-1)/fs;\nplot(t, data)\n\n\n\nPython\nPython ist eine allgemeine (general purpose) Programmiersprache, die in vielen verschiedenen Bereichen wie wissenschaftlichem Rechnen, Datenanalyse und maschinellem Lernen weit verbreitet ist.\n\nğŸ‘ğŸ¼ StÃ¤rken:\n\nEine Vielzahl von Bibliotheken und Modulen wie NumPy, SciPy und Pandas, die leistungsstarke Werkzeuge fÃ¼r wissenschaftliches Rechnen und Datenanalyse bieten.\nDatenanalysewerkzeuge wie Pandas-Dataframes, die Seaborn-Visualisierungsbibliothek, und Jupyter Notebooks.\nOpen-source und kostenlos\n\n\n\nğŸ‘ğŸ¼ SchwÃ¤chen:\n\nKann in einigen numerischen Berechnungen langsamer sein als Matlab.\nDa Python eine allgemeine Sprache ist, muss man fÃ¼r numerische Anwendungen immer verschiedene Packages importieren (z.B.) numpy, wenn man damit rechnen will. Dies fÃ¼hrt zu weniger gut lesbarem Code.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nVisualisierung\nMachine learning und KÃ¼nstliche Intelligenz\nExperimente programmieren, z.B. mit PsychoPy\n\n\n\nBeispielcode:\nimport pandas as pd\nimport seaborn as sns\ndata = pd.read_csv('data.csv')\nsns.lineplot(data=data, x='time', y='voltage')\n\n\n\nR\nR ist eine Programmiersprache und Umgebung fÃ¼r statistisches Rechnen und Grafiken.\n\nğŸ‘ğŸ¼ StÃ¤rken:\n\nEntwickelt von Statistikern fÃ¼r statistisches Rechnen und Grafiken.\nEine groÃŸe Bibliothek von statistischen Werkzeugen und Paketen, einschliesslich Visualisierungspackages (grammar of graphics).\nOpen-source und kostenlos\ntidyverse Packages fÃ¼r Data Wrangling (sehr elegante Syntax, um mit Daten zu arbeiten).\n\n\n\nğŸ‘ğŸ¼ SchwÃ¤chen:\n\nSteilere Lernkurve als Python.\nKann in einigen numerischen Berechnungen langsamer sein als Matlab oder Python.\nEntwickelt von Statistiker (nicht von Software Designers). R gilt als sehr idiosynkratisch.\n\n\n\nTypische Anwendung:\n\nStatistische Analyse\nDatenvisualisierung. R hat eine sehr gute Bibliothek fÃ¼r Grafiken, die ggplot2 Bibliothek. Diese Bibliothek verwendet die sogenannte grammar of graphics (GoG) - eine Methode, um Daten in Grafiken zu visualisieren. Die GoG ist eine sehr elegante und effiziente Methode, um Daten zu visualisieren.\n\n\n\nBeispielcode:\nlibrary(tidyverse)\ndata &lt;- read.csv('data.csv')\nggplot(data, aes(x=time, y=voltage)) + geom_line()\n\n\n\nFazit\nMatlab, Python und R sind leistungsstarke Werkzeuge fÃ¼r die neurowissenschaftliche Forschung. Die Wahl der Sprache hÃ¤ngt unter anderem von der spezifischen Aufgabe ab. Weitere Faktoren ist Tradition: bestimmte Gruppen bevorzugen eher eine Sprache als andere. So ist Matlab unter Ingenieuren weit verbreiten und R unter Statistikern. Python ist im Bereich KÃ¼nstliche Intelligenz und Machine Learning die beliebteste Sprache. Eine neuere Sprache ist Julia - diese vereint die Vorteile aller oben genannten Sprachen (ohne viele deren Nachteile), ist aber weniger weit verbreitet.\nUm mehr zu erfahren, erkunden Sie die umfangreichen Online-Ressourcen und Dokumentationen fÃ¼r jede Sprache."
  },
  {
    "objectID": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "href": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "title": "Programmiersprachen",
    "section": "In dieser Veranstaltung verwendete Software",
    "text": "In dieser Veranstaltung verwendete Software\nWir haben uns entschieden, in dieser Veranstaltung Python zu verwenden, um ein Experiment zu erstellen, und R fÃ¼r die Analyse der Daten. Matlab wird nicht verwendet; einerseits da es kommerziell ist, andererseits weil es aus unserer Sicht nicht die beste Wahl fÃ¼r die Analyse von Verhaltensdaten ist. Ausserdem ist es schon schwierig genug, eine Programmiersprache zu lernen, ohne gleichzeitig noch zwei weitere zu lernen."
  },
  {
    "objectID": "pages/chapters/software.html#python-1",
    "href": "pages/chapters/software.html#python-1",
    "title": "Programmiersprachen",
    "section": "Python",
    "text": "Python\nWenn Sie Python suf Ihrem Rechner installieren wollen, kÃ¶nnen Sie entweder den offiziellen Installer https://www.python.org/downloads/ downloaden, oder die Anaconda Distribution https://www.anaconda.com/products/distribution verwenden. Die Anaconda Distribution ist eine Python-Distribution, die viele nÃ¼tzliche Pakete enthÃ¤lt, die fÃ¼r wissenschaftliches Rechnen und Datenanalyse verwendet werden. Wenn man tatsÃ¤chlich mit Python arbeiten will, empfiehlt es sich, die Anaconda Distribution zu benutzen. Wir werden in dieser Veranstaltung Python benutzen, um ein Experiment zu programmieren. DafÃ¼r reicht es aus, den PsychoPy Installer zu verwenden; diesen finden Sie unter diesem Link: PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen BenutzeroberflÃ¤che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/chapters/software.html#r-1",
    "href": "pages/chapters/software.html#r-1",
    "title": "Programmiersprachen",
    "section": "R",
    "text": "R\nAb der vierten Sitzung werden wir viel mit R arbeiten, um Daten aufzubereiten und grafisch darzustellen. DafÃ¼r mÃ¼ssen Sie die aktuelle Version von R installieren. Diese ist zurzeit R 4.2.2, und kann unter folgender URL geladen werden:\nR ğŸ‘‰ https://cloud.r-project.org/\nWir empfehlen fÃ¼r die Arbeit mit R die RStudio IDE zu verwenden. Diese ist kostenlos und kann unter folgender URL heruntergeladen werden:\nRStudio ğŸ‘‰ https://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "pages/chapters/software.html#lernen",
    "href": "pages/chapters/software.html#lernen",
    "title": "Programmiersprachen",
    "section": "Lernen",
    "text": "Lernen\nDataCamp"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html",
    "href": "pages/chapters/summarizing-data.html",
    "title": "Aggregierte Statistiken",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nZusammenfassende Statistiken berechnen.\nIn within-subject Designs aggregierte Statistiken berechnen.\nStandardfehler berechnen, welche Messwiederholungen berÃ¼cksichtigen.\nWir haben in den vorherigen Kapiteln gesehen, wie wir Daten aus Verhaltensexperimenten in R einlesen und bearbeiten kÃ¶nnen. In diesem Kapitel werden wir uns mit der Frage beschÃ¤ftigen, wie wir zusammenfassende Statistiken erstellen kÃ¶nnen, um diese grafisch darzustellen und zu interpretieren. Da wir uns in den Neurowissenschaften meist mit within-subject Designs beschÃ¤ftigen, werden wir uns in diesem Kapitel auf Messwiederholungsdaten konzentrieren."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#individuell-fÃ¼r-jede-person-in-jeder-bedingung",
    "href": "pages/chapters/summarizing-data.html#individuell-fÃ¼r-jede-person-in-jeder-bedingung",
    "title": "Aggregierte Statistiken",
    "section": "Individuell fÃ¼r jede Person in jeder Bedingung",
    "text": "Individuell fÃ¼r jede Person in jeder Bedingung\n\naccuracy_individual &lt;- data |&gt;\n    group_by(ID, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(correct),\n        accuracy = mean(correct)\n    )\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\naccuracy_individual\n\n# A tibble: 27 Ã— 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   &lt;fct&gt; &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 JH    valid        64       60    0.938\n 2 JH    neutral      80       66    0.825\n 3 JH    invalid      16       13    0.812\n 4 NS    valid        64       58    0.906\n 5 NS    neutral      80       56    0.7  \n 6 NS    invalid      16       11    0.688\n 7 rh    valid        64       61    0.953\n 8 rh    neutral      80       64    0.8  \n 9 rh    invalid      16        2    0.125\n10 sb    valid        64       62    0.969\n# â€¦ with 17 more rows\n\n\n\naccuracy_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per person/condition\") +\n  facet_wrap(~ID) +\n  theme_linedraw(base_size = 14) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-bedingung-Ã¼ber-alle-personen-aggregiert",
    "href": "pages/chapters/summarizing-data.html#pro-bedingung-Ã¼ber-alle-personen-aggregiert",
    "title": "Aggregierte Statistiken",
    "section": "Pro Bedingung, Ã¼ber alle Personen aggregiert",
    "text": "Pro Bedingung, Ã¼ber alle Personen aggregiert\n\naccuracy_aggregated &lt;- data |&gt;\n    group_by(condition) |&gt;\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\naccuracy_aggregated\n\n# A tibble: 3 Ã— 4\n  condition     N ncorrect accuracy\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 valid       576      475    0.825\n2 neutral     720      453    0.629\n3 invalid     144       56    0.389\n\n\n\naccuracy_aggregated |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = 1), linewidth = 2) +\n  geom_point(size = 4) +\n  scale_fill_manual(values = c(invalid = \"#9E0142\",\n                    neutral = \"#C4C4B7\",\n                    valid = \"#2EC762\")) +\n  labs(x = \"Cue\",\n      y = \"Proportion correct\",\n      title = \"Accuracy per condition\") +\n  theme_linedraw(base_size = 14) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nHands-on\n\n\n\nWir beurteilen Sie die beiden obenstehenden Plots. Was fÃ¤llt Ihnen auf? Sind die Mittelwerte aussagekrÃ¤ftig?\n\n\n\n\n\n\n\n\nLÃ¶sung\n\n\n\n\n\nEs fehlt eine Darstellung der Unsicherheit, die wir in der SchÃ¤tzung des Mittelwerts haben."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#standardfehler",
    "href": "pages/chapters/summarizing-data.html#standardfehler",
    "title": "Aggregierte Statistiken",
    "section": "Standardfehler",
    "text": "Standardfehler\nWir wollen wir nicht mehr nur den Mittelwert betrachten, sondern auch die Standardabweichung und den Standardfehler. Letzteres ist eine Mass fÃ¼r die Unsicherheit, die wir in der SchÃ¤tzung des Mittelwerts haben. Leider gibt es keine Funktion in R, die uns den Standardfehler berechnet. Der Standardfehler ist definiert als die Standardabweichung geteilt durch die Wurzel aus der Anzahl der Datenpunkte: \\[SE = sd/ \\sqrt{n}\\].\nWir kÃ¶nnen eine solche Funktion einfach selber definieren. sd() berechnet die Standardabweichung eines Vektors, und die Anzahl Datenpunkte ist die LÃ¤nge des Vektors (length()), den wir als Argument Ã¼bergeben.\n\nse &lt;- function(x) {\n  sd(x) / sqrt(length(x))\n}"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#aggregierte-accuracy-mit-standardfehler",
    "href": "pages/chapters/summarizing-data.html#aggregierte-accuracy-mit-standardfehler",
    "title": "Aggregierte Statistiken",
    "section": "Aggregierte Accuracy mit Standardfehler",
    "text": "Aggregierte Accuracy mit Standardfehler\nEine MÃ¶glichkeit wÃ¤re, die Anzahl korrekter Entscheidungen in jeder Bedingung insgesamt, d.h. Ã¼ber alle Personen aggregiert, zu berechnen. Wir berechnen dabei den Standardfehler des Mittelwertes um ein Mass fÃ¼r die Unsicherheit zu enthalten, mit der wir die Mittelwerte schÃ¤tzen kÃ¶nnen.\n\ndata |&gt;\n    group_by(condition) |&gt;\n            summarise(\n                  n = n(),\n                  ncorrect = sum(correct),\n                  accuracy = mean(correct),\n                  se = se(correct)\n            )\n\n# A tibble: 3 Ã— 5\n  condition     n ncorrect accuracy     se\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 valid       576      475    0.825 0.0159\n2 neutral     720      453    0.629 0.0180\n3 invalid     144       56    0.389 0.0408\n\n\n\n\n\n\n\n\nHands-on\n\n\n\n\nWas sagen uns diese Kennzahlen?\nWelche Informationen gehen dabei verloren?\nÃœberlegen Sie sich, was wir genau berechnet haben.\n\n\n\n\n\n\n\n\n\nEin Exkurs Ã¼ber within-person Standardfehler\n\n\n\n\n\nFolgender Code erstellt einen Dataframe mit 10 Personen, die jeweils zu zwei Messzeitpunkten getestet werden. Es handelt sich also um ein within-subject Design.\n\nlibrary(tidyverse)\n\ndfw &lt;- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |&gt;\n    mutate(subject = as_factor(subject))\n\nDer Dataframe ist im wide Format â€“ um die Daten zu analysieren, ist das long Format besser geeignet. Wir konvertieren vom wide ins long Format mit der Funktion pivot_longer().\n\ndfw\n\n# A tibble: 10 Ã— 3\n   subject pretest posttest\n   &lt;fct&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 1          59.4     64.5\n 2 2          46.4     52.4\n 3 3          46       49.7\n 4 4          49       48.7\n 5 5          32.5     37.4\n 6 6          45.2     49.5\n 7 7          60.3     59.9\n 8 8          54.3     54.1\n 9 9          45.4     49.6\n10 10         38.9     48.5\n\n\n\ndfl &lt;- dfw |&gt;\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |&gt;\n    mutate(condition = as_factor(condition))\n\n\ndfl\n\n# A tibble: 20 Ã— 3\n   subject condition value\n   &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;\n 1 1       pretest    59.4\n 2 1       posttest   64.5\n 3 2       pretest    46.4\n 4 2       posttest   52.4\n 5 3       pretest    46  \n 6 3       posttest   49.7\n 7 4       pretest    49  \n 8 4       posttest   48.7\n 9 5       pretest    32.5\n10 5       posttest   37.4\n11 6       pretest    45.2\n12 6       posttest   49.5\n13 7       pretest    60.3\n14 7       posttest   59.9\n15 8       pretest    54.3\n16 8       posttest   54.1\n17 9       pretest    45.4\n18 9       posttest   49.6\n19 10      pretest    38.9\n20 10      posttest   48.5\n\n\nWas uns hier interessiert ist vor allem die â€œVerbesserungâ€ jeder Person vom ersten zum zweiten Messzeitpunkt. Diese kÃ¶nnen wir grafisch darstellen.\n\n# Use a consistent y range\nymax &lt;- max(dfl$value)\nymin &lt;- min(dfl$value)\n\n\n# Plot the individuals\ndfl |&gt;\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWir stellen fest, dass fast jede Person zum zweiten Messzeitpunkt einen hÃ¶heren Wert als beim ersten aufweist. Gleichzeitig gibt es aber auch erhebliche Unterschiede zwischen den Personen in Bezug auf ihren Anfangswert. Diese interindividuellen Unterschiede sind aber hier nicht von Interesse. Wir kÃ¶nnen davon ausgehen, dass diese Unterschiede auf â€œstabileâ€ Eigenschaften der Personen zurÃ¼ckzufÃ¼hren sind. Die Personen sind also eine Quelle der VariabilitÃ¤t, die unsere Fragestellung â€œstÃ¶rtâ€ - diese lautet: wie ist die Ã„nderung zwischen den beiden Zeitpunkten?\nWir kÃ¶nnen so tun, als ob der Messzeitpunkt eine between-subject Variable wÃ¤re. In diesem Fall wÃ¼rden wir die Standardfehler wie folgt berechnen.\n\ndflsum_between_1 &lt;- dfl |&gt;\n    group_by(condition) |&gt;\n    summarize(\n        mean = mean(value),\n        se = se(value)\n    )\n\ndflsum_between_1\n\n# A tibble: 2 Ã— 3\n  condition  mean    se\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 pretest    47.7  2.72\n2 posttest   51.4  2.29\n\n\nEine Alternative dazu bietet die Funktion summarySE() aus dem Rmisc Package.\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between &lt;- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\nDIe Fehlerbalken im folgenden Plot berÃ¼cksichtigen folgendermassen nicht die Tatsachen, dass ein grosser Anteil der VariabilitÃ¤t auf â€œstabileâ€ Personenunterschiede zurÃ¼ckzufÃ¼hren ist. In diesem Fall sind die â€œerrorbarsâ€ sehr gross, und es sieht so aus, als ob es keinen feststellbaren Unterschied zwischen den Zeitpunkten gibt. Wir vermuten aber aufgrund der individuellen Grafiken, dass es sehr wohl einen Unterschied gibt.\n\ndflsum_between |&gt;\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWenn wir nur die Unterschiede zwischen den Personen berÃ¼cksichtigen kÃ¶nnten, hÃ¤tten wir in diesem Fall kleinere Standardfehler, da wir sozusagen die PersonenvariabilitÃ¤t subtrahieren kÃ¶nnen.\nIm Rmisc Package gibt es eine solche Funktion: mit summarySEwithin() kÃ¶nnen wir korrekt Standardfehler in within-subject Designs berechnen.\n\ndflsum &lt;- dfl |&gt;\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\nDie resultierenden Fehlerbalken sind nun kleiner.\n\ndflsum |&gt;\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60) +\n    ggtitle(\"Correct within standard errors\")\n\n\n\n\nWenn wir beide Varianten zusammen darstellen, wird der Unterschiedlich offentsichtlich. In dieser Grafik sind die between Standardfehler in rot eingezeichnet; die within Standardfehler sind in schwarz.\n\ndflsum_between |&gt;\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"black\", data = dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nWas wir hier machen ist eigentlich einfach. Um die within Standardfehler zu berechnen, mÃ¼ssen wir zuerst die personen-spezifische Mittelwerte von den Daten subtrahieren. Dies kÃ¶nnen wir mit der Funktion normDataWithin() machen.\n\ndfNorm_long &lt;- Rmisc::normDataWithin(data=dfl, \n                                     idvar=\"subject\",    \n                                     measurevar=\"value\")\ndfNorm_long\n\n   subject condition value valueNormed\n1        1   pretest  59.4      47.035\n2        1  posttest  64.5      52.135\n3       10   pretest  38.9      44.785\n4       10  posttest  48.5      54.385\n5        2   pretest  46.4      46.585\n6        2  posttest  52.4      52.585\n7        3   pretest  46.0      47.735\n8        3  posttest  49.7      51.435\n9        4   pretest  49.0      49.735\n10       4  posttest  48.7      49.435\n11       5   pretest  32.5      47.135\n12       5  posttest  37.4      52.035\n13       6   pretest  45.2      47.435\n14       6  posttest  49.5      51.735\n15       7   pretest  60.3      49.785\n16       7  posttest  59.9      49.385\n17       8   pretest  54.3      49.685\n18       8  posttest  54.1      49.485\n19       9   pretest  45.4      47.485\n20       9  posttest  49.6      51.685\n\n\nWenn wir nun die â€œnormiertenâ€ Daten plotten, sind die Unterschiede zwischen den Personen â€œverschwundenâ€, weil wir eben die Daten normiert haben.\n\ndfNorm_long |&gt;\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\nDie Argumente der Funktion summarySEwithin() sind folgende:\n\n\nmeasurevar: die outcome` Variable\n\nwithinvars: eine o(oder mehrere) within-subject Variablen\n\nidvar: die Gruppierungsvariable der within-subject Variablen (Versuchsperson)\n\nna.rm: sollen fehlende Werte ignoriert werden?\n\n\nconf.interval: der gewÃ¼nschte Konfidenzintervall (default: 0.95)\n\nIm Output erhalten wir die Mittelwerte der outcome Variablen fÃ¼r jede Stufe der within-Variable, sowie Standardabweichungen, Standardfehler und Konfidenzintervalle.\n\ndflsum &lt;- dfl |&gt;\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\nZum Vergleich: die Berechnung der Standardfehler in dflsum berÃ¼cksichtigt die Tatsache, dass Personen sich von Anfang an unterscheiden, und subtrahiert von jedem Datenpunkt den Mittelwert der Person.\n\ndflsum\n\n  condition  N value       sd        se       ci\n1   pretest 10 47.74 2.262361 0.7154214 1.618396\n2  posttest 10 51.43 2.262361 0.7154214 1.618396\n\n\nBei der Berechnung der Standardfehler in dflsum_between haben wir im Prinzip so getan, als seien die Messzeitpunkte unabhÃ¤ngig voneinander. Wir haben also die Standardfehler in dflsum_between so berechnet, als ob wir die Daten in zwei unabhÃ¤ngige Gruppen aufgeteilt hÃ¤tten.\n\ndflsum_between\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#accuracy-mit-within-person-standardfehler",
    "href": "pages/chapters/summarizing-data.html#accuracy-mit-within-person-standardfehler",
    "title": "Aggregierte Statistiken",
    "section": "Accuracy mit within-person Standardfehler",
    "text": "Accuracy mit within-person Standardfehler\nWir kÃ¶nnen nun dieses Prinzip auf unsere RDK daten anwenden. Die messwiederholte Variable ist nun nicht mehr der Messzeitunkt, sondern die cue-Bedingung, und die outcome Variable ist accuracy, also die Proportion korrekter Antworten.\n\naccuracy_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nAuch hier stellen wir fest, dass es scheinbar einen Trend gibt, dass die Proportion korrekter Antworten in der valid Bedingung hoch, und in der invalid Bedingung niedrig ist. In der neutral Bedingung liegt die accuracy dazwischen.\nOhne BerÃ¼cksichtigung der Messwiederholungen erhalten wir folgende Standarfehler:\nVon Hand berechnet:\n\ndatasum &lt;- data |&gt;\n   group_by(condition) |&gt; \n   summarise(N = n(),\n             accuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n# A tibble: 3 Ã— 5\n  condition     N accuracy    sd     se\n  &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 valid       576    0.825 0.381 0.0159\n2 neutral     720    0.629 0.483 0.0180\n3 invalid     144    0.389 0.489 0.0408\n\n\nMit der Funktion summarySE():\n\ndatasum_2 &lt;- data |&gt;\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n  condition   N   correct        sd         se         ci\n1     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n\n\nWenn wir nun die within Standardfehler berechnen, erhalten wir folgende Ergebnisse:\n\ndatasum_3 &lt;- data |&gt;\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n  condition   N   correct        sd         se         ci\n1     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n\n\n\np_accuracy &lt;- datasum_3 |&gt;\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-versuchsperson",
    "href": "pages/chapters/summarizing-data.html#pro-versuchsperson",
    "title": "Aggregierte Statistiken",
    "section": "Pro Versuchsperson",
    "text": "Pro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und Standarabweichung zusammen. Wenn wir Daten anhand mehrerer statistischer Kennzahlen zusammenfassen mÃ¶chten, kÃ¶nnen wir dies entweder manuell machen, oder die Funktion across() verwenden.\nEinfachere Version:\n\nby_subj &lt;- data |&gt; \n  drop_na(rt) |&gt; \n  group_by(ID, condition) |&gt;  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\nKomplizierte Version:\n\nfuns &lt;- list(mean = mean, median = median, sd = sd, se = se)\n\nby_subj &lt;- data %&gt;%\n  drop_na(rt) |&gt; \n  group_by(ID, condition) %&gt;% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\nby_subj \n\n# A tibble: 27 Ã— 6\n# Groups:   ID [9]\n   ID    condition  mean median     sd      se\n   &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 JH    valid     0.696  0.658 0.190  0.0240 \n 2 JH    neutral   0.799  0.733 0.202  0.0226 \n 3 JH    invalid   0.775  0.739 0.163  0.0421 \n 4 NS    valid     0.738  0.715 0.191  0.0240 \n 5 NS    neutral   0.885  0.844 0.201  0.0226 \n 6 NS    invalid   0.894  0.913 0.207  0.0518 \n 7 rh    valid     0.443  0.390 0.185  0.0233 \n 8 rh    neutral   0.525  0.503 0.0841 0.00941\n 9 rh    invalid   0.423  0.389 0.151  0.0378 \n10 sb    valid     0.386  0.349 0.175  0.0218 \n# â€¦ with 17 more rows\n\n\n\nby_subj |&gt; \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), linewidth = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\nWir kÃ¶nnen selbstverstÃ¤ndlich auch die indivuellen mittleren Reaktionszeiten mit Standardfehler plotten:\n\nby_subj |&gt; \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#Ã¼ber-versuchsperson-aggregiert",
    "href": "pages/chapters/summarizing-data.html#Ã¼ber-versuchsperson-aggregiert",
    "title": "Aggregierte Statistiken",
    "section": "Ãœber Versuchsperson aggregiert",
    "text": "Ãœber Versuchsperson aggregiert\n\nrtsum &lt;- data |&gt;\n  drop_na(rt) |&gt; \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n  condition   N        rt        sd         se         ci\n1     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n\n\n\np_rt &lt;- rtsum |&gt;\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\np_rt\n\n\n\n\nWir haben oben die beiden Grafiken als Variablen p_accuracy und p_rt gespeichert. Nun kÃ¶nnen wir diese Grafiken mit dem patchwork Package kombinieren.\npatchwork muss zuerst installiert werden: install.packages(\"patchwork\")\n\nlibrary(patchwork)\n\n\np_accuracy / p_rt"
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html",
    "href": "pages/chapters/uebung_1_experiment.html",
    "title": "Ãœbung 1",
    "section": "",
    "text": "In dieser Ãœbung fÃ¼hren Sie mit zwei Personen das Random Dot Experiment durch und laden die DatensÃ¤tze hoch. In dieser Ãœbung gibt es kein Peer Feedback. Die erhobenen Daten werden wir dann in den kommenden Sitzungen verwenden."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#random-dot-experiment-durchfÃ¼hren",
    "href": "pages/chapters/uebung_1_experiment.html#random-dot-experiment-durchfÃ¼hren",
    "title": "Ãœbung 1",
    "section": "Random Dot Experiment durchfÃ¼hren",
    "text": "Random Dot Experiment durchfÃ¼hren\n\nDas fertige Experiment befindet sich auf Github. Sie kÃ¶nnen es unter diesem Link downloaden. (Wenn Sie auf den grÃ¼nen Button Code klicken, kann man das Experiment als Zip-Datei herunterladen: Download ZIP)\nFÃ¼hren Sie das Experiment ein- oder mehrere Male selber durch. Kontrollieren Sie, ob ein Datensatz gespeichert wird.\nTesten Sie zwei Personen (Alter zwischen 20 und 60 Jahre). Diese Personen sollten die Hypothese nicht kennen (also keine Mitstudierende aus dem ComputerLab)."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#datenabgabe",
    "href": "pages/chapters/uebung_1_experiment.html#datenabgabe",
    "title": "Ãœbung 1",
    "section": "Datenabgabe",
    "text": "Datenabgabe\n\nDaten abgeben: Zippen Sie bitte die .csv-DatensÃ¤tze der getesteten Personen (nicht von den Selbsttests) und laden Sie das ZIP File bis in 10 Tagen auf ILIAS."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#trouble-shooting",
    "href": "pages/chapters/uebung_1_experiment.html#trouble-shooting",
    "title": "Ãœbung 1",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nBitte Fehlermeldung im Fenster genau durchlesen. Dort finden Sie Hinweise darauf, was schief gelaufen ist.\nDas Experiment startet nicht.\n\nUnter Einstellungen (Radsymbol) den Reiter Basic auswÃ¤hlen. Bei Use PsychoPy version die laufende PsychoPy Version auswÃ¤hlen (z.B. 2022.2.5).\n\nDas Experiment startet zwar, der Bildschirm ist aber dann einfach fÃ¼r eine kurze Zeit grau und das Fenster schliesst sich wieder.\n\nZugriffsrechte gegeben?\nUnter Einstellungen (Radsymbol) den Reiter Input auswÃ¤hlen. Keyboard Backend auf PsychToolbox statt ioHub."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html",
    "href": "pages/chapters/uebung_2_data_wrangling.html",
    "title": "Ãœbung 2",
    "section": "",
    "text": "Die Ãœbung 2 besteht aus den zwei folgenden Aufgaben:\n1. Skript erstellen und ausfÃ¼hren: In diesem Skript werden die Daten unseres PsychoPy-Experiments eingelesen, Variablen erstellt und erste Werte berechnet. Das Skript muss von einer anderen Person ausgefÃ¼hrt werden kÃ¶nnen (Reproduzierbarkeit) und gut kommentiert sein. Zeit: 1 Woche.\n2. Peer Feedback: Mittels Ilias wird Ihnen ein Skript einer anderen Person zugeordnet. Ihr Auftrag ist es, dieses Skript auszufÃ¼hren und dazu Feedback zu geben. Zeit: 1 Woche."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung",
    "href": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung",
    "title": "Ãœbung 2",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nLaden Sie zuerst das RStudio Projekt fÃ¼r Ãœbung 2 herunter. Dieses muss â€œentzipptâ€ werden. In dem Projektordner finden Sie den Ordner data. Darin befinden sich alle DatensÃ¤tze des PsychoPy Experiments. Das Projekt kann durch einen Doppelklick auf das Projekt-File uebung-2.Rproj geÃ¶ffnet werden.\n\n\n\n\n\n\n\nWichtig\n\n\n\nğŸ‘‰ RStudio Projekt fÃ¼r Ãœbung 2 herunterladen\n\n\n\nProjekte ermÃ¶glichen, relative Pfade. So stellen wir sicher, dass andere Personen, die dieses Projekt Ã¶ffnen, dieses File auch sehen und ausfÃ¼hren kÃ¶nnen.\n\n\nÃ–ffnen Sie das File uebung-2_script.r. Dieses File kÃ¶nnen Sie genau so verwenden und nach Bearbeitung speichern. FÃ¼gen Sie dem Filenamen Ihre Initialen an, das kÃ¶nnte dann so aussehen: uebung-2_script_gw.r.\n\n\nPraktischer ist es mit RMarkdown zu arbeiten. Das werden wir in den nÃ¤chsten Wochen lernen. DafÃ¼r eignen sich z.B. .qmd-Files. Hier kann fÃ¼r Text die Markdown-Syntax verwendet werden, und der Code wird in Code-Blocks geschrieben."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#kommentare-code",
    "href": "pages/chapters/uebung_2_data_wrangling.html#kommentare-code",
    "title": "Ãœbung 2",
    "section": "Kommentare & Code",
    "text": "Kommentare & Code\n\nKommentare werden mit #davor gekennzeichnet, so weiss R, dass dies Text und nicht ausfÃ¼hrbarer Code ist. Verwenden Sie also vor jedem Kommentar am Anfang der Zeile ein #.\nKommentieren Sie mit knappen, genauen Angaben. So weiss Ihr Peer Reviewer, was das Skript machen wird und was das Ziel des Codes ist."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#aufgaben",
    "href": "pages/chapters/uebung_2_data_wrangling.html#aufgaben",
    "title": "Ãœbung 2",
    "section": "Aufgaben",
    "text": "Aufgaben\n\nGehen Sie das Skript durch. Das Skript enthÃ¤lt ein â€œGerÃ¼stâ€ an Code, mit dem Sie arbeiten kÃ¶nnen. Sie kÃ¶nnen auch den Code der Website Ã¼bernehmen und etwas anpassen, wenn nÃ¶tig. Ãœberall wo ___ steht, mÃ¼ssen Sie das Fehlende einfÃ¼gen. Manchmal ist das ein Kommentar. Manchmal ist es ein CodestÃ¼ck.\nSie finden hier Infos dazu, wie die Daten bearbeitet werden kÃ¶nnen."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#reproduzierbar-machen",
    "href": "pages/chapters/uebung_2_data_wrangling.html#reproduzierbar-machen",
    "title": "Ãœbung 2",
    "section": "Reproduzierbar machen",
    "text": "Reproduzierbar machen\nSobald Sie den Code und die Kommentare ergÃ¤nzt haben, ist es wichtig, das Skript auf seine Reproduzierbarkeit zu testen.\n\nLÃ¶schen Sie die Variablen im Workspace. Verwenden Sie dazu z.B. das â€œBesenâ€-Icon unter Environment oder nutzen Sie unter dem Reiter Session den Befehl Clear Workspace. FÃ¼hren Sie danach das Skript nochmals von oben bis unten aus.\nPrÃ¼fen Sie, ob alle Pfade relativ, also nicht an Ihren Rechner gebunden sind.\nPrÃ¼fen Sie, ob alles gut und verstÃ¤ndlich kommentiert ist.\nPrÃ¼fen Sie, ob Sie die 3 Werte fÃ¼r Accuracy pro Bedingung (fÃ¼r valide, invalide und neutral) als Kommentar in das Skript geschrieben haben."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#hochladen",
    "href": "pages/chapters/uebung_2_data_wrangling.html#hochladen",
    "title": "Ãœbung 2",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie das uebung-2_script_initialen.r - Skript auf Ilias hoch."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung-1",
    "href": "pages/chapters/uebung_2_data_wrangling.html#vorbereitung-1",
    "title": "Ãœbung 2",
    "section": "Vorbereitung",
    "text": "Vorbereitung\n\nLesen Sie hier die Peer Feedback-GrundsÃ¤tze durch.\nLaden Sie das Ihnen zugeordnete .r-Skript herunter und speichern Sie es in Ihr R-Projektordner, wo sich auch das Projekt-File uebung-2.Rproj und Ihr eigenens .r-Skript befindet.\nÃ–ffnen Sie das Projekt. LÃ¶schen Sie alle gespeicherten Variablen im Workspace. Verwenden Sie dazu z.B. das â€œBesenâ€-Icon unter Environment oder nutzen Sie unter dem Reiter Session den Befehl Clear Workspace."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#fragen-fÃ¼r-peer-review",
    "href": "pages/chapters/uebung_2_data_wrangling.html#fragen-fÃ¼r-peer-review",
    "title": "Ãœbung 2",
    "section": "Fragen fÃ¼r Peer Review",
    "text": "Fragen fÃ¼r Peer Review\nÃ–ffnen Sie das .r-Skript und fÃ¼hren Sie es von oben bis unten aus und schreiben Sie zu folgenden Punkten eine RÃ¼ckmeldung in ein Word/Text-File.\n1. Reproduzierbarkeit des Codes\n\nIst das Skript ausfÃ¼hrbar?\nWenn nein: Wo genau gibt es eine Fehlermeldung, weshalb kommt diese und wie kÃ¶nnte diese behoben werden?\nStimmen die 3 Accuracy pro Bedingung - Werte mit den im Kommentar beschriebenen Werten Ã¼berein?\nStimmen die Werte mit den von Ihnen selber errechneten Werten Ã¼berein?\n\n2. Kommentierung/Implementierung des Codes\n\nGeben Sie mit mind. 5 SÃ¤tzen RÃ¼ckmeldung zum .r-Skript. MÃ¶gliche Themen kÃ¶nnten z.B. sein: War der Code angemessen kommentiert? Was war gut? Was hÃ¤tte man besser machen kÃ¶nnen? Sind Ihnen an den Daten Ã¤hnliche Dinge aufgefallen? Haben Sie etwas gelernt von dem gereviewten Skript? Oder haben Sie etwas besser gelÃ¶st gehabt in Ihrem Skript? Haben Sie VorschlÃ¤ge? usw."
  },
  {
    "objectID": "pages/chapters/uebung_2_data_wrangling.html#hochladen-1",
    "href": "pages/chapters/uebung_2_data_wrangling.html#hochladen-1",
    "title": "Ãœbung 2",
    "section": "Hochladen",
    "text": "Hochladen\nLaden Sie Ihr Peer Review anschliessend als Word/Text-File auf Ilias hoch."
  },
  {
    "objectID": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "href": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "title": "1. Sitzung",
    "section": "(Model-based) Cognitive Neuroscience",
    "text": "(Model-based) Cognitive Neuroscience\n\n\nWas heisst Model-based Neuroscience?\nWelche Kenntnisse brauchen wir, um Experiment durchzufÃ¼hren und Daten auszuwerten?\nWelche Programmiertechniken/sprachen brauchen wir?"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "href": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience: Beispiel",
    "text": "Model-based Neuroscience: Beispiel\nMulder, M. J., Wagenmakers, E.-J., Ratcliff, R., Boekel, W., & Forstmann, B. U. (2012). Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff. Journal of Neuroscience, 32(7), 2335â€“2343.\nğŸ‘‰ https://www.jneurosci.org/content/32/7/2335\nIn dieser Studie geht es darum, den Einfluss von Vorwissen (prior knowledge) auf eine simple perzeptuelle Entscheidung zu untersuchen.\n\nAls Task haben die Autoren ein Random Dot Motion Experiment benutzt.\nFÃ¼r die Datenanalyse wurde unter anderem ein Diffusion Decision Model verwendet."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model",
    "href": "slides/01_introduction.html#diffusion-decision-model",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience",
    "href": "slides/01_introduction.html#model-based-neuroscience",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\nÃœberfliegen Sie das Paper, und achten Sie dabei darauf, welche Skills Sie benÃ¶tigen, um eine solche Studie durchzufÃ¼hren.\n\nWelches theoretische Wissen brauchen Sie?\nWelche Programmierkenntnisse brauchen Sie?\n\nfÃ¼r das Experiment\nfÃ¼r die Datenanalyse\n\nWelche statistischen Verfahen brauchen Sie, um die Daten auszuwerten?\nWarum wurde das Experiment im Scanner und ausserhalb des Scanners durchgefÃ¼hrt?\nWas kann man mit einer solchen Studie herausfinden?"
  },
  {
    "objectID": "slides/01_introduction.html#vorwissen",
    "href": "slides/01_introduction.html#vorwissen",
    "title": "1. Sitzung",
    "section": "Vorwissen",
    "text": "Vorwissen\nEs wurden zwei verschiedene Typen von Vorwissen benutzt.\n\nA-Priori Wahrscheinlichkeit, dass die Punktwolke sich nach rechts oder nach links bewegte.\nAsymmetrische Belohnung fÃ¼r korrekte links/rechts Entscheidungen."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model-1",
    "href": "slides/01_introduction.html#diffusion-decision-model-1",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-1",
    "href": "slides/01_introduction.html#model-based-neuroscience-1",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\n\nSchematische Darstellung der erwarteten Resultate.\n\nStarting point: korrekte und inkorrekte RTs unterschieden sich.\nDrift rate: korrekte und inkorrekte RTs sind sich Ã¤hnlich.\n\n\n\nTatsÃ¤chliche Resultate: Quantifizierung des Bias anhand des DDM."
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-2",
    "href": "slides/01_introduction.html#model-based-neuroscience-2",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\nBOLD Responses der Areale welche besonder stark sowohl auf die â€œprior probabilityâ€ als auch auf die â€œpayoffâ€ Manipulation reagierten.\n\n\n\nright MedFG (right medial frontal gyrus)\nACG (anterior cingulate cortex)\nSFG (superior frontal gyrus)\nleft middle temporal gyrus\nIPS (intra-parietal sulcus).\n\n\n\n\n\nDiese Areale sollen eine besondere Rolle in der Verarbeitung von Bias im Entscheidungsverhalten haben."
  },
  {
    "objectID": "slides/01_introduction.html#wichtige-skills",
    "href": "slides/01_introduction.html#wichtige-skills",
    "title": "1. Sitzung",
    "section": "Wichtige Skills",
    "text": "Wichtige Skills\n\n\n\nTheorien Ã¼ber Entscheidungsverhalten\nExperimente programmieren\n\nTiming (inside/outside scanner)\n\nData cleaning and manipulation (data wrangling)\nStatistische Verfahren fÃ¼r messwiederholte Daten\n\nPsychometric curve\nBinary choices / Reaktionszeiten\nrepeated-measures ANOVA\n\n\n\n\nGrafische Darstellung der Resultate\nKognitive Prozessmodelle\n\nfit Diffusion Decision Model (DDM)\n\nAuswertung von fRMI Daten\n\n\n\n\nMit diesen Themen (ausser der Analyse von fMRI Daten) beschÃ¤ftigen wir uns in diesem Kurs.\n\n\n\nğŸ  Neurowissenschaft im Computerlab FS22"
  },
  {
    "objectID": "slides/02_psychopy.html#bias-rdk-experiment",
    "href": "slides/02_psychopy.html#bias-rdk-experiment",
    "title": "2. Sitzung",
    "section": "Bias RDK Experiment",
    "text": "Bias RDK Experiment\n\n\n\nRandom-dot motion direction-discrimination task\nInside/outside scanner (timing)\nBias: cue (probability left/right/unbiased)\nFixation cross\nRDK: 3x3 pixels, coherence\n40 bias trials, 40 neutral trials\n32 valid, 8 invalid trials"
  },
  {
    "objectID": "slides/02_psychopy.html#psychopy",
    "href": "slides/02_psychopy.html#psychopy",
    "title": "2. Sitzung",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy.html#pavlovia",
    "href": "slides/02_psychopy.html#pavlovia",
    "title": "2. Sitzung",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy.html#understanding-your-computer",
    "href": "slides/02_psychopy.html#understanding-your-computer",
    "title": "2. Sitzung",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: VariabilitÃ¤t ~15 ms.\nScreen refresh fÃ¤ngt oben an und endet (~10 ms spÃ¤ter) unten."
  },
  {
    "objectID": "slides/02_psychopy.html#probieren-sie-es-selber",
    "href": "slides/02_psychopy.html#probieren-sie-es-selber",
    "title": "2. Sitzung",
    "section": "Probieren Sie es selber!",
    "text": "Probieren Sie es selber!\n\nVersuchen Sie selber, Teile des Experiments in PsychoPy zu implementieren\n\n\nWenn Sie eine Starthilfe benÃ¶tigen, downloaden Sie ein Beipiel: ğŸ‘‰ Practice Trials\nEine EinfÃ¼hrung finden Sie hier: ğŸ‘‰ Verhaltensexperiment mit PsychoPy\n\n\n\n\nğŸ  Neurowissenschaft im Computerlab FS23"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#perceptual-decisions",
    "href": "slides/02_psychopy_gw.html#perceptual-decisions",
    "title": "PsychoPy Experiment",
    "section": "Perceptual decisions",
    "text": "Perceptual decisions\n\nberuhen auf der Wahrnehmung, Evaluation, Integration von Sinnesempfindungen\nsind oft handlungsrelevant\nneurowissenschaftlich untersucht werden die neuronalen Schaltkreise welche Wahrnehmungssignale kodieren, speichern und analysieren und wie diese mit Verhalten zusammenhÃ¤ngen\nmÃ¶gliche Fragenstellungen: Gewichtung von Sinnesinformationen bei sensorischen Konflikten oder der Einfluss von Vorwissen auf Entscheidungen\n\n\n\n\n\n\n\nImportant\n\n\n\nIn welchen Situationen treffen wir perzeptuelle Entscheidungen?\nWo ist der Einfluss von Vorwissen auf perzeptuelle Entscheidungen alltagsrelevant?\n\nDiskutieren Sie die Fragen in kleinen Gruppen und finden Sie je 3 Beispiele."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-i",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-i",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment I",
    "text": "Random-dot motion Experiment I\n\n\n\nRandom-dot motion direction-discrimination task (Bias in the brain: Mulder et al., 2012)\ncoherence: probability that a dot moves coherent with the motion direction\nbias: prior probabity cue before random-dot task (left/right/unbiased) or reward cue for a left or right answer (if correct)\nmeasures: response times and accuracy"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-ii",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-ii",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment II",
    "text": "Random-dot motion Experiment II\n\n\n\n\n\n\nImportant\n\n\nWie wirken sich die beiden Formen von Vorwissen auf das Antwortverhalten aus?\n\nBei welcher Bedingung antworten die Personen schneller?\nWo machen sie mehr Fehler?\n\nWas denken Sie? Diskutieren Sie die Fragen in kleinen Gruppen ohne im Paper nachzuschauen."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iii",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iii",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment III",
    "text": "Random-dot motion Experiment III"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iv",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iv",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment IV",
    "text": "Random-dot motion Experiment IV\n\nStimuli\n\nrandom dots: 3x3 pixels, coherence level: 8%\n\nConditions\n\n40 bias trials and 40 neutral trials (half of motion to left / other half to the right)\n32 valid (cue correct) and 8 invalid (cue incorrect) trials\n\nTrials and Timing\n\nFixation 1 (100/350/800/1200 ms)\nCue (1000 ms)\nFixation 2 (3400/4000/4500/5000 ms)\nDots (1500 ms)\nFeedback"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#psychopy",
    "href": "slides/02_psychopy_gw.html#psychopy",
    "title": "PsychoPy Experiment",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#pavlovia",
    "href": "slides/02_psychopy_gw.html#pavlovia",
    "title": "PsychoPy Experiment",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#understanding-your-computer",
    "href": "slides/02_psychopy_gw.html#understanding-your-computer",
    "title": "PsychoPy Experiment",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: VariabilitÃ¤t ~15 ms.\nScreen refresh fÃ¤ngt oben an und endet (~10 ms spÃ¤ter) unten."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#stimuli",
    "href": "slides/02_psychopy_gw.html#stimuli",
    "title": "PsychoPy Experiment",
    "section": "Stimuli",
    "text": "Stimuli\nErstellen Sie einen Random Dot Stimulus. Implementieren Sie dabei so genau wie mÃ¶glich die Parameter von Mulder et al.Â 2012\nBeachten Sie folgende Aspekte:\n\nTiming (Stimulusdauer)\nFarbe\nGrÃ¶sse\nKohÃ¤renz\n\n(Die Bewegungsrichtung kÃ¶nnen Sie noch vernachlÃ¤ssigen.)"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#trial-i",
    "href": "slides/02_psychopy_gw.html#trial-i",
    "title": "PsychoPy Experiment",
    "section": "Trial I",
    "text": "Trial I\nErstellen Sie einen Trial noch ohne Instruktion fÃ¼rs Vorwissen. Implementieren Sie dabei so genau wie mÃ¶glich die Parameter von Mulder et al.Â 2012\n\nBewegungsrichtung (inkl. conditions.csv file)\nFixationskreuze\nTiming (ITI: Inter-Trial-Intervall)\nAntwort der Versuchsperson aufnehmen\n\n(Die Instruktion bezÃ¼glich Vorwissen kÃ¶nnen Sie noch vernachlÃ¤ssigen.)"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#trial-ii",
    "href": "slides/02_psychopy_gw.html#trial-ii",
    "title": "PsychoPy Experiment",
    "section": "Trial II",
    "text": "Trial II\nErstellen Sie einen Trial mit Vorwissen. Implementieren Sie dabei so genau wie mÃ¶glich die Parameter von Mulder et al.Â 2012\nBeachten Sie folgende Aspekte:\n\nCue / Vorwissen kann valide, invalide, neutral sein\nstimmt in 3 von 4 FÃ¤llen"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#instruktion-debriefing",
    "href": "slides/02_psychopy_gw.html#instruktion-debriefing",
    "title": "PsychoPy Experiment",
    "section": "Instruktion & Debriefing",
    "text": "Instruktion & Debriefing\nFÃ¼gen Sie eine Instruktion und ein kurzes Debriefing hinzu.\n\n\n\nğŸ  Neurowissenschaft im Computerlab FS23"
  },
  {
    "objectID": "pages/exercises/exercise_01.html",
    "href": "pages/exercises/exercise_01.html",
    "title": "Ãœbung 1",
    "section": "",
    "text": "Note\n\n\n\nDiese Ãœbung muss nicht abgegeben werden; sie dient als Vorbereitung fÃ¼r die folgende Sitzung.\n\n\n\n\nInstallieren Sie PsychoPy von der Website. PsychoPy ist ein Open-Source Programm fÃ¼r MacOS, Windows und Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente (Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren kÃ¶nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI Scanner und mit EEG verwenden.\nPsychoPy ğŸ‘‰ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das â€œStandalone packageâ€ fÃ¼r MacOS oder Windows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu bereiten â€” es ist daher (zurzeit noch) besser, die Version 2021.2.3 zu installieren.\n\n\n\n\n\nWas verstehen Sie unter folgenen Begriffen:\n\n\nModel-based Neuroscience\nEvidence accumulation\n\n\nWas kÃ¶nnte man unter Vorwissen (prior knowledge) verstehen? In welchen Kontexten kÃ¶nnte es bei Entscheidungen nÃ¼tzlich sein, Vorwissen zu benutzen?"
  },
  {
    "objectID": "pages/exercises/exercise_01.html#aufgabe-1",
    "href": "pages/exercises/exercise_01.html#aufgabe-1",
    "title": "Ãœbung 1",
    "section": "",
    "text": "Installieren Sie PsychoPy von der Website. PsychoPy ist ein Open-Source Programm fÃ¼r MacOS, Windows und Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente (Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren kÃ¶nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI Scanner und mit EEG verwenden.\nPsychoPy ğŸ‘‰ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das â€œStandalone packageâ€ fÃ¼r MacOS oder Windows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu bereiten â€” es ist daher (zurzeit noch) besser, die Version 2021.2.3 zu installieren."
  },
  {
    "objectID": "pages/exercises/exercise_01.html#aufgabe-2",
    "href": "pages/exercises/exercise_01.html#aufgabe-2",
    "title": "Ãœbung 1",
    "section": "",
    "text": "Was verstehen Sie unter folgenen Begriffen:\n\n\nModel-based Neuroscience\nEvidence accumulation\n\n\nWas kÃ¶nnte man unter Vorwissen (prior knowledge) verstehen? In welchen Kontexten kÃ¶nnte es bei Entscheidungen nÃ¼tzlich sein, Vorwissen zu benutzen?"
  },
  {
    "objectID": "pages/exercises/exercise_02.html",
    "href": "pages/exercises/exercise_02.html",
    "title": "Ãœbung 2",
    "section": "",
    "text": "Note\n\n\n\nDie Daten, welche Sie in dieser Ãœbung sammeln, mÃ¼ssen abgegeben werden; wir werden diese im Verlauf des Semesters analysieren. Bitte die Datenfiles in einem ZIP File bis 8. MÃ¤rz auf ILIAS hochladen.\n\n\n\n\n\nDas fertige Experiment befindet sich auf Github. Sie kÃ¶nnen es unter diesem Link downloaden. ğŸ‘‰ LINK.\nFÃ¼hren Sie das Experiment ein- oder mehrere Male selber durch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen Testperson und laden Sie das ZIP FIle auf ILIAS."
  },
  {
    "objectID": "pages/exercises/exercise_02.html#bias-rdk-experiment-durchfÃ¼hren",
    "href": "pages/exercises/exercise_02.html#bias-rdk-experiment-durchfÃ¼hren",
    "title": "Ãœbung 2",
    "section": "",
    "text": "Das fertige Experiment befindet sich auf Github. Sie kÃ¶nnen es unter diesem Link downloaden. ğŸ‘‰ LINK.\nFÃ¼hren Sie das Experiment ein- oder mehrere Male selber durch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen Testperson und laden Sie das ZIP FIle auf ILIAS."
  },
  {
    "objectID": "pages/solutions/solution_03.html",
    "href": "pages/solutions/solution_03.html",
    "title": "Ãœbung 3: LÃ¶sung",
    "section": "",
    "text": "In dieser Aufgabe bearbeiten Sie Daten aus einem Detektionssexperiment. Versuchspersonen mussten in zwei Bedingungen (bias und no_bias) ein Signal, welches in Rauschen eingebettet war, detektieren. Im Datensatz sind folgende Variablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable fÃ¼r Signal (0: absent, 1: present)\ncorrect: Indikatorvariable fÃ¼r korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\n\n\nAufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d fÃ¼r den Datensatz.\nÃœberprÃ¼fen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\nd &lt;- read_csv(\"data/data-exercise-03.csv\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nRows: 5,756\nColumns: 6\n$ subject        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2â€¦\n$ condition      &lt;chr&gt; \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\",â€¦\n$ signal_present &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0â€¦\n$ correct        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1â€¦\n$ rt             &lt;dbl&gt; 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.370, 0.559,â€¦\n$ trial_num      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd &lt;- d |&gt;\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen Ã¼ber dem Bedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants &lt;- d |&gt;\n    group_by(subject, condition) |&gt;\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions &lt;- d |&gt;\n    group_by(condition) |&gt;\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\nsum_stats_participants &lt;-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(outlier_P = (mean_P - mean_C) &gt; 2 * sd_C)\n\n\n# show outlier participants\nsum_stats_participants |&gt;\n    filter(outlier_P == 1) |&gt;\n    show()\n\n# A tibble: 0 Ã— 6\n# Groups:   subject [0]\n# â€¦ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer Bedingung mehr als zwei Standardabweichungen Ã¼ber dem Bedingungsmittelwert liegt. Dies bedeutet, dass sich in excluded keine Personen befinden, und der Dataframe folglich \\(0\\) Zeilen hat.\n\nexcluded &lt;- sum_stats_participants |&gt;\n    filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 0 Ã— 6\n# Groups:   subject [0]\n# â€¦ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nDer nÃ¤chste Schritt wÃ¤re also nicht unbedingt notwendig.\n\nd_cleaned &lt;- d |&gt;\n    filter(!(subject %in% excluded$subject)) |&gt;\n    mutate(subject = fct_drop(subject))\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen lÃ¤nger als 4 Standardabweichungen Ã¼ber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn lÃ¤nger gebraucht haben, als 4 Standardabweichungen Ã¼ber dem Bedingungsmittelwert. Das bedeutet (rt - mean_C) &gt; 4 * sd_C, und nicht abs(rt - mean_C) &gt; 4 * sd_C. Letzteres wÃ¼rde auch Trials als Ausreisser identifizieren, welche 4 Standardabweichungen unter dem Bedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies bedeutet, wir brauchen rt &lt; 0.100, und nicht rt &lt; 100.\n\nd_cleaned &lt;- d_cleaned |&gt;\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) &gt; 4 * sd_C ~ \"too slow\",\n            rt &lt; 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |&gt;\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt;\n    filter(trial_type != \"OK\")\n\n# A tibble: 165 Ã— 9\n   subject condition signal_present correct     rt trial_â€¦Â¹ mean_C  sd_C trialâ€¦Â²\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  \n 1 2       bias                   0       1 4.08          1  0.697 0.751 too slâ€¦\n 2 2       bias                   1       1 0.035        41  0.697 0.751 too faâ€¦\n 3 2       bias                   0       1 6.92         50  0.697 0.751 too slâ€¦\n 4 2       bias                   0       1 0.085        51  0.697 0.751 too faâ€¦\n 5 2       bias                   0       1 0.033        70  0.697 0.751 too faâ€¦\n 6 2       bias                   0       1 5.09         74  0.697 0.751 too slâ€¦\n 7 2       bias                   0       1 6.59         94  0.697 0.751 too slâ€¦\n 8 2       bias                   0       1 5.09        121  0.697 0.751 too slâ€¦\n 9 2       bias                   1       1 0.077       138  0.697 0.751 too faâ€¦\n10 3       no_bias                1       0 0.0958        4  0.691 0.773 too faâ€¦\n# â€¦ with 155 more rows, and abbreviated variable names Â¹â€‹trial_num, Â²â€‹trial_type\n\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756 Datenpunkte.\n\nnrow(d_cleaned)\n\n[1] 5756\n\n\n\nd_cleaned &lt;- d_cleaned |&gt;\n    filter(trial_type == \"OK\") |&gt;\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\nNach dem Entfernen haben wir noch 5591.\n\nnrow(d_cleaned)\n\n[1] 5591\n\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt; write_csv(\"data/data-cleaned.csv\")"
  },
  {
    "objectID": "pages/solutions/solution_03.html#aufgaben",
    "href": "pages/solutions/solution_03.html#aufgaben",
    "title": "Ãœbung 3: LÃ¶sung",
    "section": "",
    "text": "Aufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d fÃ¼r den Datensatz.\nÃœberprÃ¼fen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\nd &lt;- read_csv(\"data/data-exercise-03.csv\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nRows: 5,756\nColumns: 6\n$ subject        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2â€¦\n$ condition      &lt;chr&gt; \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\",â€¦\n$ signal_present &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0â€¦\n$ correct        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1â€¦\n$ rt             &lt;dbl&gt; 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.370, 0.559,â€¦\n$ trial_num      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd &lt;- d |&gt;\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen Ã¼ber dem Bedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants &lt;- d |&gt;\n    group_by(subject, condition) |&gt;\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions &lt;- d |&gt;\n    group_by(condition) |&gt;\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\nsum_stats_participants &lt;-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(outlier_P = (mean_P - mean_C) &gt; 2 * sd_C)\n\n\n# show outlier participants\nsum_stats_participants |&gt;\n    filter(outlier_P == 1) |&gt;\n    show()\n\n# A tibble: 0 Ã— 6\n# Groups:   subject [0]\n# â€¦ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer Bedingung mehr als zwei Standardabweichungen Ã¼ber dem Bedingungsmittelwert liegt. Dies bedeutet, dass sich in excluded keine Personen befinden, und der Dataframe folglich \\(0\\) Zeilen hat.\n\nexcluded &lt;- sum_stats_participants |&gt;\n    filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 0 Ã— 6\n# Groups:   subject [0]\n# â€¦ with 6 variables: subject &lt;fct&gt;, condition &lt;fct&gt;, mean_P &lt;dbl&gt;,\n#   mean_C &lt;dbl&gt;, sd_C &lt;dbl&gt;, outlier_P &lt;lgl&gt;\n\n\nDer nÃ¤chste Schritt wÃ¤re also nicht unbedingt notwendig.\n\nd_cleaned &lt;- d |&gt;\n    filter(!(subject %in% excluded$subject)) |&gt;\n    mutate(subject = fct_drop(subject))\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen lÃ¤nger als 4 Standardabweichungen Ã¼ber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn lÃ¤nger gebraucht haben, als 4 Standardabweichungen Ã¼ber dem Bedingungsmittelwert. Das bedeutet (rt - mean_C) &gt; 4 * sd_C, und nicht abs(rt - mean_C) &gt; 4 * sd_C. Letzteres wÃ¼rde auch Trials als Ausreisser identifizieren, welche 4 Standardabweichungen unter dem Bedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies bedeutet, wir brauchen rt &lt; 0.100, und nicht rt &lt; 100.\n\nd_cleaned &lt;- d_cleaned |&gt;\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |&gt;\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) &gt; 4 * sd_C ~ \"too slow\",\n            rt &lt; 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |&gt;\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt;\n    filter(trial_type != \"OK\")\n\n# A tibble: 165 Ã— 9\n   subject condition signal_present correct     rt trial_â€¦Â¹ mean_C  sd_C trialâ€¦Â²\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  \n 1 2       bias                   0       1 4.08          1  0.697 0.751 too slâ€¦\n 2 2       bias                   1       1 0.035        41  0.697 0.751 too faâ€¦\n 3 2       bias                   0       1 6.92         50  0.697 0.751 too slâ€¦\n 4 2       bias                   0       1 0.085        51  0.697 0.751 too faâ€¦\n 5 2       bias                   0       1 0.033        70  0.697 0.751 too faâ€¦\n 6 2       bias                   0       1 5.09         74  0.697 0.751 too slâ€¦\n 7 2       bias                   0       1 6.59         94  0.697 0.751 too slâ€¦\n 8 2       bias                   0       1 5.09        121  0.697 0.751 too slâ€¦\n 9 2       bias                   1       1 0.077       138  0.697 0.751 too faâ€¦\n10 3       no_bias                1       0 0.0958        4  0.691 0.773 too faâ€¦\n# â€¦ with 155 more rows, and abbreviated variable names Â¹â€‹trial_num, Â²â€‹trial_type\n\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756 Datenpunkte.\n\nnrow(d_cleaned)\n\n[1] 5756\n\n\n\nd_cleaned &lt;- d_cleaned |&gt;\n    filter(trial_type == \"OK\") |&gt;\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\nNach dem Entfernen haben wir noch 5591.\n\nnrow(d_cleaned)\n\n[1] 5591\n\n\n\nd_cleaned |&gt;\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |&gt; write_csv(\"data/data-cleaned.csv\")"
  }
]