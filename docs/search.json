[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "Fr√ºhjahrssemester 2023"
  },
  {
    "objectID": "pages/admin/01_overview.html",
    "href": "pages/admin/01_overview.html",
    "title": "√úbersicht",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses Forschungsgebiets. Das bedeutet, wir analysieren Daten aus Verhaltensexperimenten ‚Äî sowohl mit herk√∂mmlichen statistischen Verfahren, als auch mit mathematischen Modellen. Die Resultate dieser Analysen k√∂nnen wiederum in der Analyse bildgebender Verfahren oder EEG benutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Themen daraus aufgreifen. Das Buch ist auf SpringerLink verf√ºgbar: An Introduction to Model-Based Cognitive Neuroscience.\n\nWir werden folgende Themen im Laufe des Semester behandeln:\n\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. bin√§re Daten, Reaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinf√ºhrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von Entscheidungsverhalten)"
  },
  {
    "objectID": "pages/admin/01_overview.html#experimente",
    "href": "pages/admin/01_overview.html#experimente",
    "title": "√úbersicht",
    "section": "Experimente",
    "text": "Experimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen Benutzeroberfl√§che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/admin/01_overview.html#datenanalyse",
    "href": "pages/admin/01_overview.html#datenanalyse",
    "title": "√úbersicht",
    "section": "Datenanalyse",
    "text": "Datenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu analysieren werden wir R verwenden. Sie sollten daher die aktuelle Version von R installieren (Version 4.2.2), sowie RStudio.\nR üëâ https://cloud.r-project.org/\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download\nF√ºr Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, √§hnlich wie Jamovi, mit dem sich simple Bayesianische Tests durchf√ºhren lassen.\nJASP üëâ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R aus benutzen. Die daf√ºr ben√∂tigte Software werden wir im Verlauf des Semesters installieren."
  },
  {
    "objectID": "pages/admin/03_zulip_forum.html",
    "href": "pages/admin/03_zulip_forum.html",
    "title": "Zulip Forum",
    "section": "",
    "text": "Wir benutzen in dieser Veranstaltung Zulip als Diskussionforum. Zulip hat einige Vorteile gegen√ºber ILIAS und Email:\n\nZulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum f√ºr die Vormittags- und Nachmittagsveranstaltungen.\nDie Diskussion ist f√ºr alle Teilnehmer*innen sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron) stattfinden.\n\nBitte erstellen Sie unter diesem Link einen Account. Sie m√ºssen daf√ºr Ihre Uni Emailadresse verwenden. Account erstellen üëâ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, k√∂nnen Sie sich unter folgendem Link einloggen. Zulip Forum üëâ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App f√ºr alle g√§ngigen Betriebssysteme erh√§ltlich. Apps üëâ zulip.com/apps\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Andrew Ellis},\n  title = {Zulip {Forum}},\n  url = {https://kogpsy.github.io/neuroscicomplabFS23//03_zulip_forum.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. n.d. ‚ÄúZulip Forum.‚Äù https://kogpsy.github.io/neuroscicomplabFS23//03_zulip_forum.html."
  },
  {
    "objectID": "pages/admin/dozierende.html",
    "href": "pages/admin/dozierende.html",
    "title": "Dozierende",
    "section": "",
    "text": "Andrew ist Data Scientist an der Berner Fachhochschule und Wissenschaftlicher Mitarbeiter an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre der Uni Bern. An der BFH besch√§ftigt er sich haupts√§chlich mit der Verwendung k√ºnstlicher Intelligenz in der Lehre, und versucht ein intelligentes Tutoring-System zu entwickeln.\nüì¨ Email: andrew.ellis@unibe.ch\nüîó Website: www.kog.psy.unibe.ch/ueber_uns/personen/dr_ellis_andrew"
  },
  {
    "objectID": "pages/admin/dozierende.html#gerda-wyssen",
    "href": "pages/admin/dozierende.html#gerda-wyssen",
    "title": "Dozierende",
    "section": "Gerda Wyssen",
    "text": "Gerda Wyssen\nGerda arbeitet an ihrer Dissertation an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre. Sie untersucht den Einfluss von Gleichgewichts- und Bewegungsinformationen auf r√§umliches Denken. Hierzu nutzt sie die Moog Bewegungsplattform oder das starke Magnetfeld eines 7T MRI Scanners. Besonders faszinierend findet sie Bewegungsillusionen.\nüì¨ Email: gerda.wyssen@unibe.ch\nüîó Website: www.kog.psy.unibe.ch/ueber_uns/personen/m_sc_wyssen_gerda"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html",
    "href": "pages/admin/leistungsnachweise.html",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Unsere Veranstaltungen werden so aufgebaut sein, dass wir etwa die H√§lfte der Zeit Inhalt pr√§sentieren; die andere H√§lfte ist praktischen Hands-on Sessions gewidmet. Dies wird jedoch stark vom jeweiligen Inhalt anh√§ngig sein. Wir denken, dass der Umgang mit Programmiersprachen und Datenanalyse am besten gelernt wird, indem man selber ausprobiert. Deshalb werden wir versuchen, die Theorie auf das N√∂tigste zu beschr√§nken, und uns mehr auf praktische Anwendungen zu fokussieren."
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "href": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "title": "Leistungskontrollen",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nLeistungsnachweise werden in Form von √úbungen erbracht. Es wird insgesamt 5 √úbungen geben ‚Äì davon m√ºssen alle abgegeben werden. Die √úbungen werden in den Veranstaltungen angek√ºndigt und in den entsprechenden Ordner auf ILIAS hochgeladen. Je nach Umfang der √úbung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens eine Woche betragen.\nDie Evaluation der √úbungen erfolgt in Form von Peer-Feedback; dies bedeutet, dass Sie nach dem Abgabetermin aufgefordert werden, zu den √úbungen von zuf√§llig ausgew√§hlten Mitstudierenden Feedback zu geben. Danach erhalten Sie selber von anderen Mitstudierenden Feedback zu Ihrer √úbung. Das Peer-Feedback ist somit Teil des Leistungsnachweises. Auf Ilias finden Sie Informationen zur Art und Form des Feedbacks passend zur √úbung. Grunds√§tzliche Guidelines zum Peer-Feedback finden Sie untenstehend.\nILIAS (Montag) üëâ 468703-FS2023-1\nILIAS (Donnerstag) üëâ 468703-FS2023-0"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "href": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "title": "Leistungskontrollen",
    "section": "Peer Feedback Guidelines",
    "text": "Peer Feedback Guidelines\nWissenschaftliche Artikel werden von Forschenden aus denselben/√§hnlichen Forschungsgebieten begutachtet. In diesem Kurs w√§hlen wir f√ºr das Feedback zu den √úbungen ebenfalls dieses Prinzip des peer review. F√ºr jede √úbung erhalten Sie einen klaren Begutachtungsauftrag mit Fragen wie z.B. Was w√ºrde die Grafik informativer machen?. Wir bitten Sie, beim Verfassen des Peer-Feedbacks folgende Richtlinien zu beachten:\n\nbe kind: Seien Sie freundlich. W√§hlen Sie Ihre R√ºckmeldungspunkte sorgf√§ltig. Nehmen Sie sich Zeit und geben Sie nicht sehr knappes, versp√§tetes oder gar kein Feedback. Schreiben Sie was Ihnen positiv aufgefallen ist und unbedingt beibehalten werden sollte.\nbe specific: Beschreiben Sie das Problem oder die Kritikpunkte pr√§zise und spezifisch (statt z.B. ‚ÄúCode l√§uft nicht‚Äù k√∂nnten Sie schreiben ‚Äúin Zeile 34 gibt es eine Fehlermeldung, es scheint die Variable wurde falsch benannt, ‚Ä¶‚Äù)\nbe helpful: Seien Sie konstruktiv. Es gibt immer etwas was verbessert werden k√∂nnte. Beschreiben Sie diese Punkte und f√ºgen Sie bestenfalls einen L√∂sungsansatz oder -vorschlag hinzu (statt z.B. ‚Äúdie Farben sind nicht geeignet f√ºr farbenblinde Personen‚Äù k√∂nnten Sie schreiben ‚Äúdie viridis Palette w√ºrde die Grafik f√ºr farbenblinde Personen zug√§nglich machen‚Äù).\n\nWertvolles Feedback zu geben ben√∂tigt Zeit. Deshalb planen Sie sich bitte ca. 1 Lektion f√ºr das jeweilige Peer Feedback ein."
  },
  {
    "objectID": "pages/admin/syllabus.html",
    "href": "pages/admin/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Sitzungen\nAn den 14 Sitzungen werden wir voraussichtlich diese Themen behandeln (kleine √Ñnderungen vorbehalten).\n\n1 Einf√ºhrung\nSitzung 1\n\nWir schauen uns ein paar in den Neurowissenschaften verwendeten Programmiersprachen (Python, R, Matlab) an, und diskutieren ChatGPT.\nEinf√ºhrung in DataCamp (f√ºr Python/R).\n\n\n\n\n\n\n\nHands-on\n\n\n\nAuf DataCamp den Python Einf√ºhrungskurs ausprobieren.\n\n\n\n\n2 Experimente mit Python programmieren\nSitzungen 2 und 3\n\nWir erstellen selber ein Experiment mit Python und PsychoPy.\n\n\n\n3 Data Wrangling\nSitzungen 4 und 5\n\nWir schauen uns an, wie wir mit R die Daten aus unserem selber programmierten Experiment einlesen und bearbeiten k√∂nnen, um damit statistische Analysen durchzuf√ºhren.\n\n\n\n4 Visualisieren\nSitzung 6\n\nExplorative Datenanalyse und grafische Darstellung mit mit R package ggplot2.\n\n\n\n5 Signal Detection Theory\nSitzungen 7 und 8\n\nWir verwenden ein in den Neurowissenschaften und der Psychologie beliebtes Modell f√ºr kategoriale oder ordinale Verhaltensdaten, um Daten aus unserem Experiment zu analysieren.\n\n\n\n6 Reaktionszeiten\nSitzungen 9 und 10\n\nIn diesen Sitzungen schauen wir uns Analysemethoden f√ºr Reaktionszeitdaten an.\n\n\n\n7 Bayesianische Datenanalyse\nSitzungen 11, 12, 13, und 14\n\nIm letzten Thema geht es um einen modernen Ansatz in der Statistik, welcher auf den Axiomen der Wahrscheinlichkeitstheorie beruht, und einige Vorteile gegen√ºber der herk√∂mmlichen (frequentistischen) Statistik bietet. Wir werden hier mit dem Programm Jasp arbeiten.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "pages/chapters/chatgpt.html",
    "href": "pages/chapters/chatgpt.html",
    "title": "ChatGPT",
    "section": "",
    "text": "Eventuell haben Sie in den letzten Wochen von ChatGPT geh√∂rt, vielleicht schon selber benutzt. Sowohl an Hochschulen als auch an Gymnasien stellt sich die brennende Frage, wie Lehrpersonen und Studierende/Sch√ºler damit umgehen sollen. Darf man ChatGPT benutzen? Werden die abgegeben √úbungen darauf untersucht, ob sie mit Hilfe k√ºnstlicher Intelligenz generiert wurden.\nWir versuchen hier, unsere Haltung in Bezug auf ChatGPT bekanntzugeben, und zu erkl√§ren, was ChatGPT kann, und wo es hilfreich sein k√∂nnte.\n\n\n\n\nChatGPT benutzt das Codex Modell von OpenAI, welches auf Programmiersprachen spezialisiert ist. Vor allem Python, aber auch R (und Matlab) Code spricht ChatGPT hervorragend.\n\n\n\nNein. ChatGPT besteht aus verschiedenen Komponent. Eines davon ist ein large language model (LLM), die weiteren Komponenten braucht es, um einen Chatbot zu kreieren, welcher menschen√§hnliche Konversationen f√ºhren kann.\nDas LLM hat im wesentlichen die Verteilung von Wortst√§mmen (Tokens) des Textkorpus (mit dem es trainiert wurde) gelernt. Die Aufgabe des LLM ist es, gegeben einen Input (Prompt) eine oder mehrere wahrscheinliche Vervollst√§ndigungen zu erzeugen. Wenn nun im Textkorpus Programmcode vorkam, wird das LLM syntaktisch korrekten Code zu generieren. Das LLM hat jedoch keine M√∂glichkeit, diesen Code auszuf√ºhren, auf Korrektheit zu √ºberpr√ºfen, oder √ºberhaupt herauszufinden, ob der Code sinnvoll ist.\nChatGPT kann mitunter hervorragenden Code generieren, aber ob der Code wirklich das macht, was er soll, liegt in der Verantwortung der Benutzer:in.\n\nImmer kritisch √ºberpr√ºfen, ob von ChatGPT generierter Code wirklich korrekt ist, und tut was verlangt wird!\n\n\n\n\nSie k√∂nnen ChatGPT helfen, gute Antworten zu erzeugen, in dem Sie gute Fragen stellen. Dies bedeutet, dass Sie in der Frage (Prompt) m√∂glichst viele Kontextinformationen mitliefern. Denken Sie daran, dass ChatGPT, gegeben dem Input und den Trainingsdaten, eine m√∂glichst wahrscheinliche Sequenz von Token erzeugt.\n\n\n\n\nWir gehen davon aus, dass Technologien wie ChatGPT nicht mehr vom modernen Unterricht wegzudenken sind, und es daher sinnvoll und notwendig ist, einen m√∂glichst guten Umgang damit zu erlernen.\n\n\n\n\n\n\nHinweis\n\n\n\nChatGPT darf f√ºr die √úbungen genutzt werden.\n\n\nEs ist aus unserer Sicht jedoch sinnvoll, wenn Sie ChatGPT als eine von vielen m√∂glichen Quellen benutzen (wie z.B. Google, Stackoverflow), und diese auch als solche transparent angeben.\nAus unserer Sicht ist ChatGPT (und Codex) ein sehr wertvolles Tool. Sie sind jedoch daf√ºr verantwortlich, dass ihr Code ausf√ºhrbar ist. Dies wird beim Peer-Feedback eines der Kriterien sein. Das Ziel ist prim√§r, dass sie Code verstehen und anwenden k√∂nnen, nicht dass sie Code aus dem Nichts selber schreiben k√∂nnen. Dies ist √ºbrigens auch die Vorgehensweise vieler erfahrener Programmierer - oft wird zuerst mal gegoogelt und im Internet nachgeschaut, ob es schon L√∂sungsans√§tze gibt. ChatGPT macht im Prinzip nichts anderes.\n\n\n\nIm Prinzip ja, aber Sie w√ºrden dabei wahrscheinlich sehr wenig lernen. Den Umgang mit Computern und das Programmieren lernt man, indem man selber Code ausf√ºhrt, Fehler macht und versucht zu verstehen was der Fehler war. Das Ziel sollte sein, dass Sie jederzeit erkl√§ren k√∂nnten, was Ihr Code macht, oder wieso Sie ein bestimmtes Feedback gegeben haben. Ohne selber etwas daf√ºr zu tun wird der Lern efolg wahrscheinlich ausbleiben.\n\n\n\nChatGPT kann sowohl Code generieren als auch Code evaluieren. Sie k√∂nnen ChatGPT benutzen\n\num Vorschl√§ge zu erhalten, wenn Sie nicht weiterkommen.\num ein Ger√ºst f√ºr ein Programm zu erstellen.\num Code auf Lesbarkeit/Verst√§ndlichkeit zu √ºberpr√ºfen.\num Code kommentieren zu lassen.\num Code zu verstehen/bewerten zu lassen.\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte √ºberpr√ºfen Sie aber immer kritisch den Output von ChatGPT, und stellen sie sicher, dass der Code tats√§chlich ausgef√ºhrt werden kann."
  },
  {
    "objectID": "pages/chapters/data-cleaning.html",
    "href": "pages/chapters/data-cleaning.html",
    "title": "Data cleaning",
    "section": "",
    "text": "Vertiefung\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden\nNun wollen wir versuchen, einzelne Trials, zu identifizieren, in denen Versuchpersonen nicht aufgepasst haben, oder einfach geraten wurde.\nAm h√§ufigsten werden die folgenden beiden Kriterien verwendet, um entweder einzelne Datenpunkte, oder Versuchspersonen, auszuschliessen:\nNun ist in Experimenten, in denen ein Bias erzeugt wird, etwas heikel, Trials oder Versuchspersonen aufgrund der Anzahl korrekter Antworten auszuschliessen - wir haben ja die Korrektheit der Antworten experimentell manipuliert.\nDeswegen richten wir hier unseren Fokus auf die Reaktionszeiten. Wir gehen davon aus, dass Reaktionszeiten, die zu schnell oder yu langsam waren, aufgrund von Rateprozessen zustande kamen. Was genau zu schnell oder zu langsam heisst, ist schwierig zu beantworten, und h√§ngt stark vom jeweiligen Task ab. Deshalb ist es wichtig, sich a priori Gedanken dar√ºber zu machen, welche Kriterien angewandt werden sollen."
  },
  {
    "objectID": "pages/chapters/data-cleaning.html#eigenschaften-von-reaktionszeiten",
    "href": "pages/chapters/data-cleaning.html#eigenschaften-von-reaktionszeiten",
    "title": "Data cleaning",
    "section": "Eigenschaften von Reaktionszeiten",
    "text": "Eigenschaften von Reaktionszeiten\nDie wichtigsten Merkmale von Reaktionszeiten sind\n\nSie sind rechtsschief\nSie sind nicht normalverteilt\nStreuung (Standardabweichung) steigt ungef√§hr linear mit wachsendem Mittelwert (Wagenmakers and Brown 2007)\n\n\nDie Rechtschiefe ist eine nat√ºrliche Konsequenz der Tatsache, dass es viele M√∂glichkeiten gibt, langsamer zu werden, aber nur wenige M√∂glichkeiten, schneller zu werden. Reaktionszeiten k√∂nnen nicht negativ sein Ausserdem gibt es eine Untergrenze, welche durch unsere Physiologie bestimmt ist. Schellere Reaktionszeiten als 200 Millisekunden sind kaum m√∂glich.\nDie Konsequenz daraus ist, dass Reaktionszeiten nicht normalverteilt sind. In folgender Grafik sind zwei Verteilungen dargestellt. Die gelbe Verteilung ist eine Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 0.4\\), w√§hrend die graue Verteilung eine LogNormal Verteilung darstellt.\n\nEine LogNormal-Verteilung bedeutet, dass der Logarithmus einer Zufallsvariablen normalverteilt ist.\n\n\n\n\n\nObwohl die Normalverteilung so aussieht, als k√∂nne sie Reaktionszeiten repr√§sentieren, ist der Wertebereich von \\([-\\infty, \\infty]\\) nicht daf√ºr geeignet. Ausserdem erlaubt die Normalverteilung keine extremen Werte, und ist nicht asymmetrisch."
  },
  {
    "objectID": "pages/chapters/datacamp.html",
    "href": "pages/chapters/datacamp.html",
    "title": "DataCamp",
    "section": "",
    "text": "Im Rahmen dieser Lehrveranstaltung k√∂nnen alle Teilnehmende sich bei DataCamp registrieren\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL an. DataCamp Kurse auf unterschiedlichen Niveaus an; sowohl f√ºr Anf√§nger als auch f√ºr Fortgeschrittene gibt es ein breites Angebot an Kursen.\nSie k√∂nnen Sich unter folgendem Link mit Ihrer Uni Bern E-Mail Adresse (*unibe.ch) registrieren:\nüëâüèº DataCamp registration"
  },
  {
    "objectID": "pages/chapters/datacamp.html#hands-on-session",
    "href": "pages/chapters/datacamp.html#hands-on-session",
    "title": "DataCamp",
    "section": "Hands-on session",
    "text": "Hands-on session\nWir werden in der zweiten Sitzung mit Psychopy und Python ein Experiment erstellen. In Psychopy k√∂nnen Sie viel sehr √ºber die grafische Oberfl√§che; es gibt jedoch einige kleine Dinge, welche wir mit Python selber coden m√ºssen. Deshalb w√§re es f√ºr Sie hiflreich, wenn Sie sich vorher auf der DataCamp Website ein wenig mit Python vertraut machen.\n\n1 - Python Basics\nJe nachdem wie viel Erfahrung Sie mit Python haben, k√∂nnen Sie sich entweder f√ºr den Kurs ‚ÄúIntroduction to Python‚Äù oder ‚ÄúIntermediate Python‚Äù entscheiden.\nüëâüèº Introduction to Python\nüëâüèº Intermediate Python\nF√ºr fortgeschrittene empfehlen wir die Kurse:\nüëâüèº Python Data Science Toolbox (Part 1)\nüëâüèº Python Data Science Toolbox (Part 2)\nDiese Kurse sind nicht obligatorisch; Sie brauchen f√ºr PsychoPy wirklich nur Grundkenntnisse. Python ist aber sowohl in der Forschung als der Privatwirtschaft sehr beliebt und Sie werden es sicherlich noch √∂fters brauchen, wenn Sie sich mit Datenanalyse besch√§ftigen.\n\n\n2 - Python Code mit ChatGPT generieren\nDies ben√∂tigt einen ChatGPT Account; einen solchen k√∂nnen Sie bei OpenAI gratis erstellen.\nüëâüèº chat.openai.com/chat\nVersuchen Sie, mit ChatGPT ein paar Zeilen Python Code zu generieren. Sie k√∂nnen hierzu einige Beispiele als den DataCamp Kursen verwenden.\n\nKann ChatGPT die Aufgaben l√∂sen?\nWie kann Ihnen ChatGPT helfen, Code zu schreiben?\nWas m√ºssen Sie beachten, wenn Sie Code von ChatGPT verwenden?"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html",
    "href": "pages/chapters/experiment_stepbystep.html",
    "title": "Experiment erstellen: Step by step",
    "section": "",
    "text": "Schauen Sie sich in PsychoPy die verschiedenen m√∂glichen Bausteine f√ºr Experimente an. Versuchen Sie St√ºck f√ºr St√ºck das Experiment von Mulder et al. (2012) nachzubauen."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#allgemeine-informationen-zu-psychopy",
    "href": "pages/chapters/experiment_stepbystep.html#allgemeine-informationen-zu-psychopy",
    "title": "Experiment erstellen: Step by step",
    "section": "Allgemeine Informationen zu PsychoPy",
    "text": "Allgemeine Informationen zu PsychoPy\nHilfreiche Informationen zum Erstellen von Experimenten in PsychoPy finden Sie hier:\n\nPsychoPy Website\nWalk-through: Builder\nDiskussionsforum"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#random-dot-stimulus",
    "href": "pages/chapters/experiment_stepbystep.html#random-dot-stimulus",
    "title": "Experiment erstellen: Step by step",
    "section": "1. Random Dot Stimulus",
    "text": "1. Random Dot Stimulus\nErstellen Sie einen Random Dot Stimulus. Beachten Sie folgende Aspekte:\n\nTiming (Stimulusdauer): 1500 ms\nFarbe\nGr√∂sse: gut sichtbar\nKoh√§renz: 0.08\nField size: 75% des Displays\n\n(Die Bewegungsrichtung k√∂nnen Sie noch vernachl√§ssigen.)"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#trialschleife",
    "href": "pages/chapters/experiment_stepbystep.html#trialschleife",
    "title": "Experiment erstellen: Step by step",
    "section": "2. Trialschleife",
    "text": "2. Trialschleife\nErstellen Sie eine Trial-Schleife.\n\nFixation 1 (100/350/800/1200 ms) (Zur Vereinfachung k√∂nnen Sie hier auch nur einen Wert w√§hlen.)\nCue (1000 ms)\nFixation 2 (3400/4000/4500/5000 ms) (Zur Vereinfachung k√∂nnen Sie hier auch nur einen Wert w√§hlen.)\nDots (1500 ms)\nFeedback\nTiming (ITI: Inter-Trial-Intervall)\nAntwort der Versuchsperson aufnehmen\n\n(Die Variation der Bewegungsrichtung und des Vorwissens k√∂nnen Sie noch vernachl√§ssigen.)"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#bedingungen",
    "href": "pages/chapters/experiment_stepbystep.html#bedingungen",
    "title": "Experiment erstellen: Step by step",
    "section": "3. Bedingungen",
    "text": "3. Bedingungen\n\nVariieren Sie die Bewegungsrichtung der Random Dots mit dem conditions.csv file: Bewegungsrichtung ist zu 50% rechts, zu 50% links.\nVariieren Sie den Cue f√ºrs Vorwissen in jedem Trial mit dem conditions.csv file: Der Cue kann valide (4x), invalide (2x) oder neutral (4x) sein. Die Bewegungsrichtungen m√ºssen auf alle Bedingungen gleich verteilt sein."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#instruktion-und-debriefing",
    "href": "pages/chapters/experiment_stepbystep.html#instruktion-und-debriefing",
    "title": "Experiment erstellen: Step by step",
    "section": "4. Instruktion und Debriefing",
    "text": "4. Instruktion und Debriefing\n\nF√ºgen Sie zu Beginn des Experiments eine Instruktion hinzu.\nF√ºgen Sie am Ende des Experiments ein Debriefing hinzu."
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#test",
    "href": "pages/chapters/experiment_stepbystep.html#test",
    "title": "Experiment erstellen: Step by step",
    "section": "5. Test",
    "text": "5. Test\nF√ºhren Sie das Experiment aus und schauen Sie sich den Datensatz an: Sind die untenstehenden Infos auf jeder Zeile vorhanden?\n\nVersuchspersonennummer\nRichtung des Stimulus\nCue / Vorwissen\nAntwort der Versuchsperson\nAntwortdauer der Versuchsperson"
  },
  {
    "objectID": "pages/chapters/experiment_stepbystep.html#√ºbungsexperiment",
    "href": "pages/chapters/experiment_stepbystep.html#√ºbungsexperiment",
    "title": "Experiment erstellen: Step by step",
    "section": "6. √úbungsexperiment",
    "text": "6. √úbungsexperiment\n\nLaden Sie hier das Experiment f√ºr √úbung 1 herunter.\nVergleichen Sie das Experiment mit Ihrer Version, was f√§llt Ihnen auf?"
  },
  {
    "objectID": "pages/chapters/importing_data.html",
    "href": "pages/chapters/importing_data.html",
    "title": "Daten importieren",
    "section": "",
    "text": "Lernziele\n\n\n\n\n\nIn der heutigen Sitzung lernen wir:\n\nMit RStudio arbeiten\nEinzelne Psychopy .csv Datens√§tze importieren\nVariablen ausw√§hlen/umbenennen\nNeue Variablen berechnen\nMehrere Datens√§tze importieren\nMit ChatGPT Code verstehen"
  },
  {
    "objectID": "pages/chapters/importing_data.html#csv-file-importieren",
    "href": "pages/chapters/importing_data.html#csv-file-importieren",
    "title": "Daten importieren",
    "section": "CSV File importieren",
    "text": "CSV File importieren\nWir werden nun das File ZZ_rdk-discrimination_2022_Mar_07_1403.csv aus dem testdata Ordner einlesen. Bevor wir das tun, ist es sinnvoll, sich das File z.B. in Excel anschauen.\n\n\n\n\n\n\nL√∂sung\n\n\n\n√ñffnen Sie ZZ_rdk-discrimination_2022_Mar_07_1403.csv in Excel.\nWas steht in den Spalten? Was steht in den Zeilen?\n\n\nNun k√∂nnen Sie entweder √ºber die GUI-Option (Menu > File > Import Dataset > From text (readr)) oder direkt das File einlesen.\n\ntestdata <- read_csv(\"testdata/ZZ_rdk-discrimination_2022_Mar_07_1403.csv\") \n\nVariablen √ºberpr√ºfen\n\nglimpse(testdata)\n\nRows: 167\nColumns: 39\n$ cue                                        <chr> \"none\", \"left\", \"right\", \"l‚Ä¶\n$ direction                                  <chr> \"right\", \"right\", \"right\", ‚Ä¶\n$ practice_block_loop.thisRepN               <dbl> 0, 0, 0, 0, 0, 0, NA, NA, N‚Ä¶\n$ practice_block_loop.thisTrialN             <dbl> 0, 1, 2, 3, 4, 5, NA, NA, N‚Ä¶\n$ practice_block_loop.thisN                  <dbl> 0, 1, 2, 3, 4, 5, NA, NA, N‚Ä¶\n$ practice_block_loop.thisIndex              <dbl> 5, 2, 1, 0, 4, 3, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisRepN                  <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisTrialN                <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisN                     <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisIndex                 <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ static_isi.started                         <dbl> 0.01033428, 0.03202713, 0.0‚Ä¶\n$ static_isi.stopped                         <dbl> 2.010334, 2.032027, 2.03217‚Ä¶\n$ fixation_pre.started                       <dbl> 26.79425, 36.16522, 44.7852‚Ä¶\n$ fixation_pre.stopped                       <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ image.started                              <dbl> 27.19849, 36.28205, 46.0032‚Ä¶\n$ image.stopped                              <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ fixation_post.started                      <dbl> 28.17814, 37.28240, 47.0037‚Ä¶\n$ fixation_post.stopped                      <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_background.started                    <dbl> 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_background.stopped                    <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_stimulus.started                      <dbl> 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_stimulus.stopped                      <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_keyboard_response.keys                <chr> \"None\", \"f\", \"j\", \"f\", \"Non‚Ä¶\n$ dots_keyboard_response.started             <dbl> 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_keyboard_response.stopped             <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ feedback_text.started                      <dbl> 33.70200, 42.28899, 52.9229‚Ä¶\n$ feedback_text.stopped                      <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_keyboard_response.rt                  <dbl> NA, 0.9339199, 0.8488816, 0‚Ä¶\n$ instruction_main_text.started              <dbl> NA, NA, NA, NA, NA, NA, 81.‚Ä¶\n$ instruction_main_text.stopped              <chr> NA, NA, NA, NA, NA, NA, \"No‚Ä¶\n$ instruction_main_keyboard_response.keys    <chr> NA, NA, NA, NA, NA, NA, \"sp‚Ä¶\n$ instruction_main_keyboard_response.rt      <dbl> NA, NA, NA, NA, NA, NA, 3.1‚Ä¶\n$ instruction_main_keyboard_response.started <dbl> NA, NA, NA, NA, NA, NA, 81.‚Ä¶\n$ instruction_main_keyboard_response.stopped <chr> NA, NA, NA, NA, NA, NA, \"No‚Ä¶\n$ Pseudonym                                  <chr> \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ‚Ä¶\n$ date                                       <chr> \"2022_Mar_07_1403\", \"2022_M‚Ä¶\n$ expName                                    <chr> \"rdk-discrimination\", \"rdk-‚Ä¶\n$ psychopyVersion                            <chr> \"03.02.21\", \"03.02.21\", \"03‚Ä¶\n$ frameRate                                  <dbl> 59.9, 59.9, 59.9, 59.9, 59.‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data.html#practice-trials-l√∂schen",
    "href": "pages/chapters/importing_data.html#practice-trials-l√∂schen",
    "title": "Daten importieren",
    "section": "Practice Trials l√∂schen",
    "text": "Practice Trials l√∂schen\nVielleicht haben Sie bemerkt, dass die ersten 6 Zeilen √úbungstrials sind. Diese wollen wir nicht analysieren, und k√∂nnen folglich gel√∂scht werden.\n\nlibrary(kableExtra)\n\ntestdata |> \n  slice_head(n = 12) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  column_spec(2:7, bold = TRUE) |> \n  row_spec(1:6, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\n\n cue \n    direction \n    practice_block_loop.thisRepN \n    practice_block_loop.thisTrialN \n    practice_block_loop.thisN \n    practice_block_loop.thisIndex \n    main_blocks_loop.thisRepN \n    main_blocks_loop.thisTrialN \n    main_blocks_loop.thisN \n    main_blocks_loop.thisIndex \n    static_isi.started \n    static_isi.stopped \n    fixation_pre.started \n    fixation_pre.stopped \n    image.started \n    image.stopped \n    fixation_post.started \n    fixation_post.stopped \n    dots_background.started \n    dots_background.stopped \n    dots_stimulus.started \n    dots_stimulus.stopped \n    dots_keyboard_response.keys \n    dots_keyboard_response.started \n    dots_keyboard_response.stopped \n    feedback_text.started \n    feedback_text.stopped \n    dots_keyboard_response.rt \n    instruction_main_text.started \n    instruction_main_text.stopped \n    instruction_main_keyboard_response.keys \n    instruction_main_keyboard_response.rt \n    instruction_main_keyboard_response.started \n    instruction_main_keyboard_response.stopped \n    Pseudonym \n    date \n    expName \n    psychopyVersion \n    frameRate \n  \n\n\n none \n    right \n    0 \n    0 \n    0 \n    5 \n    NA \n    NA \n    NA \n    NA \n    0.0103343 \n    2.010334 \n    26.79425 \n    None \n    27.19849 \n    None \n    28.17814 \n    None \n    32.18642 \n    None \n    32.18642 \n    None \n    None \n    32.18642 \n    None \n    33.70200 \n    None \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n left \n    right \n    0 \n    1 \n    1 \n    2 \n    NA \n    NA \n    NA \n    NA \n    0.0320271 \n    2.032027 \n    36.16522 \n    None \n    36.28205 \n    None \n    37.28240 \n    None \n    41.30145 \n    None \n    41.30145 \n    None \n    f \n    41.30145 \n    None \n    42.28899 \n    None \n    0.9339199 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    right \n    0 \n    2 \n    2 \n    1 \n    NA \n    NA \n    NA \n    NA \n    0.0321732 \n    2.032173 \n    44.78521 \n    None \n    46.00329 \n    None \n    47.00374 \n    None \n    52.01072 \n    None \n    52.01072 \n    None \n    j \n    52.01072 \n    None \n    52.92295 \n    None \n    0.8488816 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n left \n    left \n    0 \n    3 \n    3 \n    0 \n    NA \n    NA \n    NA \n    NA \n    0.0321533 \n    2.032153 \n    55.39138 \n    None \n    56.19407 \n    None \n    57.22527 \n    None \n    61.23181 \n    None \n    61.23181 \n    None \n    f \n    61.23181 \n    None \n    62.21611 \n    None \n    0.9396018 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n none \n    left \n    0 \n    4 \n    4 \n    4 \n    NA \n    NA \n    NA \n    NA \n    0.0321391 \n    2.032139 \n    64.71204 \n    None \n    64.81315 \n    None \n    65.84603 \n    None \n    69.25240 \n    None \n    69.25240 \n    None \n    None \n    69.25240 \n    None \n    70.78541 \n    None \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    left \n    0 \n    5 \n    5 \n    3 \n    NA \n    NA \n    NA \n    NA \n    0.0323178 \n    2.032318 \n    73.24960 \n    None \n    74.45209 \n    None \n    75.48391 \n    None \n    79.99045 \n    None \n    79.99045 \n    None \n    f \n    79.99045 \n    None \n    80.80311 \n    None \n    0.7490084 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    81.30346 \n    None \n    space \n    3.187924 \n    81.30346 \n    None \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    0 \n    0 \n    18 \n    0.0160001 \n    2.016000 \n    86.52245 \n    None \n    86.89231 \n    None \n    87.92302 \n    None \n    92.92987 \n    None \n    92.92987 \n    None \n    j \n    92.92987 \n    None \n    93.70924 \n    None \n    0.7136441 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    1 \n    1 \n    31 \n    0.0318162 \n    2.031816 \n    96.17699 \n    None \n    96.54602 \n    None \n    97.57770 \n    None \n    101.58423 \n    None \n    101.58423 \n    None \n    j \n    101.58423 \n    None \n    102.26673 \n    None \n    0.6271285 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n none \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    2 \n    2 \n    66 \n    0.0321148 \n    2.032115 \n    104.76463 \n    None \n    105.13302 \n    None \n    106.16508 \n    None \n    110.67183 \n    None \n    110.67183 \n    None \n    f \n    110.67183 \n    None \n    111.38828 \n    None \n    0.6703410 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n none \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    3 \n    3 \n    75 \n    0.0321121 \n    2.032112 \n    113.88535 \n    None \n    115.08794 \n    None \n    116.11989 \n    None \n    119.52612 \n    None \n    119.52612 \n    None \n    j \n    119.52612 \n    None \n    120.15512 \n    None \n    0.5738488 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n left \n    left \n    NA \n    NA \n    NA \n    NA \n    0 \n    4 \n    4 \n    13 \n    0.0321118 \n    2.032112 \n    122.62295 \n    None \n    123.82583 \n    None \n    124.85742 \n    None \n    129.36397 \n    None \n    129.36397 \n    None \n    j \n    129.36397 \n    None \n    130.25975 \n    None \n    0.8405913 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n\n\n\n\nUm den obigen Code auszuf√ºhren, brauchen Sie das Package kableExtra.\nDie Variable main_blocks_loop.thisN ist die Trialnummer. Diese k√∂nnen wir verwenden, um die Zeilen auszuschliessen, die nicht zum Main Block geh√∂ren.\n\ntestdata |> \n  slice_head(n = 12) |> \n  select(starts_with(\"main_block\")) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  row_spec(1:7, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\n\n main_blocks_loop.thisRepN \n    main_blocks_loop.thisTrialN \n    main_blocks_loop.thisN \n    main_blocks_loop.thisIndex \n  \n\n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n 0 \n    0 \n    0 \n    18 \n  \n\n 0 \n    1 \n    1 \n    31 \n  \n\n 0 \n    2 \n    2 \n    66 \n  \n\n 0 \n    3 \n    3 \n    75 \n  \n\n 0 \n    4 \n    4 \n    13 \n  \n\n\n\n\nMit folgendem Code filtern wir zuerst, so dass , bei wir nur noch Zeilen behalten, bei denen nicht der Wert NA in der Spalte main_blocks_loop.thisN steht. Dann w√§hlen wir alle Spalten ausser practice_block_loop.\n\ntestdata <- testdata |> \n    filter(!is.na(main_blocks_loop.thisN)) |>\n    select(-contains(\"practice_block_loop\"))\n\n\n\n\n\n\n\nChatGPT\n\n\n\nFalls Code nicht verst√§ndlich finden, k√∂nnen Sie ChatGPT fragen. Benutzen Sie folgenden Prompt:\nWhat does the following R code do? \n\ntestdata <- testdata |> \n    filter(!is.na(main_blocks_loop.thisN)) |>\n    select(-contains(\"practice_block_loop\"))"
  },
  {
    "objectID": "pages/chapters/importing_data.html#variablen-ausw√§hlen",
    "href": "pages/chapters/importing_data.html#variablen-ausw√§hlen",
    "title": "Daten importieren",
    "section": "Variablen ausw√§hlen",
    "text": "Variablen ausw√§hlen\nDie folgenden Variablen enthalten Informationen zu den Inter-Trial Intervallen, Fixationskreuzen, Feedback, etc, und sind f√ºr uns an dieser Stelle nicht interessant.\n\ntestdata |>\n    select(contains(\"static\"),\n           contains(\"fixation\"),\n           contains(\"image\"),\n           contains(\"instruction\"),\n           contains(\"feedback\"))\n\n# A tibble: 160 √ó 16\n   static_isi.‚Ä¶¬π stati‚Ä¶¬≤ fixat‚Ä¶¬≥ fixat‚Ä¶‚Å¥ fixat‚Ä¶‚Åµ fixat‚Ä¶‚Å∂ image‚Ä¶‚Å∑ image‚Ä¶‚Å∏ instr‚Ä¶‚Åπ\n           <dbl>   <dbl>   <dbl> <chr>     <dbl> <chr>     <dbl> <chr>     <dbl>\n 1        0.0160    2.02    86.5 None       87.9 None       86.9 None         NA\n 2        0.0318    2.03    96.2 None       97.6 None       96.5 None         NA\n 3        0.0321    2.03   105.  None      106.  None      105.  None         NA\n 4        0.0321    2.03   114.  None      116.  None      115.  None         NA\n 5        0.0321    2.03   123.  None      125.  None      124.  None         NA\n 6        0.0321    2.03   133.  None      135.  None      134.  None         NA\n 7        0.0321    2.03   142.  None      144.  None      143.  None         NA\n 8        0.0321    2.03   152.  None      154.  None      153.  None         NA\n 9        0.0321    2.03   161.  None      163.  None      162.  None         NA\n10        0.0321    2.03   172.  None      173.  None      172.  None         NA\n# ‚Ä¶ with 150 more rows, 7 more variables: instruction_main_text.stopped <chr>,\n#   instruction_main_keyboard_response.keys <chr>,\n#   instruction_main_keyboard_response.rt <dbl>,\n#   instruction_main_keyboard_response.started <dbl>,\n#   instruction_main_keyboard_response.stopped <chr>,\n#   feedback_text.started <dbl>, feedback_text.stopped <chr>, and abbreviated\n#   variable names ¬π‚Äãstatic_isi.started, ¬≤‚Äãstatic_isi.stopped, ‚Ä¶\n\n\nMit select k√∂nnen wir alle Variablen ausser diesen ausw√§hlen.\n\ntestdata <- testdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\ntestdata\n\n# A tibble: 167 √ó 23\n   cue   direc‚Ä¶¬π pract‚Ä¶¬≤ pract‚Ä¶¬≥ pract‚Ä¶‚Å¥ pract‚Ä¶‚Åµ main_‚Ä¶‚Å∂ main_‚Ä¶‚Å∑ main_‚Ä¶‚Å∏ main_‚Ä¶‚Åπ\n   <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 none  right         0       0       0       5      NA      NA      NA      NA\n 2 left  right         0       1       1       2      NA      NA      NA      NA\n 3 right right         0       2       2       1      NA      NA      NA      NA\n 4 left  left          0       3       3       0      NA      NA      NA      NA\n 5 none  left          0       4       4       4      NA      NA      NA      NA\n 6 right left          0       5       5       3      NA      NA      NA      NA\n 7 <NA>  <NA>         NA      NA      NA      NA      NA      NA      NA      NA\n 8 right right        NA      NA      NA      NA       0       0       0      18\n 9 right right        NA      NA      NA      NA       0       1       1      31\n10 none  right        NA      NA      NA      NA       0       2       2      66\n# ‚Ä¶ with 157 more rows, 13 more variables: dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>,\n#   dots_keyboard_response.started <dbl>, dots_keyboard_response.stopped <chr>,\n#   dots_keyboard_response.rt <dbl>, Pseudonym <chr>, date <chr>,\n#   expName <chr>, psychopyVersion <chr>, frameRate <dbl>, and abbreviated\n#   variable names ¬π‚Äãdirection, ¬≤‚Äãpractice_block_loop.thisRepN, ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data.html#variablen-umbennen",
    "href": "pages/chapters/importing_data.html#variablen-umbennen",
    "title": "Daten importieren",
    "section": "Variablen umbennen",
    "text": "Variablen umbennen\nNun wollen Variablen identifizieren, die uns interessieren. Diese wollen wir umbenennen.\n\ntestdata <- testdata |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\ntestdata\n\n# A tibble: 167 √ó 6\n   trial ID    cue   direction response     rt\n   <dbl> <chr> <chr> <chr>     <chr>     <dbl>\n 1    NA ZZ    none  right     None     NA    \n 2    NA ZZ    left  right     f         0.934\n 3    NA ZZ    right right     j         0.849\n 4    NA ZZ    left  left      f         0.940\n 5    NA ZZ    none  left      None     NA    \n 6    NA ZZ    right left      f         0.749\n 7    NA ZZ    <NA>  <NA>      <NA>     NA    \n 8     0 ZZ    right right     j         0.714\n 9     1 ZZ    right right     j         0.627\n10     2 ZZ    none  right     f         0.670\n# ‚Ä¶ with 157 more rows"
  },
  {
    "objectID": "pages/chapters/importing_data.html#neue-variablen-definieren",
    "href": "pages/chapters/importing_data.html#neue-variablen-definieren",
    "title": "Daten importieren",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\nNun wollen wir zwei neue Variablen erstellen: eine ‚Äúcharacter‚Äù Variable, die uns sagt, ob ‚Äúrechts‚Äù oder ‚Äúlinks‚Äù entschieden wurde, und eine numerische Variable mit derselben Information. Je nachdem, ob wir die Daten grafisch darstellen oder analysieren wollen, brauchen wir beide Variablen.\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\nFolgender Code l√∂st das gleiche Problem mit der Funktion as.numeric(). Fragen Sie ruhig ChatGPT, falls Sie den Code nicht verstehen.\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = as.numeric(choice == \"right\"))\n\nWir erstellen ausserdem hier eine Variable, welche angibt, ob der Cue valid, invalid oder neutral war. Ein Cue ist genau dann valide, wenn er dieselbe Richtung hat wie der Random Dot Stimulus, d.h. wenn cue == direction.\n\ntestdata <- testdata |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\n\n\n\n\n\nChatGPT\n\n\n\nWhat does the R function case_when() do?\n\n\nZum Schluss erstellen wir noch eine Variable, welche festh√§lt, ob die Antwort der Versuchsperson korrekt war.\n\ntestdata <- testdata |>\n    mutate(correct = as.numeric(choice == direction))"
  },
  {
    "objectID": "pages/chapters/importing_data.html#gruppierungsvariablen",
    "href": "pages/chapters/importing_data.html#gruppierungsvariablen",
    "title": "Daten importieren",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\n\nglimpse(testdata)\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10‚Ä¶\n$ ID        <chr> \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", ‚Ä¶\n$ cue       <chr> \"none\", \"left\", \"right\", \"left\", \"none\", \"right\", NA, \"right‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"left\", \"left\", \"left\", NA, \"righ‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084, NA, 0.71‚Ä¶\n$ choice    <chr> \"left\", \"left\", \"right\", \"left\", \"left\", \"left\", NA, \"right\"‚Ä¶\n$ condition <chr> \"neutral\", \"invalid\", \"valid\", \"valid\", \"neutral\", \"invalid\"‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,‚Ä¶\n\n\n\ntestdata <- testdata |>\n    mutate_if(is.character, as.factor)\n\n\nglimpse(testdata)\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10‚Ä¶\n$ ID        <fct> ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ‚Ä¶\n$ cue       <fct> none, left, right, left, none, right, NA, right, right, none‚Ä¶\n$ direction <fct> right, right, right, left, left, left, NA, right, right, rig‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084, NA, 0.71‚Ä¶\n$ choice    <fct> left, left, right, left, left, left, NA, right, right, left,‚Ä¶\n$ condition <fct> neutral, invalid, valid, valid, neutral, invalid, NA, valid,‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,‚Ä¶"
  },
  {
    "objectID": "pages/chapters/importing_data.html#accuracy-pro-bedingung",
    "href": "pages/chapters/importing_data.html#accuracy-pro-bedingung",
    "title": "Daten importieren",
    "section": "Accuracy pro Bedingung",
    "text": "Accuracy pro Bedingung\nWir k√∂nnen nun die accuracy in jeder Cue-Bedingung berechnen. Es gibt hier zwei M√∂glichkeiten: wir berechen die Anzahl Trials (N), und die Anzahl korrekter Antworten (ncorrect) separat. Der Anteil korrekter Antworten ist dann einfach ncorrect/N. Dasselbe Ergebnis erhalten wir, wenn wir einfach den Mittelwert der korrekten Antworten nehmen.\n\ntestaccuracy <- testdata |>\n    group_by(condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = ncorrect/N,\n              accuracy2 = mean(correct))\n\ntestaccuracy\n\n# A tibble: 4 √ó 5\n  condition     N ncorrect accuracy accuracy2\n  <fct>     <int>    <dbl>    <dbl>     <dbl>\n1 invalid      18       14    0.778     0.778\n2 neutral      82       67    0.817     0.817\n3 valid        66       62    0.939     0.939\n4 <NA>          1       NA   NA        NA"
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html",
    "href": "pages/chapters/psychopy_experiments.html",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "",
    "text": "Neurowissenschaftliche Experimente m√ºssen exakt auf die Fragestellung zugeschnitten werden um aussagekr√§ftige Daten zu liefern. Deshalb programmieren die meisten Forschenden ihre Experimentalparadigmen selbst. So k√∂nnen beispielsweise Instruktionen oder verwendete Stimuli, deren Gr√∂sse und Anzeigedauer pr√§zise definiert werden. In dieser Sitzung erstellen wir mit PsychoPy ein perzeptuelles Entscheidungsexperiment, √§hnlich dem Experiment aus Mulder et al. (2012). Dieses neurowissenschaftliche Experiment untersucht den Einfluss von Vorwissen auf Entscheidungsverhalten von Menschen sowie die dazugeh√∂rigen neuronalen Korrelate."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#ablauf",
    "href": "pages/chapters/psychopy_experiments.html#ablauf",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Ablauf",
    "text": "Ablauf\nDas Experiment besteht aus der Instruktion, mehreren Versuchsbl√∂cken und der Nachbesprechung. Die Anweisungen und die Nachbesprechung sind Textanzeigen, w√§hrend die Versuche (und die Versuchsbl√∂cke) etwas komplizierter sind."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#trial",
    "href": "pages/chapters/psychopy_experiments.html#trial",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Trial",
    "text": "Trial\nZun√§chst wird ein Fixationskreuz entweder f√ºr 100 ms, 350 ms, 800 ms oder 1200 ms angezeigt. Die tats√§chliche Dauer wird f√ºr jeden Versuch randomisiert. Eine solche Randomisierung kann nicht √ºber die Benutzeroberfl√§che vorgenommen werden, sondern erfordert ein kleines St√ºck Python-Code. Sehen Sie sich den Codeblock der Routine Fixation_pre_cue an, um zu erfahren, wie dies erreicht werden kann.\n\nDas Experiment wurde im Scanner und ausserhalb durchgef√ºhrt. Die beiden Version unterscheiden sich ganz stark in ihrem Timing. Wir implementieren hier die Scanner Version des Tasks.\n\nAnschlie√üend wird f√ºr 1000 ms ein Hinweis (cue) pr√§sentiert. Dabei kann es sich entweder um einen Pfeil handeln, der nach rechts zeigt, einen Pfeil, der nach links zeigt, oder einen einfachen Kreis (f√ºr die Kontrollbedingung). Der Codeblock in der Cue-Routine legt den tats√§chlichen Hinweis f√ºr jeden Versuch auf der Grundlage der Schleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz pr√§sentiert - dieses Mal f√ºr entweder 3400 ms, 4000 ms, 4500 ms oder 5000 ms. Wie beim ersten Fixationskreuz wird die tats√§chliche Dauer zuf√§llig gew√§hlt.\nNach dem zweiten Fixationskreuz wird f√ºr 1500 ms der eigentliche Stimulus angezeigt: ein random dot kinematogram (RDK). Die Punkte bewegen sich entweder nach rechts oder nach links mit einem Koh√§renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs wird durch die Schleifenvariable direction bestimmt und im Codeblock der Routine Dots festgelegt. Die Teilnehmer m√ºssen entscheiden, welche Richtung sie wahrnehmen, und k√∂nnen ihre Antwort durch Dr√ºcken der linken oder rechten Pfeiltaste auf der Tastatur eingeben.\nSchlie√ülich wird ein Feedback-Bildschirm angezeigt. Wenn der Teilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis ‚Äúzu schnell‚Äù angezeigt. Wurde w√§hrend des gesamten Stimulus keine Antwort erfasst, wird das Wort ‚Äúmiss‚Äù angezeigt. War die Antwort richtig, wird ‚Äú+5 Punkte‚Äù angezeigt, war sie falsch, wird ‚Äú+0 Punkte‚Äù angezeigt."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "href": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Experimentalschleife: main_blocks_loop",
    "text": "Experimentalschleife: main_blocks_loop\nMit loops in PsychoPy haben wir die M√∂glichkeit, eine oder mehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt, um denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber jedes Mal mit anderen Werten f√ºr die loop variables. Eine Schleife wiederholt also einen Versuch einige Male, wobei die Schleifenvariablen bei jeder Wiederholung ge√§ndert werden. Der Versuch selbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen, ob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird nur die main_blocks_loop erkl√§rt, aber das Prinzip gilt auch f√ºr die practice_block_loop.\nUm die verschiedenen Werte f√ºr die Schleifenvariablen zu definieren, m√ºssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop Variablen cue und direction. Das Stichwort kann entweder left, right oder none, sein, w√§hrend die Richtung left oder right sein kann.\nIn der Benutzeroberfl√§che k√∂nnen wir die Variablen loopType und nReps f√ºr die Schleife angeben, wenn wir sie anklicken. Mit ersterer k√∂nnen wir steuern, ob wir z.B. die Zeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach unten ablaufen lassen wollen, w√§hrend die letztere definiert, wie oft jede Zeile der Bedingungsdatei wiederholt werden soll.\nF√ºr die main_blocks_loop haben wir eine Bedingungsdatei mit 80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen entsprechen. In der einen H√§lfte der neutralen Trials bewegen sich die Punkte nach rechts, in der anderen H√§lfte nach links. Bei den voreingenommenen Versuchen sind 32 der Hinweise g√ºltig (d.¬†h. sie stimmen mit der Bewegungsrichtung der Punkte √ºberein) und 16 ung√ºltig, wobei sich die Punkte sowohl bei g√ºltigen als auch bei ung√ºltigen Hinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der Versuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so dass alle diese Reihen zweimal durchlaufen werden (insgesamt 160 Versuche), und die Variable ‚ÄúloopType‚Äù wird auf random gesetzt, so dass die Versuche in zuf√§lliger Reihenfolge durchgef√ºhrt werden."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#daten",
    "href": "pages/chapters/psychopy_experiments.html#daten",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Daten",
    "text": "Daten\nWenn man die default-Einstellungen nicht √§ndert, speichert PsychoPy die Daten automatisch in einem trial-by-trial CSV File. Das bedeutet, dass jeder Trial 1 Zeile generiert. Das CSV File erh√§lt einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es m√∂glich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV Files werden in einem Ordner mit dem Name data abgelegt.\n\nBei der Wahl vom Datenfile-Namen empfiehlt es sich immer Datum und Uhrzeit anzuh√§ngen. Dies verhindert, dass Daten √ºberschrieben werden, wenn z.B. eine Versuchspersonen-ID falsch eingetippt oder doppelt vergeben wird."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "href": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Degrees of Visual Angle",
    "text": "Degrees of Visual Angle\nOftmals werden Gr√∂ssenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abh√§ngig sind. Degrees of visual angle gibt die wahrgenommene Gr√∂sse des Stimulus an, und ber√ºcksichtigt die Gr√∂sse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von üëâ OpenSesame. √úblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem üëâ Link mehr Information.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm f√ºr die Erstellung behavioraler Experimente."
  },
  {
    "objectID": "pages/chapters/software.html",
    "href": "pages/chapters/software.html",
    "title": "Programmiersprachen",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit dem Einsatz vom Computern im Bereich Cognitive Neuroscience. Es ist nicht Ziel dieses Kurses, EEG oder fMRI Daten zu analysieren (daf√ºr gibt es eigene Kurse); wir werden uns stattdessen mit Daten aus Verhaltensexperimenten besch√§ftigen. Dies sind zum Beispiel bin√§re Antworten oder Reaktionszeiten, welche wir mit entsprechenden Modellen untersuchen werden. Unsere Anwendungsbeispiele werden immer aus der neurowissenschaftlichen Forschung stammen; der Fokus wird aber vor allem der Umgang mit Computern sein. Unser Ziel ist es, dass Sie nach dem Abschluss dieses Kurses eine neurowissenschaftliches Paper lesen k√∂nnen, und die darin verwendeten Experimente nachvollziehen k√∂nnen. Sie k√∂nnten eventuell sogar das Experiment selber programmieren, und die Daten analysieren."
  },
  {
    "objectID": "pages/chapters/software.html#programmiersprachen",
    "href": "pages/chapters/software.html#programmiersprachen",
    "title": "Programmiersprachen",
    "section": "Programmiersprachen",
    "text": "Programmiersprachen\nProgrammiersprachen sind essentielle Werkzeuge f√ºr die Neurowissenschaftliche Forschung. Wir werden uns zuerst einen kurzen √úberblick √ºber drei h√§ufig verwendete Programmiersprachen (Matlab, Python und R) verschaffen und kurz deren Verwendungszwecke und Vor- und Nachteile diskutieren.\n\nMatlab\nMatlab ist ein Software f√ºr numerische Anwendung, welche in den Ingenieurwissenschaften, Naturwissenschaften und der Mathematik weit verbreitet ist.\n\nüëçüèº St√§rken:\n\nLeistungsstarke Matrix- und Vektoroperationen, gut geeignet f√ºr Matrix-basierte Operationen, die in der Neurowissenschaftlichen Forschung h√§ufig vorkommen.\nUmfangreiche Bibliothek von integrierten Funktionen f√ºr wissenschaftliches Rechnen.\n\n\n\nüëéüèº Schw√§chen:\n\nTeuer\nWeniger flexibel als Python oder R in Bezug auf Datenarten und Strukturen.\nMatlab is kommerziell und propriet√§r. Dies bedeutet man muss teuere Lizenzen kaufen, und der Source Code der Software ist nicht offen.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nSignalverarbeitung\nVisualisierung\nViele fMRI Forscher arbeiten mit Matlab, da es daf√ºr eine spezielle Toolbox gibt: SPM\nExperimente programmieren, z.B. mit Psychtoolbox\n\n\n\nBeispielcode:\nload('data.mat')\nfs = 1000;\nt = (0:numel(data)-1)/fs;\nplot(t, data)\n\n\n\nPython\nPython ist eine allgemeine (general purpose) Programmiersprache, die in vielen verschiedenen Bereichen wie wissenschaftlichem Rechnen, Datenanalyse und maschinellem Lernen weit verbreitet ist.\n\nüëçüèº St√§rken:\n\nEine Vielzahl von Bibliotheken und Modulen wie NumPy, SciPy und Pandas, die leistungsstarke Werkzeuge f√ºr wissenschaftliches Rechnen und Datenanalyse bieten.\nDatenanalysewerkzeuge wie Pandas-Dataframes, die Seaborn-Visualisierungsbibliothek, und Jupyter Notebooks.\nOpen-source und kostenlos\n\n\n\nüëéüèº Schw√§chen:\n\nKann in einigen numerischen Berechnungen langsamer sein als Matlab.\nDa Python eine allgemeine Sprache ist, muss man f√ºr numerische Anwendungen immer verschiedene Packages importieren (z.B.) numpy, wenn man damit rechnen will. Dies f√ºhrt zu weniger gut lesbarem Code.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nVisualisierung\nMachine learning und K√ºnstliche Intelligenz\nExperimente programmieren, z.B. mit PsychoPy\n\n\n\nBeispielcode:\nimport pandas as pd\nimport seaborn as sns\ndata = pd.read_csv('data.csv')\nsns.lineplot(data=data, x='time', y='voltage')\n\n\n\nR\nR ist eine Programmiersprache und Umgebung f√ºr statistisches Rechnen und Grafiken.\n\nüëçüèº St√§rken:\n\nEntwickelt von Statistikern f√ºr statistisches Rechnen und Grafiken.\nEine gro√üe Bibliothek von statistischen Werkzeugen und Paketen, einschliesslich Visualisierungspackages (grammar of graphics).\nOpen-source und kostenlos\ntidyverse Packages f√ºr Data Wrangling (sehr elegante Syntax, um mit Daten zu arbeiten).\n\n\n\nüëéüèº Schw√§chen:\n\nSteilere Lernkurve als Python.\nKann in einigen numerischen Berechnungen langsamer sein als Matlab oder Python.\nEntwickelt von Statistiker (nicht von Software Designers). R gilt als sehr idiosynkratisch.\n\n\n\nTypische Anwendung:\n\nStatistische Analyse\nDatenvisualisierung. R hat eine sehr gute Bibliothek f√ºr Grafiken, die ggplot2 Bibliothek. Diese Bibliothek verwendet die sogenannte grammar of graphics (GoG) - eine Methode, um Daten in Grafiken zu visualisieren. Die GoG ist eine sehr elegante und effiziente Methode, um Daten zu visualisieren.\n\n\n\nBeispielcode:\nlibrary(tidyverse)\ndata <- read.csv('data.csv')\nggplot(data, aes(x=time, y=voltage)) + geom_line()\n\n\n\nFazit\nMatlab, Python und R sind leistungsstarke Werkzeuge f√ºr die neurowissenschaftliche Forschung. Die Wahl der Sprache h√§ngt unter anderem von der spezifischen Aufgabe ab. Weitere Faktoren ist Tradition: bestimmte Gruppen bevorzugen eher eine Sprache als andere. So ist Matlab unter Ingenieuren weit verbreiten und R unter Statistikern. Python ist im Bereich K√ºnstliche Intelligenz und Machine Learning die beliebteste Sprache. Eine neuere Sprache ist Julia - diese vereint die Vorteile aller oben genannten Sprachen (ohne viele deren Nachteile), ist aber weniger weit verbreitet.\nUm mehr zu erfahren, erkunden Sie die umfangreichen Online-Ressourcen und Dokumentationen f√ºr jede Sprache."
  },
  {
    "objectID": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "href": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "title": "Programmiersprachen",
    "section": "In dieser Veranstaltung verwendete Software",
    "text": "In dieser Veranstaltung verwendete Software\nWir haben uns entschieden, in dieser Veranstaltung Python zu verwenden, um ein Experiment zu erstellen, und R f√ºr die Analyse der Daten. Matlab wird nicht verwendet; einerseits da es kommerziell ist, andererseits weil es aus unserer Sicht nicht die beste Wahl f√ºr die Analyse von Verhaltensdaten ist. Ausserdem ist es schon schwierig genug, eine Programmiersprache zu lernen, ohne gleichzeitig noch zwei weitere zu lernen."
  },
  {
    "objectID": "pages/chapters/software.html#python-1",
    "href": "pages/chapters/software.html#python-1",
    "title": "Programmiersprachen",
    "section": "Python",
    "text": "Python\nWenn Sie Python suf Ihrem Rechner installieren wollen, k√∂nnen Sie entweder den offiziellen Installer https://www.python.org/downloads/ downloaden, oder die Anaconda Distribution https://www.anaconda.com/products/distribution verwenden. Die Anaconda Distribution ist eine Python-Distribution, die viele n√ºtzliche Pakete enth√§lt, die f√ºr wissenschaftliches Rechnen und Datenanalyse verwendet werden. Wenn man tats√§chlich mit Python arbeiten will, empfiehlt es sich, die Anaconda Distribution zu benutzen. Wir werden in dieser Veranstaltung Python benutzen, um ein Experiment zu programmieren. Daf√ºr reicht es aus, den PsychoPy Installer zu verwenden; diesen finden Sie unter diesem Link: PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen Benutzeroberfl√§che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/chapters/software.html#r-1",
    "href": "pages/chapters/software.html#r-1",
    "title": "Programmiersprachen",
    "section": "R",
    "text": "R\nAb der vierten Sitzung werden wir viel mit R arbeiten, um Daten aufzubereiten und grafisch darzustellen. Daf√ºr m√ºssen Sie die aktuelle Version von R installieren. Diese ist zurzeit R 4.2.2, und kann unter folgender URL geladen werden:\nR üëâ https://cloud.r-project.org/\nWir empfehlen f√ºr die Arbeit mit R die RStudio IDE zu verwenden. Diese ist kostenlos und kann unter folgender URL heruntergeladen werden:\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "pages/chapters/software.html#lernen",
    "href": "pages/chapters/software.html#lernen",
    "title": "Programmiersprachen",
    "section": "Lernen",
    "text": "Lernen\nDataCamp"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html",
    "href": "pages/chapters/summarizing-data.html",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "",
    "text": "Vertiefung\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden\nOb eine Variable als factor definiert ist, wird als Attribut gespeichert. Attribute werden aber in einem .csv. File nicht mitgespeichert; deshalb m√ºssen wir die Gruppierungsvariablen wieder als factor definieren."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-versuchsperson",
    "href": "pages/chapters/summarizing-data.html#pro-versuchsperson",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Pro Versuchsperson",
    "text": "Pro Versuchsperson\n\ndata\n\n# A tibble: 1,440 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\ndata |> \n  group_by(ID, condition)\n\n# A tibble: 1,440 √ó 9\n# Groups:   ID, condition [27]\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\naccuracy\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#visualisieren",
    "href": "pages/chapters/summarizing-data.html#visualisieren",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Visualisieren",
    "text": "Visualisieren\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead."
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#√ºber-versuchsperson-aggregieren",
    "href": "pages/chapters/summarizing-data.html#√ºber-versuchsperson-aggregieren",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "√úber Versuchsperson aggregieren",
    "text": "√úber Versuchsperson aggregieren"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#ein-exkurs-√ºber-within-person-standardfehler",
    "href": "pages/chapters/summarizing-data.html#ein-exkurs-√ºber-within-person-standardfehler",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Ein Exkurs √ºber Within-person Standardfehler",
    "text": "Ein Exkurs √ºber Within-person Standardfehler\n\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as.factor(subject))\n\n\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n\n\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\n\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60)\n\n\n\n\n\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n\n\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, idvar=\"subject\", measurevar=\"value\")\n?Rmisc::normDataWithin\n\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\n\n# Show the between-S CI's in red, and the within-S CI's in black\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), data=dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#within-person-standardfehler",
    "href": "pages/chapters/summarizing-data.html#within-person-standardfehler",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Within-person Standardfehler",
    "text": "Within-person Standardfehler\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nDer Standardfehler is definiert als: \\[SE = sd/ \\sqrt{n}\\]\nLeider gibt es in R keine Funktion, welche den Standardfehler berechnet (sch√§tzt); wir k√∂nnen aber ganz einfach selber eine Funktion definieren.\n\nse <- function(x) sd(x)/sqrt(length(x))\n\n\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             ccuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n# A tibble: 3 √ó 5\n  condition     N ccuracy    sd     se\n  <fct>     <int>   <dbl> <dbl>  <dbl>\n1 invalid     144   0.389 0.489 0.0408\n2 neutral     720   0.629 0.483 0.0180\n3 valid       576   0.825 0.381 0.0159\n\n\n\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n\n\n\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n\n\n\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#pro-versuchsperson-1",
    "href": "pages/chapters/summarizing-data.html#pro-versuchsperson-1",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Pro Versuchsperson",
    "text": "Pro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und Standarabweichung zusammen.\n\nfuns <- list(mean = mean, median = median, sd = sd)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\nby_subj \n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition  mean median     sd\n   <fct> <fct>     <dbl>  <dbl>  <dbl>\n 1 JH    invalid   0.775  0.739 0.163 \n 2 JH    neutral   0.799  0.733 0.202 \n 3 JH    valid     0.696  0.658 0.190 \n 4 NS    invalid   0.894  0.913 0.207 \n 5 NS    neutral   0.885  0.844 0.201 \n 6 NS    valid     0.738  0.715 0.191 \n 7 rh    invalid   0.423  0.389 0.151 \n 8 rh    neutral   0.525  0.503 0.0841\n 9 rh    valid     0.443  0.390 0.185 \n10 sb    invalid   0.376  0.341 0.0924\n# ‚Ä¶ with 17 more rows\n\n\nEinfachere Version:\n\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\n\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\nse <- function(x, ...) sd(x, ...)/sqrt(length(x))\n\nby_subj <- data %>% \n  group_by(ID, condition) %>% \n  summarise(mean = mean(rt, na.rm = TRUE), \n            median = median(rt, na.rm = TRUE), \n            sd = sd(rt, na.rm = TRUE), \n            se = se(rt, na.rm = TRUE))\n\n\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")"
  },
  {
    "objectID": "pages/chapters/summarizing-data.html#√ºber-versuchsperson-aggregieren-1",
    "href": "pages/chapters/summarizing-data.html#√ºber-versuchsperson-aggregieren-1",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "√úber Versuchsperson aggregieren",
    "text": "√úber Versuchsperson aggregieren\n\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n  condition   N        rt        sd         se         ci\n1   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n\n\n\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\np_rt\n\n\n\n\n\nlibrary(patchwork)\n\n\np_accuracy / p_rt"
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html",
    "href": "pages/chapters/uebung_1_experiment.html",
    "title": "√úbung 1",
    "section": "",
    "text": "In dieser √úbung f√ºhren Sie mit zwei Personen das Random Dot Experiment durch und laden die Datens√§tze hoch. In dieser √úbung gibt es kein Peer Feedback. Die erhobenen Daten werden wir dann in den kommenden Sitzungen verwenden."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#random-dot-experiment-durchf√ºhren",
    "href": "pages/chapters/uebung_1_experiment.html#random-dot-experiment-durchf√ºhren",
    "title": "√úbung 1",
    "section": "Random Dot Experiment durchf√ºhren",
    "text": "Random Dot Experiment durchf√ºhren\n\nDas fertige Experiment befindet sich auf Github. Sie k√∂nnen es unter diesem Link downloaden. (Wenn Sie auf den gr√ºnen Button Code klicken, kann man das Experiment als Zip-Datei herunterladen: Download ZIP)\nF√ºhren Sie das Experiment ein- oder mehrere Male selber durch. Kontrollieren Sie, ob ein Datensatz gespeichert wird.\nTesten Sie zwei Personen (Alter zwischen 20 und 60 Jahre). Diese Personen sollten die Hypothese nicht kennen (also keine Mitstudierende aus dem ComputerLab)."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#datenabgabe",
    "href": "pages/chapters/uebung_1_experiment.html#datenabgabe",
    "title": "√úbung 1",
    "section": "Datenabgabe",
    "text": "Datenabgabe\n\nDaten abgeben: Zippen Sie bitte die .csv-Datens√§tze der getesteten Personen (nicht von den Selbsttests) und laden Sie das ZIP File bis in 10 Tagen auf ILIAS."
  },
  {
    "objectID": "pages/chapters/uebung_1_experiment.html#trouble-shooting",
    "href": "pages/chapters/uebung_1_experiment.html#trouble-shooting",
    "title": "√úbung 1",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nBitte Fehlermeldung im Fenster genau durchlesen. Dort finden Sie Hinweise darauf, was schief gelaufen ist.\nDas Experiment startet nicht.\n\nUnter Einstellungen (Radsymbol) den Reiter Basic ausw√§hlen. Bei Use PsychoPy version die laufende PsychoPy Version ausw√§hlen (z.B. 2022.2.5).\n\nDas Experiment startet zwar, der Bildschirm ist aber dann einfach f√ºr eine kurze Zeit grau und das Fenster schliesst sich wieder.\n\nZugriffsrechte gegeben?\nUnter Einstellungen (Radsymbol) den Reiter Input ausw√§hlen. Keyboard Backend auf PsychToolbox statt ioHub."
  },
  {
    "objectID": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "href": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "title": "1. Sitzung",
    "section": "(Model-based) Cognitive Neuroscience",
    "text": "(Model-based) Cognitive Neuroscience\n\n\nWas heisst Model-based Neuroscience?\nWelche Kenntnisse brauchen wir, um Experiment durchzuf√ºhren und Daten auszuwerten?\nWelche Programmiertechniken/sprachen brauchen wir?"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "href": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience: Beispiel",
    "text": "Model-based Neuroscience: Beispiel\nMulder, M. J., Wagenmakers, E.-J., Ratcliff, R., Boekel, W., & Forstmann, B. U. (2012). Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff. Journal of Neuroscience, 32(7), 2335‚Äì2343.\nüëâ https://www.jneurosci.org/content/32/7/2335\nIn dieser Studie geht es darum, den Einfluss von Vorwissen (prior knowledge) auf eine simple perzeptuelle Entscheidung zu untersuchen.\n\nAls Task haben die Autoren ein Random Dot Motion Experiment benutzt.\nF√ºr die Datenanalyse wurde unter anderem ein Diffusion Decision Model verwendet."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model",
    "href": "slides/01_introduction.html#diffusion-decision-model",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience",
    "href": "slides/01_introduction.html#model-based-neuroscience",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\n√úberfliegen Sie das Paper, und achten Sie dabei darauf, welche Skills Sie ben√∂tigen, um eine solche Studie durchzuf√ºhren.\n\nWelches theoretische Wissen brauchen Sie?\nWelche Programmierkenntnisse brauchen Sie?\n\nf√ºr das Experiment\nf√ºr die Datenanalyse\n\nWelche statistischen Verfahen brauchen Sie, um die Daten auszuwerten?\nWarum wurde das Experiment im Scanner und ausserhalb des Scanners durchgef√ºhrt?\nWas kann man mit einer solchen Studie herausfinden?"
  },
  {
    "objectID": "slides/01_introduction.html#vorwissen",
    "href": "slides/01_introduction.html#vorwissen",
    "title": "1. Sitzung",
    "section": "Vorwissen",
    "text": "Vorwissen\nEs wurden zwei verschiedene Typen von Vorwissen benutzt.\n\nA-Priori Wahrscheinlichkeit, dass die Punktwolke sich nach rechts oder nach links bewegte.\nAsymmetrische Belohnung f√ºr korrekte links/rechts Entscheidungen."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model-1",
    "href": "slides/01_introduction.html#diffusion-decision-model-1",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-1",
    "href": "slides/01_introduction.html#model-based-neuroscience-1",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\n\nSchematische Darstellung der erwarteten Resultate.\n\nStarting point: korrekte und inkorrekte RTs unterschieden sich.\nDrift rate: korrekte und inkorrekte RTs sind sich √§hnlich.\n\n\n\nTats√§chliche Resultate: Quantifizierung des Bias anhand des DDM."
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-2",
    "href": "slides/01_introduction.html#model-based-neuroscience-2",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\nBOLD Responses der Areale welche besonder stark sowohl auf die ‚Äúprior probability‚Äù als auch auf die ‚Äúpayoff‚Äù Manipulation reagierten.\n\n\n\nright MedFG (right medial frontal gyrus)\nACG (anterior cingulate cortex)\nSFG (superior frontal gyrus)\nleft middle temporal gyrus\nIPS (intra-parietal sulcus).\n\n\n\n\n\nDiese Areale sollen eine besondere Rolle in der Verarbeitung von Bias im Entscheidungsverhalten haben."
  },
  {
    "objectID": "slides/01_introduction.html#wichtige-skills",
    "href": "slides/01_introduction.html#wichtige-skills",
    "title": "1. Sitzung",
    "section": "Wichtige Skills",
    "text": "Wichtige Skills\n\n\n\nTheorien √ºber Entscheidungsverhalten\nExperimente programmieren\n\nTiming (inside/outside scanner)\n\nData cleaning and manipulation (data wrangling)\nStatistische Verfahren f√ºr messwiederholte Daten\n\nPsychometric curve\nBinary choices / Reaktionszeiten\nrepeated-measures ANOVA\n\n\n\n\nGrafische Darstellung der Resultate\nKognitive Prozessmodelle\n\nfit Diffusion Decision Model (DDM)\n\nAuswertung von fRMI Daten\n\n\n\n\nMit diesen Themen (ausser der Analyse von fMRI Daten) besch√§ftigen wir uns in diesem Kurs.\n\n\n\nüè† Neurowissenschaft im Computerlab FS22"
  },
  {
    "objectID": "slides/02_psychopy.html#bias-rdk-experiment",
    "href": "slides/02_psychopy.html#bias-rdk-experiment",
    "title": "2. Sitzung",
    "section": "Bias RDK Experiment",
    "text": "Bias RDK Experiment\n\n\n\nRandom-dot motion direction-discrimination task\nInside/outside scanner (timing)\nBias: cue (probability left/right/unbiased)\nFixation cross\nRDK: 3x3 pixels, coherence\n40 bias trials, 40 neutral trials\n32 valid, 8 invalid trials"
  },
  {
    "objectID": "slides/02_psychopy.html#psychopy",
    "href": "slides/02_psychopy.html#psychopy",
    "title": "2. Sitzung",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy.html#pavlovia",
    "href": "slides/02_psychopy.html#pavlovia",
    "title": "2. Sitzung",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy.html#understanding-your-computer",
    "href": "slides/02_psychopy.html#understanding-your-computer",
    "title": "2. Sitzung",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: Variabilit√§t ~15 ms.\nScreen refresh f√§ngt oben an und endet (~10 ms sp√§ter) unten."
  },
  {
    "objectID": "slides/02_psychopy.html#probieren-sie-es-selber",
    "href": "slides/02_psychopy.html#probieren-sie-es-selber",
    "title": "2. Sitzung",
    "section": "Probieren Sie es selber!",
    "text": "Probieren Sie es selber!\n\nVersuchen Sie selber, Teile des Experiments in PsychoPy zu implementieren\n\n\nWenn Sie eine Starthilfe ben√∂tigen, downloaden Sie ein Beipiel: üëâ Practice Trials\nEine Einf√ºhrung finden Sie hier: üëâ Verhaltensexperiment mit PsychoPy\n\n\n\n\nüè† Neurowissenschaft im Computerlab FS23"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#perceptual-decisions",
    "href": "slides/02_psychopy_gw.html#perceptual-decisions",
    "title": "PsychoPy Experiment",
    "section": "Perceptual decisions",
    "text": "Perceptual decisions\n\nberuhen auf der Wahrnehmung, Evaluation, Integration von Sinnesempfindungen\nsind oft handlungsrelevant\nneurowissenschaftlich untersucht werden die neuronalen Schaltkreise welche Wahrnehmungssignale kodieren, speichern und analysieren und wie diese mit Verhalten zusammenh√§ngen\nm√∂gliche Fragenstellungen: Gewichtung von Sinnesinformationen bei sensorischen Konflikten oder der Einfluss von Vorwissen auf Entscheidungen\n\n\n\n\n\n\n\nHands-on\n\n\n\nIn welchen Situationen treffen wir perzeptuelle Entscheidungen?\nWo ist der Einfluss von Vorwissen auf perzeptuelle Entscheidungen alltagsrelevant?\n\nDiskutieren Sie die Fragen in kleinen Gruppen und finden Sie je 3 Beispiele."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-i",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-i",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment I",
    "text": "Random-dot motion Experiment I\n\n\n\nRandom-dot motion direction-discrimination task (Bias in the brain: Mulder et al., 2012)\ncoherence: probability that a dot moves coherent with the motion direction\nbias: prior probabity cue before random-dot task (left/right/unbiased) or reward cue for a left or right answer (if correct)\nmeasures: response times and accuracy"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-ii",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-ii",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment II",
    "text": "Random-dot motion Experiment II\n\n\n\n\n\n\nHands-on\n\n\nWie wirken sich die beiden Formen von Vorwissen auf das Antwortverhalten aus?\n\nBei welcher Bedingung antworten die Personen schneller?\nWo machen sie mehr Fehler?\n\nWas denken Sie? Diskutieren Sie die Fragen in kleinen Gruppen ohne im Paper nachzuschauen."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iii",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iii",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment III",
    "text": "Random-dot motion Experiment III"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iv",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iv",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment IV",
    "text": "Random-dot motion Experiment IV\n\nStimuli\n\nrandom dots: 3x3 pixels, coherence level: 8%\n\nConditions\n\n40 bias trials and 40 neutral trials (half of motion to left / other half to the right)\n32 valid (cue correct) and 8 invalid (cue incorrect) trials\n\nTrials and Timing\n\nFixation 1 (100/350/800/1200 ms)\nCue (1000 ms)\nFixation 2 (3400/4000/4500/5000 ms)\nDots (1500 ms)\nFeedback"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#psychopy",
    "href": "slides/02_psychopy_gw.html#psychopy",
    "title": "PsychoPy Experiment",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#pavlovia",
    "href": "slides/02_psychopy_gw.html#pavlovia",
    "title": "PsychoPy Experiment",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#understanding-your-computer",
    "href": "slides/02_psychopy_gw.html#understanding-your-computer",
    "title": "PsychoPy Experiment",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: Variabilit√§t ~15 ms.\nScreen refresh f√§ngt oben an und endet (~10 ms sp√§ter) unten."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#stimuli",
    "href": "slides/02_psychopy_gw.html#stimuli",
    "title": "PsychoPy Experiment",
    "section": "Stimuli",
    "text": "Stimuli\nErstellen Sie einen Random Dot Stimulus. Implementieren Sie dabei so genau wie m√∂glich die Parameter von Mulder et al.¬†2012\nBeachten Sie folgende Aspekte:\n\nTiming (Stimulusdauer)\nFarbe\nGr√∂sse\nKoh√§renz\n\n(Die Bewegungsrichtung k√∂nnen Sie noch vernachl√§ssigen.)"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#trial-i",
    "href": "slides/02_psychopy_gw.html#trial-i",
    "title": "PsychoPy Experiment",
    "section": "Trial I",
    "text": "Trial I\nErstellen Sie einen Trial noch ohne Instruktion f√ºrs Vorwissen. Implementieren Sie dabei so genau wie m√∂glich die Parameter von Mulder et al.¬†2012\n\nBewegungsrichtung (inkl. conditions.csv file)\nFixationskreuze\nTiming (ITI: Inter-Trial-Intervall)\nAntwort der Versuchsperson aufnehmen\n\n(Die Instruktion bez√ºglich Vorwissen k√∂nnen Sie noch vernachl√§ssigen.)"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#trial-ii",
    "href": "slides/02_psychopy_gw.html#trial-ii",
    "title": "PsychoPy Experiment",
    "section": "Trial II",
    "text": "Trial II\nErstellen Sie einen Trial mit Vorwissen. Implementieren Sie dabei so genau wie m√∂glich die Parameter von Mulder et al.¬†2012\nBeachten Sie folgende Aspekte:\n\nCue / Vorwissen kann valide, invalide, neutral sein\nstimmt in 3 von 4 F√§llen"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#instruktion-debriefing",
    "href": "slides/02_psychopy_gw.html#instruktion-debriefing",
    "title": "PsychoPy Experiment",
    "section": "Instruktion & Debriefing",
    "text": "Instruktion & Debriefing\nF√ºgen Sie eine Instruktion und ein kurzes Debriefing hinzu.\n\n\n\nüè† Neurowissenschaft im Computerlab FS23"
  },
  {
    "objectID": "pages/exercises/exercise_01.html",
    "href": "pages/exercises/exercise_01.html",
    "title": "√úbung 1",
    "section": "",
    "text": "Vertiefung\n\n\n\nDiese √úbung muss nicht abgegeben werden; sie dient als Vorbereitung f√ºr die folgende Sitzung.\n\n\n\n\nInstallieren Sie PsychoPy von der Website. PsychoPy ist ein Open-Source Programm f√ºr MacOS, Windows und Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente (Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren k√∂nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI Scanner und mit EEG verwenden.\nPsychoPy üëâ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das ‚ÄúStandalone package‚Äù f√ºr MacOS oder Windows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu bereiten ‚Äî es ist daher (zurzeit noch) besser, die Version 2021.2.3 zu installieren.\n\n\n\n\n\nWas verstehen Sie unter folgenen Begriffen:\n\n\nModel-based Neuroscience\nEvidence accumulation\n\n\nWas k√∂nnte man unter Vorwissen (prior knowledge) verstehen? In welchen Kontexten k√∂nnte es bei Entscheidungen n√ºtzlich sein, Vorwissen zu benutzen?"
  },
  {
    "objectID": "pages/exercises/exercise_02.html",
    "href": "pages/exercises/exercise_02.html",
    "title": "√úbung 2",
    "section": "",
    "text": "Vertiefung\n\n\n\nDie Daten, welche Sie in dieser √úbung sammeln, m√ºssen abgegeben werden; wir werden diese im Verlauf des Semesters analysieren. Bitte die Datenfiles in einem ZIP File bis 8. M√§rz auf ILIAS hochladen.\n\n\n\n\n\nDas fertige Experiment befindet sich auf Github. Sie k√∂nnen es unter diesem Link downloaden. üëâ LINK.\nF√ºhren Sie das Experiment ein- oder mehrere Male selber durch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen Testperson und laden Sie das ZIP FIle auf ILIAS."
  },
  {
    "objectID": "pages/solutions/solution_03.html",
    "href": "pages/solutions/solution_03.html",
    "title": "√úbung 3: L√∂sung",
    "section": "",
    "text": "In dieser Aufgabe bearbeiten Sie Daten aus einem Detektionssexperiment. Versuchspersonen mussten in zwei Bedingungen (bias und no_bias) ein Signal, welches in Rauschen eingebettet war, detektieren. Im Datensatz sind folgende Variablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable f√ºr Signal (0: absent, 1: present)\ncorrect: Indikatorvariable f√ºr korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\n\n\nAufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\nd <- read_csv(\"data/data-exercise-03.csv\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nRows: 5,756\nColumns: 6\n$ subject        <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2‚Ä¶\n$ condition      <chr> \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\",‚Ä¶\n$ signal_present <dbl> 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0‚Ä¶\n$ correct        <dbl> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1‚Ä¶\n$ rt             <dbl> 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.370, 0.559,‚Ä¶\n$ trial_num      <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, ‚Ä¶\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd <- d |>\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants <- d |>\n    group_by(subject, condition) |>\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- d |>\n    group_by(condition) |>\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\nsum_stats_participants <-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(outlier_P = (mean_P - mean_C) > 2 * sd_C)\n\n\n# show outlier participants\nsum_stats_participants |>\n    filter(outlier_P == 1) |>\n    show()\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer Bedingung mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegt. Dies bedeutet, dass sich in excluded keine Personen befinden, und der Dataframe folglich \\(0\\) Zeilen hat.\n\nexcluded <- sum_stats_participants |>\n    filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 0 √ó 6\n# Groups:   subject [0]\n# ‚Ä¶ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\n\nDer n√§chste Schritt w√§re also nicht unbedingt notwendig.\n\nd_cleaned <- d |>\n    filter(!(subject %in% excluded$subject)) |>\n    mutate(subject = fct_drop(subject))\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4 Standardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn l√§nger gebraucht haben, als 4 Standardabweichungen √ºber dem Bedingungsmittelwert. Das bedeutet (rt - mean_C) > 4 * sd_C, und nicht abs(rt - mean_C) > 4 * sd_C. Letzteres w√ºrde auch Trials als Ausreisser identifizieren, welche 4 Standardabweichungen unter dem Bedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies bedeutet, wir brauchen rt < 0.100, und nicht rt < 100.\n\nd_cleaned <- d_cleaned |>\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) > 4 * sd_C ~ \"too slow\",\n            rt < 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |>\n    filter(trial_type != \"OK\")\n\n# A tibble: 165 √ó 9\n   subject condition signal_present correct     rt trial_‚Ä¶¬π mean_C  sd_C trial‚Ä¶¬≤\n   <fct>   <fct>              <dbl>   <dbl>  <dbl>    <dbl>  <dbl> <dbl> <fct>  \n 1 2       bias                   0       1 4.08          1  0.697 0.751 too sl‚Ä¶\n 2 2       bias                   1       1 0.035        41  0.697 0.751 too fa‚Ä¶\n 3 2       bias                   0       1 6.92         50  0.697 0.751 too sl‚Ä¶\n 4 2       bias                   0       1 0.085        51  0.697 0.751 too fa‚Ä¶\n 5 2       bias                   0       1 0.033        70  0.697 0.751 too fa‚Ä¶\n 6 2       bias                   0       1 5.09         74  0.697 0.751 too sl‚Ä¶\n 7 2       bias                   0       1 6.59         94  0.697 0.751 too sl‚Ä¶\n 8 2       bias                   0       1 5.09        121  0.697 0.751 too sl‚Ä¶\n 9 2       bias                   1       1 0.077       138  0.697 0.751 too fa‚Ä¶\n10 3       no_bias                1       0 0.0958        4  0.691 0.773 too fa‚Ä¶\n# ‚Ä¶ with 155 more rows, and abbreviated variable names ¬π‚Äãtrial_num, ¬≤‚Äãtrial_type\n\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756 Datenpunkte.\n\nnrow(d_cleaned)\n\n[1] 5756\n\n\n\nd_cleaned <- d_cleaned |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\nNach dem Entfernen haben wir noch 5591.\n\nnrow(d_cleaned)\n\n[1] 5591\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |> write_csv(\"data/data-cleaned.csv\")"
  }
]