[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "FrÃ¼hjahrssemester 2023"
  },
  {
    "objectID": "pages/admin/01_overview.html",
    "href": "pages/admin/01_overview.html",
    "title": "Ãœbersicht",
    "section": "",
    "text": "In diesem Kurs beschÃ¤ftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses Forschungsgebiets. Das bedeutet, wir analysieren Daten aus Verhaltensexperimenten â€” sowohl mit herkÃ¶mmlichen statistischen Verfahren, als auch mit mathematischen Modellen. Die Resultate dieser Analysen kÃ¶nnen wiederum in der Analyse bildgebender Verfahren oder EEG benutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Themen daraus aufgreifen. Das Buch ist auf SpringerLink verfÃ¼gbar: An Introduction to Model-Based Cognitive Neuroscience.\n\nWir werden folgende Themen im Laufe des Semester behandeln:\n\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. binÃ¤re Daten, Reaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinfÃ¼hrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von Entscheidungsverhalten)"
  },
  {
    "objectID": "pages/admin/01_overview.html#experimente",
    "href": "pages/admin/01_overview.html#experimente",
    "title": "Ãœbersicht",
    "section": "Experimente",
    "text": "Experimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen BenutzeroberflÃ¤che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/admin/01_overview.html#datenanalyse",
    "href": "pages/admin/01_overview.html#datenanalyse",
    "title": "Ãœbersicht",
    "section": "Datenanalyse",
    "text": "Datenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu analysieren werden wir R verwenden. Sie sollten daher die aktuelle Version von R installieren (Version 4.2.2), sowie RStudio.\nR ğŸ‘‰ https://cloud.r-project.org/\nRStudio ğŸ‘‰ https://www.rstudio.com/products/rstudio/download/#download\nFÃ¼r Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, Ã¤hnlich wie Jamovi, mit dem sich simple Bayesianische Tests durchfÃ¼hren lassen.\nJASP ğŸ‘‰ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R aus benutzen. Die dafÃ¼r benÃ¶tigte Software werden wir im Verlauf des Semesters installieren."
  },
  {
    "objectID": "pages/admin/03_zulip_forum.html",
    "href": "pages/admin/03_zulip_forum.html",
    "title": "Zulip Forum",
    "section": "",
    "text": "Wir benutzen in dieser Veranstaltung Zulip als Diskussionforum. Zulip hat einige Vorteile gegenÃ¼ber ILIAS und Email:\n\nZulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum fÃ¼r die Vormittags- und Nachmittagsveranstaltungen.\nDie Diskussion ist fÃ¼r alle Teilnehmer*innen sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron) stattfinden.\n\nBitte erstellen Sie unter diesem Link einen Account. Sie mÃ¼ssen dafÃ¼r Ihre Uni Emailadresse verwenden. Account erstellen ğŸ‘‰ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, kÃ¶nnen Sie sich unter folgendem Link einloggen. Zulip Forum ğŸ‘‰ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App fÃ¼r alle gÃ¤ngigen Betriebssysteme erhÃ¤ltlich. Apps ğŸ‘‰ zulip.com/apps\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Andrew Ellis},\n  title = {Zulip {Forum}},\n  url = {https://kogpsy.github.io/neuroscicomplabFS23//03_zulip_forum.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. n.d. â€œZulip Forum.â€ https://kogpsy.github.io/neuroscicomplabFS23//03_zulip_forum.html."
  },
  {
    "objectID": "pages/admin/dozierende.html",
    "href": "pages/admin/dozierende.html",
    "title": "Dozierende",
    "section": "",
    "text": "Andrew ist Data Scientist an der Berner Fachhochschule und Wissenschaftlicher Mitarbeiter an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre der Uni Bern. An der BFH beschÃ¤ftigt er sich hauptsÃ¤chlich mit der Verwendung kÃ¼nstlicher Intelligenz in der Lehre, und versucht ein intelligentes Tutoring-System zu entwickeln.\nğŸ“¬ Email: andrew.ellis@unibe.ch\nğŸ”— Website: www.kog.psy.unibe.ch/ueber_uns/personen/dr_ellis_andrew"
  },
  {
    "objectID": "pages/admin/dozierende.html#gerda-wyssen",
    "href": "pages/admin/dozierende.html#gerda-wyssen",
    "title": "Dozierende",
    "section": "Gerda Wyssen",
    "text": "Gerda Wyssen\nGerda arbeitet an ihrer Dissertation an der Abteilung Kognitive Psychologie, Wahrnehmung und Methodenlehre. Sie untersucht den Einfluss von Gleichgewichts- und Bewegungsinformationen auf rÃ¤umliches Denken. Hierzu nutzt sie die Moog Bewegungsplattform oder das starke Magnetfeld eines 7T MRI Scanners. Besonders faszinierend findet sie Bewegungsillusionen.\nğŸ“¬ Email: gerda.wyssen@unibe.ch\nğŸ”— Website: www.kog.psy.unibe.ch/ueber_uns/personen/m_sc_wyssen_gerda"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html",
    "href": "pages/admin/leistungsnachweise.html",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Unsere Veranstaltungen werden so aufgebaut sein, dass wir etwa die HÃ¤lfte der Zeit Inhalt prÃ¤sentieren; die andere HÃ¤lfte ist praktischen Hands-on Sessions gewidmet. Dies wird jedoch stark vom jeweiligen Inhalt anhÃ¤ngig sein. Wir denken, dass der Umgang mit Programmiersprachen und Datenanalyse am besten gelernt wird, indem man selber ausprobiert. Deshalb werden wir versuchen, die Theorie auf das NÃ¶tigste zu beschrÃ¤nken, und uns mehr auf praktische Anwendungen zu fokussieren."
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "href": "pages/admin/leistungsnachweise.html#leistungsnachweise",
    "title": "Leistungskontrollen",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nLeistungsnachweise werden in Form von Ãœbungen erbracht. Es wird insgesamt 5 Ãœbungen geben â€“ davon mÃ¼ssen alle abgegeben werden. Die Evaluation der Ãœbungen erfolgen in Form von Peer-Feedback; dies bedeutet, dass Sie nach dem Abgabetermin aufgefordert werden, zu den Ãœbungen von zufÃ¤llig ausgewÃ¤hlten Mitstudierenden Feedback zu geben. Danach erhalten Sie selber von anderen Mitstudierenden Feedback zu Ihrer Ãœbung.\nDie Ãœbungen werden in den entsprechenden Ordner auf ILIAS hochgeladen - dort erhalten Sie auch genauere Angaben zur Art des Feedbacks. GrundsÃ¤tzliche Guidelines finden Sie untenstehend.\nILIAS (Montag) ğŸ‘‰ 468703-FS2023-1\nILIAS (Donnerstag) ğŸ‘‰ 468703-FS2023-0"
  },
  {
    "objectID": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "href": "pages/admin/leistungsnachweise.html#peer-feedback-guidelines",
    "title": "Leistungskontrollen",
    "section": "Peer Feedback Guidelines",
    "text": "Peer Feedback Guidelines\nWissenschaftliche Artikel werden von Forschenden aus denselben/Ã¤hnlichen Forschungsgebieten begutachtet. In diesem Kurs wÃ¤hlen wir fÃ¼r das Feedback zu den Ãœbungen ebenfalls dieses Prinzip des peer review. FÃ¼r jede Ãœbung erhalten Sie einen klaren Begutachtungsauftrag mit Fragen wie z.B. Was wÃ¼rde die Grafik informativer machen?. Wir bitten Sie, beim Verfassen des Peer Feedbacks folgende grundsÃ¤tzlichen Richtlinien zu beachten:\n\nbe kind: Seien Sie freundlich. WÃ¤hlen Sie Ihre RÃ¼ckmeldungspunkte sorgfÃ¤ltig. Nehmen Sie sich Zeit und geben Sie nicht sehr knappes, verspÃ¤tetes oder gar kein Feedback. Schreiben Sie was Ihnen positiv aufgefallen ist und unbedingt beibehalten werden sollte.\nbe specific: Beschreiben Sie das Problem oder die Kritikpunkte prÃ¤zise und spezifisch (statt z.B. â€œCode lÃ¤uft nichtâ€ kÃ¶nnten Sie schreiben â€œin Zeile 34 gibt es eine Fehlermeldung, es scheint die Variable wurde falsch benannt, â€¦â€)\nbe helpful: Seien Sie konstruktiv. Es gibt immer etwas was verbessert werden kÃ¶nnte. Beschreiben Sie diese Punkte und fÃ¼gen Sie bestenfalls einen LÃ¶sungsansatz oder -vorschlag hinzu (statt z.B. â€œdie Farben sind nicht geeignet fÃ¼r farbenblinde Personenâ€ kÃ¶nnten Sie schreiben â€œdie viridis Palette wÃ¼rde die Grafik fÃ¼r farbenblinde Personen zugÃ¤nglich machenâ€).\n\nDiese Punkte einzuhalten benÃ¶tigt etwas Zeit. Deshalb planen Sie sich bitte ca. 1 Lektion fÃ¼r das jeweilige Peer Feedback ein."
  },
  {
    "objectID": "pages/admin/syllabus.html",
    "href": "pages/admin/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Sitzungen\nAn den 14 Sitzungen werden wir voraussichtlich diese Themen behandeln (kleine Ã„nderungen vorbehalten).\n\n1 EinfÃ¼hrung\nSitzung 1\n\nWir schauen uns ein paar in den Neurowissenschaften verwendeten Programmiersprachen (Python, R, Matlab) an, und diskutieren ChatGPT.\nEinfÃ¼hrung in DataCamp (fÃ¼r Python/R).\n\n\n\n\n\n\n\nHands-on\n\n\n\nAuf DataCamp den Python EinfÃ¼hrungskurs ausprobieren.\n\n\n\n\n2 Experimente mit Python programmieren\nSitzungen 2 und 3\n\nWir erstellen selber ein Experiment mit Python und PsychoPy.\n\n\n\n3 Data Wrangling\nSitzungen 4 und 5\n\nWir schauen uns an, wie wir mit R die Daten aus unserem selber programmierten Experiment einlesen und bearbeiten kÃ¶nnen, um damit statistische Analysen durchzufÃ¼hren.\n\n\n\n4 Visualisieren\nSitzung 6\n\nExplorative Datenanalyse und grafische Darstellung mit mit R package ggplot2.\n\n\n\n5 Signal Detection Theory\nSitzungen 7 und 8\n\nWir verwenden ein in den Neurowissenschaften und der Psychologie beliebtes Modell fÃ¼r kategoriale oder ordinale Verhaltensdaten, um Daten aus unserem Experiment zu analysieren.\n\n\n\n6 Reaktionszeiten\nSitzungen 9 und 10\n\nIn diesen Sitzungen schauen wir uns Analysemethoden fÃ¼r Reaktionszeitdaten an.\n\n\n\n7 Bayesianische Datenanalyse\nSitzungen 11, 12, 13, und 14\n\nIm letzten Thema geht es um einen modernen Ansatz in der Statistik, welcher auf den Axiomen der Wahrscheinlichkeitstheorie beruht, und einige Vorteile gegenÃ¼ber der herkÃ¶mmlichen (frequentistischen) Statistik bietet. Wir werden hier mit dem Programm Jasp arbeiten.\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "pages/chapters/chatgpt.html",
    "href": "pages/chapters/chatgpt.html",
    "title": "ChatGPT",
    "section": "",
    "text": "Eventuell haben Sie in den letzten Wochen von ChatGPT gehÃ¶rt, vielleicht schon selber benutzt. Sowohl an Hochschulen als auch an Gymnasien stellt sich die brennende Frage, wie Lehrpersonen und Studierende/SchÃ¼ler damit umgehen sollen. Darf man ChatGPT benutzen? Werden die abgegeben Ãœbungen darauf untersucht, ob sie mit Hilfe kÃ¼nstlicher Intelligenz generiert wurden.\nWir versuchen hier, unsere Haltung in Bezug auf ChatGPT bekanntzugeben, und zu erklÃ¤ren, was ChatGPT kann, und wo es hilfreich sein kÃ¶nnte.\n\n\n\n\nChatGPT benutzt das Codex Modell von OpenAI, welches auf Programmiersprachen spezialisiert ist. Vor allem Python, aber auch R (und Matlab) Code spricht ChatGPT hervorragend.\n\n\n\nNein. ChatGPT besteht aus verschiedenen Komponent. Eines davon ist ein large language model (LLM), die weiteren Komponenten braucht es, um einen Chatbot zu kreieren, welcher menschenÃ¤hnliche Konversationen fÃ¼hren kann.\nDas LLM hat im wesentlichen die Verteilung von WortstÃ¤mmen (Tokens) des Textkorpus (mit dem es trainiert wurde) gelernt. Die Aufgabe des LLM ist es, gegeben einen Input (Prompt) eine oder mehrere wahrscheinliche VervollstÃ¤ndigungen zu erzeugen. Wenn nun im Textkorpus Programmcode vorkam, wird das LLM syntaktisch korrekten Code zu generieren. Das LLM hat jedoch keine MÃ¶glichkeit, diesen Code auszufÃ¼hren, auf Korrektheit zu Ã¼berprÃ¼fen, oder Ã¼berhaupt herauszufinden, ob der Code sinnvoll ist.\nChatGPT kann mitunter hervorragenden Code generieren, aber ob der Code wirklich das macht, was er soll, liegt in der Verantwortung der Benutzer:in.\n\nImmer kritisch Ã¼berprÃ¼fen, ob von ChatGPT generierter Code wirklich korrekt ist, und tut was verlangt wird!\n\n\n\n\nSie kÃ¶nnen ChatGPT helfen, gute Antworten zu erzeugen, in dem Sie gute Fragen stellen. Dies bedeutet, dass Sie in der Frage (Prompt) mÃ¶glichst viele Kontextinformationen mitliefern. Denken Sie daran, dass ChatGPT, gegeben dem Input und den Trainingsdaten, eine mÃ¶glichst wahrscheinliche Sequenz von Token erzeugt.\n\n\n\n\nWir gehen davon aus, dass Technologien wie ChatGPT nicht mehr vom modernen Unterricht wegzudenken sind, und es daher sinnvoll und notwendig ist, einen mÃ¶glichst guten Umgang damit zu erlernen.\n\n\n\n\n\n\nHinweis\n\n\n\nChatGPT darf fÃ¼r die Ãœbungen genutzt werden.\n\n\nEs ist aus unserer Sicht jedoch sinnvoll, wenn Sie ChatGPT als eine von vielen mÃ¶glichen Quellen benutzen (wie z.B. Google, Stackoverflow), und diese auch als solche transparent angeben.\nAus unserer Sicht ist ChatGPT (und Codex) ein sehr wertvolles Tool. Sie sind jedoch dafÃ¼r verantwortlich, dass ihr Code ausfÃ¼hrbar ist. Dies wird beim Peer-Feedback eines der Kriterien sein. Das Ziel ist primÃ¤r, dass sie Code verstehen und anwenden kÃ¶nnen, nicht dass sie Code aus dem Nichts selber schreiben kÃ¶nnen. Dies ist Ã¼brigens auch die Vorgehensweise vieler erfahrener Programmierer - oft wird zuerst mal gegoogelt und im Internet nachgeschaut, ob es schon LÃ¶sungsansÃ¤tze gibt. ChatGPT macht im Prinzip nichts anderes.\n\n\n\nIm Prinzip ja, aber Sie wÃ¼rden dabei wahrscheinlich sehr wenig lernen. Den Umgang mit Computern und das Programmieren lernt man, indem man selber Code ausfÃ¼hrt, Fehler macht und versucht zu verstehen was der Fehler war. Das Ziel sollte sein, dass Sie jederzeit erklÃ¤ren kÃ¶nnten, was Ihr Code macht, oder wieso Sie ein bestimmtes Feedback gegeben haben. Ohne selber etwas dafÃ¼r zu tun wird der Lern efolg wahrscheinlich ausbleiben.\n\n\n\nChatGPT kann sowohl Code generieren als auch Code evaluieren. Sie kÃ¶nnen ChatGPT benutzen\n\num VorschlÃ¤ge zu erhalten, wenn Sie nicht weiterkommen.\num ein GerÃ¼st fÃ¼r ein Programm zu erstellen.\num Code auf Lesbarkeit/VerstÃ¤ndlichkeit zu Ã¼berprÃ¼fen.\num Code kommentieren zu lassen.\num Code zu verstehen/bewerten zu lassen.\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte Ã¼berprÃ¼fen Sie aber immer kritisch den Output von ChatGPT, und stellen sie sicher, dass der Code tatsÃ¤chlich ausgefÃ¼hrt werden kann."
  },
  {
    "objectID": "pages/chapters/datacamp.html",
    "href": "pages/chapters/datacamp.html",
    "title": "DataCamp",
    "section": "",
    "text": "Im Rahmen dieser Lehrveranstaltung kÃ¶nnen alle Teilnehmende sich bei DataCamp registrieren\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL an. DataCamp Kurse auf unterschiedlichen Niveaus an; sowohl fÃ¼r AnfÃ¤nger als auch fÃ¼r Fortgeschrittene gibt es ein breites Angebot an Kursen.\nSie kÃ¶nnen Sich unter folgendem Link mit Ihrer Uni Bern E-Mail Adresse (*unibe.ch) registrieren:\nğŸ‘‰ğŸ¼ DataCamp registration"
  },
  {
    "objectID": "pages/chapters/datacamp.html#hands-on-session",
    "href": "pages/chapters/datacamp.html#hands-on-session",
    "title": "DataCamp",
    "section": "Hands-on session",
    "text": "Hands-on session\nWir werden in der zweiten Sitzung mit Psychopy und Python ein Experiment erstellen. In Psychopy kÃ¶nnen Sie viel sehr Ã¼ber die grafische OberflÃ¤che; es gibt jedoch einige kleine Dinge, welche wir mit Python selber coden mÃ¼ssen. Deshalb wÃ¤re es fÃ¼r Sie hiflreich, wenn Sie sich vorher auf der DataCamp Website ein wenig mit Python vertraut machen.\n\n1 - Python Basics\nJe nachdem wie viel Erfahrung Sie mit Python haben, kÃ¶nnen Sie sich entweder fÃ¼r den Kurs â€œIntroduction to Pythonâ€ oder â€œIntermediate Pythonâ€ entscheiden.\nğŸ‘‰ğŸ¼ Introduction to Python\nğŸ‘‰ğŸ¼ Intermediate Python\nFÃ¼r fortgeschrittene empfehlen wir die Kurse:\nğŸ‘‰ğŸ¼ Python Data Science Toolbox (Part 1)\nğŸ‘‰ğŸ¼ Python Data Science Toolbox (Part 2)\nDiese Kurse sind nicht obligatorisch; Sie brauchen fÃ¼r PsychoPy wirklich nur Grundkenntnisse. Python ist aber sowohl in der Forschung als der Privatwirtschaft sehr beliebt und Sie werden es sicherlich noch Ã¶fters brauchen, wenn Sie sich mit Datenanalyse beschÃ¤ftigen.\n\n\n2 - Python Code mit ChatGPT generieren\nDies benÃ¶tigt einen ChatGPT Account; einen solchen kÃ¶nnen Sie bei OpenAI gratis erstellen.\nğŸ‘‰ğŸ¼ chat.openai.com/chat\nVersuchen Sie, mit ChatGPT ein paar Zeilen Python Code zu generieren. Sie kÃ¶nnen hierzu einige Beispiele als den DataCamp Kursen verwenden.\n\nKann ChatGPT die Aufgaben lÃ¶sen?\nWie kann Ihnen ChatGPT helfen, Code zu schreiben?\nWas mÃ¼ssen Sie beachten, wenn Sie Code von ChatGPT verwenden?"
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html",
    "href": "pages/chapters/psychopy_experiments.html",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "",
    "text": "Neurowissenschaftliche Experimente mÃ¼ssen exakt auf die Fragestellung zugeschnitten werden um aussagekrÃ¤ftige Daten zu liefern. Deshalb programmieren die meisten Forschenden ihre Experimentalparadigmen selbst. So kÃ¶nnen beispielsweise Instruktionen oder verwendete Stimuli, deren GrÃ¶sse und Anzeigedauer prÃ¤zise definiert werden. In dieser Sitzung erstellen wir mit PsychoPy ein perzeptuelles Entscheidungsexperiment, Ã¤hnlich dem Experiment aus Mulder et al. (2012). Dieses neurowissenschaftliche Experiment untersucht den Einfluss von Vorwissen auf Entscheidungsverhalten von Menschen sowie die dazugehÃ¶rigen neuronalen Korrelate."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#ablauf",
    "href": "pages/chapters/psychopy_experiments.html#ablauf",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Ablauf",
    "text": "Ablauf\nDas Experiment besteht aus der Instruktion, mehreren VersuchsblÃ¶cken und der Nachbesprechung. Die Anweisungen und die Nachbesprechung sind Textanzeigen, wÃ¤hrend die Versuche (und die VersuchsblÃ¶cke) etwas komplizierter sind."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#trial",
    "href": "pages/chapters/psychopy_experiments.html#trial",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Trial",
    "text": "Trial\nZunÃ¤chst wird ein Fixationskreuz entweder fÃ¼r 100 ms, 350 ms, 800 ms oder 1200 ms angezeigt. Die tatsÃ¤chliche Dauer wird fÃ¼r jeden Versuch randomisiert. Eine solche Randomisierung kann nicht Ã¼ber die BenutzeroberflÃ¤che vorgenommen werden, sondern erfordert ein kleines StÃ¼ck Python-Code. Sehen Sie sich den Codeblock der Routine Fixation_pre_cue an, um zu erfahren, wie dies erreicht werden kann.\n\nDas Experiment wurde im Scanner und ausserhalb durchgefÃ¼hrt. Die beiden Version unterscheiden sich ganz stark in ihrem Timing. Wir implementieren hier die Scanner Version des Tasks.\n\nAnschlieÃŸend wird fÃ¼r 1000 ms ein Hinweis (cue) prÃ¤sentiert. Dabei kann es sich entweder um einen Pfeil handeln, der nach rechts zeigt, einen Pfeil, der nach links zeigt, oder einen einfachen Kreis (fÃ¼r die Kontrollbedingung). Der Codeblock in der Cue-Routine legt den tatsÃ¤chlichen Hinweis fÃ¼r jeden Versuch auf der Grundlage der Schleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz prÃ¤sentiert - dieses Mal fÃ¼r entweder 3400 ms, 4000 ms, 4500 ms oder 5000 ms. Wie beim ersten Fixationskreuz wird die tatsÃ¤chliche Dauer zufÃ¤llig gewÃ¤hlt.\nNach dem zweiten Fixationskreuz wird fÃ¼r 1500 ms der eigentliche Stimulus angezeigt: ein random dot kinematogram (RDK). Die Punkte bewegen sich entweder nach rechts oder nach links mit einem KohÃ¤renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs wird durch die Schleifenvariable direction bestimmt und im Codeblock der Routine Dots festgelegt. Die Teilnehmer mÃ¼ssen entscheiden, welche Richtung sie wahrnehmen, und kÃ¶nnen ihre Antwort durch DrÃ¼cken der linken oder rechten Pfeiltaste auf der Tastatur eingeben.\nSchlieÃŸlich wird ein Feedback-Bildschirm angezeigt. Wenn der Teilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis â€œzu schnellâ€ angezeigt. Wurde wÃ¤hrend des gesamten Stimulus keine Antwort erfasst, wird das Wort â€œmissâ€ angezeigt. War die Antwort richtig, wird â€œ+5 Punkteâ€ angezeigt, war sie falsch, wird â€œ+0 Punkteâ€ angezeigt."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "href": "pages/chapters/psychopy_experiments.html#experimentalschleife-main_blocks_loop",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Experimentalschleife: main_blocks_loop",
    "text": "Experimentalschleife: main_blocks_loop\nMit loops in PsychoPy haben wir die MÃ¶glichkeit, eine oder mehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt, um denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber jedes Mal mit anderen Werten fÃ¼r die loop variables. Eine Schleife wiederholt also einen Versuch einige Male, wobei die Schleifenvariablen bei jeder Wiederholung geÃ¤ndert werden. Der Versuch selbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen, ob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird nur die main_blocks_loop erklÃ¤rt, aber das Prinzip gilt auch fÃ¼r die practice_block_loop.\nUm die verschiedenen Werte fÃ¼r die Schleifenvariablen zu definieren, mÃ¼ssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop Variablen cue und direction. Das Stichwort kann entweder left, right oder none, sein, wÃ¤hrend die Richtung left oder right sein kann.\nIn der BenutzeroberflÃ¤che kÃ¶nnen wir die Variablen loopType und nReps fÃ¼r die Schleife angeben, wenn wir sie anklicken. Mit ersterer kÃ¶nnen wir steuern, ob wir z.B. die Zeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach unten ablaufen lassen wollen, wÃ¤hrend die letztere definiert, wie oft jede Zeile der Bedingungsdatei wiederholt werden soll.\nFÃ¼r die main_blocks_loop haben wir eine Bedingungsdatei mit 80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen entsprechen. In der einen HÃ¤lfte der neutralen Trials bewegen sich die Punkte nach rechts, in der anderen HÃ¤lfte nach links. Bei den voreingenommenen Versuchen sind 32 der Hinweise gÃ¼ltig (d.Â h. sie stimmen mit der Bewegungsrichtung der Punkte Ã¼berein) und 16 ungÃ¼ltig, wobei sich die Punkte sowohl bei gÃ¼ltigen als auch bei ungÃ¼ltigen Hinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der Versuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so dass alle diese Reihen zweimal durchlaufen werden (insgesamt 160 Versuche), und die Variable â€œloopTypeâ€ wird auf random gesetzt, so dass die Versuche in zufÃ¤lliger Reihenfolge durchgefÃ¼hrt werden."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#daten",
    "href": "pages/chapters/psychopy_experiments.html#daten",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Daten",
    "text": "Daten\nWenn man die default-Einstellungen nicht Ã¤ndert, speichert PsychoPy die Daten automatisch in einem trial-by-trial CSV File. Das bedeutet, dass jeder Trial 1 Zeile generiert. Das CSV File erhÃ¤lt einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es mÃ¶glich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV Files werden in einem Ordner mit dem Name data abgelegt.\n\nBei der Wahl vom Datenfile-Namen empfiehlt es sich immer Datum und Uhrzeit anzuhÃ¤ngen. Dies verhindert, dass Daten Ã¼berschrieben werden, wenn z.B. eine Versuchspersonen-ID falsch eingetippt oder doppelt vergeben wird."
  },
  {
    "objectID": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "href": "pages/chapters/psychopy_experiments.html#degrees-of-visual-angle",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Degrees of Visual Angle",
    "text": "Degrees of Visual Angle\nOftmals werden GrÃ¶ssenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abhÃ¤ngig sind. Degrees of visual angle gibt die wahrgenommene GrÃ¶sse des Stimulus an, und berÃ¼cksichtigt die GrÃ¶sse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von ğŸ‘‰ OpenSesame. Ãœblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem ğŸ‘‰ Link mehr Information.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm fÃ¼r die Erstellung behavioraler Experimente."
  },
  {
    "objectID": "pages/chapters/software.html",
    "href": "pages/chapters/software.html",
    "title": "Programmiersprachen",
    "section": "",
    "text": "In diesem Kurs beschÃ¤ftigen wir uns im weiteren Sinne mit dem Einsatz vom Computern im Bereich Cognitive Neuroscience. Es ist nicht Ziel dieses Kurses, EEG oder fMRI Daten zu analysieren (dafÃ¼r gibt es eigene Kurse); wir werden uns stattdessen mit Daten aus Verhaltensexperimenten beschÃ¤ftigen. Dies sind zum Beispiel binÃ¤re Antworten oder Reaktionszeiten, welche wir mit entsprechenden Modellen untersuchen werden. Unsere Anwendungsbeispiele werden immer aus der neurowissenschaftlichen Forschung stammen; der Fokus wird aber vor allem der Umgang mit Computern sein. Unser Ziel ist es, dass Sie nach dem Abschluss dieses Kurses eine neurowissenschaftliches Paper lesen kÃ¶nnen, und die darin verwendeten Experimente nachvollziehen kÃ¶nnen. Sie kÃ¶nnten eventuell sogar das Experiment selber programmieren, und die Daten analysieren."
  },
  {
    "objectID": "pages/chapters/software.html#programmiersprachen",
    "href": "pages/chapters/software.html#programmiersprachen",
    "title": "Programmiersprachen",
    "section": "Programmiersprachen",
    "text": "Programmiersprachen\nProgrammiersprachen sind essentielle Werkzeuge fÃ¼r die Neurowissenschaftliche Forschung. Wir werden uns zuerst einen kurzen Ãœberblick Ã¼ber drei hÃ¤ufig verwendete Programmiersprachen (Matlab, Python und R) verschaffen und kurz deren Verwendungszwecke und Vor- und Nachteile diskutieren.\n\nMatlab\nMatlab ist ein Software fÃ¼r numerische Anwendung, welche in den Ingenieurwissenschaften, Naturwissenschaften und der Mathematik weit verbreitet ist.\n\nğŸ‘ğŸ¼ StÃ¤rken:\n\nLeistungsstarke Matrix- und Vektoroperationen, gut geeignet fÃ¼r Matrix-basierte Operationen, die in der Neurowissenschaftlichen Forschung hÃ¤ufig vorkommen.\nUmfangreiche Bibliothek von integrierten Funktionen fÃ¼r wissenschaftliches Rechnen.\n\n\n\nğŸ‘ğŸ¼ SchwÃ¤chen:\n\nTeuer\nWeniger flexibel als Python oder R in Bezug auf Datenarten und Strukturen.\nMatlab is kommerziell und proprietÃ¤r. Dies bedeutet man muss teuere Lizenzen kaufen, und der Source Code der Software ist nicht offen.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nSignalverarbeitung\nVisualisierung\nViele fMRI Forscher arbeiten mit Matlab, da es dafÃ¼r eine spezielle Toolbox gibt: SPM\nExperimente programmieren, z.B. mit Psychtoolbox\n\n\n\nBeispielcode:\nload('data.mat')\nfs = 1000;\nt = (0:numel(data)-1)/fs;\nplot(t, data)\n\n\n\nPython\nPython ist eine allgemeine (general purpose) Programmiersprache, die in vielen verschiedenen Bereichen wie wissenschaftlichem Rechnen, Datenanalyse und maschinellem Lernen weit verbreitet ist.\n\nğŸ‘ğŸ¼ StÃ¤rken:\n\nEine Vielzahl von Bibliotheken und Modulen wie NumPy, SciPy und Pandas, die leistungsstarke Werkzeuge fÃ¼r wissenschaftliches Rechnen und Datenanalyse bieten.\nDatenanalysewerkzeuge wie Pandas-Dataframes, die Seaborn-Visualisierungsbibliothek, und Jupyter Notebooks.\nOpen-source und kostenlos\n\n\n\nğŸ‘ğŸ¼ SchwÃ¤chen:\n\nKann in einigen numerischen Berechnungen langsamer sein als Matlab.\nDa Python eine allgemeine Sprache ist, muss man fÃ¼r numerische Anwendungen immer verschiedene Packages importieren (z.B.) numpy, wenn man damit rechnen will. Dies fÃ¼hrt zu weniger gut lesbarem Code.\n\n\n\nTypische Anwendung:\n\nDatenverarbeitung und -analyse,\nVisualisierung\nMachine learning und KÃ¼nstliche Intelligenz\nExperimente programmieren, z.B. mit PsychoPy\n\n\n\nBeispielcode:\nimport pandas as pd\nimport seaborn as sns\ndata = pd.read_csv('data.csv')\nsns.lineplot(data=data, x='time', y='voltage')\n\n\n\nR\nR ist eine Programmiersprache und Umgebung fÃ¼r statistisches Rechnen und Grafiken.\n\nğŸ‘ğŸ¼ StÃ¤rken:\n\nEntwickelt von Statistikern fÃ¼r statistisches Rechnen und Grafiken.\nEine groÃŸe Bibliothek von statistischen Werkzeugen und Paketen, einschliesslich Visualisierungspackages (grammar of graphics).\nOpen-source und kostenlos\ntidyverse Packages fÃ¼r Data Wrangling (sehr elegante Syntax, um mit Daten zu arbeiten).\n\n\n\nğŸ‘ğŸ¼ SchwÃ¤chen:\n\nSteilere Lernkurve als Python.\nKann in einigen numerischen Berechnungen langsamer sein als Matlab oder Python.\nEntwickelt von Statistiker (nicht von Software Designers). R gilt als sehr idiosynkratisch.\n\n\n\nTypische Anwendung:\n\nStatistische Analyse\nDatenvisualisierung. R hat eine sehr gute Bibliothek fÃ¼r Grafiken, die ggplot2 Bibliothek. Diese Bibliothek verwendet die sogenannte grammar of graphics (GoG) - eine Methode, um Daten in Grafiken zu visualisieren. Die GoG ist eine sehr elegante und effiziente Methode, um Daten zu visualisieren.\n\n\n\nBeispielcode:\nlibrary(tidyverse)\ndata <- read.csv('data.csv')\nggplot(data, aes(x=time, y=voltage)) + geom_line()\n\n\n\nFazit\nMatlab, Python und R sind leistungsstarke Werkzeuge fÃ¼r die neurowissenschaftliche Forschung. Die Wahl der Sprache hÃ¤ngt unter anderem von der spezifischen Aufgabe ab. Weitere Faktoren ist Tradition: bestimmte Gruppen bevorzugen eher eine Sprache als andere. So ist Matlab unter Ingenieuren weit verbreiten und R unter Statistikern. Python ist im Bereich KÃ¼nstliche Intelligenz und Machine Learning die beliebteste Sprache. Eine neuere Sprache ist Julia - diese vereint die Vorteile aller oben genannten Sprachen (ohne viele deren Nachteile), ist aber weniger weit verbreitet.\nUm mehr zu erfahren, erkunden Sie die umfangreichen Online-Ressourcen und Dokumentationen fÃ¼r jede Sprache."
  },
  {
    "objectID": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "href": "pages/chapters/software.html#in-dieser-veranstaltung-verwendete-software",
    "title": "Programmiersprachen",
    "section": "In dieser Veranstaltung verwendete Software",
    "text": "In dieser Veranstaltung verwendete Software\nWir haben uns entschieden, in dieser Veranstaltung Python zu verwenden, um ein Experiment zu erstellen, und R fÃ¼r die Analyse der Daten. Matlab wird nicht verwendet; einerseits da es kommerziell ist, andererseits weil es aus unserer Sicht nicht die beste Wahl fÃ¼r die Analyse von Verhaltensdaten ist. Ausserdem ist es schon schwierig genug, eine Programmiersprache zu lernen, ohne gleichzeitig noch zwei weitere zu lernen."
  },
  {
    "objectID": "pages/chapters/software.html#python-1",
    "href": "pages/chapters/software.html#python-1",
    "title": "Programmiersprachen",
    "section": "Python",
    "text": "Python\nWenn Sie Python suf Ihrem Rechner installieren wollen, kÃ¶nnen Sie entweder den offiziellen Installer https://www.python.org/downloads/ downloaden, oder die Anaconda Distribution https://www.anaconda.com/products/distribution verwenden. Die Anaconda Distribution ist eine Python-Distribution, die viele nÃ¼tzliche Pakete enthÃ¤lt, die fÃ¼r wissenschaftliches Rechnen und Datenanalyse verwendet werden. Wenn man tatsÃ¤chlich mit Python arbeiten will, empfiehlt es sich, die Anaconda Distribution zu benutzen. Wir werden in dieser Veranstaltung Python benutzen, um ein Experiment zu programmieren. DafÃ¼r reicht es aus, den PsychoPy Installer zu verwenden; diesen finden Sie unter diesem Link: PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen BenutzeroberflÃ¤che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/chapters/software.html#r-1",
    "href": "pages/chapters/software.html#r-1",
    "title": "Programmiersprachen",
    "section": "R",
    "text": "R\nAb der vierten Sitzung werden wir viel mit R arbeiten, um Daten aufzubereiten und grafisch darzustellen. DafÃ¼r mÃ¼ssen Sie die aktuelle Version von R installieren. Diese ist zurzeit R 4.2.2, und kann unter folgender URL geladen werden:\nR ğŸ‘‰ https://cloud.r-project.org/\nWir empfehlen fÃ¼r die Arbeit mit R die RStudio IDE zu verwenden. Diese ist kostenlos und kann unter folgender URL heruntergeladen werden:\nRStudio ğŸ‘‰ https://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "pages/chapters/software.html#lernen",
    "href": "pages/chapters/software.html#lernen",
    "title": "Programmiersprachen",
    "section": "Lernen",
    "text": "Lernen\nDataCamp"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "href": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "title": "1. Sitzung",
    "section": "(Model-based) Cognitive Neuroscience",
    "text": "(Model-based) Cognitive Neuroscience\n\n\nWas heisst Model-based Neuroscience?\nWelche Kenntnisse brauchen wir, um Experiment durchzufÃ¼hren und Daten auszuwerten?\nWelche Programmiertechniken/sprachen brauchen wir?"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "href": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience: Beispiel",
    "text": "Model-based Neuroscience: Beispiel\nMulder, M. J., Wagenmakers, E.-J., Ratcliff, R., Boekel, W., & Forstmann, B. U. (2012). Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff. Journal of Neuroscience, 32(7), 2335â€“2343.\nğŸ‘‰ https://www.jneurosci.org/content/32/7/2335\nIn dieser Studie geht es darum, den Einfluss von Vorwissen (prior knowledge) auf eine simple perzeptuelle Entscheidung zu untersuchen.\n\nAls Task haben die Autoren ein Random Dot Motion Experiment benutzt.\nFÃ¼r die Datenanalyse wurde unter anderem ein Diffusion Decision Model verwendet."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model",
    "href": "slides/01_introduction.html#diffusion-decision-model",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience",
    "href": "slides/01_introduction.html#model-based-neuroscience",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\nÃœberfliegen Sie das Paper, und achten Sie dabei darauf, welche Skills Sie benÃ¶tigen, um eine solche Studie durchzufÃ¼hren.\n\nWelches theoretische Wissen brauchen Sie?\nWelche Programmierkenntnisse brauchen Sie?\n\nfÃ¼r das Experiment\nfÃ¼r die Datenanalyse\n\nWelche statistischen Verfahen brauchen Sie, um die Daten auszuwerten?\nWarum wurde das Experiment im Scanner und ausserhalb des Scanners durchgefÃ¼hrt?\nWas kann man mit einer solchen Studie herausfinden?"
  },
  {
    "objectID": "slides/01_introduction.html#vorwissen",
    "href": "slides/01_introduction.html#vorwissen",
    "title": "1. Sitzung",
    "section": "Vorwissen",
    "text": "Vorwissen\nEs wurden zwei verschiedene Typen von Vorwissen benutzt.\n\nA-Priori Wahrscheinlichkeit, dass die Punktwolke sich nach rechts oder nach links bewegte.\nAsymmetrische Belohnung fÃ¼r korrekte links/rechts Entscheidungen."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model-1",
    "href": "slides/01_introduction.html#diffusion-decision-model-1",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-1",
    "href": "slides/01_introduction.html#model-based-neuroscience-1",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\n\nSchematische Darstellung der erwarteten Resultate.\n\nStarting point: korrekte und inkorrekte RTs unterschieden sich.\nDrift rate: korrekte und inkorrekte RTs sind sich Ã¤hnlich.\n\n\n\nTatsÃ¤chliche Resultate: Quantifizierung des Bias anhand des DDM."
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-2",
    "href": "slides/01_introduction.html#model-based-neuroscience-2",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\nBOLD Responses der Areale welche besonder stark sowohl auf die â€œprior probabilityâ€ als auch auf die â€œpayoffâ€ Manipulation reagierten.\n\n\n\nright MedFG (right medial frontal gyrus)\nACG (anterior cingulate cortex)\nSFG (superior frontal gyrus)\nleft middle temporal gyrus\nIPS (intra-parietal sulcus).\n\n\n\n\n\nDiese Areale sollen eine besondere Rolle in der Verarbeitung von Bias im Entscheidungsverhalten haben."
  },
  {
    "objectID": "slides/01_introduction.html#wichtige-skills",
    "href": "slides/01_introduction.html#wichtige-skills",
    "title": "1. Sitzung",
    "section": "Wichtige Skills",
    "text": "Wichtige Skills\n\n\n\nTheorien Ã¼ber Entscheidungsverhalten\nExperimente programmieren\n\nTiming (inside/outside scanner)\n\nData cleaning and manipulation (data wrangling)\nStatistische Verfahren fÃ¼r messwiederholte Daten\n\nPsychometric curve\nBinary choices / Reaktionszeiten\nrepeated-measures ANOVA\n\n\n\n\nGrafische Darstellung der Resultate\nKognitive Prozessmodelle\n\nfit Diffusion Decision Model (DDM)\n\nAuswertung von fRMI Daten\n\n\n\n\nMit diesen Themen (ausser der Analyse von fMRI Daten) beschÃ¤ftigen wir uns in diesem Kurs.\n\n\n\nğŸ  Neurowissenschaft im Computerlab FS22"
  },
  {
    "objectID": "slides/02_psychopy.html#bias-rdk-experiment",
    "href": "slides/02_psychopy.html#bias-rdk-experiment",
    "title": "2. Sitzung",
    "section": "Bias RDK Experiment",
    "text": "Bias RDK Experiment\n\n\n\nRandom-dot motion direction-discrimination task\nInside/outside scanner (timing)\nBias: cue (probability left/right/unbiased)\nFixation cross\nRDK: 3x3 pixels, coherence\n40 bias trials, 40 neutral trials\n32 valid, 8 invalid trials"
  },
  {
    "objectID": "slides/02_psychopy.html#psychopy",
    "href": "slides/02_psychopy.html#psychopy",
    "title": "2. Sitzung",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy.html#pavlovia",
    "href": "slides/02_psychopy.html#pavlovia",
    "title": "2. Sitzung",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy.html#understanding-your-computer",
    "href": "slides/02_psychopy.html#understanding-your-computer",
    "title": "2. Sitzung",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: VariabilitÃ¤t ~15 ms.\nScreen refresh fÃ¤ngt oben an und endet (~10 ms spÃ¤ter) unten."
  },
  {
    "objectID": "slides/02_psychopy.html#probieren-sie-es-selber",
    "href": "slides/02_psychopy.html#probieren-sie-es-selber",
    "title": "2. Sitzung",
    "section": "Probieren Sie es selber!",
    "text": "Probieren Sie es selber!\n\nVersuchen Sie selber, Teile des Experiments in PsychoPy zu implementieren\n\n\nWenn Sie eine Starthilfe benÃ¶tigen, downloaden Sie ein Beipiel: ğŸ‘‰ Practice Trials\nEine EinfÃ¼hrung finden Sie hier: ğŸ‘‰ Verhaltensexperiment mit PsychoPy\n\n\n\n\nğŸ  Neurowissenschaft im Computerlab FS23"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#perceptual-decisions",
    "href": "slides/02_psychopy_gw.html#perceptual-decisions",
    "title": "PsychoPy Experiment",
    "section": "Perceptual decisions",
    "text": "Perceptual decisions\n\nberuhen auf der Wahrnehmung, Evaluation, Integration von Sinnesempfindungen\nsind oft handlungsrelevant\nneurowissenschaftlich untersucht werden die neuronalen Schaltkreise welche Wahrnehmungssignale kodieren, speichern und analysieren und wie diese mit Verhalten zusammenhÃ¤ngen\nmÃ¶gliche Fragenstellungen: Gewichtung von Sinnesinformationen bei sensorischen Konflikten oder der Einfluss von Vorwissen auf Entscheidungen\n\n\n\n\n\n\n\nHands-on\n\n\n\nIn welchen Situationen treffen wir perzeptuelle Entscheidungen?\nWo ist der Einfluss von Vorwissen auf perzeptuelle Entscheidungen alltagsrelevant?\n\nDiskutieren Sie die Fragen in kleinen Gruppen und finden Sie je 3 Beispiele."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-i",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-i",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment I",
    "text": "Random-dot motion Experiment I\n\n\n\nRandom-dot motion direction-discrimination task (Bias in the brain: Mulder et al., 2012)\ncoherence: probability that a dot moves coherent with the motion direction\nbias: prior probabity cue before random-dot task (left/right/unbiased) or reward cue for a left or right answer (if correct)\nmeasures: response times and accuracy"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-ii",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-ii",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment II",
    "text": "Random-dot motion Experiment II\n\n\n\n\n\n\nHands-on\n\n\nWie wirken sich die beiden Formen von Vorwissen auf das Antwortverhalten aus?\n\nBei welcher Bedingung antworten die Personen schneller?\nWo machen sie mehr Fehler?\n\nWas denken Sie? Diskutieren Sie die Fragen in kleinen Gruppen ohne im Paper nachzuschauen."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iii",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iii",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment III",
    "text": "Random-dot motion Experiment III"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#psychopy",
    "href": "slides/02_psychopy_gw.html#psychopy",
    "title": "PsychoPy Experiment",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#pavlovia",
    "href": "slides/02_psychopy_gw.html#pavlovia",
    "title": "PsychoPy Experiment",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#understanding-your-computer",
    "href": "slides/02_psychopy_gw.html#understanding-your-computer",
    "title": "PsychoPy Experiment",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: VariabilitÃ¤t ~15 ms.\nScreen refresh fÃ¤ngt oben an und endet (~10 ms spÃ¤ter) unten."
  },
  {
    "objectID": "slides/02_psychopy_gw.html#probieren-sie-es-selber",
    "href": "slides/02_psychopy_gw.html#probieren-sie-es-selber",
    "title": "PsychoPy Experiment",
    "section": "Probieren Sie es selber!",
    "text": "Probieren Sie es selber!\n\n\n\n\n\n\nHands-on\n\n\nVersuchen Sie selber, Teile des Experiments in PsychoPy zu implementieren\n\n\n\n\nWenn Sie eine Starthilfe benÃ¶tigen, downloaden Sie ein Beipiel: ğŸ‘‰ Practice Trials\nEine EinfÃ¼hrung finden Sie hier: ğŸ‘‰ Verhaltensexperiment mit PsychoPy\n\n\n\n\nğŸ  Neurowissenschaft im Computerlab FS23"
  },
  {
    "objectID": "pages/exercises/exercise_01.html",
    "href": "pages/exercises/exercise_01.html",
    "title": "Ãœbung 1",
    "section": "",
    "text": "Vertiefung\n\n\n\nDiese Ãœbung muss nicht abgegeben werden; sie dient als Vorbereitung fÃ¼r die folgende Sitzung.\n\n\n\n\nInstallieren Sie PsychoPy von der Website. PsychoPy ist ein Open-Source Programm fÃ¼r MacOS, Windows und Linux, mit welchen wir sehr viele verschiedene Verhaltensexperimente (Neuroscience, Psychologie, Psychophysik, Linguistik) programmieren kÃ¶nnen. Diese lassen sich z.B. mit Eyetracking verbinden, oder im fRMI Scanner und mit EEG verwenden.\nPsychoPy ğŸ‘‰ https://www.psychopy.org/download.html.\nAm einfachsten ist es, das â€œStandalone packageâ€ fÃ¼r MacOS oder Windows zu installieren.\n\nUnter MacOS scheint die neueste Version vom Februar 2022 Probleme zu bereiten â€” es ist daher (zurzeit noch) besser, die Version 2021.2.3 zu installieren.\n\n\n\n\n\nWas verstehen Sie unter folgenen Begriffen:\n\n\nModel-based Neuroscience\nEvidence accumulation\n\n\nWas kÃ¶nnte man unter Vorwissen (prior knowledge) verstehen? In welchen Kontexten kÃ¶nnte es bei Entscheidungen nÃ¼tzlich sein, Vorwissen zu benutzen?"
  },
  {
    "objectID": "pages/exercises/exercise_02.html",
    "href": "pages/exercises/exercise_02.html",
    "title": "Ãœbung 2",
    "section": "",
    "text": "Vertiefung\n\n\n\nDie Daten, welche Sie in dieser Ãœbung sammeln, mÃ¼ssen abgegeben werden; wir werden diese im Verlauf des Semesters analysieren. Bitte die Datenfiles in einem ZIP File bis 8. MÃ¤rz auf ILIAS hochladen.\n\n\n\n\n\nDas fertige Experiment befindet sich auf Github. Sie kÃ¶nnen es unter diesem Link downloaden. ğŸ‘‰ LINK.\nFÃ¼hren Sie das Experiment ein- oder mehrere Male selber durch.\nTesten Sie eine weitere Person (Alter ca. 20-60).\nZippen Sie bitte Ihren Datensatz und denjenigen der anderen Testperson und laden Sie das ZIP FIle auf ILIAS."
  },
  {
    "objectID": "pages/solutions/solution_03.html",
    "href": "pages/solutions/solution_03.html",
    "title": "Ãœbung 3: LÃ¶sung",
    "section": "",
    "text": "In dieser Aufgabe bearbeiten Sie Daten aus einem Detektionssexperiment. Versuchspersonen mussten in zwei Bedingungen (bias und no_bias) ein Signal, welches in Rauschen eingebettet war, detektieren. Im Datensatz sind folgende Variablen:\nsubject: Subjekt ID\ntrial_num: Trialnummer, durchnummeriert in jeder Bedingung\ncondition: Bedingung (_Bias_ und _No Bias_)\nsignal_present: Indikatorvariable fÃ¼r Signal (0: absent, 1: present)\ncorrect: Indikatorvariable fÃ¼r korrekte Antwort (0: incorrekt, 1: correct)\nrt: Reaktionszeit in Sekunden\n\n\n\nAufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d fÃ¼r den Datensatz.\nÃœberprÃ¼fen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\nlibrary(tidyverse)\n\n\nd <- read_csv(\"data/data-exercise-03.csv\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nRows: 5,756\nColumns: 6\n$ subject        <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2â€¦\n$ condition      <chr> \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\",â€¦\n$ signal_present <dbl> 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0â€¦\n$ correct        <dbl> 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1â€¦\n$ rt             <dbl> 4.076, 1.167, 0.598, 0.375, 0.454, 0.410, 0.370, 0.559,â€¦\n$ trial_num      <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦\n\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd <- d |>\n    mutate(subject = as_factor(subject),\n           condition = as_factor(condition))\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen Ã¼ber dem Bedingungsmittelwert liegen?\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants <- d |>\n    group_by(subject, condition) |>\n    dplyr::summarise(\n        mean_P = mean(rt))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- d |>\n    group_by(condition) |>\n    dplyr::summarise(\n        mean_C = mean(rt),\n        sd_C = sd(rt))\n\n\nsum_stats_participants <-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(outlier_P = (mean_P - mean_C) > 2 * sd_C)\n\n\n# show outlier participants\nsum_stats_participants |>\n    filter(outlier_P == 1) |>\n    show()\n\n# A tibble: 0 Ã— 6\n# Groups:   subject [0]\n# â€¦ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\n\nEs gibt keine Versuchsperson, deren mittlere Reaktionszeit in einer Bedingung mehr als zwei Standardabweichungen Ã¼ber dem Bedingungsmittelwert liegt. Dies bedeutet, dass sich in excluded keine Personen befinden, und der Dataframe folglich \\(0\\) Zeilen hat.\n\nexcluded <- sum_stats_participants |>\n    filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 0 Ã— 6\n# Groups:   subject [0]\n# â€¦ with 6 variables: subject <fct>, condition <fct>, mean_P <dbl>,\n#   mean_C <dbl>, sd_C <dbl>, outlier_P <lgl>\n\n\nDer nÃ¤chste Schritt wÃ¤re also nicht unbedingt notwendig.\n\nd_cleaned <- d |>\n    filter(!(subject %in% excluded$subject)) |>\n    mutate(subject = fct_drop(subject))\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen lÃ¤nger als 4 Standardabweichungen Ã¼ber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\nZu Aufgabe 3.a)\nWir wollen Trials identifizieren, bei denen Vpn lÃ¤nger gebraucht haben, als 4 Standardabweichungen Ã¼ber dem Bedingungsmittelwert. Das bedeutet (rt - mean_C) > 4 * sd_C, und nicht abs(rt - mean_C) > 4 * sd_C. Letzteres wÃ¼rde auch Trials als Ausreisser identifizieren, welche 4 Standardabweichungen unter dem Bedingungsmittelwert liegen.\nZu Aufgabe 3.b)\nDie Reaktionszeiten sind hier in Sekunden, nicht Millisekunden. Dies bedeutet, wir brauchen rt < 0.100, und nicht rt < 100.\n\nd_cleaned <- d_cleaned |>\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            (rt - mean_C) > 4 * sd_C ~ \"too slow\",\n            rt < 0.100 ~ \"too fast\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |>\n    filter(trial_type != \"OK\")\n\n# A tibble: 165 Ã— 9\n   subject condition signal_present correct     rt trial_â€¦Â¹ mean_C  sd_C trialâ€¦Â²\n   <fct>   <fct>              <dbl>   <dbl>  <dbl>    <dbl>  <dbl> <dbl> <fct>  \n 1 2       bias                   0       1 4.08          1  0.697 0.751 too slâ€¦\n 2 2       bias                   1       1 0.035        41  0.697 0.751 too faâ€¦\n 3 2       bias                   0       1 6.92         50  0.697 0.751 too slâ€¦\n 4 2       bias                   0       1 0.085        51  0.697 0.751 too faâ€¦\n 5 2       bias                   0       1 0.033        70  0.697 0.751 too faâ€¦\n 6 2       bias                   0       1 5.09         74  0.697 0.751 too slâ€¦\n 7 2       bias                   0       1 6.59         94  0.697 0.751 too slâ€¦\n 8 2       bias                   0       1 5.09        121  0.697 0.751 too slâ€¦\n 9 2       bias                   1       1 0.077       138  0.697 0.751 too faâ€¦\n10 3       no_bias                1       0 0.0958        4  0.691 0.773 too faâ€¦\n# â€¦ with 155 more rows, and abbreviated variable names Â¹â€‹trial_num, Â²â€‹trial_type\n\n\nVor dem Entfernen der Ausreisser Trials haben wir 5756 Datenpunkte.\n\nnrow(d_cleaned)\n\n[1] 5756\n\n\n\nd_cleaned <- d_cleaned |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\nNach dem Entfernen haben wir noch 5591.\n\nnrow(d_cleaned)\n\n[1] 5591\n\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\n\nd_cleaned |> write_csv(\"data/data-cleaned.csv\")"
  },
  {
    "objectID": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iv",
    "href": "slides/02_psychopy_gw.html#random-dot-motion-experiment-iv",
    "title": "PsychoPy Experiment",
    "section": "Random-dot motion Experiment IV",
    "text": "Random-dot motion Experiment IV\n\nStimuli\n\nrandom dots: 3x3 pixels, coherence level: 8%\n\nConditions\n\n40 bias trials and 40 neutral trials (half of motion to left / other half to the right)\n32 valid (cue correct) and 8 invalid (cue incorrect) trials\n\nTrials and Timing\n\nFixation 1 (100/350/800/1200 ms)\nCue (1000 ms)\nFixation 2 (3400/4000/4500/5000 ms)\nDots (1500 ms)\nFeedback"
  }
]