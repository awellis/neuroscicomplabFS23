---
title: "Einf√ºhrung"
description: |
  Signal Detection Theory: Entscheidungen unter Unsicherheit.
date: "2022-04-24"
author:
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern 
    affiliation-url: https://www.kog.psy.unibe.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../../bibliography.bib
format:
    html:
        toc: true
        code-link: true
execute: 
  cache: false
code-annotations: select
---

```{r}
#| include: false
# Set working directory of R
knitr::opts_knit$set(root.dir = '../../data/')
```
:::{.callout-tip collapse="false"}
## Lernziele

In der heutigen Sitzung lernen wir:

- Simple bin√§re Entscheidungen mit Signal Detection Theory modellieren
- Konzepte der Signal Detection Theorie (SDT) 
- SDT mit R simulieren
:::

# Entscheidungen unter Unsicherheit
Entscheidungsfindung unter Unsicherheit tritt auf, wenn Sie Entscheidungen treffen m√ºssen, ohne vollst√§ndige Informationen √ºber m√∂gliche Ergebnisse zu haben. Der Prozess beinhaltet:

- Identifizierung des Problems oder der Entscheidung. Dies bedeutet, dass wir unsere Hypothesen formulieren m√ºssen.
- Sammeln von Informationen (Evidenz) als Entscheidungsgrundlage.
- Sch√§tzung der Wahrscheinlichkeiten von Ergebnissen f√ºr jede Alternative unter Verwendung verrauschter Daten.
- Bewertung potenzieller Kosten und Risiken unter Ber√ºcksichtigung objektiver und subjektiver Faktoren.
- Abw√§gung von Faktoren und Auswahl der Option, die Ihren Zielen und Pr√§ferenzen am besten entspricht.

Mehrere Modelle und Werkzeuge k√∂nnen bei der Bew√§ltigung von Unsicherheit helfen:

- Erwartungs-Nutzen-Theorie: Schl√§gt vor, die Option mit dem h√∂chsten erwarteten Nutzen zu w√§hlen, berechnet durch Multiplikation der Wahrscheinlichkeit jedes Ergebnisses mit seinem Nutzen (Zufriedenheit oder Pr√§ferenz).
- Prospect-Theorie: Ber√ºcksichtigt die Verzerrungen und Heuristiken von Menschen bei der Entscheidungsfindung unter Unsicherheit, wie Verlustaversion und Wahrscheinlichkeitsgewichtung.
- Entscheidungsb√§ume: Grafische Darstellungen, die bei der Visualisierung und dem Vergleich von Optionen, Ergebnissen und Wahrscheinlichkeiten helfen.
- Bayesianische Entscheidungstheorie: Kombiniert vorhandenes Wissen mit neuen Informationen, um Wahrscheinlichkeiten zu aktualisieren und Entscheidungen auf der Grundlage der aktualisierten Wahrscheinlichkeiten zu treffen. 
  
Das Verst√§ndnis von Entscheidungsfindung unter Unsicherheit ist relevant f√ºr Bereiche wie Wirtschaft, Finanzen, Psychologie, Management und √∂ffentliche Politik, in denen Entscheidungen oft unsichere Ergebnisse beinhalten.

:::{.callout-important}
## √úbung
√úberlegen Sie sich einige Beispiele f√ºr Entscheidungen, die Sie in Ihrem Leben treffen m√ºssen, bei denen Sie nicht alle Informationen haben, die Sie ben√∂tigen, um eine fundierte Entscheidung zu treffen. 

Welche Modelle und Werkzeuge k√∂nnten Ihnen helfen, diese Entscheidungen zu treffen? Wie unterscheiden sich die Prozesse der Entscheidungsfindung in diesen Beipielen? welche Gemeinsamkeiten gibt es?


:::{.callout-tip collapse="true"}
## Beipiele
- Perzeptuelle Entscheidungen
- Kaufentscheidungen
:::
:::


# Signal Detection Theory

Wir schauen uns eine Framework an, das uns hilft, Entscheidungen unter Unsicherheit zu verstehen und zu modellieren. 

Signal-Detektionstheorie (SDT) ist eine statistische Entscheidungstheorie, die verwendet werden kann, um die Leistung eines Probanden in jeder Aufgabe zu modellieren, die eine bin√§re Entscheidung erfordert. Die SDT wurde auf viele Bereiche der Psychologie und Neurowissenschaften angewendet. F√ºr einen etwas √§lteren, aber immer noch sehr guten √úberblick siehe @goldNeuralBasisDecision2007a. Dieses Papier beschreibt mehrere Anwendungen der SDT, insbesondere f√ºr die Untersuchung von Reizmustern mit zuf√§lliger Punktverschiebung.

Die SDT kann angewendet werden, wann immer zwei m√∂gliche Stimulus-Typen unterschieden werden m√ºssen. Die Theorie wurde zuerst in Studien zur Wahrnehmung angewandt, bei denen Probanden zwischen Signalen (Reizen) und Rauschen (keine Reize) unterschieden. Die Bezeichnungen Signal und Rauschen sind geblieben, aber die SDT wurde seitdem in vielen anderen Bereichen angewendet. Beispiele (und ihre entsprechenden Signal- und Rauschreize) sind "Recognition memory" (alte und neue Elemente), L√ºgendetektion (L√ºgen und Wahrheiten), Personalauswahl (w√ºnschenswerte und unerw√ºnschte Bewerber), medizinische Diagnose (kranke und gesunde Patienten), industrielle Inspektion (inakzeptable und akzeptable Produkte) und "Information retrieval" (relevante und irrelevante Informationen). In neurowissenschaftlichen Studien werden mit SDT perzeptuelle System, aber auch Entscheidungen in anderen Bereichen untersucht. Ein m√∂gliches Anwendungsgebiet ist "value-based decision making"; hier geht Entscheidungen auf der Basis von gesch√§tzten Kosten und Nutzen einher. Ein Beispiel daf√ºr w√§re eine Kaufentscheidung, bei der der K√§ufer zwischen zwei Produkten w√§hlt, die unterschiedliche Kosten und Nutzen haben.

Die SDT geht davon aus, dass der Entscheidungstr√§ger eine bin√§re Wahl zwischen zwei Alternativen (z. B. Signal oder Rauschen) auf der Grundlage begrenzter oder unsicherer Informationen treffen muss. Die Entscheidung wird getroffen, indem die empfangenen Informationen mit einem Kriterium oder Schwellenwert verglichen werden. Wenn die Informationen diesen Schwellenwert √ºberschreiten, w√§hlt der Entscheidungstr√§ger das Signal; andernfalls w√§hlt er das Rauschen. 

:::{.callout-important}
## √úbung
Inwiefern entspricht dieses Vorgehen dem, was Sie √ºber Hypothesentests in der Statistik gelernt haben?
:::

Einer der wichtigsten Beitr√§ge der SDT ist die Unterscheidung zwischen Sensitivit√§t und Voreingenommenheit (Bias) im Entscheidungsprozess. Sensitivit√§t bezieht sich auf die F√§higkeit des Entscheidungstr√§gers, zwischen zwei verschiedenen Arten von Signalen zu unterscheiden, w√§hrend der Bias die Tendenz des Entscheidungstr√§gers bezeichnet, eine Alternative gegen√ºber der anderen a priori zu bevorzugen. Durch die Trennung dieser beiden Komponenten k√∂nnen Forscher analysieren, wie verschiedene Faktoren die Entscheidungsleistung beeinflussen.


:::{.callout-tip}
## Literatur
F√ºr eine ausf√ºhrlichere Einf√ºhrung in die SDT, siehe @stanislawCalculationSignalDetection1999b und @macmillanDetectionTheoryUser2004a. @knoblauchSignalDetectionTheory2012 bietet eine gute Einf√ºhrung in die Verwendung von R zur Durchf√ºhrung von SDT-Analysen. @decarloSignalDetectionTheory diskutiert die Beziehung zwischen SDT und verallgemeinerten linearen Modellen.
:::




## Theorie

Die zentrale Fragestellung der SDT lautet: was ist der (unbekannte) Zustand der Welt, angesichts der verrauschten Daten, die von den Sinnessystemen bereitgestellt werden? 

In einem Modell macht es Sinn, sicherzustellen, dass das Problem einfach ist -- wir beschr√§nken die Welt auf zwei m√∂gliche Zust√§nde. Diese k√∂nnen als Hypothesen betrachtet werden.

:::{.callout-important}
## Beispiele
- Signal / Rauschen
- Links / Rechts
- Ged√§chtnis: alt (schon gesehen) / neu (noch nie gesehen)
:::


Wir werden nun die Signal Detection Theorie anhand eine Beispiels durchgehen. Dieses werden wir aus zwei Perspektiven betrachten: 1) aus der Perspektive einer Person, welche die Aufgabe hat, Stimuli in zwei Klassen zu klassifizieren und 2) aus der Perspektive eines Modells, das die Leistung der Person in der Aufgabe vorhersagt.


### Die Perspektive der Versuchsperson
Wir betrachten ein Experiment, bei dem eine Person einen Stimulus in eine von zwei m√∂glichen Kategorien einordnen muss; dies k√∂nnte ein Random Dot Experiment sein, bei dem die Stimuli entweder nach links oder rechts bewegt sind, oder ein Ged√§chtnisexperiment, bei dem die Stimuli entweder alt (schon gesehen wurden) oder neu sind.

Die Aufgabe der Person ist es, eine bin√§re Klassifikation mit den Antwortoptionen `alt` und `neu` durchzuf√ºhren. Die Antwortoptionen entsprechen den beiden m√∂glichen Zust√§nden der Welt, oder genauer gesagt, Hypothesen der Person √ºber die m√∂glichen Zust√§nde der Welt.


Gegeben den Reiz hat die Person zwei Antwortm√∂glichkeiten. Daher betrachten wir nur die `Ja`-Antworten, wenn der Reiz alt (Treffer) oder `neu` (Falschalarme) ist.



#### Annahmen

1) Die Person verarbeitet den Stimulus (in diesem Fall ein Wort oder ein Bild) und gelangt zu einer internen Repr√§sentation des Stimulus. Diese interne Repr√§sentation ist nicht deterministisch, sondern variiert zuf√§llig. Die interne Repr√§sentation demzufolge eine Zufallsvariable $X$. Wir nehmen an, dass die interne Repr√§sentation normalverteilt ist, mit einer bekannten Standardabweichung $\sigma$ (der Einfachheit halber nehmen wir an, dass $\sigma=1$). 
2) Die Zufallsvariable $X$ repr√§sentiert die Information, die die Person √ºber den Stimulus hat, also die Evidenz.

3) Die Person weiss, dass die $X$ aus einer von zwei Verteilungen gezogen wurde, die sich nur in ihrer Lage (in ihrem Mittelwert) unterscheiden. Welche Verteilung es war, weiss die Person jedoch nicht -- dies muss sie anhand eines Kriteriums entscheiden.

4) Die Person hat ein Kriterium $k$, das sie verwendet, um zu entscheiden, ob der Stimulus alt oder neu ist. Eine einfache Entscheidungsregel lautet: Wenn $X > k$, dann ist der Stimulus alt, andernfalls ist er neu.

<aside>
Beispiel Recognition Memory: Wenn der Versuchsperson ein Bild gezeigt wird, ruft dies ein Gef√ºhl von 'Vertrautheit' (familiarity) hervor. Dies ist eine latente Variable.
</aside>



```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(viridis)
xlim <- c(-4.5, 4.5)
alpha <- c(0.6, 0.2)

dprime <- 1
criterion <- -0.2
colors <- viridis(n = 4, 
                  begin = 0, 
                  end = 0.98, 
                  direction = -1)

p1 <- tibble(x = seq(xlim[1], xlim[2], by = 0.1)) |> 
    ggplot(aes(x)) +
    stat_function(fun = dnorm, colour = colors[1], 
                  args = list(mean = -dprime/2, sd = 1),
                  size = 1.5) +
    stat_function(fun = dnorm, colour = colors[4], 
                  args = list(mean = dprime/2, sd = 1),
                  size = 1.5) +
    geom_vline(xintercept = c(-dprime/2, dprime/2), size = 1, linetype = "dotted", 
               alpha =  0.4) +
    scale_y_continuous(breaks = NULL) +
    scale_x_continuous(labels = NULL) +
    labs(x = "Familarity", y = "") +
    annotate("text", 
           x = 0.1, 
           y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.03,
           label = "d'", 
           size = 8) +
    annotate("segment", x = -dprime/2, 
                 xend = dprime/2, 
                 y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.01, 
                 yend = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.01,
           size = 1) +
    annotate("text", 
           x = -1.5, 
           y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.03,
           label = "new", 
           size = 6, 
           color = "grey60") +
      annotate("text", 
           x = 1.5, 
           y = dnorm(dprime/2, mean = dprime/2, sd = 1) + 0.03,
           label = "old", 
           size = 6, 
           color = "grey60") +
  theme_linedraw()
p1
```

Noch nie gesehene Stimuli (neu) produzieren eine niedrige Vertrautheit (familiarity), w√§hrend alte Stimuli eine hohe Vertrautheit produzieren.
Um einen Stimulus zu klassifizieren, braucht die Person eine Entscheidungsregel.


```{r}
#| echo: false

p2 <- p1 + 
  geom_vline(xintercept = 0, size = 1, 
               alpha = 0.4,
             linetype = "dashed") +
  geom_area(stat = "function", fun = dnorm, 
              args = list(mean = -dprime/2, sd = 1),
              fill = colors[1], alpha = 0.6,
              xlim = c(criterion, xlim[2])) +

  geom_area(stat = "function", fun = dnorm, 
              args = list(mean = dprime/2, sd = 1),
              fill = colors[4], alpha = alpha[2],
              xlim = c(criterion, xlim[2])) +
  geom_vline(xintercept = criterion, size = 1, 
               linetype = 1) +
    annotate("text", 
           x = -0.05,
           y = -0.02,
           label = "k", 
           size = 8)
p2
```

Eine einfache  Entscheidungsregel lautet: Wenn die Vertrautheit gr√∂sser als das Kriterium ist, wenn also $x > k$, dann ist der Stimulus alt, andernfalls ist er neu.

### Die Perspektive des/der externen Beobachter*in

Die Leistung der Versuchsperson kann durch die Wahrscheinlichkeit beschrieben werden, dass sie einen Treffer (`Hit`) oder einen `False Alarm` produziert. Diese Wahrscheinlichkeiten werden als _Hit Rate_ und _False Alarm Rate_ bezeichnet. Die _Hit Rate_ ist die Wahrscheinlichkeit, dass die Person einen Treffer produziert, wenn der Stimulus alt ist. Die _False Alarm Rate_ ist die Wahrscheinlichkeit, dass die Person einen Falschalarm produziert, wenn der Stimulus neu ist.

Die Antworten der Versuchspersonen k√∂nnen in einer Tabelle zusammengefasst werden, mit vier m√∂glichen Ergebnissen. Wir nennen hier die Antwortoptionen der Einfachheit halber `ja` und `nein`; die Frage an die Versuchsperson lautet: "Hast du den Stimulus schon einmal gesehen?".

|              | **Signal**     |                        |
|------------- |--------------- |------------------------|
| **Antwort**  | Ja             | Nein                   |
| Ja           | Hit            | False alarm (FA)       |
| Nein         | Miss           | Correct rejection (CR) |

- **Hit**:  Stimulus ist `alt`, Antwort ist `Ja`
- Miss: Stimulus ist `alt`, Antwort ist `Nein`
- **False alarm**: Stimulus ist `neu`, Antwort ist `Ja`
- Correct rejection: Stimulus is `neu`,  Antwort ist `Nein`


Als Forscher*in interessiert uns nicht nur, wie oft die Versuchsperson Hits und False ALarms produziert, sondern vor allem folgende Fragen:

- Wie gut kann die Person Stimuli klassifizieren?
- Hat die Person eine Vorliebe f√ºr eine der beiden Antwortoptionen?


Diese beiden Fragen k√∂nnen wir mit den Signal Detection Theory (SDT) Parametern beschreiben.

Die beiden wichtigsten SDT Parameter sind $d'$ und $c$. $d'$ ist ein Mass daf√ºr, wie weit auseinander die Verteilungen der beiden Stimuluskategorien liegen. $c$ ist ein Mass daf√ºr, ob eine Voreingenommenheit (bias) f√ºr eine der beiden Antwortoptionen besteht. Genauer gesagt ist $c$ der Abstand vom tats√§chlichen Kriterium zum Punkt welcher genau zwischen den Verteilungen liegt.

Um diese beiden Parameter aus den beobachteten Antworth√§ufigkeiten zu sch√§tzen, m√ºssen wir zuerst die relativen H√§ufigkeiten der Hits und der False Alarms sch√§tzen.


Die Hits sind die korrekten Antworten auf alte Stimuli. Dies bedeutet, dass wir z√§hlen, wie oft bei einem `alten` Stimulus die Antwort `ja` war. Die False Alarms sind die inkorrekten Antworten auf neue Stimuli. Dies bedeutet, dass wir z√§hlen, wie oft bei einem `neuen` Stimulus die Antwort `ja` war.
$$ p_{H} = \frac{Hits}{Hits + Misses} $$
$$ p_{FA} = \frac{False Alarms}{False Alarms + Correct Rejections} $$



Schauen wir uns die Grafik an: Wenn der Stimulus `neu` ist, dann werden wir mit einer Wahrscheinlichkeit von $p_{FA}$ einen False Alarm produzieren. 

$$ p_{FA} = P(y = 1 | X = 0) = 1 - \Phi(k) $$

$k$ ist die die von der Person willk√ºrlich gesetzte Klassifikationsgrenze. $\Phi$ ist die Verteilungsfunktion der Normalverteilung.

:::{.callout-important}
$\Phi(k)$ gibt hier die Wahrscheinlichkeit, dass eine Zufallsvariable $x$ kleiner als $k$ ist. Wir wollen eigentlich wissen, was die Wahrscheinlichkeit ist, dass $x$ gr√∂sser als $k$ ist -- diese ist $1 - \Phi(k)$. 
:::

```{r}
#| echo: false

xlim <- c(-4.5, 4.5)
alpha <- c(0.6, 0.2)

dprime <- 1
criterion <- -0.2
colors <- viridis(n = 4, 
                  begin = 0, 
                  end = 0.98, 
                  direction = -1)

tibble(x = seq(xlim[1], xlim[2], by = 0.1)) |> 
    ggplot(aes(x)) +
    stat_function(fun = dnorm, colour = colors[1], 
                  args = list(mean = -dprime/2, sd = 1),
                  size = 1.5) +
    geom_area(stat = "function", fun = dnorm, 
              args = list(mean = -dprime/2, sd = 1),
              fill = colors[1], alpha = 0.6,
              xlim = c(criterion, xlim[2])) +
    geom_vline(xintercept = criterion, size = 1, 
               linetype = 1) +
  ggtitle("False Alarms") +
  xlab("") +
  theme_linedraw()
```

Wenn der Stimulus `alt` ist, dann werden wir mit einer Wahrscheinlichkeit von $p_{H}$ einen Hit produzieren.

$$ p_{H} = P(y = 1 | X=1) = 1 - \Phi(k-d') $$



```{r}
#| echo: false

tibble(x = seq(xlim[1], xlim[2], by = 0.1)) |> 
    ggplot(aes(x)) +
    stat_function(fun = dnorm, colour = colors[4], 
                  args = list(mean = dprime/2, sd = 1),
                  size = 1.5) +
    geom_area(stat = "function", fun = dnorm, 
              args = list(mean = dprime/2, sd = 1),
              fill = colors[4], alpha = 0.6,
              xlim = c(criterion, xlim[2])) +
    geom_vline(xintercept = criterion, size = 1, 
               linetype = 1) +
    xlab("") +
  ggtitle("Hits") +
  theme_linedraw()
```


Wir k√∂nnen das auch in einer Gleichung schreiben:

$$ P(y = 1 | X = x) = 1 - \Phi(k-d'X) = \Phi(-k + d'X) $$
wo $X$ eine Indikatorvariable ist, d.h. sie nimmt den Wert `1` f√ºr `alt` und `0` f√ºr `neu`.

Die Gleichung gibt die bedingte Wahrheitswahrscheinlichkeit f√ºr eine `ja` Antwort, gegeben den Stimulus. Ist der Stimulus `alt`, dann ist $X = 1$ und $d'X = d'$, ist der Stimulus `neu`, dann ist $X = 0$ und $d'X = 0$.



Hier sind beide Verteilungen nochmals in einer Grafik zusammengefasst:


```{r}
#| echo: false

p2
```


Unser Ziel ist es, die Parameter $d'$ und $c$ zu sch√§tzen, d.h. wir wollen wissen: Wie weit liegen die Mittelwerte der Verteilung auseinander, und wo hat die Person ihr Kriterium gesetzt? Wir k√∂nnen dies mit folgenden Gleichung machen:

**Kriterium k**:
 Hier wollen wir wissen: Wo liegt der Wert, f√ºr den die Wahrscheinlichkeit, √ºber $k$ zu liegen, $p_{FA}$ entspricht? Wir brauchen daf√ºr die Umkehrfunktion der Verteilungsfunktion $\Phi$: $\phi^{-1}$.



:::{.callout-important collapse="true"}
## Verteilungen in R
Die Verteilungsfunktion der Normalverteilung heisst in R `pnorm()`. Die Umkehrfunktion dazu heisst Quantilfunktion und heisst in R `qnorm()`.

Die verwandten Funktionen sind die Dichtefunktion `dnorm()` und `rnorm()`, mit der wir Zufallszahlen aus der Normalverteilung ziehen k√∂nnen.

Die kumulative Verteilungsfunktion:
```{r}
#| echo: false

tibble(x = seq(-3, 3, by = 0.01)) |> 
  ggplot(aes(x)) +
  stat_function(fun = pnorm, colour = "steelblue3", 
                  args = list(mean = 0, sd = 1),
                  size = 1.5) +
  labs(x = "Probability", y = "Score") +
  scale_x_continuous(limits = c(-3, 3)) +
  scale_y_continuous(limits = c(0, 1)) + 
  ggtitle("Distribution function / cdf / pnorm()") +
  theme_linedraw()
```

Die Quantilfunktion sieht so aus:
```{r}
#| echo: false

tibble(x = seq(0, 1, by = 0.01)) |> 
  ggplot(aes(x)) +
  stat_function(fun = qnorm, colour = "steelblue3", 
                  args = list(mean = 0, sd = 1),
                  size = 1.5) +
  labs(x = "Probability", y = "Score") +
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(-3.5, 3.5), breaks = -3:3) + 
  ggtitle("Probit function / quantile function / inverse cdf / qnorm()") +
  theme_linedraw()
```
:::




Wir k√∂nnen nun umformen:
$$ p_{FA} = P(y = 1 | X = 0) = 1 - \Phi(k) $$
$$ \Phi(k) = 1 - p_{FA} $$

$$ k = \phi^{-1}(1-p_{FA}) = -\phi^{-1}(p_{FA}) $$


Wir interessieren uns nun aber f√ºr den Abstand zum optimalen Kriterium: dieser Parameter wird $c$ genannt. Im optimalen Fall ist $c = 0$, und $k=\frac{d'}{2}$. Dann w√§ren die Miss- und Fehlalarmrate gleich gross (anhand der Grafik selber √ºberpr√ºfen). $c$ ist also der Durchschnitt der Hit- und False Alarm Rate, mit $-1$ multipliziert. Negative Werte von $c$ bedeuten, dass die Person tendenziell mehr Fehlalarme produziert als Misses, positive Werte bedeuten, dass die Person tendenziell mehr Misses produziert als Fehlalarme.

$$ c = -\frac{1}{2} \left[\phi^{-1}(p_{H}) + \phi^{-1}(p_{FA})\right] $$









F√ºr $d'$ gilt:

$$ d' = k - \phi^{-1}(1-p_{H}) = \phi^{-1}(p_{H}) - \phi^{-1}(p_{FA}) $$

oder anders ausgedr√ºckt:
$$ d' = \phi^{-1}(P(y = 1 | old)) - \phi^{-1}(P(y = 1 | new)) $$

und in Worten:

$d'$ = Z-Score der Hit Rate - Z-Score der False Alarm Rate.

:::{.callout-tip}
Der Begriff Z-Score wird oftmals verwendet, und die Quantile einer Standardnormalverteilung zu bezeichnen.
:::

$d'$ quantifiziert die Sensitivit√§t eines Beobachters bei der Unterscheidung zwischen zwei Stimulusklassen. Ein gr√∂√üerer $d'$-Wert zeigt eine gr√∂ssere Sensitivit√§t an. Dies bedeutet, dass die Verteilungen der beiden  Stimulusklassen st√§rker voneinander getrennt sind und somit leichter unterscheidbar sind. 

# Ged√§chtnis-Experiment

Wir schauen uns ein Beispiel an (von diesem [Blogpost](https://vuorre.netlify.com/post/2017/10/09/bayesian-estimation-of-signal-detection-theory-models-part-1/)).

Die Daten sind aus einem Experiment, in dem die Teilnehmenden Bilder von bekannten und unbekannten Gesichtern gesehen haben. Sie mussten dann entscheiden, ob sie das Gesicht schon einmal gesehen haben oder nicht. Der  Datensatz `confcontr` ist in einem Package names `sdtalt` enthalten; dieses Package m√ºsste zuerst installiert werden.

Da wir aber lediglich den einen Datensatz ben√∂tigen, k√∂nnen Sie diesen auch downloaden, in den Ordner unseres RStudio Projekts speichern und dann laden.


:::{.callout-note}
üëâ [Daten f√ºr diese Sitzung herunterladen](../../downloadable_files/confcontr.csv)
:::


```{r}
#| message: false
#| warning: false
library(tidyverse)
confcontr <- read_csv("confcontr.csv")

# data(confcontr)

confcontr <- as_tibble(confcontr) |> 
  mutate(subno = as_factor(subno))
```

```{r}
confcontr
```

Die Variablen sind `subno` (Teilnehmende), `isold` (wurde das Gesicht schon gesehen, 1 = ja, 0 = nein), `sayold` (wurde das Gesicht schon gesehen, 1 = ja, 0 = nein).

Zuerst klassifizieren wir die Antworten als Hits, Misses, False Alarms oder Correct Rejections.

```{r}
sdt <- confcontr |> 
  mutate(type = case_when(
        isold==1 & sayold==1 ~ "Hit",
        isold==1 & sayold==0 ~ "Miss",
        isold==0 & sayold==0 ~ "CR",
        isold==0 & sayold==1 ~ "FA"))
```

Dann z√§hlen wir die Hits, Misses, False Alarms und Correct Rejections pro Teilnehmende.

```{r}
sdt_summary <- sdt |>
    group_by(subno) |>
    count(type) |> 
  pivot_wider(names_from = type, values_from = n) 
```

Die folgende Funktion dient dazu, Nullen oder Einsen zu ersetzen. Da relative H√§ufigkeiten zwischen 0 und 1 liegen, aber nicht genau 0 oder 1 sein k√∂nnen, m√ºssen wir diese Werte korrigieren: $0 < r < 1$.  Die Funktion `correct_zero_one` korrigiert die Werte, indem sie eine kleine Zahl hinzuf√ºgt oder subtrahiert.

```{r}
correct_zero_one <- function(rate, e = 0.001) {
    if (identical(rate, 0)) {
        rate = rate + e
    } else if (identical(rate, 1)) {
        rate = rate - e
    }
    rate
}
```

```{r}
sdt_summary
```


Wir berechnen die relative H√§ufigkeit der Hits und False Alarms (mit der Tabelle oben vergleichen).


```{r}
sdt_summary <- sdt_summary |>
    mutate(hit_rate = Hit/(Hit + Miss),
           fa_rate = FA/(FA + CR))
sdt_summary
```

Nun korrigeren wir die Werte, damit sie zwischen 0 und 1 liegen.

```{r}
sdt_summary <- sdt_summary |>
    mutate(across(c(hit_rate, fa_rate), correct_zero_one))
sdt_summary
```

Aus den relativen H√§ufigkeiten berechnen wir die Z-Scores der Hits und False Alarms mit der Quantilfunktion der Standardnormalverteilung, `qnorm()`.


```{r}
sdt_summary <- sdt_summary |> 
  mutate(zhr = qnorm(hit_rate),
           zfa = qnorm(fa_rate))
sdt_summary
```

Am Schluss berechnen wir  $d'$, $k$ und $c$ mit den Formeln. 

$$ k = -\phi^{-1}(p_{FA}) $$

$$ c = -\frac{1}{2} \left[\phi^{-1}(p_{H}) + \phi^{-1}(p_{FA})\right] $$

$$ d' = \phi^{-1}(p_{H}) - \phi^{-1}(p_{FA}) $$

```{r}
sdt_summary <- sdt_summary |> 
  mutate(dprime = zhr - zfa,
         k = -zfa,
         c = -0.5 * (zhr + zfa)) |>
    mutate(across(c(dprime, k, c), \(x) round(x, 2)))

sdt_summary
```



Bevor wir in der n√§chsten Sitzung weitermachen, schauen wir wir uns die gesch√§tzten Parameter $c$ und $d'$ noch an.


```{r}
sdt_summary |> 
  ggplot(aes(x = c, y = dprime)) +
      geom_hline(yintercept = 0, color = "blue", linetype = 2) +
      geom_vline(xintercept = 0, color = "blue", linetype = 2) +
      geom_point(size = 3) +
      labs(x = "c", y = "d'") +
      ggtitle("Bias vs. sensitivity") +
      theme_linedraw()
```

