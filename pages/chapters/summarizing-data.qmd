---
title: "Aggregierte Statistiken"
description: |
  Daten aus Verhaltensexperimenten zusammenfassen.
date: "2022-03-27"
author:
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Kognitive Psychologie, Wahrnehmung und Methodenlehre, Universit√§t Bern 
    affiliation-url: https://www.kog.psy.unibe.ch
    orcid: 0000-0002-2788-936X
license: CC BY
citation: true
bibliography: ../../bibliography.bib
format:
    html:
        toc: true
        code-link: true
execute: 
  cache: false
code-annotations: select
---

```{r}
#| include: false
# Set working directory of R
knitr::opts_knit$set(root.dir = "../../data/rdk_decision_experiment")
```

<!-- :::{.callout-note}
üëâ [R Code f√ºr dieses Kapitel downloaden](../../downloadable_files/summarizing-data.R)
::: -->



:::{.callout-tip collapse="false"}
## Lernziele

In der heutigen Sitzung lernen wir:

- Zusammenfassende Statistiken berechnen.
- In _within-subject_ Designs aggregierte Statistiken berechnen.
- Standardfehler berechnen, welche Messwiederholungen ber√ºcksichtigen.
:::

:::{.callout-tip}
## Wichtig

üëâ [Daten f√ºr diese Sitzung herunterladen](../../downloadable_files/rdkdata.csv)
:::


Wir haben in den vorherigen Kapiteln gesehen, wie wir Daten aus Verhaltensexperimenten in R einlesen und bearbeiten k√∂nnen. In diesem Kapitel werden wir uns mit der Frage besch√§ftigen, wie wir zusammenfassende Statistiken erstellen k√∂nnen, um diese grafisch darzustellen und zu interpretieren. Da wir uns in den Neurowissenschaften meist mit _within-subject_ Designs besch√§ftigen, werden wir uns in diesem Kapitel auf Messwiederholungsdaten konzentrieren.



# Daten aus dem RDK Experiment einlesen
Zum Schluss der letzten Sitzung haben wir f√ºr jede Versuchsperson pro Bedingung die `accuracy` berechnet, und grafisch dargestellt. Wir wiederholen diesen Schritt hier nochmals, um die Daten f√ºr die folgenden Analysen vorzubereiten.


Zuerst laden wir das `tidyverse` Package und lesen das gespeicherte `csv` File ein.

```{r}
#| message: false
#| warning: false
library(tidyverse)
data <- read_csv("data_clean/rdkdata.csv")
```


Im ersten Schritt konvertieren wir wieder alle Gruppierungsvariablen zu Faktoren. Ob eine Variable als `factor` definiert ist, wird als Attribut gespeichert. Attribute werden aber in einem `.csv.` File nicht mitgespeichert; deshalb m√ºssen wir diesen Schritt nach dem Einlesen jedesmal neu ausf√ºhren. 

```{r}
data <- data |>
  mutate(across(where(is.character), as_factor))
```


```{r}
glimpse(data)
```

Die ersten 20 Zeilen der Tabelle sehen wie folgt aus:


```{r}
data |>
  slice_head(n = 10)
```


# Individuelle und Aggregierte Kennzahlen

In neurowissenschaftlichen Fragestellungen interessieren wir uns sowohl f√ºr aggregierte Statistiken, als auch f√ºr individuelle Kennzahlen, d.h. f√ºr die Kennzahlen, die wir erhalten, wenn wir die Daten f√ºr jede Versuchsperson einzeln betrachten. Wir schauen uns dies am Beispiel der korrekten Antworten in der RDK Entscheidungsaufgabe an.

:::{.callout-important}
- √úberlegen Sie sich, in welchen F√§llen Sie aggregierte Statistiken ben√∂tigen, und in welchen F√§llen individuelle Kennzahlen.
:::



# Korrekte Entscheidungen



Wir schauen uns zuerst (wie im letzten Kapitel) die Anzahl korrekter Entscheidungen an. Wir k√∂nnen diese entweder f√ºr jede Person in jeder Bedingung berechnen, oder f√ºr jede Bedingung, aggregiert √ºber alle Personen.

## Individuell f√ºr jede Person in jeder Bedingung

```{r}
accuracy_individual <- data |>
    group_by(ID, condition) |>
    summarise(
        N = n(),
        ncorrect = sum(correct),
        accuracy = mean(correct)
    )
accuracy_individual
```



```{r}
accuracy_individual |> 
  ggplot(aes(x = condition, y = accuracy, fill = condition)) +
  geom_col() +
  geom_line(aes(group = ID), linewidth = 2) +
  geom_point(size = 4) +
  scale_fill_manual(values = c(invalid = "#9E0142",
                    neutral = "#C4C4B7",
                    valid = "#2EC762")) +
  labs(x = "Cue",
      y = "Proportion correct",
      title = "Accuracy per person/condition") +
  facet_wrap(~ID) +
  theme_linedraw(base_size = 14) +
  theme(legend.position = "none")
```


##  Pro Bedingung, √ºber alle Personen aggregiert


```{r}
accuracy_aggregated <- data |>
    group_by(condition) |>
    summarise(N = n(),
              ncorrect = sum(correct),
              accuracy = mean(correct))

accuracy_aggregated
```

```{r}
accuracy_aggregated |> 
  ggplot(aes(x = condition, y = accuracy, fill = condition)) +
  geom_col() +
  geom_line(aes(group = 1), linewidth = 2) +
  geom_point(size = 4) +
  scale_fill_manual(values = c(invalid = "#9E0142",
                    neutral = "#C4C4B7",
                    valid = "#2EC762")) +
  labs(x = "Cue",
      y = "Proportion correct",
      title = "Accuracy per condition") +
  theme_linedraw(base_size = 14) +
  theme(legend.position = "none")
```

:::{.callout-important}
## Hands-on
Wir beurteilen Sie die beiden obenstehenden Plots. Was f√§llt Ihnen auf? Sind die Mittelwerte aussagekr√§ftig?
:::

:::{.callout-tip collapse="true"}
## L√∂sung
Es fehlt eine Darstellung der Unsicherheit, die wir in der Sch√§tzung des Mittelwerts haben. 
:::



## Standardfehler

Wir wollen wir nicht mehr nur den Mittelwert betrachten, sondern auch die Standardabweichung und den Standardfehler. Letzteres ist eine Mass f√ºr die Unsicherheit, die wir in der Sch√§tzung des Mittelwerts haben. Leider gibt es keine Funktion in R, die uns den Standardfehler berechnet. Der Standardfehler ist definiert als die Standardabweichung geteilt durch die Wurzel aus der Anzahl der Datenpunkte:  $$SE = sd/ \sqrt{n}$$.


Wir k√∂nnen eine solche Funktion einfach selber definieren. `sd()` berechnet die Standardabweichung eines Vektors, und die Anzahl Datenpunkte ist die L√§nge des Vektors (`length()`), den wir als Argument √ºbergeben.

```{r}
se <- function(x) {
  sd(x) / sqrt(length(x))
}
```


## Pro Bedingung, √ºber alle Personen aggregiert

Eine M√∂glichkeit w√§re, die Anzahl korrekter Entscheidungen in jeder Bedingung insgesamt, d.h. √ºber alle Personen aggregiert, zu berechnen. Wir berechnen dabei den Standardfehler des Mittelwertes um ein Mass f√ºr die Unsicherheit zu enthalten, mit der wir die Mittelwerte sch√§tzen k√∂nnen.

```{r}
data |>
    group_by(condition) |>
            summarise(
                  n = n(),
                  ncorrect = sum(correct),
                  accuracy = mean(correct),
                  se = se(correct)
            )
```


:::{.callout-caution}
## Hands-on
- Was sagen uns diese Kennzahlen? 
- Welche Informationen gehen dabei verloren?
- √úberlegen Sie sich, was wir genau berechnet haben.
:::


## Ein Exkurs √ºber within-person Standardfehler 

:::{.callout-tip collapse="true"}

## Within-person Standardfehler berechnen

Folgender Code erstellt einen Dataframe mit 10 Personen, die jeweils zu zwei  Messzeitpunkten getestet werden. Es handelt sich also um ein within-subject Design.
```{r}
library(tidyverse)

dfw <- tribble(
 ~subject, ~pretest, ~posttest,
       1,   59.4,     64.5,
       2,   46.4,     52.4,
       3,   46.0,     49.7,
       4,   49.0,     48.7,
       5,   32.5,     37.4,
       6,   45.2,     49.5,
       7,   60.3,     59.9,
       8,   54.3,     54.1,
       9,   45.4,     49.6,
      10,   38.9,     48.5) |>
    mutate(subject = as_factor(subject))
```

Der Dataframe ist im `wide` Format -- um die Daten zu analysieren, ist das `long` Format besser geeignet. Wir konvertieren vom `wide` ins `long` Format mit der Funktion `pivot_longer()`.

```{r}
dfw
```

```{r}
dfl <- dfw |>
    pivot_longer(contains("test"),
                 names_to = "condition",
                 values_to = "value") |>
    mutate(condition = as_factor(condition))
```

```{r}
dfl
```


Was uns hier interessiert ist vor allem die "Verbesserung" jeder Person vom ersten zum zweiten Messzeitpunkt. Diese k√∂nnen wir grafisch darstellen.


```{r}
# Use a consistent y range
ymax <- max(dfl$value)
ymin <- min(dfl$value)
```

```{r}
# Plot the individuals
dfl |>
    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +
    geom_line() + geom_point(shape=21, fill="white") +
    ylim(ymin,ymax)
```

Wir stellen fest, dass fast jede Person zum zweiten Messzeitpunkt einen h√∂heren Wert als beim ersten aufweist. Gleichzeitig gibt es aber auch erhebliche Unterschiede zwischen den Personen in Bezug auf ihren Anfangswert. Diese interindividuellen Unterschiede sind aber hier nicht von Interesse. Wir k√∂nnen davon ausgehen, dass diese Unterschiede auf "stabile" Eigenschaften der Personen zur√ºckzuf√ºhren sind. Die Personen sind also eine Quelle der Variabilit√§t, die unsere Fragestellung "st√∂rt" - diese lautet: wie ist die √Ñnderung zwischen den beiden Zeitpunkten?


Wir k√∂nnen so tun, als ob der Messzeitpunkt eine __between__-subject Variable w√§re. In diesem Fall w√ºrden wir die Standardfehler wie folgt berechnen.
```{r}
dflsum_between_1 <- dfl |>
    group_by(condition) |>
    summarize(
        mean = mean(value),
        se = se(value)
    )

dflsum_between_1
```


Eine Alternative dazu bietet die Funktion `summarySE()` aus dem `Rmisc` Package.
```{r}
# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable
dflsum_between <- Rmisc::summarySE(data = dfl, 
                                   measurevar = "value", 
                                   groupvars = "condition", 
                                   na.rm = FALSE, 
                                   conf.interval = .95)
dflsum_between
```




Die Fehlerbalken im folgenden Plot ber√ºcksichtigen folgendermassen nicht die Tatsachen, dass ein grosser Anteil der Variabilit√§t auf "stabile" Personenunterschiede zur√ºckzuf√ºhren ist. In diesem Fall sind die "errorbars" sehr gross, und es sieht so aus, als ob es keinen feststellbaren Unterschied zwischen den Zeitpunkten gibt. Wir vermuten aber aufgrund der individuellen Grafiken, dass es sehr wohl einen Unterschied gibt.
  


```{r}
dflsum_between |>
    ggplot(aes(x=condition, y=value, group=1)) +
    geom_line() +
    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour="red") +
    geom_point(shape=21, size=3, fill="white") +
    ylim(ymin,ymax)
```



Wenn wir nur die Unterschiede zwischen den Personen ber√ºcksichtigen k√∂nnten, h√§tten wir in diesem Fall kleinere Standardfehler, da wir sozusagen die Personenvariabilit√§t subtrahieren k√∂nnen.


Im `Rmisc` Package gibt es eine solche Funktion: mit `summarySEwithin()` k√∂nnen wir korrekt Standardfehler in __within__-subject Designs berechnen.
```{r}
dflsum <- dfl |>
    Rmisc::summarySEwithin(measurevar = "value",
                               withinvars = "condition",
                               idvar = "subject",
                               na.rm = FALSE,
                               conf.interval = 0.95)
```


Die resultierenden Fehlerbalken sind nun kleiner.

```{r}
dflsum |>
    ggplot(aes(x = condition, y = value, group = 1)) +
    geom_line() +
    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +
    geom_point(shape = 21, size = 3, fill = "white") +
    ylim(40,60) +
    ggtitle("Correct within standard errors")
```



Wenn wir beide Varianten zusammen darstellen, wird der Unterschiedlich offentsichtlich. In dieser Grafik sind die `between` Standardfehler in rot eingezeichnet; die `within` Standardfehler sind in schwarz.
```{r}
dflsum_between |>
    ggplot(aes(x=condition, y=value, group=1)) +
    geom_line() +
    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour="red") +
    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour="black", data = dflsum) +
    geom_point(shape=21, size=3, fill="white") +
    ylim(ymin,ymax)
```





Was wir hier machen ist eigentlich einfach. Um die `within` Standardfehler zu berechnen, m√ºssen wir zuerst die personen-spezifische Mittelwerte von den Daten subtrahieren, und den Gesamtmittelwert (`grand mean`) addieren. Dies k√∂nnen wir entweder mit `mutate()`, oder mit der Funktion `normDataWithin()` machen.


__Mit `mutate()`__:
```{r}
df_norm <- dfl |>
    mutate(grand_mean = mean(value)) |>
    group_by(subject) |>
    mutate(person_mean = mean(value),
           value_normed = value - person_mean + grand_mean)

df_norm
```

__Mit `normDataWithin()`__:
```{r}
dfNorm_long <- Rmisc::normDataWithin(data=dfl, 
                                     idvar="subject",    
                                     measurevar="value")
dfNorm_long
```


Wenn wir nun die "normierten" Daten plotten, sind die Unterschiede zwischen den Personen "verschwunden", weil wir eben die Daten normiert haben.
```{r}
df_norm |> 
    ggplot(aes(x=condition, y=value_normed, colour=subject, group=subject)) +
    geom_line() + geom_point(shape=21, fill="white") +
    ylim(ymin, ymax)
```



Die Argumente der Funktion `summarySEwithin()` sind folgende:

- `measurevar`: die outcome` Variable
- `withinvars`: eine o(oder mehrere) within-subject Variablen
- `idvar`: die Gruppierungsvariable der within-subject Variablen (Versuchsperson)
- `na.rm`: sollen fehlende Werte ignoriert werden?  
- `conf.interval`: der gew√ºnschte Konfidenzintervall (default: 0.95)

Im Output erhalten wir die Mittelwerte der `outcome` Variablen f√ºr jede Stufe der within-Variable, sowie Standardabweichungen, Standardfehler und Konfidenzintervalle.

```{r}


```{r}
dflsum <- dfl |>
    Rmisc::summarySEwithin(measurevar = "value",
                               withinvars = "condition",
                               idvar = "subject",
                               na.rm = FALSE,
                               conf.interval = 0.95)
```


Zum Vergleich: die Berechnung der Standardfehler in `dflsum` ber√ºcksichtigt die Tatsache, dass Personen sich von Anfang an unterscheiden, und subtrahiert von jedem Datenpunkt den Mittelwert der Person. 

```{r}
```{r}
dflsum
```

Bei der Berechnung der Standardfehler in `dflsum_between` haben wir im Prinzip so getan, als seien die Messzeitpunkte unabh√§ngig voneinander. Wir haben also die Standardfehler in `dflsum_between` so berechnet, als ob wir die Daten in zwei unabh√§ngige Gruppen aufgeteilt h√§tten. 
 
```{r}
dflsum_between
```

<!-- end excursion -->
:::






## Accuracy mit within-person Standardfehler

Wir k√∂nnen nun dieses Prinzip auf unsere RDK daten anwenden. Die messwiederholte Variable ist nun nicht mehr der Messzeitunkt, sondern die `cue`-Bedingung, und die `outcome` Variable ist `accuracy`, also die Proportion korrekter Antworten.


```{r}
accuracy_individual |> 
  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +
    geom_line() + 
  geom_point(shape=21, fill="white")

```

Auch hier stellen wir fest, dass es scheinbar einen Trend gibt, dass die Proportion korrekter Antworten in der `valid` Bedingung hoch, und in der `invalid` Bedingung niedrig ist. In der `neutral` Bedingung liegt die `accuracy` dazwischen.


Ohne Ber√ºcksichtigung der Messwiederholungen erhalten wir folgende Standarfehler:

Von Hand berechnet:


```{r}
datasum <- data |>
   group_by(condition) |> 
   summarise(N = n(),
             accuracy = mean(correct),
             sd = sd(correct),
             se = se(correct))
datasum
```

Mit der Funktion `summarySE()`:

```{r}
datasum_2 <- data |>
    Rmisc::summarySE(measurevar = "correct",
                              groupvars = "condition",
                               na.rm = FALSE,
                               conf.interval = 0.95)
datasum_2
```

Wenn wir nun die `within` Standardfehler berechnen, erhalten wir folgende Ergebnisse:
```{r}
datasum_3 <- data |>
    Rmisc::summarySEwithin(measurevar = "correct",
                               withinvars = "condition",
                               idvar = "ID",
                               na.rm = FALSE,
                               conf.interval = 0.95)
datasum_3
```


```{r}
p_accuracy <- datasum_3 |>
    ggplot(aes(x = condition, y = correct, group = 1)) +
    geom_line() +
    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour="red") +
    geom_point(shape=21, size=3, fill="white")
p_accuracy
```




# Reaktionszeiten

Dasselbe k√∂nnen wir nun auch mit den mittleren Reaktionszeiten machen.


## Pro Versuchsperson

Wir fassen die Daten pro Person pro Block mit Mittelwert, Median und Standarabweichung zusammen. Wenn wir Daten anhand mehrerer statistischer Kennzahlen zusammenfassen m√∂chten, k√∂nnen wir dies entweder manuell machen, oder die Funktion `across()` verwenden.

Einfachere Version:

```{r}
#| message: false
by_subj <- data |> 
  drop_na(rt) |> 
  group_by(ID, condition) |>  
  dplyr::summarise(mean = mean(rt),
                   median = median(rt),
                   sd = sd(rt))
```

Komplizierte Version:

```{r}
#| message: false
funs <- list(mean = mean, median = median, sd = sd, se = se)

by_subj <- data %>%
  drop_na(rt) |> 
  group_by(ID, condition) %>% 
  dplyr::summarise(across(rt, funs, .names = "{.fn}"))
```

```{r}
by_subj 
```



```{r}
#| fig.height: 12
#| fig.width: 15

by_subj |> 
  ggplot(aes(x = condition, y = mean, fill = condition)) +
  geom_col() +
  geom_line(aes(group = ID), linewidth = 2) +
  geom_point(size = 8) +
  scale_fill_manual(
    values = c(invalid = "#9E0142",
    neutral = "#C4C4B7",
    valid = "#2EC762")
  ) +
  labs(
    x = "Cue",
    y = "Response time") +
  theme_linedraw(base_size = 28) +
  facet_wrap(~ID)
```


Wir k√∂nnen selbstverst√§ndlich auch die indivuellen mittleren Reaktionszeiten mit Standardfehler plotten:
```{r}
#| fig.height: 6
#| fig.width: 8
by_subj |> 
  ggplot(aes(condition, mean)) +
  geom_line(aes(group = 1), linetype = 3) +    
  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),
                width = 0.2, size=1, color="blue") +
  geom_point(size = 2) +
  facet_wrap(~ID, scales = "free_y")
```

## √úber Versuchsperson aggregiert
```{r}
rtsum <- data |>
  drop_na(rt) |> 
    Rmisc::summarySEwithin(measurevar = "rt",
                               withinvars = "condition",
                               idvar = "ID",
                               na.rm = FALSE,
                               conf.interval = 0.95)
rtsum
```

```{r}
p_rt <- rtsum |>
    ggplot(aes(x = condition, y = rt, group = 1)) +
    geom_line() +
    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour="red") +
    geom_point(shape=21, size=3, fill="white")
```

```{r}
#| fig.height: 6
#| fig.width: 8

p_rt
```


Wir haben oben die beiden Grafiken als Variablen `p_accuracy` und  `p_rt` gespeichert. Nun k√∂nnen wir diese Grafiken mit dem `patchwork` Package kombinieren.

<aside>
`patchwork` muss zuerst installiert werden: `install.packages("patchwork")`
</aside>

```{r}
library(patchwork)
```

```{r}
#| fig.height: 6
#| fig.width: 8

p_accuracy / p_rt
```
